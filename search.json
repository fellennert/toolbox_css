[
  {
    "objectID": "9_apis.html",
    "href": "9_apis.html",
    "title": "Chapter 9: APIs",
    "section": "",
    "text": "In the prior chapter you were shown how to make calls to web pages and get responses. In this chapter, we will cover making calls to APIs which (usually) give you content in a nice and structured manner."
  },
  {
    "objectID": "9_apis.html#application-programming-interfaces-apis",
    "href": "9_apis.html#application-programming-interfaces-apis",
    "title": "Chapter 9: APIs",
    "section": "Application Programming Interfaces (APIs)",
    "text": "Application Programming Interfaces (APIs)\n\n\n\n\n\n\n\n\n\nWhile web scraping (or screen scraping, as you extract the stuff that appears on your screen) is certainly fun, it should be seen as a last resort. More and more web platforms provide so-called Application Programming Interfaces (APIs).\n\n“An application programming interface (API) is a connection between computers or between computer programs.” (Wikipedia)\n\nThere are a bunch of different sorts of APIs, but the most common one is the REST API. REST stands for “REpresentational State Transfer” and describes a set of rules the API designers are supposed to obey when developing their particular interface. You can make different requests, such as GET content, POST a file to a server – PUT is similar, or request to DELETE a file. We will only focus on the GET part.\nAPIs offer you a structured way to communicate with the platform via your machine. In our use case, this means that you can get the data you want in a usually well-structured format and without all the “dirt” that you need to scrape off tediously (enough web scraping metaphors for today). With APIs, you can generally quite clearly define what you want and how you want it. In R, we achieve this by using the httr (Wickham 2020) package. Moreover, using APIs does not bear the risk of acquiring the information you are not supposed to access and you also do not need to worry about the server not being able to handle the load of your requests (usually, there are rate limits in place to address this particular issue). However, it’s not all fun and games with APIs: they might give you their data in a special format, both XML and JSON are common. The former is the one rvest uses as well, the latter can be tamed using jsonlite (Ooms, Temple Lang, and Hilaiel 2020) which is to be introduced as well. Moreover, you usually have to ask the platform for permission and perhaps pay to get it. Once you have received the keys you need, you can tell R to fill them automatically, similar to how your browser knows your Amazon password, etc.; usethis (Wickham et al. 2021) can help you with such tasks.\nThe best thing that can happen with APIs: some of them are so popular that people have already written specific R packages for working with them – an overview can be found on the ROpenSci website. One example of this was Twitter and the rtweet package (Kearney 2019).\n\nObtaining their data\nAPI requests are performed using URLs. Those start with the basic address of the API (e.g., https://api.nytimes.com), followed by the endpoint that you want to use (e.g., /lists). They also contain so-called headers which are provided as key-value pairs. Those headers can contain for instance authentication tokens or different search parameters. A request to the New York Times API to obtain articles for January 2019 would then look like this: https://api.nytimes.com/svc/archive/v1/2019/1.json?api-key=yourkey.\nAt most APIs, you will have to register first. As we will play with the New York Times API, do this here.\n\n\nMaking queries\nA basic query is performed using the GET() function. However, first, you need to define the call you want to make. The different keys and values they can take can be found in the API documentation. Of course, there is also a neater way to deal with the key problem. We will show it later.\n\nneeds(httr, jsonlite, tidyverse)\n#see overview here: https://developer.nytimes.com/docs/timeswire-product/1/overview\nkey &lt;- Sys.getenv(\"nyt_key\")\nkey &lt;- \"5bvQ82VImpOI3UGidss5zhkZOFZtXwpx\"\n\nnyt_headlines &lt;- modify_url(\n  url = \"https://api.nytimes.com/\",\n  path = \"svc/news/v3/content/nyt/business.json\",\n  query = list(`api-key` = key)\n  )\n\nresponse &lt;- GET(nyt_headlines)\n\nresponse\n\nResponse [https://api.nytimes.com/svc/news/v3/content/nyt/business.json?api-key=5bvQ82VImpOI3UGidss5zhkZOFZtXwpx]\n  Date: 2025-11-06 10:24\n  Status: 200\n  Content-Type: application/json; charset=utf-8\n  Size: 50.2 kB\n{\"status\":\"OK\",\"copyright\":\"Copyright (c) 2025 The New York Times Company. Al...\n\n\nWhen it comes to the NYT news API, there is the problem that the type of section is specified not in the query but in the endpoint path itself. Hence, if we were to scrape the different sections, we would have to change the path itself, e.g., through str_c() or httr::modify_url().\n\npaths &lt;- str_c(\"svc/news/v3/content/nyt/\", c(\"business\", \"world\"), \".json\")\n\nmap(paths, \n    \\(x) GET(modify_url(\n      url = \"https://api.nytimes.com/\",\n      path = x,\n      query = list(`api-key` = key))\n      )\n    )\n\n[[1]]\nResponse [https://api.nytimes.com/svc/news/v3/content/nyt/business.json?api-key=5bvQ82VImpOI3UGidss5zhkZOFZtXwpx]\n  Date: 2025-11-06 10:24\n  Status: 200\n  Content-Type: application/json; charset=utf-8\n  Size: 50.2 kB\n{\"status\":\"OK\",\"copyright\":\"Copyright (c) 2025 The New York Times Company. Al...\n\n[[2]]\nResponse [https://api.nytimes.com/svc/news/v3/content/nyt/world.json?api-key=5bvQ82VImpOI3UGidss5zhkZOFZtXwpx]\n  Date: 2025-11-06 10:24\n  Status: 200\n  Content-Type: application/json; charset=utf-8\n  Size: 53.5 kB\n{\"status\":\"OK\",\"copyright\":\"Copyright (c) 2025 The New York Times Company. Al...\n\n\nThe Status: code you want to see here is 200 which stands for success. If you want to put it inside a function, you might want to break the function once you get a non-successful query. http_error() or http_status() are your friends here.\n\nresponse |&gt; http_error() # can be used in if...else\n\n[1] FALSE\n\nresponse |&gt; http_status()\n\n$category\n[1] \"Success\"\n\n$reason\n[1] \"OK\"\n\n$message\n[1] \"Success: (200) OK\"\n\n\ncontent() will give you the content of the request.\n\nresponse |&gt; content() |&gt; str()\n\nWhat you see is also the content of the call – which is what we want. It is in a format that we cannot work with right away, though, it is in JSON.\n\n\nJSON\nThe following unordered list is stolen from this blog entry:\n\nThe data are in name/value pairs\nCommas separate data objects\nCurly brackets {} hold objects\nSquare brackets [] hold arrays\nEach data element is enclosed with quotes “” if it is a character, or without quotes if it is a numeric value\n\n\nrawToChar(response$content) |&gt; \n  str_sub(1, 250) |&gt; \n  writeLines() \n\n{\"status\":\"OK\",\"copyright\":\"Copyright (c) 2025 The New York Times Company. All Rights Reserved.\",\"num_results\":20,\"results\":[{\"slug_name\":\"06Biz-Musk-pay-incentives\",\"section\":\"Business\",\"subsection\":\"\",\"title\":\"Would Elon Musk Work Harder for $1 Tri\n\n\njsonlite helps us to bring this output into a data frame.\n\ntbl_nyt &lt;- response |&gt; \n  content(as = \"text\") |&gt;\n  jsonlite::fromJSON() \n\ntbl_nyt |&gt; str(max.level = 1)\n\nList of 4\n $ status     : chr \"OK\"\n $ copyright  : chr \"Copyright (c) 2025 The New York Times Company. All Rights Reserved.\"\n $ num_results: int 20\n $ results    :'data.frame':    20 obs. of  23 variables:\n\ntbl_nyt |&gt; pluck(4) |&gt; glimpse()\n\nRows: 20\nColumns: 23\n$ slug_name            &lt;chr&gt; \"06Biz-Musk-pay-incentives\", \"05biz-dimon-mamdani…\n$ section              &lt;chr&gt; \"Business\", \"Business\", \"Business\", \"Business\", \"…\n$ subsection           &lt;chr&gt; \"\", \"\", \"Media\", \"\", \"\", \"\", \"DealBook\", \"Media\",…\n$ title                &lt;chr&gt; \"Would Elon Musk Work Harder for $1 Trillion Than…\n$ abstract             &lt;chr&gt; \"Economists and psychologists say that compensati…\n$ uri                  &lt;chr&gt; \"nyt://article/7fce0f9b-0805-5ef6-8eda-99a0165083…\n$ url                  &lt;chr&gt; \"https://www.nytimes.com/2025/11/06/business/elon…\n$ byline               &lt;chr&gt; \"By Patricia Cohen\", \"By Lauren Hirsch\", \"By Mich…\n$ item_type            &lt;chr&gt; \"Article\", \"Article\", \"Article\", \"Article\", \"Arti…\n$ source               &lt;chr&gt; \"New York Times\", \"New York Times\", \"New York Tim…\n$ updated_date         &lt;chr&gt; \"2025-11-06T00:00:05-05:00\", \"2025-11-05T23:08:03…\n$ created_date         &lt;chr&gt; \"2025-11-06T00:00:06-05:00\", \"2025-11-05T20:44:43…\n$ published_date       &lt;chr&gt; \"2025-11-06T00:00:06-05:00\", \"2025-11-05T20:44:43…\n$ first_published_date &lt;chr&gt; \"2025-11-06T00:00:06-05:00\", \"2025-11-05T20:44:43…\n$ material_type_facet  &lt;chr&gt; \"News\", \"News\", \"News\", \"News\", \"News\", \"Video\", …\n$ kicker               &lt;chr&gt; \"news analysis\", \"\", \"\", \"\", \"\", \"\", \"DealBook Ne…\n$ subheadline          &lt;chr&gt; \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"…\n$ des_facet            &lt;list&gt; &lt;\"Executive Compensation\", \"Electric and Hybrid …\n$ org_facet            &lt;list&gt; \"Tesla Motors Inc\", \"JPMorgan Chase & Company\", …\n$ per_facet            &lt;list&gt; &lt;\"Musk, Elon\", \"Denholm, Robyn\"&gt;, &lt;\"Mamdani, Zoh…\n$ geo_facet            &lt;list&gt; &lt;&gt;, &lt;&gt;, &lt;&gt;, \"Paris (France)\", &lt;&gt;, &lt;&gt;, &lt;&gt;, &lt;&gt;, &lt;&gt;…\n$ related_urls         &lt;list&gt; [], [], [], [], [], [], [], [], [], [], [], [], …\n$ multimedia           &lt;list&gt; [&lt;data.frame[4 x 8]&gt;], [&lt;data.frame[4 x 8]&gt;], [&lt;…\n\n\n\n\nDealing with authentification\nWell, as we saw before, we would have to put our official NYT API key publicly visible in this script. This is bad practice and should be avoided, especially if you work on a joint project (where everybody uses their code) or if you put your scripts in public places (such as GitHub). The usethis package can help you here.\n\nneeds(usethis)\nusethis::edit_r_environ() # save key there\nkey &lt;- Sys.getenv(\"nyt_key\")\n\n\nExercise\n\nSearch for articles on the NYT API (find the proper parameters here) that deal with a certain topic (parameter “q”), set a certain begin and end date. Extract the results into a tibble.\n\nBonus: Provide the key by using the Sys.getenv function. So, if somebody wants to work with your code and their own key, all they need to make sure is that they have the API key stored in the environment with the same name.\n\n\nSolution. Click to expand!\n\n\nneeds(tidyverse, jsonlite, httr)\ntrump_nov_2016 &lt;- modify_url(\n  url = \"http://api.nytimes.com/\",\n  path = \"svc/search/v2/articlesearch.json\",\n  query = list(q = \"Trump\",\n               begin_date = \"20161101\",\n               end_date = \"20161110\",\n               `api-key` = Sys.getenv(\"nyt_key\"))\n) |&gt; \n  GET()\n\ntrump_nov_2016_tbl &lt;- trump_nov_2016 |&gt; \n  content(as = \"text\") |&gt;\n  fromJSON() |&gt; \n  pluck(3, 1)\n\ntrump_nov_2016_tbl[[3]][[1]]\n\n[1] \"article\""
  },
  {
    "objectID": "9_apis.html#further-links",
    "href": "9_apis.html#further-links",
    "title": "Chapter 9: APIs",
    "section": "Further links",
    "text": "Further links\n\nAPIs for social scientists: A collaborative review\nA “laymen’s guide” on web scraping (blog post)"
  },
  {
    "objectID": "6_stringr_regex.html",
    "href": "6_stringr_regex.html",
    "title": "Chapter 6: stringr and RegExes",
    "section": "",
    "text": "needs(tidyverse, rvest)\nWhen working with data, a significant number of variables will be in some sort of text format. When you want to manipulate these variables, an easy approach would be exporting the data to MS Excel and then just performing those manipulations by hand. This is very time-consuming, though, and, hence, we rather recommend the R way which scales well and works fast for data sets of varying sizes.\nQuick reminder: a string is an element of a character vector and can be created by simply wrapping some text in quotation marks:\nstring &lt;- \"Hi, how are you doing?\"\nvector_of_strings &lt;- c(\"Hi, how are you doing? not good\", \"I'm doing well, HBY?\", \"Me too, thanks for asking.\")\nNote that you can either wrap your text in double quotation marks and use single ones in the string and vice versa:\nsingle_ones &lt;- \"what's up\"\ndouble_ones &lt;- 'he said: \"I am fine\"'\nThe stringr package (Wickham 2019) contains a multitude of commands (49 in total) that can be used to achieve a couple of things, mainly manipulating character vectors, and finding and matching patterns. These goals can also be achieved with base R functions, but stringr’s advantage is its consistency. The makers of stringr describe it as\nEvery stringr function starts with str_ – which facilitates finding the proper command: just type str_ and RStudio’s auto-suggest function should take care of the rest (if it doesn’t pop up by itself, you can trigger it by hitting the tab key). Also, they take a vector of strings as their first argument, which facilitates using them in a |&gt;-pipeline and adding them to a mutate()-call.\nOne important component of stringr functions is regular expressions which will be introduced later as well."
  },
  {
    "objectID": "6_stringr_regex.html#basic-manipulations",
    "href": "6_stringr_regex.html#basic-manipulations",
    "title": "Chapter 6: stringr and RegExes",
    "section": "Basic manipulations",
    "text": "Basic manipulations\nIn the following, we will introduce you to several different operations that can be performed on strings.\n\nChanging the case of the words\nA basic operation is changing words’ cases.\n\nstr_to_lower(vector_of_strings)\n\n[1] \"hi, how are you doing? not good\" \"i'm doing well, hby?\"           \n[3] \"me too, thanks for asking.\"     \n\nstr_to_upper(vector_of_strings)\n\n[1] \"HI, HOW ARE YOU DOING? NOT GOOD\" \"I'M DOING WELL, HBY?\"           \n[3] \"ME TOO, THANKS FOR ASKING.\"     \n\nstr_to_title(vector_of_strings)\n\n[1] \"Hi, How Are You Doing? Not Good\" \"I'm Doing Well, Hby?\"           \n[3] \"Me Too, Thanks For Asking.\"     \n\nstr_to_sentence(vector_of_strings)\n\n[1] \"Hi, how are you doing? Not good\" \"I'm doing well, hby?\"           \n[3] \"Me too, thanks for asking.\"     \n\n\n\n\nDetermining a string’s length\nDetermining the string’s number of characters goes as follows:\n\nstr_length(vector_of_strings)\n\n[1] 31 20 26\n\n\n\n\nExtracting particular characters\nCharacters can be extracted (by position) using str_sub\n\nstr_sub(vector_of_strings, start = 1, end = 5) # extracting first to fifth character\n\n[1] \"Hi, h\" \"I'm d\" \"Me to\"\n\nstr_sub(vector_of_strings, start = -5, end = -1) # extracting fifth-to-last to last character\n\n[1] \" good\" \" HBY?\" \"king.\"\n\n\nYou can also use str_sub() to replace strings. E.g., to replace the last character by a full stop, you can do the following:\n\nstr_sub(vector_of_strings, start = -1) &lt;- \".\"\nvector_of_strings\n\n[1] \"Hi, how are you doing? not goo.\" \"I'm doing well, HBY.\"           \n[3] \"Me too, thanks for asking.\"     \n\n\nHowever, in everyday use, you would probably go with str_replace() and regular expressions.\n\n\nConcatenating strings\nSimilar to how c() puts together different elements (or vectors of length 1) and other vectors into a single vector, str_c() can be used to concatenate several strings into a single string. This can, for instance, be used to write some birthday invitations.\n\nnames &lt;- c(\"Inger\", \"Peter\", \"Kalle\", \"Ingrid\")\n\nstr_c(\"Hi\", names, \"I hope you're doing well. As per this letter, I invite you to my birthday party.\")\n\n[1] \"HiIngerI hope you're doing well. As per this letter, I invite you to my birthday party.\" \n[2] \"HiPeterI hope you're doing well. As per this letter, I invite you to my birthday party.\" \n[3] \"HiKalleI hope you're doing well. As per this letter, I invite you to my birthday party.\" \n[4] \"HiIngridI hope you're doing well. As per this letter, I invite you to my birthday party.\"\n\n\nWell, this looks kind of ugly, as there are no spaces, and commas are lacking as well. You can fix that by determining a separator using the sep argument.\n\nstr_c(\"Hi\", names, \"I hope you're doing well. As per this letter, I invite you to my birthday party.\", sep = \", \")\n\n[1] \"Hi, Inger, I hope you're doing well. As per this letter, I invite you to my birthday party.\" \n[2] \"Hi, Peter, I hope you're doing well. As per this letter, I invite you to my birthday party.\" \n[3] \"Hi, Kalle, I hope you're doing well. As per this letter, I invite you to my birthday party.\" \n[4] \"Hi, Ingrid, I hope you're doing well. As per this letter, I invite you to my birthday party.\"\n\n\nYou could also collapse the strings contained in a vector together into one single string using the collapse argument.\n\nstr_c(names, collapse = \", \")\n\n[1] \"Inger, Peter, Kalle, Ingrid\"\n\n\n\n\nRepetition\nRepeating (or duplicating) strings is performed using str_dup(). The function takes two arguments: the string to be duplicated and the number of times.\n\nstr_dup(\"felix\", 2)\n\n[1] \"felixfelix\"\n\nstr_dup(\"felix\", 1:3)\n\n[1] \"felix\"           \"felixfelix\"      \"felixfelixfelix\"\n\nstr_dup(names, 2)\n\n[1] \"IngerInger\"   \"PeterPeter\"   \"KalleKalle\"   \"IngridIngrid\"\n\nstr_dup(names, 1:4)\n\n[1] \"Inger\"                    \"PeterPeter\"              \n[3] \"KalleKalleKalle\"          \"IngridIngridIngridIngrid\"\n\n\n\n\nRemoving unnecessary whitespaces\nOften text contains unnecessary whitespaces.\n\nunnecessary_whitespaces &lt;- c(\"    on the left\", \"on the right    \", \"    on both sides   \", \"   literally    everywhere  \")\n\nRemoving the ones at the beginning or the end of a string can be accomplished using str_trim().\n\nstr_trim(unnecessary_whitespaces, side = \"left\")\n\n[1] \"on the left\"               \"on the right    \"         \n[3] \"on both sides   \"          \"literally    everywhere  \"\n\nstr_trim(unnecessary_whitespaces, side = \"right\")\n\n[1] \"    on the left\"            \"on the right\"              \n[3] \"    on both sides\"          \"   literally    everywhere\"\n\nstr_trim(unnecessary_whitespaces, side = \"both\") # the default option\n\n[1] \"on the left\"             \"on the right\"           \n[3] \"on both sides\"           \"literally    everywhere\"\n\n\nstr_trim() could not fix the last string though, where unnecessary whitespaces were also present in between words. Here, str_squish is more appropriate. It removes leading or trailing whitespaces as well as duplicated ones in between words.\n\nstr_squish(unnecessary_whitespaces)\n\n[1] \"on the left\"          \"on the right\"         \"on both sides\"       \n[4] \"literally everywhere\"\n\n\n\n\nFurther links\n\nR for Data Science chapter on stringr\nThe stringr cheatsheet.\n\n\n\nExercises\n\nRun the following code that downloads movies from IMDb. Clean up the column “year” in the resulting film data set. Think about how you could do it with str_sub(). Could you also use it for the dot in the “rank” column?\n\n\nneeds(rvest, tidyverse)\nimdb_top250 &lt;- read_html(\"https://www.imdb.com/chart/top/?ref_=nv_mv_250\")\n\nmovies &lt;- tibble(\n  title_raw = imdb_top250 |&gt; \n    html_elements(\".cli-title .ipc-title__text\") |&gt; \n    html_text2(),\n  year_raw = imdb_top250 |&gt; \n    html_elements(\".cli-title-metadata\") |&gt; \n    html_text2()\n) |&gt; \n  separate(title_raw, sep = \" \", into = c(\"rank\", \"title\"), extra = \"merge\")\n\n\n\nSolution. Click to expand!\n\n\nmovies_clean &lt;- movies |&gt; \n  mutate(year = str_sub(year_raw, start = 1, end = 4) |&gt; as.double(),\n         rank = str_sub(rank, start = -4, end = -2) |&gt; as.integer())\n\n\n\nConvert the following sentence to different cases:\n\n\nsentence &lt;- \"The quick brown fox jumps over the lazy dog.\"\n\n\n\nSolution. Click to expand!\n\n\nstr_to_lower(sentence)\nstr_to_sentence(sentence)\nstr_to_title(sentence)\nstr_to_upper(sentence)\n\n\n\nWhat’s the length of the following string?\n\n\ntext &lt;- \"I enjoy studying Sociology at Leipzig University.\"\n\n\n\nSolution. Click to expand!\n\n\nstr_length(text)\n\n\n\nUsing the following vectors, create a full sentence:\n\n\nstart &lt;- \"I am a large language model and I am\"\nattributes &lt;- c(\"powerful.\", \"dumb.\", \"worse at coding than your instructor.\")\nend &lt;- \"Haha, do you really think I asked ChatGPT to give you these exercises?\"\nps &lt;- \"(Of course I did, I am lazy AF.)\"\n\n\n\nSolution. Click to expand!\n\n\nstr_c(start, attributes, end, ps, sep = \" \")"
  },
  {
    "objectID": "6_stringr_regex.html#regular-expressions",
    "href": "6_stringr_regex.html#regular-expressions",
    "title": "Chapter 6: stringr and RegExes",
    "section": "Regular expressions",
    "text": "Regular expressions\n\n\n\n\n\n\n\n\n\nUp to now, you have been introduced to the more basic functions of the stringr package. Those are useful, for sure, yet limited. However, to make use of the full potential of stringr, you will first have to acquaint yourself with regular expressions (also often abbreviated as “RegEx” with plural “RegExes”).\nThose regular expressions are patterns that can be used to describe certain strings. Exemplary use cases of RegExes are the identification of phone numbers, email addresses, or whether a password you choose on a web page consists of enough characters, an uppercase character, and at least one special character. Hence, if you want to replace certain words with another one, you can write the proper RegEx and it will identify the strings you want to replace, and the stringr functions (i.e., str_replace()) will take care of the rest.\nBefore you dive into RegExes, beware that they are quite complicated at the beginning1. Yet, mastering them is very rewarding and will pay off in the future.\n\nLiteral characters\nThe most basic RegEx patterns consist of literal characters only. str_view() tells you which parts of a string match a pattern is present in the element.\n\nfive_largest_cities &lt;- c(\"Stockholm\", \"Göteborg\", \"Malmö\", \"Uppsala\", \"Västerås\")\n\nNote that RegExes are case-sensitive.\n\nstr_view(five_largest_cities, \"stockholm\")\n\n\nstr_view(five_largest_cities, \"Stockholm\")\n\n[1] │ &lt;Stockholm&gt;\n\n\nThey also match parts of words:\n\nstr_view(five_largest_cities, \"borg\", match = NA)\n\n[1] │ Stockholm\n[2] │ Göte&lt;borg&gt;\n[3] │ Malmö\n[4] │ Uppsala\n[5] │ Västerås\n\n\nMoreover, they are “greedy,” they only match the first occurrence. str_locate() locates the pattern. Look at Stockholm – we should have two matches here:\n\nstr_locate(five_largest_cities, \"o\") |&gt; \n  as_tibble() |&gt; \n  mutate(city = five_largest_cities)\n\n# A tibble: 5 × 3\n  start   end city     \n  &lt;int&gt; &lt;int&gt; &lt;chr&gt;    \n1     3     3 Stockholm\n2     6     6 Göteborg \n3    NA    NA Malmö    \n4    NA    NA Uppsala  \n5    NA    NA Västerås \n\n\nThis can be addressed in the stringr package by using str_._all() functions.\n\nstr_locate_all(five_largest_cities, \"o\") |&gt; \n  map2(five_largest_cities, \\(x, y) x |&gt; \n         as_tibble() |&gt; \n         mutate(city = y)) |&gt; \n  bind_rows()\n\n# A tibble: 3 × 3\n  start   end city     \n  &lt;int&gt; &lt;int&gt; &lt;chr&gt;    \n1     3     3 Stockholm\n2     7     7 Stockholm\n3     6     6 Göteborg \n\n\nIf you want to match multiple literal characters (or words, for that sake), you can connect them using the | meta character (more on meta characters later).\n\nstr_view(five_largest_cities, \"Stockholm|Göteborg\", match = NA)\n\n[1] │ &lt;Stockholm&gt;\n[2] │ &lt;Göteborg&gt;\n[3] │ Malmö\n[4] │ Uppsala\n[5] │ Västerås\n\n\nEvery letter of the English alphabet (or number/or combination of those) can serve as a literal character. Those literal characters match themselves. This is, however, not the case with the other sort of characters, so-called meta characters.\n\n\nMetacharacters\nWhen using RegExes, the following characters are considered meta characters and have a special meaning:\n. \\ | ( ) { } [ ] ^ $ - * + ?\n\nThe wildcard\nDid you notice how we used the dot to refer to the entirety of the str_._all() functions? This is basically what the . meta-character does: it matches every character except for a new line. The first call extracts all function names from the stringr package, the second one shows the matches (i.e., the elements of the vector where it can find the pattern).\n\nstringr_functions &lt;- ls(\"package:stringr\")\n\nstr_detect(stringr_functions, \"str_._all\")\n\n [1] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE\n[13] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE\n[25] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE\n[37] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE\n[49] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE\n[61] FALSE FALSE\n\n\nWell, as you can see, there are none. This is because the . can only replace one character. We need some sort of multiplier to find them. The ones available are:\n\n? – zero or one\n* – zero or more\n+ – one or more\n{n} – exactly n\n{n,} – n or more\n{n,m} – between n and m\n\nIn our case, the appropriate one is +:\n\nstringr_functions[str_detect(stringr_functions, \"str_.+_all\")]\n\n[1] \"str_extract_all\" \"str_locate_all\"  \"str_match_all\"   \"str_remove_all\" \n[5] \"str_replace_all\" \"str_sub_all\"     \"str_view_all\"   \n\n\nBy default, these multipliers are greedy and want to match the longest string possible:\n\nstr_view(\"coco\", \"co*\")\n\n[1] │ &lt;co&gt;&lt;co&gt;\n\n\nYou can change this behavior – make it “lazy” – by adding “?”:\n\nstr_view(\"coco\", \"co*?\")\n\n[1] │ &lt;c&gt;o&lt;c&gt;o\n\n\nHere, it only matches the first c, the shortest match possible.\nHowever, what if you want to match the character “.”? This problem might come up when searching for clock time. A naive RegEx might look like this:\n\nvectors_with_time &lt;- c(\"13500\", \"13M00\", \"13.00\")\n\nstr_view(vectors_with_time, \"13.00\")\n\n[1] │ &lt;13500&gt;\n[2] │ &lt;13M00&gt;\n[3] │ &lt;13.00&gt;\n\n\nYet, it matches everything. We need some sort of literal dot. Here, the metacharacter \\ comes in handy. By putting \\ in front of the meta character that we want to be treated as literal – the . in our case – the . loses its special meaning and is interpreted as a literal character. This procedure is referred to as “escaping.” Hence, \\ is also referred to as the “escape character.” Note that, in R, you will need to escape \\ as well, and therefore in code escaping will look like this: \\\\..\n\nstr_view(vectors_with_time, \"13\\\\.00\", match = NA)\n\n[1] │ 13500\n[2] │ 13M00\n[3] │ &lt;13.00&gt;\n\n\nBecause this gets tedious quickly in case you have multiple characters that need escaping, you can also use so called raw strings. Another alternative would be using a “raw string” (r\"()\"). This matches anything inside the raw string – but you will still need to escape some special characters, but only with one backslash:\n\nimdb_url &lt;- \"imdb.com/chart/top/?ref_=nv_mv_250\"\n\n#imdb_url |&gt; str_view(r\"(?ref_=)\") #throws an error\nimdb_url |&gt; str_view(r\"(\\?ref_=)\")\n\n[1] │ imdb.com/chart/top/&lt;?ref_=&gt;nv_mv_250\n\n\nIf you need to match “()”, you can also change the opening parentheses: r\"[]\" or r\"{}\". If this is not enough, you can also write r\"---(rawstring)---\" (you can insert as many dashes as you want to match your string).\n\nparentheses &lt;- \"a * (b + c)\"\n\nparentheses |&gt; str_view(r\"(b \\+)\")\n\n[1] │ a * (&lt;b +&gt; c)\n\nparentheses |&gt; str_view(r\"[\\(b \\+]\")\n\n[1] │ a * &lt;(b +&gt; c)\n\nsquare_brackets &lt;- \"[a/c + (a*c)]\"\n\nsquare_brackets |&gt; str_view(r\"{\\[a/c}\")\n\n[1] │ &lt;[a/c&gt; + (a*c)]\n\n\n\n\n\nSets of characters\nYou can also define sets of multiple characters using the [ ] meta characters. This can be used to define multiple possible characters that can appear in the same place.\n\nsp_ce &lt;- c(\"spice\", \"space\")\n\nstr_view(sp_ce, \"sp[ia]ce\", match = NA)\n\n[1] │ &lt;spice&gt;\n[2] │ &lt;space&gt;\n\n\nYou can also define certain ranges of characters using the - metacharacter:\n\nsp_ce &lt;- c(\"spice\", \"space\")\n\nstr_view(sp_ce, \"sp[a-g]ce\", match = NA)\n\n[1] │ spice\n[2] │ &lt;space&gt;\n\n\nSame holds for numbers:\n\namerican_phone_number &lt;- \"(555) 555-1234\"\n\nstr_view(american_phone_number, \"\\\\([0-9]{3}\\\\) [0-9]{3}-[0-9]{4}\", match = NA)\n\n[1] │ &lt;(555) 555-1234&gt;\n\nstr_view(american_phone_number, \"\\\\([:digit:]{3}\\\\) [0-9]{3}-[0-9]{4}\", match = NA)\n\n[1] │ &lt;(555) 555-1234&gt;\n\n\nThere are also predefined sets of characters, for instance, digits or letters, which are called character classes. You can find them on the stringr cheatsheet.\nFurthermore, you can put almost every meta character inside the square brackets without escaping them. This does not apply to the caret (^) in the first position, the dash -, the closing square bracket ], and the backslash \\.\n\nstr_view(vector_of_strings, \"[.]\", match = NA)\n\n[1] │ Hi, how are you doing? not goo&lt;.&gt;\n[2] │ I'm doing well, HBY&lt;.&gt;\n[3] │ Me too, thanks for asking&lt;.&gt;\n\n\n\nNegating sets of characters\nSometimes you will also want to exclude certain sets of characters or words. To achieve this, you can use the ^ meta character at the beginning of the range or set you are defining.\n\nstr_view(sp_ce, \"sp[^i]ce\", match = NA)\n\n[1] │ spice\n[2] │ &lt;space&gt;\n\n\n\n\n\nGrouping\nA related set is using groups of characters. When you do this, those matches take precedence over others. For an example, what would “ab*” match? Any number of “ab”s, or rather 1 “a” and any number of “b”s after?\n\nstr_view(\"abbbaaababbbbabab\", \"ab*\")\n\n[1] │ &lt;abbb&gt;&lt;a&gt;&lt;a&gt;&lt;ab&gt;&lt;abbbb&gt;&lt;ab&gt;&lt;ab&gt;\n\n\nThe answer is: both. But what if wanted to only match literal “ab”s but any number of them and as long as possible? We can use groupings for this.\n::: {.cell}\nstr_view(\"abbbaaababbbbabab\", \"(ab)*\")\n::: {.cell-output .cell-output-stdout}\n[1] │ &lt;ab&gt;&lt;&gt;b&lt;&gt;b&lt;&gt;a&lt;&gt;a&lt;abab&gt;&lt;&gt;b&lt;&gt;b&lt;&gt;b&lt;abab&gt;&lt;&gt;\n::: :::\nNow the “ab”s are seen as an entity and can be multiplied.\nAnother useful feature is that you can use groupings and refer to the groups using \\1 (for the first group), \\2 (for the second group), etc.\nThis is for instance handy in an str_replace():\n\nwordsalad &lt;- c(\"second The word is out of place\", \"third word The is out of place\")\n\nstr_replace(wordsalad, \"(\\\\w+) (\\\\w+) (\\\\w+)\", \"\\\\2 \\\\1 \\\\3\") |&gt; \n  str_view()\n\n[1] │ The second word is out of place\n[2] │ word third The is out of place\n\nstr_replace(wordsalad, \"(\\\\w+) (\\\\w+) (\\\\w+)\", \"\\\\3 \\\\1 \\\\2\") |&gt; \n  str_view()\n\n[1] │ word second The is out of place\n[2] │ The third word is out of place\n\n\n\n\nAnchors\nThere is also a way to define whether you want the pattern to be present in the beginning ^ or at the end $ of a string. sentences are a couple of (i.e., 720) predefined example sentences. If we were now interested in the number of sentences that begin with a “the,” we could write the following RegEx:\n\nshortened_sentences &lt;- sentences[1:10]\n\nstr_view(shortened_sentences, regex(\"^the\", ignore_case = TRUE), match = NA)\n\n [1] │ &lt;The&gt; birch canoe slid on the smooth planks.\n [2] │ Glue the sheet to the dark blue background.\n [3] │ It's easy to tell the depth of a well.\n [4] │ &lt;The&gt;se days a chicken leg is a rare dish.\n [5] │ Rice is often served in round bowls.\n [6] │ &lt;The&gt; juice of lemons makes fine punch.\n [7] │ &lt;The&gt; box was thrown beside the parked truck.\n [8] │ &lt;The&gt; hogs were fed chopped corn and garbage.\n [9] │ Four hours of steady work faced us.\n[10] │ A large size in stockings is hard to sell.\n\n\nIf we wanted to know how many start with a “The” and end with a full stop, we could do this one:\n\nstr_view(shortened_sentences, \"^The.+\\\\.$\")\n\n[1] │ &lt;The birch canoe slid on the smooth planks.&gt;\n[4] │ &lt;These days a chicken leg is a rare dish.&gt;\n[6] │ &lt;The juice of lemons makes fine punch.&gt;\n[7] │ &lt;The box was thrown beside the parked truck.&gt;\n[8] │ &lt;The hogs were fed chopped corn and garbage.&gt;\n\n\n\nBoundaries\nNote that right now, the RegEx also matches the sentence which starts with a “These.” To address this, we need to tell the machine that it should only accept a “The” if there starts a new word thereafter. In RegEx syntax, this is done using so-called boundaries. Those are defined as \\b as a word boundary and \\B as no word boundary. (Note that you will need an additional escape character as you will have to escape the escape character itself.)\nIn my example, we would include the former if we were to search for sentences that begin with a single “The” and the latter if we were to search for sentences that begin with a word that starts with a “The” but are not “The” – such as “These.”\n\nstr_view(shortened_sentences, \"^The\\\\b.+\\\\.$\")\n\n[1] │ &lt;The birch canoe slid on the smooth planks.&gt;\n[6] │ &lt;The juice of lemons makes fine punch.&gt;\n[7] │ &lt;The box was thrown beside the parked truck.&gt;\n[8] │ &lt;The hogs were fed chopped corn and garbage.&gt;\n\nstr_view(shortened_sentences, \"^The\\\\B.+\\\\.$\")\n\n[4] │ &lt;These days a chicken leg is a rare dish.&gt;\n\n\n\n\nLookarounds\nA final common task is to extract certain words or values based on what comes before or after them. Look at the following example:\n\nheights &lt;- c(\"1m30cm\", \"2m01cm\", \"3m10cm\")\n\nHere, to identify the height in meters, the first task is to identify all the numbers that are followed by an “m”. The RegEx syntax for this looks like this: A(?=pattern) with A being the entity that is supposed to be found (hence, in this case, [0-9]+).\n\nstr_view(heights, \"[0-9]+(?=m)\")\n\n[1] │ &lt;1&gt;m30cm\n[2] │ &lt;2&gt;m01cm\n[3] │ &lt;3&gt;m10cm\n\n\nThe second step now is to identify the centimeters. This could of course be achieved using the same RegEx and replacing m with cm. However, we can also harness a so-called negative look ahead A(?!pattern), a so-called look behind (?&lt;=pattern)A. The negative counterpart, the negative look behind (?&lt;!pattern)A could be used to extract the meters.\nThe negative lookahead returns everything that is not followed by the defined pattern. The look behind returns everything that is preceded by the pattern, the negative look behind returns everything that is not preceded by the pattern.\nIn the following, we demonstrate how you could extract the centimeters using negative look ahead and look behind.\n\nstr_view(heights, \"[0-9]+(?!m)\") # negative look ahead\n\n[1] │ 1m&lt;30&gt;cm\n[2] │ 2m&lt;01&gt;cm\n[3] │ 3m&lt;10&gt;cm\n\n\n\nstr_view(heights, \"(?&lt;=m)[0-9]+\") # look behind\n\n[1] │ 1m&lt;30&gt;cm\n[2] │ 2m&lt;01&gt;cm\n[3] │ 3m&lt;10&gt;cm\n\n\n\n\n\nFurther links\n\nR for Data Science chapter on RegExes\nA YouTube video on RegExes by Johns Hopkins professor Roger Peng.\nAnd a chapter by Roger Peng.\nA website for practicing RegExes.\n\n\n\nExercises\n\nWrite a RegEx for Swedish mobile numbers. Test it with str_detect(\"+46 71-738 25 33\", \"[insert your RegEx here]\").\n\n\n\nSolution. Click to expand!\n\n\nstr_detect(\"+46 71-738 25 33\", \"\\\\+46 [0-9]{2}\\\\-[0-9]{3} [0-9]{2} [0-9]{2}\")\n\n\n\nGiven the vector c(\"apple\", \"banana\", \"cherry\", \"date\", \"elderberry\"), use a regular expression to identify fruits that contain the letter “a” exactly three times.\n\n\n\nSolution. Click to expand!\n\n\nfruits &lt;- c(\"apple\", \"banana\", \"cherry\", \"date\", \"elderberry\")\nstr_detect(fruits, \"^([^a]*a){3}[^a]*$\")\n\n# alternatively\nstr_count(fruits, \"a\") == 3\n\n\n\nGiven the sentence vector c(\"The cat sat on the mat.\", \"Mat is what it sat on.\", \"On the mat, it sat.\"), write a regular expression to identify sentences that start with “The” and end with “mat.”.\n\n\n\nSolution. Click to expand!\n\n\ncats &lt;- c(\"The cat sat on the mat.\", \"Mat is what it sat on.\", \"On the mat, it sat.\")\nstr_detect(cats, \"^The.*mat.$\")\n\n\n\nExtract all email addresses from the following vector: c(\"john.doe@example.com\", \"alice_smith@company.net\", \"r.user@domain.org\", \"I am @ the office RN\", \"facebook.com\").\n\n\n\nSolution. Click to expand!\n\n\naddresses &lt;- c(\"john.doe@example.com\", \"alice_smith@company.net\", \"r.user@domain.org\", \"I am @ the office RN\", \"facebook.com\")\n\nstr_detect(addresses, \"[a-z.\\\\_]+\\\\@[a-z]+\\\\.[a-z]+\")\n\n\n\nCheck a vector of passwords for strength. A strong password should have at least 8 characters, include an uppercase and a lowercase letter, a number, and a special character (e.g., !@#$%^&*).\n\n\n\nSolution. Click to expand!\n\n\npassword &lt;- c(\"Hi!123456\")\n\nif (str_detect(password, \"[A-Z]{1,}\") &\n    str_detect(password, \"[a-z]{1,}\") &\n    str_detect(password, \"[0-9]{1,}\") &\n    str_detect(password, \"[\\\\!\\\\@\\\\#\\\\$\\\\%\\\\^\\\\&\\\\*]{1,}\") &\n    str_length(password) &gt; 7){\n  \"strong password\"\n}else{\n  \"weak password\"\n}\n\n\n\nFrom “The theme of this theater is therapeutic.”, extract all words that start with “the” but are not followed by “me”.\n\n\n\nSolution. Click to expand!\n\n\nsentence &lt;- \"The theme of this theater is therapeutic.\" |&gt; str_to_lower()\nstr_extract_all(sentence, \"\\\\bthe(?!me)\\\\w*\\\\b\")"
  },
  {
    "objectID": "6_stringr_regex.html#more-advanced-string-manipulation",
    "href": "6_stringr_regex.html#more-advanced-string-manipulation",
    "title": "Chapter 6: stringr and RegExes",
    "section": "More advanced string manipulation",
    "text": "More advanced string manipulation\nNow that you have learned about RegExes, you can unleash the full power of stringr.\n\n\n\n\n\n\n\n\n\nThe basic syntax of a stringr function looks as follows: str_.*(string, regex(\"\")). Some stringr functions also have the suffix _all which implies that they operate not only on the first match (“greedy”) but on every match.\nTo demonstrate the different functions, we will again rely on the subset of example sentences.\n\nDetect matches\nstr_detect can be used to determine whether a certain pattern is present in the string.\n\nstr_detect(shortened_sentences, \"The\\\\b\")\n\n [1]  TRUE FALSE FALSE FALSE FALSE  TRUE  TRUE  TRUE FALSE FALSE\n\n\nThis also works very well in a dplyr::filter() call. Finding all action movies in the IMDB data set can be solved like this:\n\nimdb_raw &lt;- read_csv(\"https://www.dropbox.com/s/81o3zzdkw737vt0/imdb2006-2016.csv?dl=1\")\n\nRows: 1000 Columns: 12\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (5): Title, Genre, Description, Director, Actors\ndbl (7): Rank, Year, Runtime (Minutes), Rating, Votes, Revenue (Millions), M...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nimdb_raw |&gt; \n  filter(str_detect(Genre, \"Adventure\"))\n\n# A tibble: 259 × 12\n    Rank Title       Genre Description Director Actors  Year `Runtime (Minutes)`\n   &lt;dbl&gt; &lt;chr&gt;       &lt;chr&gt; &lt;chr&gt;       &lt;chr&gt;    &lt;chr&gt;  &lt;dbl&gt;               &lt;dbl&gt;\n 1     1 Guardians … Acti… A group of… James G… Chris…  2014                 121\n 2     2 Prometheus  Adve… Following … Ridley … Noomi…  2012                 124\n 3     5 Suicide Sq… Acti… A secret g… David A… Will …  2016                 123\n 4     6 The Great … Acti… European m… Yimou Z… Matt …  2016                 103\n 5     9 The Lost C… Acti… A true-lif… James G… Charl…  2016                 141\n 6    10 Passengers  Adve… A spacecra… Morten … Jenni…  2016                 116\n 7    11 Fantastic … Adve… The advent… David Y… Eddie…  2016                 133\n 8    13 Rogue One   Acti… The Rebel … Gareth … Felic…  2016                 133\n 9    14 Moana       Anim… In Ancient… Ron Cle… Auli'…  2016                 107\n10    16 The Secret… Anim… The quiet … Chris R… Louis…  2016                  87\n# ℹ 249 more rows\n# ℹ 4 more variables: Rating &lt;dbl&gt;, Votes &lt;dbl&gt;, `Revenue (Millions)` &lt;dbl&gt;,\n#   Metascore &lt;dbl&gt;\n\n\nIf you want to know whether there are multiple matches present in each string, you can use str_count. Here, it might be advisable to set the ignore_case option to TRUE:\n\nstr_count(shortened_sentences, regex(\"the\\\\b\", ignore_case = TRUE))\n\n [1] 2 2 1 0 0 1 2 1 0 0\n\n\nIf you want to locate the match in the string, use str_locate. This returns a matrix, which is a vector of multiple dimensions.\n\nstr_locate(shortened_sentences, regex(\"The\\\\b\", ignore_case = TRUE))\n\n      start end\n [1,]     1   3\n [2,]     6   8\n [3,]    19  21\n [4,]    NA  NA\n [5,]    NA  NA\n [6,]     1   3\n [7,]     1   3\n [8,]     1   3\n [9,]    NA  NA\n[10,]    NA  NA\n\n\nMoreover, this is a good example for the greediness of stringr functions. Hence, it is advisable to use str_locate_all which returns a list with one matrix for each element of the original vector:\n\nstr_locate_all(shortened_sentences, regex(\"The\\\\b\", ignore_case = TRUE)) |&gt; pluck(1)\n\n     start end\n[1,]     1   3\n[2,]    25  27\n\n\n\n\nMutating strings\nMutating strings usually implies the replacement of certain elements (e.g., words) with other elements (or removing them, which is a special case of replacing them with nothing). In stringr this is performed using str_replace(string, pattern, replacement) and str_replace_all(string, pattern, replacement).\nIf we wanted, for instance, to replace the first occurrence of “m” letters with “meters,” we would go about this the following way:\n\nstr_replace(heights, \"m\", \"meters\")\n\n[1] \"1meters30cm\" \"2meters01cm\" \"3meters10cm\"\n\n\nNote that str_replace_all would have lead to the following outcome:\n\nstr_replace_all(heights, \"m\", \"meters\")\n\n[1] \"1meters30cmeters\" \"2meters01cmeters\" \"3meters10cmeters\"\n\n\nHowever, we also want to replace the “cm” with “centimeters,” hence, we can harness another feature of str_replace_all(), providing multiple replacements:\n\nstr_replace_all(heights, c(\"cm\" = \"centimeters\", \"m\" = \"meters\"))\n\n[1] \"1meters30centimeterseters\" \"2meters01centimeterseters\"\n[3] \"3meters10centimeterseters\"\n\n\nWhat becomes obvious is that a “simple” RegEx containing just literal characters more often than not does not suffice. It will be your task to fix this. And while on it, you can also address the meter/meters problem – a “1” needs meter instead of meters. Another feature is that the replacements are performed in order. You can harness this for solving the problem.\n\n\nExtracting text\nstr_extract(_all)() can be used to extract matching strings. In the mtcars data set, the first word describes the car brand. Here, we harness another RegEx, the \\\\w which stands for any word character. Its opponent is \\\\W for any non-word character.\n\nmtcars |&gt; \n  rownames_to_column(var = \"car_model\") |&gt; \n  transmute(manufacturer = str_extract(car_model, \"^\\\\w+\\\\b\")) |&gt; \n  head(6)\n\n  manufacturer\n1        Mazda\n2        Mazda\n3       Datsun\n4       Hornet\n5       Hornet\n6      Valiant\n\n\n\n\nSplit vectors\nAnother use case here would have been to split it into two columns: manufacturer and model. One approach would be to use str_split(). This function splits the string at every occurrence of the predefined pattern. In this example, we use a word boundary as the pattern:\n\nmanufacturer_model &lt;- rownames(mtcars)\nstr_split(manufacturer_model, \"\\\\b\") |&gt; \n  head()\n\n[[1]]\n[1] \"\"      \"Mazda\" \" \"     \"RX4\"   \"\"     \n\n[[2]]\n[1] \"\"      \"Mazda\" \" \"     \"RX4\"   \" \"     \"Wag\"   \"\"     \n\n[[3]]\n[1] \"\"       \"Datsun\" \" \"      \"710\"    \"\"      \n\n[[4]]\n[1] \"\"       \"Hornet\" \" \"      \"4\"      \" \"      \"Drive\"  \"\"      \n\n[[5]]\n[1] \"\"           \"Hornet\"     \" \"          \"Sportabout\" \"\"          \n\n[[6]]\n[1] \"\"        \"Valiant\" \"\"       \n\n\nThis outputs a list containing the different singular words/special characters. This doesn’t make sense in this case. Here, however, the structure of the string is always roughly the same: “\\[manufacturer\\]\\[ \\]\\[model description\\]”. Moreover, the manufacturer is only one word. Hence, the task can be fixed by splitting the string after the first word, which should indicate the manufacturer. This can be accomplished using str_split_fixed(). Fixed means that the number of splits is predefined. This returns a matrix that can easily become a tibble.\n\nstr_split_fixed(manufacturer_model, \"(?&lt;=\\\\w)\\\\b\", n = 2) |&gt; \n  as_tibble() |&gt; \n  rename(manufacturer = V1,\n         model = V2) |&gt; \n  mutate(model = str_squish(model))\n\nWarning: The `x` argument of `as_tibble.matrix()` must have unique column names if\n`.name_repair` is omitted as of tibble 2.0.0.\nℹ Using compatibility `.name_repair`.\n\n\n# A tibble: 32 × 2\n   manufacturer model       \n   &lt;chr&gt;        &lt;chr&gt;       \n 1 Mazda        \"RX4\"       \n 2 Mazda        \"RX4 Wag\"   \n 3 Datsun       \"710\"       \n 4 Hornet       \"4 Drive\"   \n 5 Hornet       \"Sportabout\"\n 6 Valiant      \"\"          \n 7 Duster       \"360\"       \n 8 Merc         \"240D\"      \n 9 Merc         \"230\"       \n10 Merc         \"280\"       \n# ℹ 22 more rows\n\n\n\n\nFurther links\nLook at the “Further links” provided above.\n\n\nExercises\n\nRun the following code that downloads movies from IMDb. Create a tibble with the two columns “rank” and “title” by extracting the respective part of the raw title.\n\n\nneeds(rvest, tidyverse)\nimdb_top250 &lt;- read_html(\"https://www.imdb.com/chart/top/?ref_=nv_mv_250\")\n\nraw_title &lt;- imdb_top250 |&gt; \n    html_elements(\".cli-title .ipc-title__text\") |&gt; \n    html_text2()\n\n\n\nSolution. Click to expand!\n\n\ntibble(\n  rank = raw_title |&gt; str_extract(\"^[0-9]{1,3}\") |&gt; as.integer(),\n  title = raw_title |&gt; str_remove(\"^[0-9]{1,3}\\\\. \")\n)\n\n\n\nReplace m and cm appropriately in the vector of heights.\n\n\nheights &lt;- c(\"1m30cm\", \"2m01cm\", \"3m10cm\")\n\n\n\nSolution. Click to expand!\n\n\nstr_replace_all(heights, c(\"(?&lt;=[2-9]{1})m\" = \"meters\", \n                           \"(?&lt;=[0-9]{2})m\" = \"meters\", \n                           \"(?&lt;=1)m\" = \"meter\", \n                           \"(?&lt;=01)cm$\" = \"centimeter\", \n                           \"cm$\" = \"centimeters\"))\n\n\n\nRun the following code and clean up the resulting table.\n\n\nneeds(rvest, janitor, lubridate, tidyverse)\n\nsenator_table_raw &lt;- read_html(\"https://en.wikipedia.org/wiki/List_of_current_United_States_senators\") |&gt; \n  html_elements(css = \"#senators\") |&gt; \n  html_table() |&gt; \n  pluck(1) |&gt; \n  clean_names() |&gt; \n  select(state, senator, party = party_2, born, occupations = occupation_s, assumed_office)\n\n\nRemove the footnotes in the “party” column.\n\n\n\nSolution. Click to expand!\n\n\nsenator_table_party_cleaned &lt;- senator_table_raw |&gt; \n  mutate(party = str_remove_all(party, \"\\\\[.\\\\]|\\\\(.+\\\\)\"))\n\n\n\nBring their date of birth (“born”) in proper shape.\n\n\n\nSolution. Click to expand!\n\n\nsenator_table_born_party_cleaned &lt;- senator_table_party_cleaned |&gt; \n  mutate(born = str_extract(born, \"19[0-9]{2}\\\\-[01][0-9]\\\\-[0-3][0-9]\") |&gt; ymd())\n\n\n\nBonus: fix their “occupation” by separating the single jobs (combine look-ahead and -behind for that.)\n\n\n\nSolution. Click to expand!\n\n\nsenator_table_cleaned &lt;- senator_table_born_party_cleaned |&gt; \n  mutate(occupation_clean = str_replace_all(occupations, c(\"(?&lt;=[a-z])(?=[A-Z])\" = \"; \", \"CEO\" = \"CEO \")) |&gt; \n           str_squish())"
  },
  {
    "objectID": "6_stringr_regex.html#footnotes",
    "href": "6_stringr_regex.html#footnotes",
    "title": "Chapter 6: stringr and RegExes",
    "section": "Footnotes",
    "text": "Footnotes\n\n\ncomment from Felix: “honestly, I was quite overwhelmed when I encountered them first”↩︎"
  },
  {
    "objectID": "lectures-week_3.html",
    "href": "lectures-week_3.html",
    "title": "Week 3: Regexes & Crawling the web",
    "section": "",
    "text": "This lecture answers the following questions:"
  },
  {
    "objectID": "lectures-week_3.html#slides",
    "href": "lectures-week_3.html#slides",
    "title": "Week 3: Regexes & Crawling the web",
    "section": "Slides",
    "text": "Slides\nPlease click here to download the slides for Tuesday, October 28, 2025. Caveat: the original slides contain recordings of my screen demonstrating web scraping. These could not be included due to storage constraints.\nPlease click here to download the slides for Thursday, October 30, 2025.\n\n\n\nAlternatively, read them here (probably not the best if you’re visiting this page on a mobile device):\n\nTuesday, Oct. 28, 2025\n\n\n\n\n\nThursday, Oct. 30, 2025"
  },
  {
    "objectID": "4_python.html",
    "href": "4_python.html",
    "title": "Chapter 4: Introduction to Python for R Users",
    "section": "",
    "text": "This tutorial introduces Python programming with a focus on comparisons to R. If you’re familiar with R, you’ll find many concepts translate directly, though the syntax differs. Python is a general-purpose programming language that’s become increasingly popular in data science, offering powerful libraries for data manipulation, visualization, and machine learning.\n\n\nPython can be run in various environments:\n\nRStudio/Positron (see this blog post: Using Python in RStudio)\nJupyter notebooks (similar to RMarkdown/Quarto)\nVSCode with Python extensions\n\nFor this tutorial, we’ll use Python code chunks in Quarto, which can execute Python code just like they execute R code.\n\n# This is a comment in Python (like # in R)\nprint(\"Hello from Python!\")\n\nHello from Python!"
  },
  {
    "objectID": "4_python.html#introduction",
    "href": "4_python.html#introduction",
    "title": "Chapter 4: Introduction to Python for R Users",
    "section": "",
    "text": "This tutorial introduces Python programming with a focus on comparisons to R. If you’re familiar with R, you’ll find many concepts translate directly, though the syntax differs. Python is a general-purpose programming language that’s become increasingly popular in data science, offering powerful libraries for data manipulation, visualization, and machine learning.\n\n\nPython can be run in various environments:\n\nRStudio/Positron (see this blog post: Using Python in RStudio)\nJupyter notebooks (similar to RMarkdown/Quarto)\nVSCode with Python extensions\n\nFor this tutorial, we’ll use Python code chunks in Quarto, which can execute Python code just like they execute R code.\n\n# This is a comment in Python (like # in R)\nprint(\"Hello from Python!\")\n\nHello from Python!"
  },
  {
    "objectID": "4_python.html#python-environments",
    "href": "4_python.html#python-environments",
    "title": "Chapter 4: Introduction to Python for R Users",
    "section": "Python Environments",
    "text": "Python Environments\n\nWhat Are Environments?\nOne of the biggest differences between Python and R is how they handle packages and dependencies. In R, when you install a package with install.packages(), it typically goes into a central library that all your R projects share. Python takes a different approach with virtual environments.\nA Python environment is an isolated directory that contains:\n\nA specific Python version\nInstalled packages and their specific versions\nDependencies for those packages\n\nImagine you have Project A that needs version 1.0 of a package, and Project B needs version 2.0 of the same package. In R, you’d typically have one version installed. In Python, you create separate environments for each project.\n\n\nCommon Environment Tools\nWe will use conda for all things environment management in this tutorial. Other options include: - venv (built-in Python tool) - virtualenv (third-party tool)\nconda is more powerful and manages both Python versions and packages. It’s popular in data science.\n\n# Create environment with specific Python version\nconda create -n toolbox_env python=3.9\n\n# Activate\nconda activate toolbox_env\n\n# Install packages\nconda install pandas numpy matplotlib selenium openpyxl\n\n# Deactivate\nconda deactivate\n\nOr do it the reticulate way in Quarto:\n\nreticulate::conda_create(\"toolbox_env\", packages = \"python=3.9\")\nreticulate::conda_install(\"toolbox_env\", packages = c(\"pandas\", \"numpy\", \"matplotlib\", \"selenium\", \"openpyxl\"))\nreticulate::use_condaenv(\"toolbox_env\", required = TRUE)\n\n\n\nWhy Environments Matter for This Tutorial\nIf you’re working through this tutorial:\n\nUsing Jupyter/Quarto: These typically run in their own environment. Your code chunks will execute in whatever environment is active.\nInstalling packages: When we eventually use packages like NumPy, selenium, or Pandas, you’ll want to install them in an environment:\n\n\nconda install pandas numpy matplotlib selenium\n\n\nChecking your environment: You can see what’s installed with:\n\n\nconda list            # for conda\n\n\n\nQuick Setup Recommendation\nIf you have not created your environment using reticulate yet, I recommend doing it manually in the console.\n\n# Create a dedicated environment\nconda create -n toolbox_env python=3.9 pandas numpy matplotlib jupyter\n\n# Activate it\nconda activate toolbox_env\n\n# When working on exercises, make sure this environment is active!\n\n\n\n\n\n\n\nCompared to R\n\n\n\nThink of it this way: In R, you might use RStudio Projects to organize your work. In Python, you use Projects plus environments to isolate not just files, but also package versions.\n\n\n\n\nChecking Your Current Environment\n\nimport sys\n\n# Where is Python running from?\nprint(f\"Python executable: {sys.executable}\")\n\n# What version?\nprint(f\"Python version: {sys.version}\")\n\nIf you’re using conda, you can also check in your terminal:\n\nconda info --envs  # List all environments"
  },
  {
    "objectID": "4_python.html#data-types",
    "href": "4_python.html#data-types",
    "title": "Chapter 4: Introduction to Python for R Users",
    "section": "Data Types",
    "text": "Data Types\nPython has several fundamental data types. Unlike R, where everything is a vector by default, Python distinguishes between individual values (scalars) and collections. You will also use an assignment operator = instead of &lt;-.\n\nNumbers\nPython has two main numeric types: integers (int) and floating-point numbers (float).\n\n# Integer\nx = 42\nprint(type(x))  # Check the type\n\n&lt;class 'int'&gt;\n\nprint(x)\n\n42\n\n# Float\ny = 3.14159\nprint(type(y))\n\n&lt;class 'float'&gt;\n\nprint(y)\n\n3.14159\n\n\n\n\n\n\n\n\nCompared to R\n\n\n\nIn R, you’d use class() instead of type(). R doesn’t strictly distinguish between integers and doubles unless you explicitly create an integer with 42L.\n\n\n\n\nStrings\nStrings represent text data. Python treats single quotes ' and double quotes \" identically (unlike R where they’re essentially the same but double quotes are conventional).\n\n# Strings in Python\ngreeting = \"Hello\"\nname = 'World'\n\n# String concatenation uses +\nmessage = greeting + \" \" + name + \"!\"\nprint(message)\n\nHello World!\n\n# Or use f-strings (formatted string literals) -- Python 3.6+\nmessage_formatted = f\"{greeting} {name}!\"\nprint(message_formatted)\n\nHello World!\n\n\n\n\n\n\n\n\nCompared to R\n\n\n\nIn R, you’d use paste() or paste0() for concatenation, or str_c() from the tidyverse. Python’s f-strings are similar to glue::glue() in R.\n\n\n\n\nBooleans\nBoolean values are True and False (note the capitalization - this matters in Python!).\n\n# Booleans in Python\nis_python_fun = True\nis_this_hard = False\n\nprint(is_python_fun)\n\nTrue\n\nprint(type(is_python_fun))\n\n&lt;class 'bool'&gt;\n\n\n\n\n\n\n\n\nCompared to R\n\n\n\nR uses TRUE and FALSE (all caps), while Python uses True and False (capitalized). Python is case-sensitive, so true would throw an error.\n\n\n\n\nNone\nPython’s equivalent of R’s NULL or NA is None.\n\n# None represents absence of value\nnothing = None\nprint(nothing)\n\nNone\n\nprint(type(nothing))\n\n&lt;class 'NoneType'&gt;"
  },
  {
    "objectID": "4_python.html#collections-lists-tuples-and-dictionaries",
    "href": "4_python.html#collections-lists-tuples-and-dictionaries",
    "title": "Chapter 4: Introduction to Python for R Users",
    "section": "Collections: Lists, Tuples, and Dictionaries",
    "text": "Collections: Lists, Tuples, and Dictionaries\nPython has several built-in collection types. These are roughly analogous to R’s vectors and lists, but with important differences.\n\nLists\nPython lists are ordered, mutable (changeable) collections. They’re similar to R’s lists, not R’s atomic vectors.\n\n# Creating a list\nnumbers = [1, 2, 3, 4, 5]\nmixed_list = [1, \"two\", 3.0, True]  # Can contain different types\n\nprint(numbers)\n\n[1, 2, 3, 4, 5]\n\nprint(mixed_list)\n\n[1, 'two', 3.0, True]\n\n\nIndexing: Python uses 0-based indexing (the first element is at position 0), unlike R’s 1-based indexing.\n\n# Accessing elements\nfruits = [\"apple\", \"banana\", \"cherry\", \"date\"]\n\nprint(fruits[0])      # First element (R would use fruits[1])\n\napple\n\nprint(fruits[-2])     # Last element (negative indexing from end)\n\ncherry\n\nprint(fruits[1:3])    # Slicing: elements 1 and 2 (end index is exclusive)\n\n['banana', 'cherry']\n\n\n\n\n\n\n\n\nCompared to R\n\n\n\nR’s c(1, 2, 3, 4, 5) creates an atomic vector. Python’s [1, 2, 3, 4, 5] is more like R’s list(1, 2, 3, 4, 5), though it can be used for numeric operations when converted to a NumPy array.\n\n\nSome common list operations:\n\n# List operations\nnumbers = [1, 2, 3]\n\n# Append (like R's c() or append())\nnumbers.append(4)\nprint(numbers)\n\n[1, 2, 3, 4]\n\n# Extend with another list\nnumbers.extend([5, 6])\nprint(numbers)\n\n[1, 2, 3, 4, 5, 6]\n\n# Length\nprint(len(numbers))  # R's length()\n\n6\n\n\n\n\nTuples\nTuples are like lists but immutable (can’t be changed after creation). They use parentheses () instead of square brackets.\n\n# Creating a tuple\ncoordinates = (10, 20)\nprint(coordinates)\n\n(10, 20)\n\nprint(type(coordinates))\n\n&lt;class 'tuple'&gt;\n\n# Accessing works the same as lists\nprint(coordinates[0])\n\n10\n\n\n# But you can't modify them\n#coordinates[0] = 15  # This would raise an error!\n\n\n\n\n\n\n\nCompared to R\n\n\n\nR doesn’t have a direct equivalent to tuples, though you could think of them as named lists that are “frozen.”\n\n\n\n\nDictionaries\nDictionaries store key-value pairs. They’re similar to R’s named lists or named vectors.\n\n# Creating a dictionary\nperson = {\n    \"name\": \"Alice\",\n    \"age\": 30,\n    \"city\": \"Leipzig\"\n}\n\nprint(person)\n\n{'name': 'Alice', 'age': 30, 'city': 'Leipzig'}\n\n# Accessing values by key\nprint(person[\"name\"])\n\nAlice\n\nprint(person[\"age\"])\n\n30\n\n# Adding new key-value pairs\nperson[\"occupation\"] = \"Data Scientist\"\nprint(person)\n\n{'name': 'Alice', 'age': 30, 'city': 'Leipzig', 'occupation': 'Data Scientist'}\n\n\n\n\n\n\n\n\nCompared to R\n\n\n\nThis is similar to:\n\nperson &lt;- list(\n  name = \"Alice\",\n  age = 30,\n  city = \"Leipzig\"\n)\nperson$name  # or person[[\"name\"]]"
  },
  {
    "objectID": "4_python.html#simple-operations",
    "href": "4_python.html#simple-operations",
    "title": "Chapter 4: Introduction to Python for R Users",
    "section": "Simple Operations",
    "text": "Simple Operations\n\nArithmetic Operations\nPython supports standard arithmetic operators, similar to R.\n\n# Basic arithmetic\na = 11\nb = 3\n\na + b       # Addition\n\n14\n\na - b       # Subtraction\n\n8\n\na * b       # Multiplication\n\n33\n\na / b       # Division (always returns float)\n\n3.6666666666666665\n\na // b      # Floor division (integer division - R uses %/%)\n\n3\n\na % b       # Modulus (remainder)\n\n2\n\na ** b      # Exponentiation (R uses a^b or a**b in newer versions)\n\n1331\n\n\n\n\n\n\n\n\nCompared to R\n\n\n\nMost operators are the same.\nKey differences:\n\n/ always returns float in Python 3 (R returns integer if both are integers)\n// for integer division (R: %/%)\n** for exponentiation (R traditionally uses ^, though ** now works)\n\n\n\n\n\nComparison Operations\n\n# Comparison operators\nx = 5\ny = 10\n\nx == y #Equal\n\nFalse\n\nx != y # Not equal\n\nTrue\n\nx &gt; y  # Greater than\n\nFalse\n\nx &lt;= y # Less than or equal to\n\nTrue\n\n\n\n\n\n\n\n\nCompared to R\n\n\n\nSame operators, but Python uses != for “not equal” (R can use != or &lt;&gt;).\n\n\n\n\nLogical Operations\nPython uses words instead of symbols for logical operations.\n\n# Logical operators\na = True\nb = False\n\na and b # R equ: a & b\n\nFalse\n\na or b # R equ: a | b\n\nTrue\n\nnot a # R equ: !a\n\nFalse\n\n\n\n\n\n\n\n\nCompared to R\n\n\n\n\nPython: and, or, not\nR: &, |, ! (for element-wise); &&, || (for scalar)"
  },
  {
    "objectID": "4_python.html#flow-control-with-if-elif-else",
    "href": "4_python.html#flow-control-with-if-elif-else",
    "title": "Chapter 4: Introduction to Python for R Users",
    "section": "Flow Control with if, elif, else",
    "text": "Flow Control with if, elif, else\nSometimes you want your code to only run in specific cases. Python uses if statements for conditional execution.\n\n# Basic if statement\nx = 3\n\nif x &lt;= 5:\n    print(\"x is smaller than or equal to 5\")\n\nx is smaller than or equal to 5\n\n\nAdd an else block for an alternative action:\n\nx = 10\n\nif x &lt;= 5:\n    print(\"x is smaller than or equal to 5\")\nelse:\n    print(\"x is greater than 5\")\n\nx is greater than 5\n\n\n\nelif - Multiple Conditions\nWhen you need to check multiple conditions sequentially, use elif (short for “else if”). Python will check each condition in order and execute the first block where the condition is True.\n\nscore = 75\n\nif score &gt;= 90:\n    print(\"Grade: A\")\nelif score &gt;= 80:\n    print(\"Grade: B\")\nelif score &gt;= 70:\n    print(\"Grade: C\")\nelif score &gt;= 60:\n    print(\"Grade: D\")\nelse:\n    print(\"Grade: F\")\n\nGrade: C\n\n\nYou can have as many elif statements as you need. Python checks them from top to bottom and stops at the first True condition. Note that the final else is optional but highly recommended as a catch-all.\n\ntemperature = 25\n\nif temperature &lt; 0:\n    print(\"Freezing!\")\nelif temperature &lt; 10:\n    print(\"Cold\")\nelif temperature &lt; 20:\n    print(\"Cool\")\nelif temperature &lt; 30:\n    print(\"Warm\")\nelse:\n    print(\"Hot!\")\n\nWarm\n\n\n\n\n\n\n\n\nCompared to R\n\n\n\nComparison to R: R uses else if (two words) instead of elif:\n\ntemperature = 25\nif (temperature &lt; 0) {\n  print(\"Freezing\")\n} else if (temperature &gt;= 10) {\n  print(\"Cold\")\n} else if (temperature &lt; 20) {\n  print(\"Cool\")\n} else if (temperature &lt; 30) {\n  print(\"Warm\")\n} else {\n  print(\"Hot!\")\n}\n\n[1] \"Cold\"\n\n\n\n\nImportant: The condition must evaluate to a single boolean value (True or False)."
  },
  {
    "objectID": "4_python.html#functions",
    "href": "4_python.html#functions",
    "title": "Chapter 4: Introduction to Python for R Users",
    "section": "Functions",
    "text": "Functions\nFunctions allow you to package code into reusable blocks. Just like in R, functions are essential for writing clean, maintainable code that follows the DRY (Don’t Repeat Yourself) principle.\n\nDefining Functions\nThe basic syntax for defining a function in Python:\n\ndef function_name(parameter1, parameter2):\n    \"\"\"This is a docstring - describes what the function does.\"\"\"\n    # Function body\n    result = parameter1 + parameter2\n    return result\n\n# Call the function\nanswer = function_name(5, 3)\nanswer\n\n8\n\n\n\n\n\n\n\n\nCompared to R\n\n\n\n\nfunction_name &lt;- function(parameter1, parameter2) {\n  result &lt;- parameter1 + parameter2\n  return(result)\n}\n\n\n\n\n\nA Simple Example\n\ndef greet(name):\n    \"\"\"Greet someone by name.\"\"\"\n    return f\"Hello, {name}!\"\n\ngreet(\"Alice\")\n\n'Hello, Alice!'\n\ngreet(\"Bob\")\n\n'Hello, Bob!'\n\n\n### Hint: Python coders tend to use \"\" around real text/natural language and '' around symbol-like expressions (e.g., column names -- see below)\n\n\n\nDefault Arguments\nYou can provide default values for parameters, just like in R.\n\ndef greet_with_title(name, title = \"Dr.\"):\n    \"\"\"Greet someone with their title.\"\"\"\n    return f\"Hello, {title} {name}!\"\n\ngreet_with_title(\"Smith\")                    # Uses default title\n\n'Hello, Dr. Smith!'\n\ngreet_with_title(\"Smith\", \"Prof.\")           # Overrides default\n\n'Hello, Prof. Smith!'\n\ngreet_with_title(\"Smith\", title = \"Mr.\")       # Named argument (more explicit)\n\n'Hello, Mr. Smith!'\n\n\n\n\n\n\n\n\nCompared to R\n\n\n\n\nrgreet_with_title &lt;- function(name, title = \"Dr.\") {\n  paste0(\"Hello, \", title, \" \", name, \"!\")\n}\n\n\n\n\n\nreturn\nPer the official style guide it is idiomatic to be consistent with return statements:\n\nBe consistent in return statements. Either all return statements in a function should return an expression, or none of them should. If any return statement returns an expression, any return statements where no value is returned should explicitly state this as return None, and an explicit return statement should be present at the end of the function (if reachable)\n\n\n\n\n\n\n\nCompared to R\n\n\n\nThe object created in the last call will automatically be returned. return(object) shall be avoided unless you need an early return.\n\n\n\n\nMultiple Return Values\nPython can return multiple values as a tuple (similar to R’s lists).\n\ndef calculate_stats(numbers):\n    \"\"\"Calculate mean and standard deviation.\"\"\"\n    n = len(numbers)\n    mean = sum(numbers) / n\n    \n    # Calculate standard deviation\n    squared_diff = [(x - mean) ** 2 for x in numbers] # this is a list comprehension, an abbreviated for loop\n    variance = sum(squared_diff) / n\n    std_dev = variance ** 0.5\n    \n    return mean, std_dev  # Returns a tuple\n\ndata = [2, 4, 4, 4, 5, 5, 7, 9]\n\nmean_value, std_value = calculate_stats(data) # make sure to define both objects, or unpack the tuple later\nmean_value\n\n5.0\n\nstd_value\n\n2.0\n\n#this is the same as:\nresults = calculate_stats(data)\nmean_value = results[0]\nstd_value = results[1]\nmean_value\n\n5.0\n\nstd_value\n\n2.0\n\n\n\n\n\n\n\n\nCompared to R\n\n\n\nComparison to R: R typically returns a list or vector:\n\nrcalculate_stats &lt;- function(numbers) {\n  list(mean = mean(numbers), sd = sd(numbers))\n}\n\n\n\n\n\nDocstrings\nPython uses triple-quoted strings (“““…”““) right after the function definition to document what the function does. This is similar to roxygen2 comments in R.\n\ndef convert_temperature(celsius):\n    \"\"\"\n    Convert temperature from Celsius to Fahrenheit.\n    \n    Parameters:\n    -----------\n    celsius : float\n        Temperature in Celsius\n        \n    Returns:\n    --------\n    float\n        Temperature in Fahrenheit\n    \"\"\"\n    fahrenheit = (celsius * 9/5) + 32\n    return fahrenheit\n\nconvert_temperature(0)\n\n32.0\n\nconvert_temperature(100)\n\n212.0\n\n\n#'You can access the docstring with `help()` in an interactive session (e.g., Jupyter):\n#help(convert_temperature)\n\n\n\nLambda Functions (Anonymous Functions)\nPython has lambda functions for short, one-line functions. These are similar to R’s anonymous functions function(x) x + 1 or the shorthand \\(x) x + 1 in purrr.\n\n# Regular function\ndef add_ten(x):\n    return x + 10\n\n# Lambda function (anonymous)\nadd_ten_lambda = lambda x: x + 10\n\nadd_ten(5)\n\n15\n\nadd_ten_lambda(5)\n\n15\n\n\nLambda functions are especially useful when you need a simple function as an argument:\n\n# Sort a list of tuples by the second element\npairs = [(1, 'one'), (3, 'three'), (2, 'two')]\nsorted_pairs = sorted(pairs, key=lambda x: x[1])\nsorted_pairs\n\n[(1, 'one'), (3, 'three'), (2, 'two')]\n\n\n\n\n\n\n\n\nCompared to R\n\n\n\nR equivalent\n\nadd_ten &lt;- function(x) x + 10\n# or in purrr\nadd_ten &lt;- \\(x) x + 10\n\n\n\n\n\nVariable Scope\nPython follows similar scoping rules to R: variables defined inside functions are local to that function.\n\nx = 10  # Global variable\n\ndef modify_variable():\n    x = 5  # Local variable - doesn't affect global x\n    return x\n\nmodify_variable()  # Returns 5\n\n5\n\nx                  # Still 10\n\n10\n\n\nTo modify a global variable inside a function, you need the global keyword (though this is generally discouraged):\n\ncounter = 0\n\ndef increment_counter():\n    global counter\n    counter += 1\n    return counter\n\nincrement_counter()\n\n1\n\nincrement_counter()\n\n2\n\ncounter\n\n2\n\n\n\n\n\n\n\n\nCompared to R\n\n\n\nComparison to R: R uses &lt;&lt;- for assigning to parent environments, which is also discouraged."
  },
  {
    "objectID": "4_python.html#loops",
    "href": "4_python.html#loops",
    "title": "Chapter 4: Introduction to Python for R Users",
    "section": "Loops",
    "text": "Loops\nLoops allow you to repeat operations. Python has for loops and while loops, similar to R.\n\nFor Loops\nfor loops in Python iterate over sequences (lists, tuples, strings, ranges, etc.).\n\n# Basic for loop\nfruits = [\"apple\", \"banana\", \"cherry\"]\n\nfor fruit in fruits:\n    print(f\"I like {fruit}\")\n\nI like apple\nI like banana\nI like cherry\n\n\n\n\n\n\n\n\nCompared to R\n\n\n\nR’s equivalent would be:\n\nfruits = c(\"apple\", \"banana\", \"cherry\")\nfor (fruit in fruits) {\n  print(paste(\"I like\", fruit))\n}\n\n[1] \"I like apple\"\n[1] \"I like banana\"\n[1] \"I like cherry\"\n\n\n\n\n\nThe range() Function\nrange() generates a sequence of numbers and is commonly used with for loops. It’s similar to R’s seq() or : operator.\n\n# range(stop) - from 0 to stop-1\nfor i in range(5):\n    print(i)\n\n0\n1\n2\n3\n4\n\n\n\n# range(start, stop) - from start to stop-1\nfor i in range(2, 7):\n    print(i)\n\n2\n3\n4\n5\n6\n\n\n\n# range(start, stop, step) - with custom step\nfor i in range(0, 10, 2):\n    print(i)\n\n0\n2\n4\n6\n8\n\n\n\n\n\n\n\n\nCompared to R\n\n\n\nR equivalents:\n\nfor (i in 0:4) { }           # range(5)\nfor (i in 2:6) { }           # range(2, 7)\nfor (i in seq(0, 8, by=2)) { } # range(0, 10, 2)\n\n\n\n\n\n\nEnumerate\nWhen you need both the index and the value, use enumerate().\n\n# enumerate provides index and value\ncolors = [\"red\", \"green\", \"blue\"]\nenumerate(colors)\n\n&lt;enumerate object at 0x122b01480&gt;\n\nfor index, color in enumerate(colors):\n    print(f\"Color {index}: {color}\")\n\nColor 0: red\nColor 1: green\nColor 2: blue\n\n# Start counting from 1 instead of 0\nfor index, color in enumerate(colors, start=1):\n    print(f\"Color {index}: {color}\")\n\nColor 1: red\nColor 2: green\nColor 3: blue\n\n\n\n\n\n\n\n\nCompared to R\n\n\n\nR’s seq_along() is similar:\n\ncolors = c(\"red\", \"green\", \"blue\")\nfor (i in seq_along(colors)) {\n  print(paste(\"Color\", i, \":\", colors[i]))\n}\n\n[1] \"Color 1 : red\"\n[1] \"Color 2 : green\"\n[1] \"Color 3 : blue\"\n\n\n\n\n\n\nNested Loops\nYou can nest loops just like in R.\n\n# Nested loops - multiplication table\nfor i in range(1, 4):\n    for j in range(1, 4):\n        print(f\"{i} x {j} = {i * j}\")\n\n1 x 1 = 1\n1 x 2 = 2\n1 x 3 = 3\n2 x 1 = 2\n2 x 2 = 4\n2 x 3 = 6\n3 x 1 = 3\n3 x 2 = 6\n3 x 3 = 9\n\n\n\n\nList Comprehensions\nOne of Python’s most powerful features is list comprehensions – a concise way to create lists. This is similar to R’s sapply() or purrr::map().\nNow that you understand for loops, list comprehensions will make more sense as they’re essentially condensed for loops. List comprehensions will yield a list.\n\n# Traditional loop approach\nsquares = [] # define list\nfor i in range(1, 6):\n    squares.append(i ** 2) # build list as you go -- more efficient than vector growing in R\nprint(squares)\n\n[1, 4, 9, 16, 25]\n\n# List comprehension - more Pythonic\nsquares = [i ** 2 for i in range(1, 6)]\nprint(squares)\n\n[1, 4, 9, 16, 25]\n\n# With condition (like dplyr::filter)\n#[expression *for* item *in* iterable *if* condition]\neven_squares = [i ** 2 for i in range(1, 11) if i % 2 == 0]\nprint(even_squares)\n\n[4, 16, 36, 64, 100]\n\n\n\n\n\n\n\n\nCompared to R\n\n\n\nR equivalent:\n\nneeds(tidyverse)\nsquares &lt;- sapply(1:5, function(x) x^2)\n# or with purrr\nsquares &lt;- map(1:5, \\(x) x^2)\n\n\n\nThe general syntax for list comprehensions is:\n[expression *for* item *in* iterable *if* condition]\nThis reads almost like English: “Create a list of expression for each item in iterable if condition is true.”\n\n\nWhile Loops\nwhile loops continue executing as long as a condition is True. They’re identical in concept to R’s while loops.\n\n# Basic while loop\ncount = 0\n\nwhile count &lt; 5:\n    print(f\"Count is: {count}\")\n    count += 1  # Increment \n\nCount is: 0\nCount is: 1\nCount is: 2\nCount is: 3\nCount is: 4\n\nprint(\"Loop finished!\")\n\nLoop finished!\n\n\n\n\n\n\n\n\nCompared to R\n\n\n\nVery similar syntax, though Python uses count += 1 instead of count &lt;- count + 1.\n\n\n\n# while loop with user input simulation\n# Let's simulate checking until we find a value\nimport random\n\ntarget = 7\nattempts = 0\nguess = 0\n\nwhile guess != target:\n    guess = random.randint(1, 10)\n    attempts += 1\n    print(f\"Attempt {attempts}: guessed {guess}\")\n\nAttempt 1: guessed 10\nAttempt 2: guessed 8\nAttempt 3: guessed 3\nAttempt 4: guessed 3\nAttempt 5: guessed 3\nAttempt 6: guessed 5\nAttempt 7: guessed 3\nAttempt 8: guessed 6\nAttempt 9: guessed 1\nAttempt 10: guessed 1\nAttempt 11: guessed 10\nAttempt 12: guessed 5\nAttempt 13: guessed 8\nAttempt 14: guessed 9\nAttempt 15: guessed 5\nAttempt 16: guessed 9\nAttempt 17: guessed 7\n\nprint(f\"Found {target} in {attempts} attempts!\")\n\nFound 7 in 17 attempts!\n\n\n\n\nbreak and continue\nControl loop execution with break and continue.\n\n# break - exit the loop immediately\nfor i in range(10):\n    if i == 5:\n        break\n    print(i)\n\n0\n1\n2\n3\n4\n\n# continue - skip rest of current iteration\nfor i in range(10):\n    if i % 2 == 0:  # Skip even numbers\n        continue\n    print(i)\n\n1\n3\n5\n7\n9\n\n\n\n\n\n\n\n\nCompared to R\n\n\n\nbreak and next work the same way (next in R is continue in Python).\n\n\n\n\nPractical Examples\nExample 1: Filter and Transform Data Let’s say we have a list of student grades and we want to filter out those who passed (grade &gt;= 70) and calculate the average grade.\n\n# Sample data\nstudents = [\n    {\"name\": \"Alice\", \"grade\": 85},\n    {\"name\": \"Bob\", \"grade\": 72},\n    {\"name\": \"Charlie\", \"grade\": 90},\n    {\"name\": \"Diana\", \"grade\": 68},\n    {\"name\": \"Eve\", \"grade\": 95}\n]\n\n# Filter students who passed (grade &gt;= 70)\npassing_students = [s for s in students if s[\"grade\"] &gt;= 70]\n\nprint(\"Passing students:\")\n\nPassing students:\n\nfor student in passing_students:\n    print(f\"{student['name']}: {student['grade']}\")\n\nAlice: 85\nBob: 72\nCharlie: 90\nEve: 95\n\n# Calculate average grade\ngrades = [s[\"grade\"] for s in students]\naverage = sum(grades) / len(grades)\nprint(f\"\\nClass average: {average:.2f}\")\n\n\nClass average: 82.00\n\n\n\n\n\n\n\n\nCompared to R\n\n\n\nThis is similar to using dplyr::filter() and summarize().\n\n\nExample 2: FizzBuzz\nA classic programming exercise - counting with special rules.\n\n# FizzBuzz: Print numbers 1-20, but:\n# - \"Fizz\" for multiples of 3\n# - \"Buzz\" for multiples of 5\n# - \"FizzBuzz\" for multiples of both\n\nfor i in range(1, 21):\n    if i % 3 == 0 and i % 5 == 0:\n        print(\"FizzBuzz\")\n    elif i % 3 == 0:\n        print(\"Fizz\")\n    elif i % 5 == 0:\n        print(\"Buzz\")\n    else:\n        print(i)\n\n1\n2\nFizz\n4\nBuzz\nFizz\n7\n8\nFizz\nBuzz\n11\nFizz\n13\n14\nFizzBuzz\n16\n17\nFizz\n19\nBuzz"
  },
  {
    "objectID": "4_python.html#key-python-conventions",
    "href": "4_python.html#key-python-conventions",
    "title": "Chapter 4: Introduction to Python for R Users",
    "section": "Key Python Conventions",
    "text": "Key Python Conventions\n\nIndentation\nPython uses indentation to define code blocks (unlike R which uses {}). This is not optional – incorrect indentation will cause errors!"
  },
  {
    "objectID": "4_python.html#finally-the-zen-of-python",
    "href": "4_python.html#finally-the-zen-of-python",
    "title": "Chapter 4: Introduction to Python for R Users",
    "section": "Finally: The Zen of Python",
    "text": "Finally: The Zen of Python\nPython has a philosophy! Type import this to see it:\n\nimport this\n\nThe Zen of Python, by Tim Peters\n\nBeautiful is better than ugly.\nExplicit is better than implicit.\nSimple is better than complex.\nComplex is better than complicated.\nFlat is better than nested.\nSparse is better than dense.\nReadability counts.\nSpecial cases aren't special enough to break the rules.\nAlthough practicality beats purity.\nErrors should never pass silently.\nUnless explicitly silenced.\nIn the face of ambiguity, refuse the temptation to guess.\nThere should be one-- and preferably only one --obvious way to do it.\nAlthough that way may not be obvious at first unless you're Dutch.\nNow is better than never.\nAlthough never is often better than *right* now.\nIf the implementation is hard to explain, it's a bad idea.\nIf the implementation is easy to explain, it may be a good idea.\nNamespaces are one honking great idea -- let's do more of those!"
  },
  {
    "objectID": "4_python.html#exercises",
    "href": "4_python.html#exercises",
    "title": "Chapter 4: Introduction to Python for R Users",
    "section": "Exercises",
    "text": "Exercises\nExercise 1: Temperature Converter Write a program that converts temperatures between Celsius and Fahrenheit. Formula: \\(F = (C \\times 9/5) + 32\\)\n\nConvert each to Fahrenheit using a for loop\nPrint the results\nStore each Celsius value and its Fahrenheit equivalent in a DataFrame.\n\n\n\nSolution. Click to expand!\n\n\ntemperatures_celsius = [0, 10, 20, 30, 40]\ntemperatures_fahrenheit = []\n\nfor temp in temperatures_celsius:\n    fahrenheit = (temp * 9/5) + 32\n    temperatures_fahrenheit.append(fahrenheit)\n\ntemperatures_fahrenheit\n\n[32.0, 50.0, 68.0, 86.0, 104.0]\n\n\n\nExercise 2: Word Counter\nGiven a sentence, count how many times each word appears.\nHint: Use sentence.split() to get a list of words, and a dictionary to store counts. The operator in yields True if an element is in another list, e.g., if word in word_counts\n\n\nSolution. Click to expand!\n\n\npython_sentence = \"the quick brown fox jumps over the lazy dog the fox\"\n\n# Split sentence into words\nwords = python_sentence.split()\n\n# Count occurrences using a dictionary\nword_counts = {}\nfor word in words:\n    if word in word_counts:\n        word_counts[word] += 1\n    else:\n        word_counts[word] = 1\n\nword_counts\n\n{'the': 3, 'quick': 1, 'brown': 1, 'fox': 2, 'jumps': 1, 'over': 1, 'lazy': 1, 'dog': 1}\n\n# Expected output: {'the': 3, 'quick': 1, 'brown': 1, ...}\n\n\nExercise 3: Prime Numbers\nWrite a function that checks if a number is prime. Then use it to find all prime numbers between 1 and 50.\n\n\nSolution. Click to expand!\n\n\ndef is_prime(n):\n    \"\"\"Check if a number is prime\"\"\"\n    if n &lt; 2:\n        return False\n    if n == 2:\n        return True\n    if n % 2 == 0:\n        return False\n    for i in range(3, n):\n        if n % i == 0:\n            return False\n    return True\n\nis_prime(50)\n\nFalse\n\n# Find all prime numbers between 1 and 50\nprimes = []\nfor num in range(1, 51):\n    if is_prime(num):\n        primes.append(num)\n\nprimes\n\n[2, 3, 5, 7, 11, 13, 17, 19, 23, 29, 31, 37, 41, 43, 47]\n\n\n\nExercise 4: List Manipulation\n\nCreate a list of numbers from 1 to 20:\nCreate a new list with only even numbers\nCreate a new list with squares of odd numbers\nCalculate the sum of numbers divisible by 3\n\n\n\nSolution. Click to expand!\n\n\n# a. Create a list of numbers from 1 to 20\nnumbers = list(range(1, 21))\n\n# b. Create a new list with only even numbers\neven_numbers = [num for num in numbers if num % 2 == 0]\neven_numbers\n\n[2, 4, 6, 8, 10, 12, 14, 16, 18, 20]\n\n# c. Create a new list with squares of odd numbers\nodd_squares = [num ** 2 for num in numbers if num % 2 != 0]\nodd_squares\n\n[1, 9, 25, 49, 81, 121, 169, 225, 289, 361]\n\n# d. Calculate the sum of numbers divisible by 3\ndivisible_by_3 = [num for num in numbers if num % 3 == 0]\nsum(divisible_by_3)\n\n63\n\n\n\nThe syntax might be different, but the concepts you know from R will translate well!"
  },
  {
    "objectID": "4_python.html#further-resources",
    "href": "4_python.html#further-resources",
    "title": "Chapter 4: Introduction to Python for R Users",
    "section": "Further Resources",
    "text": "Further Resources\n\nOfficial Python Tutorial\nLearn Python the Hard Way\nAutomate the Boring Stuff with Python\nReal Python"
  },
  {
    "objectID": "8_selenium.html",
    "href": "8_selenium.html",
    "title": "Chapter 8: selenium",
    "section": "",
    "text": "Sometimes you will run into the problem of a website being not as “scrape-able” as you might have wanted it to. This might be due to Javascript, them blocking you for not being a “real” person, captchas, login forms, you name it. To avoid this, you can use a package called selenium. What it basically does is controlling a web browser. Its original purpose is to automate testing of web-based applications. However, it’s also perfectly suited for helping you with your scraping endeavors.\nselenium is a Python application. An R wrapper (RSelenium) exists, yet its rather tedious to use, since you would likely have to run your browser out of a Docker container. And if you’re on a recent Mac with a Silicon processor, these containers might not even exist yet. Therefore, in this script you will use the original Python version and run Python in this quarto document from your R session. For this, you can use reticulate, which allows you to switch between the R and the Python world. Hence, you can do your scraping in Python and your data manipulations in R and store all of this in one notebook."
  },
  {
    "objectID": "8_selenium.html#install-python-using-reticulate-and-miniconda",
    "href": "8_selenium.html#install-python-using-reticulate-and-miniconda",
    "title": "Chapter 8: selenium",
    "section": "Install Python using reticulate and miniconda",
    "text": "Install Python using reticulate and miniconda\n\n\n\n\n\n\n\n\n\nTo get started with selenium, you first need to activate your Python environment. Then, you need to install the selenium package.\n\nreticulate::use_condaenv(\"toolbox_env\", required = TRUE)\nreticulate::conda_install(\"toolbox_env\", \"selenium\")"
  },
  {
    "objectID": "8_selenium.html#selenium",
    "href": "8_selenium.html#selenium",
    "title": "Chapter 8: selenium",
    "section": "selenium",
    "text": "selenium\n\n\n\n\n\n\n\n\n\nNow we’re good to go and can start working with selenium. In this tutorial, you will also learn about some basics of coding in Python. Even more so than in R, we will rely on custom-made functions that we need to define as well as for loops. They are different in so far as we do not need to preallocate space to objects – such as lists – but rather can grow them iteratively (similar to dplyr::bind_rows()/base R’s rbind()). What’s more is that proper indentation of code is key here. In this tutorial, though, we will focus on navigating around websites and then, once we are done, grabbing their raw html code, which we can then read in using xml2::read_html() and wrangle using rvest functions. If you want to go full Python, you can get into BeautifulSoup, Python’s rvest equivalent.\n\nOpen a browser and navigate around\nFirst of all, we need to open a browser. For this, we need to have one installed, I will use Firefox in this example which you can download here. For a basic example, we import the required packages and open a website containing books that we can scrape.\n\nfrom selenium import webdriver\nfrom selenium.webdriver.common.by import By\n\n# opens a Firefox window\ndriver = webdriver.Firefox()\n\n# Navigate to the website\ndriver.get(\"https://books.toscrape.com/\")\n\nNote that we do not have to assign anything to the driver object, it will adapt as we run the code. To grab the entire page, we just extract page_source from the driver (driver.page_source). Then we can write this html file into a directory by supplying the output_path.\n\nhtml = driver.page_source\n\noutput_path = \"temp/book_example.html\"\nwith open(output_path, \"w\", encoding=\"utf-8\") as f:\n            f.write(html)\n\nYou can also take a screenshot of the page:\n\ndriver.save_screenshot(\"screenshot.png\")\n\nThen we can continue with R’s rvest, read in the document and perform our manipulations in R:\n\nneeds(rvest)\nbooks &lt;- read_html(\"temp/book_example.html\") |&gt; \n  html_elements(\"h3 a\") |&gt; \n  html_text2()\n\nhead(books)\n\n[1] \"A Light in the ...\"           \"Tipping the Velvet\"          \n[3] \"Soumission\"                   \"Sharp Objects\"               \n[5] \"Sapiens: A Brief History ...\" \"The Requiem Red\"             \n\n\nThis is all fun and games, but we would probably want to navigate around the website and systematically scrape the pages. In this case, we would like to click the button to get to the next page. For this, we can use the click() function. The button to be clicked can be identified in multiple ways, here I will show you two ways to locate it: by text (i.e., which text is on the button) and by CSS selector (i.e., the thing SelectorGadget will give you).\n\nbutton = driver.find_element(By.LINK_TEXT, \"next\")\nbutton.click()\n\nbutton = driver.find_element(By.CSS_SELECTOR, \".next a\")\nbutton.click()\n\nEt voilà, we’re on the next page.\nSo this now gives us the tools to automate the scraping here and we can write our first loop which navigates through the first 5 pages, grabs the html content on the go and stores it in the respective paths. To make our code clean, we define the saving function before. We also import time and random so that we can add random delays between requests:\n\nimport time\nimport random\n\ndef save_html(html, output_path):\n  with open(output_path, \"w\", encoding=\"utf-8\") as f:\n            f.write(html)\n            \ndef wait_random(min_secs, max_secs):\n  time.sleep(random.uniform(min_secs, max_secs))\n            \noutput_paths = []\nfor i in range(1, 6):\n    output_path = f\"temp/books_page_{i}.html\"\n    output_paths.append(output_path)\n    \nprint(output_paths)\n\ndriver.get(\"https://books.toscrape.com/\") # navigate to landing page\nfor path in output_paths:\n    html = driver.page_source\n    save_html(html, path)\n    button = driver.find_element(By.CSS_SELECTOR, \".next a\")\n    button.click()\n    wait_random(1, 3)\n\nNow we can use R’s fs library to check our path and read-in the html files:\n\nneeds(fs, tidyverse)\n\ndir_ls(\"temp\", regexp = \"books\")\n\ntemp/books_page_1.html temp/books_page_2.html temp/books_page_3.html \ntemp/books_page_4.html temp/books_page_5.html \n\nbooks &lt;- dir_ls(\"temp\", regexp = \"books\") |&gt; \n  map(\\(x) read_html(x) |&gt; \n        html_elements(\"h3 a\") |&gt; \n        html_attr(\"title\")) |&gt; \n  reduce(c)\n\nhead(books)\n\n[1] \"A Light in the Attic\"                 \n[2] \"Tipping the Velvet\"                   \n[3] \"Soumission\"                           \n[4] \"Sharp Objects\"                        \n[5] \"Sapiens: A Brief History of Humankind\"\n[6] \"The Requiem Red\"                      \n\n\nIf we want to go back and forth – similar to an rvest::session() – we can use different functions:\n\ndriver.back() # Go back\ntime.sleep(1) # Brief pause for demonstration\ndriver.forward() # Go forward\ntime.sleep(1)\ndriver.refresh() #refresh page\n\nFinally, part of navigating a page is also scrolling around. This is particularly helpful if we want to (a) appear human, and (b), when we have dynamic content that unfolds as we move. Remember the IMDb example?\nScrolling is not straightforward, especially since it’s relying on JavaScript in the background, and you will want to consider the following points: Always add waits after scrolling to allow content to load – and check for this new content after scrolling, so that the browser stops scrolling once the limit has been reached. Also use random scolling delays to appear more human-like. We will use a training page to illustrate how this can be achieved.\n\ndriver.get(\"https://www.scrapingcourse.com/infinite-scrolling\")\n\nLet’s check, without the scrolling, how many different products we see:\n\nelements = driver.find_elements(By.CSS_SELECTOR, \".product-name\")\nlen(elements)\ndriver.refresh()\n\nThere are 12 elements. let’s do one scroll to the bottom.\n\ndriver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n   \ntime.sleep(1)\n        \nelements = driver.find_elements(By.CSS_SELECTOR, \".product-name\")\nlen(elements)\n\nWe can do this over and over again, until there are no new elements, in a while loop. In the end, we store the full page’s html.\n\ndriver.get(\"https://www.scrapingcourse.com/infinite-scrolling\")\nelements = driver.find_elements(By.CSS_SELECTOR, \".product-name\")\nstart_length = len(elements)\nnew_length = start_length + 1\n\nwhile start_length &lt; new_length: #loop runs until there are no new elements\n  start_length = new_length\n  driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n  wait_random(1, 3)\n  new_elements = driver.find_elements(By.CSS_SELECTOR, \".product-name\")\n  new_length = len(new_elements)\n  \nsite_html = driver.page_source\n\nSometimes you also need to scroll down to see a particular button. This can be achieved using the following command:\n\nbutton = driver.find_element(CSS_SELECTOR, \"[CSS selector]\") # find button\n\n# Scroll to the button\ndriver.execute_script(\"arguments[0].scrollIntoView({block: 'center'});\", button)\n\nOr you need to handle some problems on a page, like in this example you need to wait for a bit for the page to refresh. It will sometimes fail on first click but work on second. For this we can define an exception.\n\ndriver.get(\"https://www.imdb.com/search/title/?title_type=feature,tv_movie,tv_special,video,tv_series,tv_miniseries&interests=in0000073\")\n\ndef click_button_with_retry(driver):\n   try:\n       button = driver.find_element(By.CLASS_NAME, \"ipc-see-more__button\")\n       button.click()\n   except:\n       time.sleep(10)\n       button = driver.find_element(By.CLASS_NAME, \"ipc-see-more__button\") \n       button.click()\n       \ni = 1\nwhile i &lt; 4:\n  wait_random(1, 3)\n  click_button_with_retry(driver)\n  i += 1\n\n\n\nSend input to forms and boxes\n\n\n\n\n\n\n\n\n\nWith selenium we can also send input to web forms in an automated manner by using send_keys(). Let’s look at IMDb for this.\nImagine we have a list of movies we are interested in.\n\nmovie_list = [\"top gun\", \"pirates of the carribean\", \"fear and loathing in las vegas\", \"batman\"]\n\ndriver.get(\"https://imdb.com\")\n\nFirst, we need to find the search box, for instance using the CSS selector. We also need to locate the button. And finally we can send our input text and click the button.\n\nsearch_box = driver.find_element(By.CSS_SELECTOR, \"#suggestion-search\")\nsearch_button = driver.find_element(By.CSS_SELECTOR, \"#suggestion-search-button\")\n\nsearch_box.send_keys(\"top gun\")\nsearch_button.click()\n\nIf you want to do this in a loop, make sure to clear the search box in between searches:\n\nsearch_box.clear() \n\n\n\nCaptcha and Error handling\nAnother common problem you might encounter when scraping the web is that you need to solve captchas to prove that you are human. Since selenium is simulating a browser, you can just intervene whenever and solve them yourselves. For this, we need to write a function that detects when human input is required, rings a little bell, and then, once you have solved the little riddle, allows you to continue.\n\ndef play_alert_windows():\n    import winsound\n    winsound.Beep(1000, 500)  # 1000 Hz for 500ms\n\ndef play_alert_mac():\n  import subprocess\n  subprocess.run([\"afplay\", \"/System/Library/Sounds/Ping.aiff\"])\n\nplay_alert_mac()\n  \ndef play_alert_linux():\n  print(\"\\a\") # ascii bell\n        \ndef captcha_detected(driver):\n    page_source = driver.page_source.lower()\n    captcha_keywords = [\"captcha\", \"recaptcha\", \"verify you're human\", \"roboter\"]\n    return any(keyword in page_source for keyword in captcha_keywords)\n\ndef solve_captcha_manually():\n    play_alert_mac() # or play_alert_windows() if you're using a Windows machine\n    print(\"CAPTCHA detected! Please solve it manually.\")\n    input(\"Press Enter when you've solved the CAPTCHA...\")\n    print(\"Resuming scrape...\")\n    time.sleep(2)\n\nSo let’s see how this works in real life using a demo website.\n\ndriver.get(\"https://www.google.com/recaptcha/api2/demo\")\n\nif captcha_detected(driver):\n        solve_captcha_manually()\nsubmit_button = driver.find_element(By.CSS_SELECTOR, \"#recaptcha-demo-submit\")\nsubmit_button.click()\n\nThis is it for this brief introduction to selenium. Now that we’re done, we can just close the browser using\n\ndriver.quit()\n\nOf course, there is a lot more than this tutorial does cover. Find more information – including a 12 hour YouTube tutorial under the following links."
  },
  {
    "objectID": "8_selenium.html#further-links",
    "href": "8_selenium.html#further-links",
    "title": "Chapter 8: selenium",
    "section": "Further links",
    "text": "Further links\n\nselenium manual\nGetting started\nA 12 hour course on YouTube"
  },
  {
    "objectID": "8_selenium.html#exercises",
    "href": "8_selenium.html#exercises",
    "title": "Chapter 8: selenium",
    "section": "Exercises",
    "text": "Exercises\nIn general, you could try all the rvest exercises with selenium to see how these things differ. Also every page is different, therefore it will probably be best if you just start with your own things. However, here is a quite tricky example.\n\nDriving home for Christmas. I want to visit my family over the holidays, please give me an overview of trains (“https://bahn.de”) that go from Leipzig to Regensburg on December 20 in a tibble format. The tibble should contain: Date and time, number of changes, price.\n\nHint: Provide the initial search request using user input, then save the html, scroll down, and click “spätere Verbindungen,” save the html, etc.\nBonus (very tricky): do it for Dec 20 through 23 and make a visualization of the price (y-axis) over time (x-axis).\n\n\nSolution. Click to expand!\n\n\ndriver.get(\"https://bahn.de\")\n## enter search things manually\n\noutput_paths = []\nfor i in range(1, 20):\n    output_path = f\"temp/bahn_page_{i}.html\"\n    output_paths.append(output_path)\n    \nfor path in output_paths:\n  driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n  wait_random(1, 3)\n  html = driver.page_source\n  save_html(html, path)\n  later_connections = driver.find_element(By.XPATH, '//button[normalize-space()=\"Spätere Verbindungen\"]')\n  later_connections.click()\n  wait_random(1, 3)\n\n\nfile_names &lt;- dir_ls(\"temp\") %&gt;% \n  .[str_detect(., \"bahn\")] |&gt; \n  enframe(name = NULL, value = \"file_name\") |&gt; \n  mutate(number = str_extract(file_name, \"[0-9]{1,2}\") |&gt; as.numeric()) |&gt; \n  arrange(number)\n\nbahn_list &lt;- dir_ls(\"temp\") %&gt;% \n  .[str_detect(., \"bahn\")] |&gt; \n  map(read_html) |&gt; \n  set_names(dir_ls(\"temp\") %&gt;% \n  .[str_detect(., \"bahn\")]) %&gt;% \n  .[file_names$file_name]\n\nraw_info &lt;- bahn_list |&gt; \n  map(\\(x) x |&gt; \n        html_elements(\"div.reiseplan__infos\") |&gt;\n        html_text2())\n\nraw_price &lt;- bahn_list |&gt; \n  map(\\(x) x |&gt; \n        html_elements(\"span.reise-preis__preis\") |&gt;\n        html_text2())\n\noutput_tbl &lt;- tibble(\n  start = raw_info |&gt; \n    reduce(c) |&gt; \n    str_extract(\"geplante Abfahrt[0-9]{2}\\\\:[0-9]{2}\") |&gt; \n    str_remove(\"geplante Abfahrt\"),\n  end = raw_info |&gt; \n    reduce(c) |&gt; \n    str_extract(\"Ankunft[0-9]{2}\\\\:[0-9]{2}\") |&gt; \n    str_remove(\"Ankunft\"),\n  changes = raw_info |&gt; \n    reduce(c) |&gt; \n    str_extract(\"Umstieg[e]?[0-9]\") |&gt; \n    str_remove(\"Umstieg[e]?\") |&gt; \n    as.numeric(),\n  price = raw_price |&gt; \n    reduce(c) |&gt; \n    str_extract(\"[0-9,]*\") |&gt; \n    str_replace(\",\", \"\\\\.\")) |&gt; \n  replace_na(list(changes = 0)) |&gt; \n  #mutate(est_time_min = as.numeric((end - start))/60) |&gt; \n  mutate(former_value = lag(start) |&gt; \n           str_extract(\"[0-9]{2}\") |&gt; \n           as.numeric(),\n         start_hour = str_extract(start, \"[0-9]{2}\") |&gt; \n           as.numeric(),\n         diff_start_next = start_hour - former_value,\n         day_break = case_when(\n           diff_start_next &lt; -18 ~ \"break\",\n           TRUE ~ NA)) |&gt; \n  fill(day_break, .direction = \"down\") |&gt; \n  filter(is.na(day_break)) |&gt; \n  distinct(start, end, changes, price)\n\n## BONUS\n\ndates &lt;- bahn_list |&gt; \n  map(\\(x) x |&gt; \n        html_elements(\"div.reiseloesung-heading\") |&gt;\n        html_text2()) |&gt; \n  map(\\(x) if(length(x) == 0) \"Fr. 20. Dez. 2024\" else x) |&gt; \n  map(\\(x) str_c(x, collapse = \";\"))\n\noutput_tbl &lt;- bind_cols(\n  start = raw_info |&gt; \n    map(\\(x) x |&gt; \n          str_extract(\"geplante Abfahrt[0-9]{2}\\\\:[0-9]{2}\") |&gt; \n          str_remove(\"geplante Abfahrt\")) |&gt; \n    map2(dates, \\(x, y) x |&gt; \n           enframe(name = NULL, value = \"start\") |&gt; \n           mutate(date = y)) |&gt; \n    list_rbind(),\n  end = raw_info |&gt; \n    map(\\(x) x |&gt; \n          str_extract(\"Ankunft[0-9]{2}\\\\:[0-9]{2}\") |&gt; \n          str_remove(\"Ankunft\") |&gt; \n          enframe(name = NULL, value = \"end\")) |&gt;\n    list_rbind(),\n  raw_info |&gt; \n    map(\\(x) x |&gt; \n          str_extract(\"Umstieg[e]?[0-9]\") |&gt; \n          str_remove(\"Umstieg[e]?\") |&gt; \n          enframe(name = NULL, value = \"changes\")) |&gt; \n    list_rbind() |&gt; \n    replace_na(list(changes = \"0\")),\n  raw_price |&gt;\n    map(\\(x) x |&gt; \n          str_extract(\"[0-9,]*\") |&gt; \n          str_replace(\",\", \"\\\\.\") |&gt; \n          enframe(name = NULL, value = \"price\")) |&gt; \n    list_rbind()\n)\n  \n  \nlengths &lt;- raw_info |&gt; \n    map(\\(x) x |&gt; \n          str_extract(\"geplante Abfahrt[0-9]{2}\\\\:[0-9]{2}\") |&gt; \n          str_remove(\"geplante Abfahrt\")) |&gt; \n  map(length) |&gt; \n  reduce(c) |&gt; \n  map2(1:19, \\(x, y) rep(y, x)) |&gt; \n  reduce(c)\n\n\ndec_20 &lt;- output_tbl |&gt; \n  mutate(page = lengths) |&gt; \n  slice(1:66) |&gt; \n  mutate(date = \"Fr. 20. Dez. 2024\") |&gt; \n  distinct(date, start, end, changes, price)\n\ndec_21 &lt;- output_tbl |&gt; \n  mutate(page = lengths) |&gt; \n  filter(page &gt; 5, str_detect(date, \"21\\\\.\")) |&gt; \n  slice(21:69) |&gt; \n  mutate(date = \"Sa. 21. Dez. 2024\") |&gt; \n  distinct(date, start, end, changes, price)\n\ndec_22 &lt;- output_tbl |&gt; \n  mutate(page = lengths) |&gt; \n  filter(str_detect(date, \"22\\\\.\")) |&gt; \n  slice(32:78) |&gt; \n  mutate(date = \"So. 22. Dez. 2024\") |&gt; \n  distinct(date, start, end, changes, price)\n\ndec_23 &lt;- output_tbl |&gt; \n  mutate(page = lengths) |&gt; \n  filter(str_detect(date, \"23\\\\.\")) |&gt; \n  slice(35:100) |&gt; \n  mutate(date = \"Mo. 23. Dez. 2024\") |&gt; \n  distinct(date, start, end, changes, price)\n\nbind_rows(dec_20, dec_21, dec_22, dec_23) |&gt; \n  mutate(date = str_replace(date, \" Dez\\\\. \", \"12.\") |&gt; \n           str_remove(\"^[A-Za-z]{2}\\\\. \"),\n         date_time = str_c(date, \" \", start, \":00\") |&gt; \n           parse_date_time(orders = \"%d.%m.%Y %H:%M:%S\"),\n         price = as.numeric(price)) |&gt; \n  ungroup() |&gt; \n  ggplot() +\n  geom_line(aes(date_time, price))\n\n\n\nCheck out all the movies’ pages using a loop and adequate waiting times.\n\n\ndriver.get(\"https://imdb.com\")\n\nmovie_list = [\"top gun\", \"pirates of the carribean\", \"fear and loathing in las vegas\", \"batman\"] #this is how you create a list to loop over in python\n\n# for replacing spaces with underscores\ntext = \"fear and loathing\"\nnew_text = text.replace(\" \", \"_\")\nnew_text\n\n\nStore the results in HTML files.\n\n\n\nSolution. Click to expand!\n\n\nfor movie in movie_list:\n    # Find elements inside the loop (good practice)\n    search_box = driver.find_element(By.CSS_SELECTOR, \"#suggestion-search\")\n    search_button = driver.find_element(By.CSS_SELECTOR, \"#suggestion-search-button\")\n    \n    # Clear previous search\n    search_box.clear()  # Clear previous text\n    \n    # Perform search\n    search_box.send_keys(movie)\n    wait_random(1, 3)\n    search_button.click()\n    \n    # Save results\n    movie_file = movie.replace(\" \", \"_\")\n    output_path = f\"temp/{movie_file}.html\"\n    html = driver.page_source\n    save_html(html, output_path)\n    wait_random(1, 3)\n\n\n\nUse rvest to extract the exact years and titles of the results. Note: if you want to store your data in a nice tibble, the vectors need to be of the same length. use this function to replace missing elements (NULL) in a list: replace_null &lt;- function(list){modify(list, \\(x) if(is.null(x)) NA else x)}\n\n\n\nSolution. Click to expand!\n\n\nhtmls &lt;- dir_ls(\"temp\") %&gt;%\n  .[!str_detect(., \"books\")] |&gt; \n  map(read_html)\n\nreplace_null &lt;- function(list){\n  modify(list, \\(x) if(is.null(x)) NA else x)\n}\n\nextract_data &lt;- function(html){\n  raw &lt;- html |&gt; \n    html_elements(\".find-title-result .ipc-metadata-list-summary-item__c\") |&gt; \n    html_text2()\n  tibble(\n    title = map(str_split(raw, \"\\\\n\"), \\(x) pluck(x, 1)) |&gt;\n      replace_null() |&gt; \n      reduce(c),\n    year = map(str_split(raw, \"\\\\n\"), \\(x) pluck(x, 2)) |&gt; \n      replace_null() |&gt; \n      reduce(c)\n  )\n}\n\nmovie_tibble &lt;- htmls |&gt; \n  map(extract_data) |&gt; \n  list_rbind()"
  },
  {
    "objectID": "1_r_index.html",
    "href": "1_r_index.html",
    "title": "Chapter 1: Preface",
    "section": "",
    "text": "Dear student,\nif you read this script, you are either participating in one of my courses on digital methods for the social sciences, or at least interested in this topic. If you have any questions or remarks regarding this script, hit me up at felix.lennert@uni-leipzig.de.\nThis script will introduce you to techniques I regard as elementary for any aspiring (computational) social scientist: the collection of digital trace data via either scraping the web or acquiring data from application programming interfaces (APIs), the analysis of text in an automated fashion (text mining), the analysis and visualization of spatial data, and the modeling of human behavior in silico (agent-based modeling).\nThe following chapters draw heavily on packages from the tidyverse (Wickham et al. 2019) and related packages. If you have not acquired sufficient familiarity yet, you can have a look at the excellent book R for Data Science (Wickham, Çetinkaya-Rundel, and Grolemund 2023).\nI have added brief videos to each section. In these, I will briefly go through the code of the respective section and show a bit of what’s going on in there. I sometimes spontaneously elaborate a bit more on the examples at hand or show things in the data, so they may add some value. However, the script should be sufficient to provide you an understanding the concepts I introduce."
  },
  {
    "objectID": "1_r_index.html#outline",
    "href": "1_r_index.html#outline",
    "title": "Chapter 1: Preface",
    "section": "Outline",
    "text": "Outline\nThis script will unfold as follows:\nChapter 2, “Brief R Recap,” briefly introduces RStudio Projects, Quarto, tidy data and tidyr, dplyr, ggplot, functions, loops, and purrr. These techniques are vital for the things that will come next.\nChapter 3, 4, and 5 introduce Python and the reticulate package, which allows you to use Python in an R environment. It also introduces pandas, a powerful data manipulation package for Python.\nChapter 6, “stringr and RegExes,” deals with string manipulation using, you guessed it, stringr and RegExes.\nChapters 7 and 8, “Crawling the Web and Extracting Data” and “APIs,” introduce the reader to the basics of rvest, HTML, and CSS selectors and how these can be used to acquire data from the web. Moreover, I introduce the httr package and explain how you can use it to make requests to APIs.\nChapter 9, “selenium,” introduces selenium, a Python package that allows you to control a “headless browser” – this is invaluable if you want to scrape dynamic web sites. It will also feature an introduction to reticulate, an R package that allows you to use Python code in an R environment.\nChapter 10, “OCR with tesseract,” shows you how to digitize text from pdf files or images in an automated fashion using tesseract.\nChapter 11, “OpenAI whisper” focuses on the transcription of audio files. This includes diarization.\nChapter 12, “Text Preprocessing and Featurization,” touches upon the basics of bringing text into a numeric format that lends itself to quantitative analyses. It also introduces feature weighting using TF-IDF (i.e., determining which tokens matter more than others), Named-Entity Recognition, and Part-of-Speech-tagging.\nChapter 13, “Dictionary-based analysis,” covers dictionary-based text analysis.\nChapter 14, “Supervised Classification,” deals with the classification of text in a supervised manner using tidymodels.\nChapter 15, “Unsupervised Classification,” deals with the classification of text in an unsupervised manner using “classic” Laten Dirichlet Allocation, Structural Topic Models, and Seeded Topic Models.\nChapter 16, “Word Embeddings,” showcases new text analysis techniques that are based on distributional representations of words, commonly referred to as word embeddings.\nChapter 17, “BERT” demonstrates how you can use BERT for supervised classification. This script will only contain small data-sets, since these large language models require more computing power (e.g., a server with plenty of RAM as well as sufficient CPU and/or GPU power)\nChapter 18, “Local LLMs,” introduces local large language models (LLMs) and showcases how you can use them for information extraction.\nAll chapters try to deal with social scientific examples. Data sets will be provided via Dropbox, therefore the script shall run more or less out of the box. I tried to include “Further links” for the avid readers or the ones that are dissatisfied with my coverage of the content. Exercises are included, the respective solutions will be added as the course unfolds (except for the R recap, please contact me in case you are interested)."
  },
  {
    "objectID": "syllabus/syllabus_toolboxCSS_winter2526.html",
    "href": "syllabus/syllabus_toolboxCSS_winter2526.html",
    "title": "06-002-107-3: Forschungsseminar B – Experimentelle Soziologie und Computational Social Science",
    "section": "",
    "text": "E-mail: felix.lennert@uni-leipzig.de\nCourse hours: Tuesdays and Thursdays, 15:15 – 16:45, NSG, SR 325; for exact dates, see schedule\nReadings: see schedule\nCourse materials: see website\nStudent hours: are to be set up individually via email; my office is H3 1.07; there is a multitude of valid reasons why you should come see me – some are listed here:\n\nthings are unclear and you need help with the material\nyou want to discuss a research idea\nyou have come across a cool new paper that I might deem interesting\nyou have recommendations for me in terms of general course resources/references/structure/behavior\nyou want some career advice from someone roughly your age\nyou forgot your mensa card at home and want some coffee/tea\nin case you need some free period supplies, no email is required, you can just get them at Leonie Steinbrinker’s office (I also have a key if she’s not there), H3 1.06"
  },
  {
    "objectID": "syllabus/syllabus_toolboxCSS_winter2526.html#extensions",
    "href": "syllabus/syllabus_toolboxCSS_winter2526.html#extensions",
    "title": "06-002-107-3: Forschungsseminar B – Experimentelle Soziologie und Computational Social Science",
    "section": "Extensions",
    "text": "Extensions\nExtensions can be granted for particular reasons. These involve, among others, internships and sickness. In the case of the former, please give me a quick heads-up so that I can arrange it (preferably with some sort of proof). If you need an extension for a different reason than the ones mentioned above, feel free to reach out anytime, and I will do my best to accommodate your needs."
  },
  {
    "objectID": "syllabus/syllabus_toolboxCSS_winter2526.html#expectations",
    "href": "syllabus/syllabus_toolboxCSS_winter2526.html#expectations",
    "title": "06-002-107-3: Forschungsseminar B – Experimentelle Soziologie und Computational Social Science",
    "section": "Expectations",
    "text": "Expectations\n\nThe Basics\n\nwritten in English\nfile format: PDF\nfont size 12 pt, 1.5 line spacing\nno typos, grammatical flaws, etc. (you are living in the age of helpers such as Grammarly, there are no more excuses)\nlength: between 4,000 and 8,000 words\ncite correctly and in a uniform manner. My preferred citation style is ASA. It is strongly advised to use Zotero and Quarto/Overleaf; resources can be provided upon request.\n\nStructured resembles an empirical research paper:\n\nthe introduction contains an empirical social scientific research question that is theoretically and practically motivated (i.e., showing its scientific and real-world relevance)\nthe theory section provides a brief overview of relevant prior research; clearly testable hypotheses are derived from the literature/goals for exploratory analyses are formulated\nin data and methods, the data (including acquisition strategy), as well as the analysis strategy, are described; in our case, the data consist of text, the analyses are related to the course content; data and methods need to enable valid results\nresults need to be visualized through tables and/or (gg)plots and described in the text; tables and visualizations need to be properly labeled so that they can “stand on their own”\ndiscussion of the results is performed in the light of the theoretical foundations; potential shortcomings and reach of the paper are outlined\nthe conclusion circles back to the introduction and connects it to the results; it needs to clearly answer the research question"
  },
  {
    "objectID": "syllabus/syllabus_toolboxCSS_winter2526.html#week-1-kick-off",
    "href": "syllabus/syllabus_toolboxCSS_winter2526.html#week-1-kick-off",
    "title": "06-002-107-3: Forschungsseminar B – Experimentelle Soziologie und Computational Social Science",
    "section": "Week 1: Kick Off",
    "text": "Week 1: Kick Off\n\nWelcome & Housekeeping (Tue, 14 October 2025; 15:15 – 16:45; NSG, SR 325)\nNo readings.\n\n\nSetting up your workstation (Thu, 16 October 2025; 15:15 – 16:45; NSG, SR 325)\n\nAcquire access to sc.uni-leipzig.de\nR recap (the corresponding chapters can be found in the R4DS book – _online)\n\nRMarkdown/Quarto – chapters 28 & 29\ndplyr – chapter 4\ntidyr – chapter 6\nggplot2 – chapters 2 & 10 & 11 & 12\npurrr & loops in different flavors – chapter 27\nfunctional programming – chapter 26\nset up reticulate in RStudio – online"
  },
  {
    "objectID": "syllabus/syllabus_toolboxCSS_winter2526.html#week-2-brief-intro-to-python-regexes",
    "href": "syllabus/syllabus_toolboxCSS_winter2526.html#week-2-brief-intro-to-python-regexes",
    "title": "06-002-107-3: Forschungsseminar B – Experimentelle Soziologie und Computational Social Science",
    "section": "Week 2: Brief Intro to Python & Regexes",
    "text": "Week 2: Brief Intro to Python & Regexes\n\nPython & Regexes(Tue, 21 October 2025; 15:15 – 16:45; NSG, SR 325)\n\nBrief intro to Python\n\nreticulate – how to run Python in R studio\ndata types\nloops\nfunctions\npandas\n\n\n\n\nRegular Expressions (Thu, 23 October 2025; 15:15 – 16:45; NSG, SR 325)\n\nstringr & Regular Expressions – R4DS book, online, chapters 15 & 16"
  },
  {
    "objectID": "syllabus/syllabus_toolboxCSS_winter2526.html#week-3-data-acquisition-i",
    "href": "syllabus/syllabus_toolboxCSS_winter2526.html#week-3-data-acquisition-i",
    "title": "06-002-107-3: Forschungsseminar B – Experimentelle Soziologie und Computational Social Science",
    "section": "Week 3: Data Acquisition I",
    "text": "Week 3: Data Acquisition I\n\nHow the Web is Written and Ethics (Tue, 28 October 2025; 15:15 – 16:45; NSG, SR 325)\n\nStoltz and Taylor (2024) – chapter 5\nBlog post on CSS selectors – online\nBlog posts on API calls – online\n\n\n\nrvest (Thu, 30 October 2025; 15:15 – 16:45; NSG, SR 325)\n\nrvest Web scraping 101 – online"
  },
  {
    "objectID": "syllabus/syllabus_toolboxCSS_winter2526.html#week-4-data-acquisition-ii",
    "href": "syllabus/syllabus_toolboxCSS_winter2526.html#week-4-data-acquisition-ii",
    "title": "06-002-107-3: Forschungsseminar B – Experimentelle Soziologie und Computational Social Science",
    "section": "Week 4: Data Acquisition II",
    "text": "Week 4: Data Acquisition II\n\nDynamic Pages and Forms (Tue, 04 November 2025; 15:15 – 16:45; NSG, SR 325)\n\nselenium documentation – online\n\n\n\nAPIs (Thu, 06 November 2025; 15:15 – 16:45; NSG, SR 325)\n\nhttr2 documentation – online"
  },
  {
    "objectID": "syllabus/syllabus_toolboxCSS_winter2526.html#week-5-data-acquisition-iii",
    "href": "syllabus/syllabus_toolboxCSS_winter2526.html#week-5-data-acquisition-iii",
    "title": "06-002-107-3: Forschungsseminar B – Experimentelle Soziologie und Computational Social Science",
    "section": "Week 5: Data Acquisition III",
    "text": "Week 5: Data Acquisition III\n\nIntro to OCR (Tue, 11 November 2025; 15:15 – 16:45; NSG, SR 325)\n\nStoltz and Taylor (2024) – chapter 5\nTesseract documentation – online\n\n\n\nIntro to Audio Transcription (Thu, 13 November 2025; 15:15 – 16:45; NSG, SR 325)\n\nStoltz and Taylor (2024) – chapter 5\nOpenAI Whisper Python package documentation – online"
  },
  {
    "objectID": "syllabus/syllabus_toolboxCSS_winter2526.html#week-6-data-acquisition-iv",
    "href": "syllabus/syllabus_toolboxCSS_winter2526.html#week-6-data-acquisition-iv",
    "title": "06-002-107-3: Forschungsseminar B – Experimentelle Soziologie und Computational Social Science",
    "section": "Week 6: Data Acquisition IV",
    "text": "Week 6: Data Acquisition IV\nOptional buffer sessions."
  },
  {
    "objectID": "syllabus/syllabus_toolboxCSS_winter2526.html#week-7-student-project-week",
    "href": "syllabus/syllabus_toolboxCSS_winter2526.html#week-7-student-project-week",
    "title": "06-002-107-3: Forschungsseminar B – Experimentelle Soziologie und Computational Social Science",
    "section": "Week 7: Student Project Week",
    "text": "Week 7: Student Project Week\nStudents are expected to show up to class and work on their projects."
  },
  {
    "objectID": "syllabus/syllabus_toolboxCSS_winter2526.html#week-8-text-as-data-i",
    "href": "syllabus/syllabus_toolboxCSS_winter2526.html#week-8-text-as-data-i",
    "title": "06-002-107-3: Forschungsseminar B – Experimentelle Soziologie und Computational Social Science",
    "section": "Week 8: Text as Data I",
    "text": "Week 8: Text as Data I\n\nBag of Words(Tue, 02 December 2025; 15:15 – 16:45; NSG, SR 325)\n\nEvans and Aceves (2016)\nGrimmer, Roberts, and Stewart (2022), chapters 3–5, 11, & 15\nStoltz and Taylor (2024), chapters 4–9\n\n\n\nSentiment Analysis, TF-IDF, and NER/POS (Thu, 04 December 2025; 15:15 – 16:45; NSG, SR 325)\n\nGrimmer et al. (2022), chapter 11\nJurafsky and Martin (n.d.), chapter 21 – online\nSilge and Robinson (2017) – online, chapters 2 & 3"
  },
  {
    "objectID": "syllabus/syllabus_toolboxCSS_winter2526.html#week-9-text-as-data-ii",
    "href": "syllabus/syllabus_toolboxCSS_winter2526.html#week-9-text-as-data-ii",
    "title": "06-002-107-3: Forschungsseminar B – Experimentelle Soziologie und Computational Social Science",
    "section": "Week 9: Text as Data II",
    "text": "Week 9: Text as Data II\n\nSupervised Machine Learning in Theory (Tue, 09 December 2025; 15:15 – 16:45; NSG, SR 325)\n\nSupervised ML\n\nBarberá et al. (2021)\nGrimmer et al. (2022), chapters 17–20\nStoltz and Taylor (2024), chapters 9 & 12\n\n\n\n\nSupervised Machine Learning in Practice (Thu, 11 December 2025; 15:15 – 16:45; NSG, SR 325)\n\nHvitfeldt and Silge (2022) – online, chapters 6 & 7\nSilge and Hvitfeldt (2019) – online"
  },
  {
    "objectID": "syllabus/syllabus_toolboxCSS_winter2526.html#week-10-text-as-data-iii",
    "href": "syllabus/syllabus_toolboxCSS_winter2526.html#week-10-text-as-data-iii",
    "title": "06-002-107-3: Forschungsseminar B – Experimentelle Soziologie und Computational Social Science",
    "section": "Week 10: Text as Data III",
    "text": "Week 10: Text as Data III\n\nUnsupervised ML in Theory and Practice (Tue, 16 December 2025; 15:15 – 16:45; NSG, SR 325)\n\nBlei (2012)\nDiMaggio, Nag, and Blei (2013)\nGrimmer et al. (2022), chapters 10, 12–3\nStoltz and Taylor (2024), chapters 10 & 11\nSilge and Robinson (2017) – online, chapter 6\n\n\n\nRemote Counseling pre-Christmas Break (Thu, 18 December 2025; 15:15 – 16:45; NSG, SR 325)\n1-on-1 project counseling available on Zoom.\n—- CHRISTMAS BREAK —-"
  },
  {
    "objectID": "syllabus/syllabus_toolboxCSS_winter2526.html#week-11-text-as-data-iv",
    "href": "syllabus/syllabus_toolboxCSS_winter2526.html#week-11-text-as-data-iv",
    "title": "06-002-107-3: Forschungsseminar B – Experimentelle Soziologie und Computational Social Science",
    "section": "Week 11: Text as Data IV",
    "text": "Week 11: Text as Data IV\n\nMeasuring Similarity and the Distributional Hypothesis (Tue, 06 January 2026; 15:15 – 16:45; NSG, SR 325)\n\nJurafsky and Martin (n.d.), chapter 6 – online\nStoltz and Taylor (2021)\n\n\n\nWord Embeddings (Thu, 08 January 2026; 15:15 – 16:45; NSG, SR 325)\n\nHvitfeldt and Silge (2022) – online, chapter 5\nStoltz and Taylor (2024), chapter 11\ntext2map: R Tools for Text Matrices – online"
  },
  {
    "objectID": "syllabus/syllabus_toolboxCSS_winter2526.html#week-12-text-as-data-v",
    "href": "syllabus/syllabus_toolboxCSS_winter2526.html#week-12-text-as-data-v",
    "title": "06-002-107-3: Forschungsseminar B – Experimentelle Soziologie und Computational Social Science",
    "section": "Week 12: Text as Data V",
    "text": "Week 12: Text as Data V\n\nSupervised Learning on Steroids: BERT (Tue, 13 January 2026; 15:15 – 16:45; NSG, SR 325)\n\nDo, Ollion, and Shen (2022)\nLaurer et al. (2024)\nTörnberg (2023)\nWankmüller (2022)\n\n\n\nActive Learning with BERT (Thu, 15 January 2026; 15:15 – 16:45; NSG, SR 325)\n\nset up environments\nAugmented Social Scientist tutorial – online\nBERTopic – online"
  },
  {
    "objectID": "syllabus/syllabus_toolboxCSS_winter2526.html#week-13-text-as-data-vi",
    "href": "syllabus/syllabus_toolboxCSS_winter2526.html#week-13-text-as-data-vi",
    "title": "06-002-107-3: Forschungsseminar B – Experimentelle Soziologie und Computational Social Science",
    "section": "Week 13: Text as Data VI",
    "text": "Week 13: Text as Data VI\n\nLLMs for information extraction (Tue, 20 January 2026; 15:15 – 16:45; NSG, SR 325)\n\nStuhler, Ton, and Ollion (2025)\n\n\n\nLocal LLMs – a primer (Thu, 22 January 2026; 15:15 – 16:45; NSG, SR 325)\n\nellmer documentation – online\nTutorial from IC2S2 by Etienne Ollion, Emilien Schultz, Julien Boelaert – online"
  },
  {
    "objectID": "syllabus/syllabus_toolboxCSS_winter2526.html#week-14-presentation-preparation-week",
    "href": "syllabus/syllabus_toolboxCSS_winter2526.html#week-14-presentation-preparation-week",
    "title": "06-002-107-3: Forschungsseminar B – Experimentelle Soziologie und Computational Social Science",
    "section": "Week 14: Presentation Preparation Week",
    "text": "Week 14: Presentation Preparation Week\nNo classes. Deadline for sending presentations: January 30, 6PM."
  },
  {
    "objectID": "syllabus/syllabus_toolboxCSS_winter2526.html#week-15-presentation-wrap-up-week",
    "href": "syllabus/syllabus_toolboxCSS_winter2526.html#week-15-presentation-wrap-up-week",
    "title": "06-002-107-3: Forschungsseminar B – Experimentelle Soziologie und Computational Social Science",
    "section": "Week 15: Presentation & Wrap Up Week",
    "text": "Week 15: Presentation & Wrap Up Week\n\nPresentations (Tue, 03 February 2026; 15:15 – 16:45; NSG, SR 325)\nNo readings.\n\n\nPresentations & Wrap-up (Thu, 05 February 2026; 15:15 – 16:45; NSG, SR 325)\nNo readings."
  },
  {
    "objectID": "syllabus/syllabus_toolboxCSS_winter2526.html#deadline-forschungsbericht",
    "href": "syllabus/syllabus_toolboxCSS_winter2526.html#deadline-forschungsbericht",
    "title": "06-002-107-3: Forschungsseminar B – Experimentelle Soziologie und Computational Social Science",
    "section": "Deadline Forschungsbericht",
    "text": "Deadline Forschungsbericht\nMarch 19, 2026 (tentative)."
  },
  {
    "objectID": "5_pandas.html",
    "href": "5_pandas.html",
    "title": "Chapter 5: pandas",
    "section": "",
    "text": "Now that you understand Python basics, let’s look at pandas – Python’s most popular library for data manipulation. If you’re familiar with R’s tidyverse (especially dplyr and tidyr), pandas will feel conceptually familiar, though the syntax differs."
  },
  {
    "objectID": "5_pandas.html#exercises",
    "href": "5_pandas.html#exercises",
    "title": "Chapter 5: pandas",
    "section": "Exercises",
    "text": "Exercises\nTake the dplyr exercises from Chapter 2 and perform them using pandas.\nOpen the IMDb file.\n\nimdb = pd.read_csv(\"data/imdb2006-2016.csv\")\nimdb\n\n     Rank                    Title  ... Revenue (Millions) Metascore\n0       1  Guardians of the Galaxy  ...             333.13      76.0\n1       2               Prometheus  ...             126.46      65.0\n2       3                    Split  ...             138.12      62.0\n3       4                     Sing  ...             270.32      59.0\n4       5            Suicide Squad  ...             325.02      40.0\n..    ...                      ...  ...                ...       ...\n995   996     Secret in Their Eyes  ...                NaN      45.0\n996   997          Hostel: Part II  ...              17.54      46.0\n997   998   Step Up 2: The Streets  ...              58.01      50.0\n998   999             Search Party  ...                NaN      22.0\n999  1000               Nine Lives  ...              19.64      11.0\n\n[1000 rows x 12 columns]\n\n\n\nFind the duplicated movie. How could you go across this?\n\n\nduplicated_movie = (imdb['Title']\n    .value_counts()\n    .reset_index()\n    .sort_values('count', ascending=False)\n    .head(1)\n    )\nduplicated_movie\n\n      Title  count\n0  The Host      2\n\nprint(duplicated_movie[['Title']])\n\n      Title\n0  The Host\n\n\n\nWhich director has made the longest movie?\n\n\nimdb.sort_values('Runtime (Minutes)', ascending=False).head(1)\n\n     Rank       Title  ... Revenue (Millions) Metascore\n828   829  Grindhouse  ...              25.03       NaN\n\n[1 rows x 12 columns]\n\n\n\nWhat’s the highest ranked movie?\n\n\nimdb.sort_values('Rank').head(1)\n\n   Rank                    Title  ... Revenue (Millions) Metascore\n0     1  Guardians of the Galaxy  ...             333.13      76.0\n\n[1 rows x 12 columns]\n\n\n\nWhich movie got the most votes?\n\n\nimdb.sort_values('Votes').head(1)\n\n     Rank           Title  Genre  ... Votes Revenue (Millions) Metascore\n478   479  Paint It Black  Drama  ...    61                NaN      71.0\n\n[1 rows x 12 columns]\n\n\n\nWhich movie had the biggest revenue in 2016?\n\n\nimdb.query('Year == 2016').sort_values('Revenue (Millions)', ascending=False).head(1)\n\n    Rank      Title  ... Revenue (Millions) Metascore\n12    13  Rogue One  ...             532.17      65.0\n\n[1 rows x 12 columns]\n\n\n\nHow much revenue did the movies in the data set make each year in total?\n\n\nimdb.groupby('Year')['Revenue (Millions)'].sum().reset_index()\n\n    Year  Revenue (Millions)\n0   2006             3624.46\n1   2007             4306.23\n2   2008             5053.22\n3   2009             5292.26\n4   2010             5989.65\n5   2011             5431.96\n6   2012             6910.29\n7   2013             7666.72\n8   2014             7997.40\n9   2015             8854.12\n10  2016            11211.65\n\n\n\nFilter movies following some conditions:\n\nMore runtime than the average runtime (hint: you could also use mutate() before).\nMovies directed by J.J. Abrams.\nMore votes than the median of all of the votes.\nThe movies which have the most common value (the mode) in terms of rating (you can use mode() from the pandas package).\n\n\n\n#a \nimdb.assign(avg_runtime = lambda x: x['Runtime (Minutes)'].mean()).assign(runtime = lambda x: x['Runtime (Minutes)']).query('runtime &gt; avg_runtime')\n\n     Rank                    Title  ... avg_runtime runtime\n0       1  Guardians of the Galaxy  ...     113.172     121\n1       2               Prometheus  ...     113.172     124\n2       3                    Split  ...     113.172     117\n4       5            Suicide Squad  ...     113.172     123\n6       7               La La Land  ...     113.172     128\n..    ...                      ...  ...         ...     ...\n979   980       The Skin I Live In  ...     113.172     120\n981   982                    Annie  ...     113.172     118\n982   983      Across the Universe  ...     113.172     133\n989   990                    Selma  ...     113.172     128\n991   992         Taare Zameen Par  ...     113.172     165\n\n[433 rows x 14 columns]\n\n\n\n#b\nimdb[imdb[\"Director\"] == \"J.J. Abrams\"]\n\n     Rank  ... Metascore\n50     51  ...      81.0\n140   141  ...      82.0\n362   363  ...      72.0\n497   498  ...      72.0\n869   870  ...      66.0\n\n[5 rows x 12 columns]\n\n\n\n#c\nimdb.assign(median_votes = lambda x: x['Votes'].median()).query('Votes &gt; median_votes')\n\n     Rank                           Title  ... Metascore median_votes\n0       1         Guardians of the Galaxy  ...      76.0     110799.0\n1       2                      Prometheus  ...      65.0     110799.0\n2       3                           Split  ...      62.0     110799.0\n4       5                   Suicide Squad  ...      40.0     110799.0\n6       7                      La La Land  ...      93.0     110799.0\n..    ...                             ...  ...       ...          ...\n971   972                       Disturbia  ...       NaN     110799.0\n983   984                   Let's Be Cops  ...      30.0     110799.0\n990   991  Underworld: Rise of the Lycans  ...      44.0     110799.0\n993   994        Resident Evil: Afterlife  ...      37.0     110799.0\n994   995                       Project X  ...      48.0     110799.0\n\n[500 rows x 13 columns]\n\n#or\nimdb.query('Votes &gt; @imdb.Votes.median()')\n\n     Rank                           Title  ... Revenue (Millions) Metascore\n0       1         Guardians of the Galaxy  ...             333.13      76.0\n1       2                      Prometheus  ...             126.46      65.0\n2       3                           Split  ...             138.12      62.0\n4       5                   Suicide Squad  ...             325.02      40.0\n6       7                      La La Land  ...             151.06      93.0\n..    ...                             ...  ...                ...       ...\n971   972                       Disturbia  ...              80.05       NaN\n983   984                   Let's Be Cops  ...              82.39      30.0\n990   991  Underworld: Rise of the Lycans  ...              45.80      44.0\n993   994        Resident Evil: Afterlife  ...              60.13      37.0\n994   995                       Project X  ...              54.72      48.0\n\n[500 rows x 12 columns]\n\n\n\n#d\nrating_mode = imdb['Rating'].mode()\nimdb[imdb['Rating'].isin(rating_mode)]\n\n     Rank  ... Metascore\n8       9  ...      78.0\n32     33  ...      52.0\n39     40  ...       NaN\n48     49  ...      68.0\n71     72  ...      60.0\n75     76  ...      50.0\n93     94  ...      57.0\n134   135  ...      61.0\n139   140  ...      44.0\n212   213  ...      61.0\n221   222  ...      73.0\n226   227  ...      82.0\n248   249  ...      75.0\n259   260  ...      76.0\n276   277  ...      71.0\n282   283  ...       NaN\n294   295  ...      55.0\n298   299  ...      66.0\n352   353  ...      47.0\n378   379  ...      64.0\n385   386  ...      64.0\n402   403  ...       NaN\n435   436  ...       NaN\n436   437  ...      33.0\n446   447  ...      59.0\n497   498  ...      72.0\n513   514  ...      72.0\n515   516  ...      72.0\n543   544  ...       NaN\n551   552  ...      79.0\n554   555  ...      33.0\n556   557  ...      77.0\n571   572  ...      75.0\n572   573  ...      51.0\n592   593  ...      69.0\n664   665  ...      88.0\n689   690  ...      85.0\n702   703  ...      60.0\n706   707  ...       NaN\n721   722  ...      76.0\n737   738  ...      57.0\n807   808  ...      82.0\n842   843  ...      80.0\n843   844  ...      73.0\n853   854  ...      70.0\n863   864  ...      81.0\n892   893  ...      56.0\n894   895  ...      46.0\n895   896  ...      55.0\n896   897  ...       NaN\n929   930  ...       NaN\n988   989  ...      89.0\n\n[52 rows x 12 columns]"
  },
  {
    "objectID": "5_pandas.html#further-resources",
    "href": "5_pandas.html#further-resources",
    "title": "Chapter 5: pandas",
    "section": "Further Resources",
    "text": "Further Resources\n\nA very helpful R vs. pandas cheatsheet\nPython for Data Analysis by Wes McKinney (pandas creator)"
  },
  {
    "objectID": "11_transcription.html",
    "href": "11_transcription.html",
    "title": "Chapter 11: OpenAI whisper",
    "section": "",
    "text": "In this chapter, I will show you how to use OpenAI Whisper for audio transcription and diarization. Whisper is a versatile tool that helps convert audio recordings into text, lending itself well for tasks like transcribing interviews, radio shows, or any other type of recorded speech. Additionally, we will use speaker diarization to identify different speakers in the audio.\nThroughout this chapter, we will use reticulate for integrating Python code within our R workflow, pydub for audio manipulation, openai-whisper for audio transcription, torch for running deep learning models, numpy for numerical operations, and pyannote.audio for speaker diarization."
  },
  {
    "objectID": "11_transcription.html#install-python-using-reticulate-and-miniconda",
    "href": "11_transcription.html#install-python-using-reticulate-and-miniconda",
    "title": "Chapter 11: OpenAI whisper",
    "section": "Install Python using reticulate and miniconda",
    "text": "Install Python using reticulate and miniconda\n\n\n\n\n\n\n\n\n\nDue to compatibility problems, we first create a newconda environment. Then we load the required packages. Note that in this case, we need to install them from pip, since they are not available from conda.\n\nneeds(reticulate)\n\n# Create fresh environment\nconda_create(\"torch_env\", python_version = \"3.11\")\nuse_condaenv(\"torch_env\", required = TRUE)\n\n# Install ALL packages at once with compatible versions\npy_run_string(\"\nimport subprocess\nimport sys\n\n# Install everything in one go to let pip resolve dependencies\npackages = [\n    'numpy&gt;=2.0',\n    'torch',\n    'torchvision', \n    'torchaudio',\n    'ffmpeg',\n    'openai-whisper',\n    'pyannote.audio',\n    'pydub',\n    'scipy',\n    'librosa',\n    'pandas',\n    'soundfile'  # helpful for audio handling\n]\n\nsubprocess.run([sys.executable, '-m', 'pip', 'install'] + packages)\n\")\n\n# Verify everything works\npy_run_string(\"\nimport torch\nimport whisper\nfrom pyannote.audio import Pipeline\nfrom pydub import AudioSegment\nimport pandas as pd\nimport numpy as np\nfrom scipy.io import wavfile\nimport librosa\n\nprint(f'✓ PyTorch: {torch.__version__}')\nprint(f'✓ MPS available: {torch.backends.mps.is_available()}')\nprint(f'✓ Numpy: {np.__version__}')\nprint('✓ All packages loaded successfully!')\n\")\n\nThereafter, we need to make sure that we activate our environment. Moreover, for pyannote, you will need an access token from huggingface (get yourself a “read” key here: https://huggingface.co/settings/tokens) and get authorization for using it before.\nThen we can load the required Python packages.\n\nimport torch\nimport whisper\nfrom pyannote.audio import Pipeline\nimport torchaudio\nimport wave\nimport os\nfrom pydub import AudioSegment\nfrom pyannote.core import Segment\nimport numpy as np\nimport pandas as pd\nfrom scipy.io import wavfile\n\nAlso, if we have a GPU available – as you probably should if you’re running these operations on a server – we need to tell our packages that they can use the GPU instead of the CPU.\n\ndevice = torch.device('cpu') # I'm using CPU here because I'm on a Mac with a silicon architecture and whisper throws all kinds of problems here\n# device = device = torch.device('cuda' if torch.cuda.is_available() else 'cpu') # if you're on a server with a suitable GPU\n\nwhisper_model = whisper.load_model(\"base\").to(\"cpu\")\n#whisper_model = whisper.load_model(\"base\").to(device) # if you're on a server with a suitable GPU\n\n# Load diarization pipeline\n\nimport os\nfrom huggingface_hub import logout, login\nimport torch\nfrom pyannote.audio import Pipeline\n\n# Clear environment variables\nos.environ.pop('HF_TOKEN', None)\nos.environ.pop('HUGGING_FACE_HUB_TOKEN', None)\n\nlogout()\n\nos.environ[\"HF_TOKEN\"] = \"your token\"\nos.environ[\"HF_TOKEN\"]\n\n# Login with NEW token\nlogin(token=os.environ[\"HF_TOKEN\"])\n\n# Now try loading\ndevice = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\npipeline = Pipeline.from_pretrained(\"pyannote/speaker-diarization-3.1\")\npipeline.to(device)\n\nprint(f\"✓ Pipeline loaded on {device}\")\n\nSince this script is for students of Leipzig University first and foremost, I had to make some changes to it so that it can run nicely on the university’s server. It’s quite a chore to install ffmpeg there – which whisper requires by default to read in sound. Here, we skip this step, but due to this the transcription function needs to be rewritten from scratch. However, this comes with the shortcoming of the model in this script only accepting .wav files. This can be circumnavigated by using the audioread library (find more infos here).\n\ndef load_audio_manually(file_path, target_sr=16000):\n    sr, audio = wavfile.read(file_path)\n    if audio.ndim &gt; 1:\n        audio = np.mean(audio, axis=1)\n    if sr != target_sr:\n        import librosa\n        audio = librosa.resample(audio.astype(np.float32), orig_sr=sr, target_sr=target_sr)\n    return audio\n\ndef transcribe_audio(file_path): #transcribe it\n    audio = load_audio_manually(file_path)\n    audio = audio.astype(np.float32) / 32768.0  # Normalize if original was int16\n    result = whisper_model.transcribe(audio)\n    return result\n\nNow we canmake our first transcription:\n\nihaveadream_transcript = transcribe_audio(\"files/mlk_ihaveadream.wav\")\nihaveadream_transcript[\"text\"]\nihaveadream_transcript[\"segments\"][0]"
  },
  {
    "objectID": "11_transcription.html#diarization",
    "href": "11_transcription.html#diarization",
    "title": "Chapter 11: OpenAI whisper",
    "section": "Diarization",
    "text": "Diarization\n\n\n\n\n\n\n\n\n\nWe can also use speaker diarization to split audio files by speaker and transcribe each segment separately. This is particularly useful if the recording contains multiple speakers. Here, we use the AudioSegment class from pydub to load the audio file. The pipeline object is used to iterate over the speaker turns, and we save each speaker segment to a separate audio file.\n\n# Load for pydub (segmentation)\naudio = AudioSegment.from_wav(\"files/thisisamerica_200_snippet.wav\")\n\n# Load audio for diarization\nwaveform, sample_rate = torchaudio.load(\"files/thisisamerica_200_snippet.wav\")\n\ndiarization_output = pipeline(\n    {\n        \"waveform\": waveform,\n        \"sample_rate\": sample_rate\n    },\n    min_speakers=2\n    )\n\ndiarization = diarization_output.speaker_diarization\n\n# Now iterate using itertracks on the annotation object\nfor turn, _, speaker in diarization.itertracks(yield_label=True):\n    start_time = turn.start * 1000\n    end_time = turn.end * 1000\n    segment_audio = audio[start_time:end_time]\n    segment_file = f\"files/carrboro_market/{speaker}-{int(turn.start)}-{int(turn.end)}.wav\"\n    segment_audio.export(segment_file, format=\"wav\")\n    print(f\"Saved segment: {segment_file}\")\n\nNext, we want to transcribe each of the diarized segments and save the results to a CSV file.\n\nimport pandas as pd\nimport glob\n\n# Initialize lists to store each attribute separately\nspeakers = []\nstart_times = []\nend_times = []\ntexts = []\n\ndef transcribe_and_collect(file_path, speaker, start_time, end_time):\n    # Perform transcription\n    result = transcribe_audio(file_path)  # Assuming transcribe_audio function exists\n    # Append each attribute to its respective list\n    speakers.append(speaker)\n    start_times.append(start_time)\n    end_times.append(end_time)\n    texts.append(result['text'])\n\n\n# Iterate over diarized segments (assuming you have diarization data)\nfor segment_file in glob.glob(\"files/carrboro_market/SPEAKER_*.wav\"):\n    parts = segment_file.split('-')\n    speaker = parts[0].split(\"/\")[2]\n    start_time = float(parts[1])\n    end_time = float(parts[2].split('.')[0])\n    transcribe_and_collect(segment_file, speaker, start_time, end_time)\n\n# Write the DataFrame to a CSV file\ntranscriptions_df = pd.DataFrame({\n    \"speaker\": speakers,\n    \"start\": start_times,\n    \"end\": end_times,\n    \"text\": texts\n})\n\ntranscriptions_df\n# Write the DataFrame to a CSV file\ntranscriptions_df.to_csv(\"files/transcriptions.csv\", index=False)\n\nSo that we can finally read it back in and wrangle the results in R.\n\nneeds(tidyverse)\ntranscriptions_df &lt;- readr::read_csv(\"files/transcriptions.csv\") |&gt; \n  dplyr::arrange(start)\n\nRows: 85 Columns: 4\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (2): speaker, text\ndbl (2): start, end\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nSo here we are, a quick introduction to transcription and diarization in Python."
  },
  {
    "objectID": "11_transcription.html#further-links",
    "href": "11_transcription.html#further-links",
    "title": "Chapter 11: OpenAI whisper",
    "section": "Further links",
    "text": "Further links\n\nwhisper GitHub repository\nPyannote audio documentation"
  },
  {
    "objectID": "10_tesseract.html",
    "href": "10_tesseract.html",
    "title": "Chapter 10: OCR with tesseract",
    "section": "",
    "text": "This chapter demonstrates how you can read images and PDF documents into R in an automated fashion. Note that OCR is not always perfect and you might have to do some significant pre- and/or post-processing. I have included some classic pre-processing commands from the magick package, post-processing will usually be conducted using RegExes."
  },
  {
    "objectID": "10_tesseract.html#install-tesseract-and-download-language-packages",
    "href": "10_tesseract.html#install-tesseract-and-download-language-packages",
    "title": "Chapter 10: OCR with tesseract",
    "section": "Install tesseract and download language packages",
    "text": "Install tesseract and download language packages\n\n\n\n\n\n\n\n\n\nBefore we can start OCRing images, we need to install tesseract via the command line. The reason for this is that the R package merely binds to the engine, but the OCRing happens “under the hood.” You can find instructions on how to install tesseract for your respective operating system here.\nOnce successfully installed, we can just load the package. In order to get the best results, we need to define the language our text is in. Multiple options are available (for a list of languages, see this website) and can be downloaded using tesseract::tesseract_download() (for Mac and Windows users).\n\nneeds(tesseract)\nenglish &lt;- tesseract(\"eng\") # use English model\n\ntesseract_download(\"deu\") # download German language model\n\nTraining data already exists. Overwriting /Users/felixlennert/Library/Application Support/tesseract5/tessdata/deu.traineddata\n\n\n[1] \"/Users/felixlennert/Library/Application Support/tesseract5/tessdata/deu.traineddata\"\n\ntesseract_info()[[\"available\"]] # check available languages\n\n[1] \"deu\"  \"eng\"  \"osd\"  \"snum\""
  },
  {
    "objectID": "10_tesseract.html#ocr-101",
    "href": "10_tesseract.html#ocr-101",
    "title": "Chapter 10: OCR with tesseract",
    "section": "OCR 101",
    "text": "OCR 101\nOnce the package and the language module is installed, you can start OCRing. For illustration purposes, we OCR the first paragraph of the RStudio Wikipedia article:\n\n\nocr(\"figures/rstudio_wiki.png\", engine = english)\n\n[1] \"RStudio IDE (or RStudio) is an integrated development environment for R, a\\nprogramming language for statistical computing and graphics. It is available in two\\nformats: RStudio Desktop is a regular desktop application while RStudio Server runs on\\na remote server and allows accessing RStudio using a web browser. The RStudio IDE\\nis a product of Posit PBC (formerly RStudio PBC, formerly RStudio Inc.).\\n\"\n\n\nNote that there are still line breaks in there. We can easily replace them with whitespace them using stringr::str_replace_all(). Make sure to remove redundant whitespaces using stringr::str_squish()\n\nneeds(tidyverse)\nocr(\"figures/rstudio_wiki.png\", engine = english) |&gt; \n  str_replace_all(\"\\\\n\", \" \") |&gt; \n  str_squish()\n\n[1] \"RStudio IDE (or RStudio) is an integrated development environment for R, a programming language for statistical computing and graphics. It is available in two formats: RStudio Desktop is a regular desktop application while RStudio Server runs on a remote server and allows accessing RStudio using a web browser. The RStudio IDE is a product of Posit PBC (formerly RStudio PBC, formerly RStudio Inc.).\"\n\n\nIf we want deeper insights to the confidence tesseract has in its word guesses, use tesseract::ocr_data().\n\nocr_data(\"figures/rstudio_wiki.png\", engine = english)\n\n# A tibble: 63 × 3\n   word        confidence bbox           \n   &lt;chr&gt;            &lt;dbl&gt; &lt;chr&gt;          \n 1 RStudio           91.8 14,18,134,43   \n 2 IDE               96.6 145,19,196,42  \n 3 (or               93.3 207,18,245,49  \n 4 RStudio)          92.9 256,18,385,49  \n 5 is                96.3 397,19,418,43  \n 6 an                96.3 429,24,461,43  \n 7 integrated        96.5 474,18,612,49  \n 8 development       93.7 624,18,806,49  \n 9 environment       96.5 816,19,991,43  \n10 for               93.2 1001,18,1038,43\n# ℹ 53 more rows"
  },
  {
    "objectID": "10_tesseract.html#advanced-ocr-with-magick-preprocessing",
    "href": "10_tesseract.html#advanced-ocr-with-magick-preprocessing",
    "title": "Chapter 10: OCR with tesseract",
    "section": "Advanced OCR with magick preprocessing",
    "text": "Advanced OCR with magick preprocessing\nThis worked quite well. One reason for this is that screenshots from the internet are usually very “clean.” However, often this is not the case, especially with book scans. There might be some noise/speckles in the image, some skewed text, etc. In our next example, we OCR the first page of the “Text As Data” book and preprocess it with magick (find instructions for magick here)\n\n\n\nTable of contents of Grimmer, Roberts, and Stewart (2022)\n\n\n\nocr(\"figures/tad_toc.png\") |&gt; \n  cat()\n\nPreface i\nPrerequisites and Notation xvll\nUses for This Book wl\nWhat This Book Is Not —\nPART |! PRELIMINARIES 1\nCHAPTER 1 Introduction 3\n1.1. How This Book Informs the Social Sciences 5\n1.2. How This Book Informs the Digital Humanities 8\n1.3 How This Book Informs Data Science in Industry\nand Government\n1.4  AGuide to This Book 2\n1.5 Conclusion *\nCHAPTER 2 Social Science Research and Text Analysis 13\n2.1 Discovery\n2.2 Measurement 18\n2.3. Inference ae\n2.4 Social Science as an Iterative and W\nCumulative Process\n2.5 An Agnostic Approach to Text Analysis\n2.6 Discovery, Measurement, and Causal Inference:\nHow the Chinese Government Censors Social\nMedia 20\n2.7 Six Principles of Text Analysis 22\n2.71 Social Science Theories and Substantive\nKnowledge are Essential for Research Design 22\n2.7.2 Text Analysis does not Replace Humans—lt\nAugments Them 24\n273 Building, Refining, and Testing Social Science\nTheories Requires Iteration and Cumulation 26\n2.74 Text Analysis Methods Distill Generalizations\nfrom Language 28\n2.75 The Best Method Depends on the Task 29\n\n\nAs we can see, there are a couple of problems – some page numbers are not detected correctly, some typos, etc. Perhaps, some manual image pre-processing can help here.\n\nneeds(magick)\n\nimage_read(\"figures/tad_toc.png\") |&gt; \n  image_resize(\"90%\") |&gt; # play around with this parameter\n  image_rotate(degrees = 3) |&gt; #straighten picture\n  image_contrast(sharpen = 100) |&gt;  # increases contrast\n  image_convert(type = \"Grayscale\") |&gt; # black and white\n  image_trim() |&gt; #trim image to remove margins \n  ocr() |&gt; \n  cat()\n\nPreface xvii\nPrerequisites and Notation xvii\nUses for This Book xviii\nWhat This Book Is Not min\nPARTI PRELIMINARIES 1\nCHAPTER 1 Introduction 3\n1.1. How This Book Informs the Social Sciences 5\n1.2 How This Book Informs the Digital Humanities 8\n1.3. How This Book Informs Data Science in Industry\nand Government 9\n1.4 A Guide to This Book 10\n1.5 Conclusion n\nCHAPTER 2 __ Social Science Research and Text Analysis 13\n2.1 Discovery 15\n2.2 Measurement 16\n2.3 Inference 17\n2.4 Social Science as an Iterative and\nCumulative Process 7\n2.5 An Agnostic Approach to Text Analysis 18\n2.6 Discovery, Measurement, and Causal Inference:\nHow the Chinese Government Censors Social\nMedia 20\n2.7 Six Principles of Text Analysis 22\n2.71 Social Science Theories and Substantive\nKnowledge are Essential for Research Design 22)\n2.72 Text Analysis does not Replace Humans—It\nAugments Them 24\n2.73 Building, Refining, and Testing Social Science\nTheories Requires Iteration and Cumulation 26\n2.74 Text Analysis Methods Distill Generalizations\nfrom Language 28\n2.75 The Best Method Depends on the Task 29\n\n\nSlight improvements! Still not perfect, but OCR hardly ever is."
  },
  {
    "objectID": "10_tesseract.html#read-pdfs",
    "href": "10_tesseract.html#read-pdfs",
    "title": "Chapter 10: OCR with tesseract",
    "section": "Read PDFs",
    "text": "Read PDFs\nIf we want to read PDFs, we can also harness the power of tesseract in combination with magick and pdftools. In this example, I ocr a multi-page PDF document containing newspaper articles.\n\nneeds(pdftools)\ngerman &lt;- tesseract(language = \"deu\")\n\ntexts &lt;- map(1:pdf_info(\"figures/snippet_dereko.pdf\")$pages, \n              \\(x) {\n                pdf_render_page(\"figures/snippet_dereko.pdf\", page = x, dpi = 300) |&gt; \n                  image_read() |&gt; # Convert raw image to magick image object\n                  ocr(engine = german) # OCR\n                }) |&gt; \n  reduce(c)\n\ntexts |&gt; str_sub(1, 1000) |&gt; cat()\n\n© Leibniz-Institut für Deutsche Sprache, Mannheim\nCOSMAS II-Server, C2API-Version 4.23.8 - 21.11.2023\nglemm - a German lemmatizer, version R-2.4.4, 04.07.2022 by Cyril Belica\nDatum : Montag, den A. Dezember 2023, 20:20:01\nArchiv : W - Archiv der geschriebenen Sprache\nKorpus : D-Korpora - Korpora aus Deutschland\nArchiv-Release: Deutsches Referenzkorpus DeRekKo-2023-I\nSuchanfrage : (((nakba or (unabhängi* or staatsgründung)) and\n(palästin* or israel*)) and 1948)\nSuchoptionen : Ei+tRi+Di, Flex\nErgebnis : 4.231 Treffer\nBelege (unsortiert)\nAnz. Treffer ı 4.231\nAnz. exportierte Belege: 4.231\nAngezeigter Kontext : 0 Absätze links, © Absätze rechts\nKontext umschließt : gesamten Treffer\nWie nirgends sonst ist im Heiligen Land die Kartografie eine Teildisziplin der Politik. Wer zwischen Israelis und Palästinensern pendelt, wird\nvon beiden Seiten mit oft höchst unterschiedlichen Landkarten ausgestattet: Hier ist von Jerusalem, dort von Al-Quds die Rede, mal fehlen\nGrenzlinien, mal liegen sie woan bewusst als Veranstaltungsort gewählt worden. Bundesweit soll auf über 500 Veranstaltungen die Staatsgründung gefeiert werden.\n(HAZ08/FEB.05113 Hannoversche Allgemeine, 27.02.2008, S. 2; Festakt zu Ehren Israels)\n\nGeburt einer nation 60 jahre Israel\n\nP\n\n1. Aufbruch nach Palästina — Die Vorgeschichte des Neuanfangs\n\n2. Staatsgründung 1948 - Die Probleme einer neuen Existenz\n\n(HAZ08/MA1.00830 Hannoversche Allgemeine, 06.05.2008, S. 5;)\n\nZu Besuch bei den Kibbuzniks — den wichtigsten Pionieren in Israels Gründerzeit\n\nVon Dirk Schmaler\n\n« Schluchot. Es sieht so aus, als sei er schon immer da gewesen. Der Stamm des riesigen Eukalyptusbaums ist mächtig und ragt mindestens\n20 Meter in den hellblauen Himmel. „Als wir den Kibbuz gründeten, haben wir als erstes diesen Baum gepflanzt, es war unser erstes Baby“,\nsagt Uri Landau und klopft auf das trockene Holz. Sie haben viel gemeinsam, der 80-jährige Mann mit dem sonnengegerbten Gesicht und\ndieser australische Eukalyptusbaum, der in der Siedlung  Das Auto hält sich an die religiösen Regeln am Shabbat, an dem keine Arbeit getan, kein Lichtschalter betätigt und kein Wagen gefahren\nwerden soll. Der uralte Volvo von Rose Bilbool springt nicht an. Doch bei der 86 Jahre alten, energischen Dame hat ein unwilliges Vehikel\nkeine Chance. Mechaniker Ahmed wird gerufen, er setzt das Auto in Gang und Rose Bilbool fährt nach Jericho.\n\nJerusalem wirkt am Shabbat wie eine verlassene Museums-Stadt. Der dunkle Teppich auf dem Hügel voraus ist der Ölberg, in der Ferne tupft\ndie Kuppel des Felsendoms einen goldenen Fleck in den Himmel. Die weißen Sandstein-Fassaden der Häuser sind heute so ziemlich das\neinzige Band, das den Osten und Westen der Stadt verbindet. (B98/FEB.12407 Berliner Zeitung, 27.02.1998; Vom Kommen und Bleiben\n[S. I)\n\nMit der Verlesung der Unabhängigkeitserklärung durch David Ben-Gurion 1948 wird die Vision der Zionisten Realität\n\nJulius H. Schoeps\n\nZwischen dem Baseler Kongreß 1897 und der Gründung des Staates Israel liegt ein h (B98/MA1.29532 Berliner Zeitung, 15.05.1998; PALÄSTINA [S. 6])\n\nIsraelis und Palästinenser erinnern sich an 1948\n\nInge Günther\n\nLeicht sind sie zu übersehen, die Überreste jener arabischen Dörfer und Städte im israelischen Kernland, die für die Palästinenser el-Nakba\nmarkieren, ihre große Katastrophe. Oft ist nicht mehr als ein von Kakteen überwucherter Steinhaufen übriggeblieben. Wie zum Beispiel von\nBeit Nuba, das 1948 von der Haganah niedergemacht wurde — dem jüdischen Widerstand, der nach der Staatsgründung die offizielle Armee\nstellte. Beit Nuba lag an der im Teilungsplan festgelegten grünen Linie und zudem, wie zahlreiche andere Orte, im strategisch wichtigen und\ndeshalb so heftig umkämpften Westkorridor nach Jerusalem.\n\nSelbst Saleh Abdel Jawad, Direktor des historischen Dokumentationszentrums an der palästinensischen Birzeit-Universität, hat Mühe, die\nStelle genau zu lokalisieren. (B98/JUL.40972 Berliner Zeitung, 01.07.1998; Die Grautöne der Wahrheit treten hervor [S. 13])\n\nAls\n\n\nEasy!"
  },
  {
    "objectID": "10_tesseract.html#further-links",
    "href": "10_tesseract.html#further-links",
    "title": "Chapter 10: OCR with tesseract",
    "section": "Further links",
    "text": "Further links\n\ntesseract R package manual\nmagick R package manual"
  },
  {
    "objectID": "10_tesseract.html#exercises",
    "href": "10_tesseract.html#exercises",
    "title": "Chapter 10: OCR with tesseract",
    "section": "Exercises",
    "text": "Exercises\nIn general, you could try all the rvest exercises with selenium to see how these things differ. Also every page is different, therefore it will probably be best if you just start with your own things. However, here is a quite tricky example.\n\nTake a screenshot of a page of your liking and OCR it. Post-process.\n\n\n\nSolution. Click to expand!\n\n\nocr(\"figures/rstudio_wiki.png\", engine = english) |&gt; \n  str_replace_all(\"\\\\n\", \" \") |&gt; \n  str_squish()\n\n\n\nOCR a PDF document you have available (e.g., one of the course readings). If you get the error “Image too small to scale,” you can use magick::image_resize().\n\n\n\nSolution. Click to expand!\n\n\ntexts &lt;- map(1:3, \n              \\(x) {\n                pdf_render_page(\"figures/Stoltz:Taylor 2020.pdf\", page = x, dpi = 300) |&gt; \n                  image_read() |&gt; # Convert raw image to magick image object\n                  image_resize(\"300%\") |&gt; \n                  ocr(engine = english) # OCR\n                }) |&gt; \n  reduce(c)"
  },
  {
    "objectID": "3_reticulate.html",
    "href": "3_reticulate.html",
    "title": "Chapter 3: reticulate",
    "section": "",
    "text": "The reticulate package provides a comprehensive set of tools for interoperability between Python and R. It allows you to call Python from R in a variety of ways, including importing Python modules, sourcing Python scripts, and using Python interactively from R.\n\nneeds(reticulate, tidyverse)\n\n\n\nBefore you can use Python in R, you need to ensure Python is installed on your system. The reticulate package will try to find Python automatically, but you can also specify which Python to use.\nFor a consistent experience across Windows and Mac, I recommend using reticulate’s built-in miniconda installation helper:\n\ninstall_miniconda()\n\nThis will install a minimal version of conda, which is a package and environment management system that works well for both R and Python.\nI would recommend using a conda environment for managing Python packages, as it helps avoid conflicts. When creating the environment, you can specify the Python version (this is important since not all Python versions are compatible with all package versions, unlike R) and packages you need. For example, to create an environment named “toolbox_env” with the numpy package:\n\nconda_create(\"toolbox_env\", packages = c(\"python=3.9\", \"numpy\"))\n\nIf you work in Positron, you might need to go to settings and select the Python interpreter from this environment. In RStudio, this can be done by navigating to Tools -&gt; Global Options -&gt; Python and selecting the appropriate interpreter. An overview of all conda environments and their paths can be found with:\n\nconda_list()\n\n          name\n1         base\n2 selenium_env\n3  toolbox_env\n                                                                      python\n1                   /Users/felixlennert/Library/r-miniconda-arm64/bin/python\n2 /Users/felixlennert/Library/r-miniconda-arm64/envs/selenium_env/bin/python\n3  /Users/felixlennert/Library/r-miniconda-arm64/envs/toolbox_env/bin/python\n\n\nSide note: you can remove an environment with\n\nconda_remove(\"r-reticulate\")\n\n\n\n\nBefore you can get started, you need to tell reticulate to use this environment:\n\nuse_condaenv(\"toolbox_env\", required = TRUE)\n\nFurther, post-creation, you can install Python packages into this environment directly from R:\n\npy_install(c(\"pandas\", \"scikit-learn\"))\n\nIn Quarto documents, like this one, you can use Python chunks directly by using the {python} engine (i.e., by typing ```{python} instead of ```{r} when creating a code block):\n\n# This is a Python chunk\nimport pandas as pd\nimport numpy as np\n\ndata = {\n    'name': ['Alice', 'Bob', 'Charlie', 'David'],\n    'age': [25, 30, 35, 40],\n    'score': [85.5, 92.0, 78.5, 88.0]\n}\n\ndf = pd.DataFrame(data)\nprint(df)\n\n      name  age  score\n0    Alice   25   85.5\n1      Bob   30   92.0\n2  Charlie   35   78.5\n3    David   40   88.0\n\n\nThe objects created in Python chunks are accessible in R if you make them globally accessible. For example, the df DataFrame created above can be accessed in R as follows:\n\ndf_r &lt;- py$df\nprint(df_r)\n\n     name age score\n1   Alice  25  85.5\n2     Bob  30  92.0\n3 Charlie  35  78.5\n4   David  40  88.0\n\n\nHowever, note that this is only the case when knitting the document. If you run the chunks interactively, the objects won’t be available in R.\nYou can enable availability behavior while coding by running Python code directly from R using the py_run_string() function:\n\npy_run_string(\"\nimport pandas as pd\nimport numpy as np\n\ndata = {\n    'name': ['Alice', 'Bob', 'Charlie', 'David'],\n    'age': [25, 30, 35, 40],\n    'score': [85.5, 92.0, 78.5, 88.0]\n}\n\ndf = pd.DataFrame(data)\nprint(df)\n\")\n\n      name  age  score\n0    Alice   25   85.5\n1      Bob   30   92.0\n2  Charlie   35   78.5\n3    David   40   88.0\n\n# This should work\nprint(py$df)\n\n     name age score\n1   Alice  25  85.5\n2     Bob  30  92.0\n3 Charlie  35  78.5\n4   David  40  88.0\n\n\nThat’s a bit cumbersome for larger code blocks, so you can also use py_run_file() to source a Python script. Note that the output objects might differ in type when accessed from R. For example, this pandas data frame becomes a named list in R.\n\npy_run_file(\"data/create_name_tbl.py\")\n\ndata_list &lt;- py$data\ntypeof(data_list)\n\n[1] \"list\"\n\n\nThis is however easily fixable:\n\ndata_list |&gt; bind_cols()\n\n# A tibble: 4 × 3\n  name      age score\n  &lt;chr&gt;   &lt;int&gt; &lt;dbl&gt;\n1 Alice      25  85.5\n2 Bob        30  92  \n3 Charlie    35  78.5\n4 David      40  88  \n\n\nAnother way of sharing objects between R and Python is of course by writing a file to disc. You can save data frames as CSV files in R and read them into Python, or vice versa. Make sure to set index=False when saving from Python to avoid an extra index column.\n\ndf.to_csv(\"data/people.csv\", index=False)\ndf.to_csv(\"data/people_w_index.csv\", index=True)\n\n\nread_csv(\"data/people.csv\")\n\nRows: 4 Columns: 3\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (1): name\ndbl (2): age, score\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n# A tibble: 4 × 3\n  name      age score\n  &lt;chr&gt;   &lt;dbl&gt; &lt;dbl&gt;\n1 Alice      25  85.5\n2 Bob        30  92  \n3 Charlie    35  78.5\n4 David      40  88  \n\nread_csv(\"data/people_w_index.csv\")\n\nNew names:\nRows: 4 Columns: 4\n── Column specification\n──────────────────────────────────────────────────────── Delimiter: \",\" chr\n(1): name dbl (3): ...1, age, score\nℹ Use `spec()` to retrieve the full column specification for this data. ℹ\nSpecify the column types or set `show_col_types = FALSE` to quiet this message.\n• `` -&gt; `...1`\n\n\n# A tibble: 4 × 4\n   ...1 name      age score\n  &lt;dbl&gt; &lt;chr&gt;   &lt;dbl&gt; &lt;dbl&gt;\n1     0 Alice      25  85.5\n2     1 Bob        30  92  \n3     2 Charlie    35  78.5\n4     3 David      40  88  \n\n\n\n\n\n\nreticulate documentation"
  },
  {
    "objectID": "3_reticulate.html#using-python-in-r-with-reticulate",
    "href": "3_reticulate.html#using-python-in-r-with-reticulate",
    "title": "Chapter 3: reticulate",
    "section": "",
    "text": "The reticulate package provides a comprehensive set of tools for interoperability between Python and R. It allows you to call Python from R in a variety of ways, including importing Python modules, sourcing Python scripts, and using Python interactively from R.\n\nneeds(reticulate, tidyverse)\n\n\n\nBefore you can use Python in R, you need to ensure Python is installed on your system. The reticulate package will try to find Python automatically, but you can also specify which Python to use.\nFor a consistent experience across Windows and Mac, I recommend using reticulate’s built-in miniconda installation helper:\n\ninstall_miniconda()\n\nThis will install a minimal version of conda, which is a package and environment management system that works well for both R and Python.\nI would recommend using a conda environment for managing Python packages, as it helps avoid conflicts. When creating the environment, you can specify the Python version (this is important since not all Python versions are compatible with all package versions, unlike R) and packages you need. For example, to create an environment named “toolbox_env” with the numpy package:\n\nconda_create(\"toolbox_env\", packages = c(\"python=3.9\", \"numpy\"))\n\nIf you work in Positron, you might need to go to settings and select the Python interpreter from this environment. In RStudio, this can be done by navigating to Tools -&gt; Global Options -&gt; Python and selecting the appropriate interpreter. An overview of all conda environments and their paths can be found with:\n\nconda_list()\n\n          name\n1         base\n2 selenium_env\n3  toolbox_env\n                                                                      python\n1                   /Users/felixlennert/Library/r-miniconda-arm64/bin/python\n2 /Users/felixlennert/Library/r-miniconda-arm64/envs/selenium_env/bin/python\n3  /Users/felixlennert/Library/r-miniconda-arm64/envs/toolbox_env/bin/python\n\n\nSide note: you can remove an environment with\n\nconda_remove(\"r-reticulate\")\n\n\n\n\nBefore you can get started, you need to tell reticulate to use this environment:\n\nuse_condaenv(\"toolbox_env\", required = TRUE)\n\nFurther, post-creation, you can install Python packages into this environment directly from R:\n\npy_install(c(\"pandas\", \"scikit-learn\"))\n\nIn Quarto documents, like this one, you can use Python chunks directly by using the {python} engine (i.e., by typing ```{python} instead of ```{r} when creating a code block):\n\n# This is a Python chunk\nimport pandas as pd\nimport numpy as np\n\ndata = {\n    'name': ['Alice', 'Bob', 'Charlie', 'David'],\n    'age': [25, 30, 35, 40],\n    'score': [85.5, 92.0, 78.5, 88.0]\n}\n\ndf = pd.DataFrame(data)\nprint(df)\n\n      name  age  score\n0    Alice   25   85.5\n1      Bob   30   92.0\n2  Charlie   35   78.5\n3    David   40   88.0\n\n\nThe objects created in Python chunks are accessible in R if you make them globally accessible. For example, the df DataFrame created above can be accessed in R as follows:\n\ndf_r &lt;- py$df\nprint(df_r)\n\n     name age score\n1   Alice  25  85.5\n2     Bob  30  92.0\n3 Charlie  35  78.5\n4   David  40  88.0\n\n\nHowever, note that this is only the case when knitting the document. If you run the chunks interactively, the objects won’t be available in R.\nYou can enable availability behavior while coding by running Python code directly from R using the py_run_string() function:\n\npy_run_string(\"\nimport pandas as pd\nimport numpy as np\n\ndata = {\n    'name': ['Alice', 'Bob', 'Charlie', 'David'],\n    'age': [25, 30, 35, 40],\n    'score': [85.5, 92.0, 78.5, 88.0]\n}\n\ndf = pd.DataFrame(data)\nprint(df)\n\")\n\n      name  age  score\n0    Alice   25   85.5\n1      Bob   30   92.0\n2  Charlie   35   78.5\n3    David   40   88.0\n\n# This should work\nprint(py$df)\n\n     name age score\n1   Alice  25  85.5\n2     Bob  30  92.0\n3 Charlie  35  78.5\n4   David  40  88.0\n\n\nThat’s a bit cumbersome for larger code blocks, so you can also use py_run_file() to source a Python script. Note that the output objects might differ in type when accessed from R. For example, this pandas data frame becomes a named list in R.\n\npy_run_file(\"data/create_name_tbl.py\")\n\ndata_list &lt;- py$data\ntypeof(data_list)\n\n[1] \"list\"\n\n\nThis is however easily fixable:\n\ndata_list |&gt; bind_cols()\n\n# A tibble: 4 × 3\n  name      age score\n  &lt;chr&gt;   &lt;int&gt; &lt;dbl&gt;\n1 Alice      25  85.5\n2 Bob        30  92  \n3 Charlie    35  78.5\n4 David      40  88  \n\n\nAnother way of sharing objects between R and Python is of course by writing a file to disc. You can save data frames as CSV files in R and read them into Python, or vice versa. Make sure to set index=False when saving from Python to avoid an extra index column.\n\ndf.to_csv(\"data/people.csv\", index=False)\ndf.to_csv(\"data/people_w_index.csv\", index=True)\n\n\nread_csv(\"data/people.csv\")\n\nRows: 4 Columns: 3\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (1): name\ndbl (2): age, score\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n# A tibble: 4 × 3\n  name      age score\n  &lt;chr&gt;   &lt;dbl&gt; &lt;dbl&gt;\n1 Alice      25  85.5\n2 Bob        30  92  \n3 Charlie    35  78.5\n4 David      40  88  \n\nread_csv(\"data/people_w_index.csv\")\n\nNew names:\nRows: 4 Columns: 4\n── Column specification\n──────────────────────────────────────────────────────── Delimiter: \",\" chr\n(1): name dbl (3): ...1, age, score\nℹ Use `spec()` to retrieve the full column specification for this data. ℹ\nSpecify the column types or set `show_col_types = FALSE` to quiet this message.\n• `` -&gt; `...1`\n\n\n# A tibble: 4 × 4\n   ...1 name      age score\n  &lt;dbl&gt; &lt;chr&gt;   &lt;dbl&gt; &lt;dbl&gt;\n1     0 Alice      25  85.5\n2     1 Bob        30  92  \n3     2 Charlie    35  78.5\n4     3 David      40  88  \n\n\n\n\n\n\nreticulate documentation"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Welcome",
    "section": "",
    "text": "This is a Quarto website for the “Forschungsseminar CSS” course at Leipzig University. It covers different techniques for the aspiring computational social scientist, hence I have dubbed it “Toolbox CSS.” You can reach me anytime at felix.lennert@uni-leipzig.de. If you’re interested in my academic work, you can visit my website.\nHere’s the official description:\nThe curriculum covers a range of topics including data management, web scraping, speech-to-text, and computational text analysis. Students will hone their R and develop skills in Python, applying these languages to real-world social science problems. The course progresses from fundamental concepts to advanced techniques, including the use of state-of-the-art AI models for text analysis.\nThe course structure consists of one lecture and one lab session per week, providing a balance of theoretical knowledge and practical application. Throughout the semester, students will benefit from hands-on coding exercises, one-on-one mentoring, and collaborative projects. The course culminates in a research paper, allowing students to apply their new skills to a topic of their choice."
  },
  {
    "objectID": "index.html#course-structure",
    "href": "index.html#course-structure",
    "title": "Welcome",
    "section": "Course Structure",
    "text": "Course Structure\nThe course consists of lectures introducing each week’s content and a course script that provides hands-on coding examples for the content. It is mostly containing R with some Python mixed in for good measure when no great R alternatives exist (e.g., for web scraping with Selenium, text classification with transformer models).\nAt the beginning of the course, students are encouraged to form groups based on research interests and general vibes. I require each student group to check in with me at the beginning of each week to report their progress (even if there’s nothing to report – no progress, no problem). This does not count towards any grade but rather serves the purpose of me receiving feedback on the learning experience (this is a new course!) – and will hopefully help me with providing more appropriate guidance.\nHere’s an overview of the topics covered:\n\n\n\n\n\n\n\n\n\nWEEK\nTITLE\nCONTENT\nINFORMAL TITLE\n\n\n\n\n1\nKick Off\nHousekeeping; Setting up workstation; R recap\nWhatever you want to know about CSS\n\n\n2\nBrief Intro to Python & Regexes\nPython basics (reticulate, data types, loops, functions, pandas); Regular expressions with stringr\nREGEXES – tame your data\n\n\n3\nData Acquisition I\nHow the web is written and ethics; rvest web scraping\nstealing data from websites without them noticing it\n\n\n4\nData Acquisition II\nDynamic pages and forms with selenium; APIs with httr2\nstealing MORE data from websites\n\n\n5\nData Acquisition III\nIntro to OCR with tesseract and transcription (OpenAI Whisper)\nmaking the computer your transcription servant\n\n\n6\nData Acquisition IV\nBuffer sessions ; Project discussion\nQuestions?\n\n\n7\nStudent Project Week\nWork on projects in class\ntime to get your hands dirty\n\n\n8\nText as Data I\nBag of words; Sentiment analysis, TF-IDF, NER/POS\nbasic text analysis\n\n\n9\nText as Data II\nSupervised machine learning in theory and practice\nadvanced text analysis with training data\n\n\n10\nText as Data III\nUnsupervised ML (topic modeling); Remote counseling pre-Christmas\nfinding patterns without labels\n\n\n11\nText as Data IV\nMeasuring similarity and distributional hypothesis; Word embeddings\ncutting-edge text analysis with vector spaces\n\n\n12\nText as Data V\nSupervised learning on steroids (BERT); Active learning with BERT\nholy shit…transformer models\n\n\n13\nText as Data VI\nLLMs for information extraction; Local LLMs primer\nunleashing the power of large language models\n\n\n14\nPresentation Preparation Week\nWork on presentations (deadline Jan 30, 6PM)\npolish your masterpiece\n\n\n15\nPresentations & Wrap Up\nPeer-reviewed presentations; Course wrap-up\nshow off your work"
  },
  {
    "objectID": "index.html#syllabus",
    "href": "index.html#syllabus",
    "title": "Welcome",
    "section": "Syllabus",
    "text": "Syllabus\nPlease click here to download the latest version of the syllabus.\n\n\n\nAlternatively, read it here (probably not the best if you’re visiting this page on a mobile device):"
  },
  {
    "objectID": "7_scraping.html",
    "href": "7_scraping.html",
    "title": "Chapter 7: Scraping Static Pages with rvest",
    "section": "",
    "text": "Today’s session will be dedicated to getting data from the web. This process is also called scraping since we scrape data off from the surface (and remodel it for our purposes). The following picture shows you the web scraping cheat sheet that outlines the process of scraping the web. On the left side, you can see the first step in scraping the web which is requesting the information from the server. This is basically what is going under the hood when you make requests using a browser. The response is the website, usually stored in an XML document, which is then the starting point for your subsequent queries and data extraction.\n\n\n\nWeb scraping cheat sheet\n\n\nIn the first part of this chapter, you will learn different techniques to get your hands on data. In particular, this will encompass making simple URL requests with read_html(), using session()s to navigate around on a web page, and submitting html_form()s to fill in forms on a web page. The second part will be dedicated to only choosing particular contents of the page."
  },
  {
    "objectID": "7_scraping.html#intro",
    "href": "7_scraping.html#intro",
    "title": "Chapter 7: Scraping Static Pages with rvest",
    "section": "",
    "text": "Today’s session will be dedicated to getting data from the web. This process is also called scraping since we scrape data off from the surface (and remodel it for our purposes). The following picture shows you the web scraping cheat sheet that outlines the process of scraping the web. On the left side, you can see the first step in scraping the web which is requesting the information from the server. This is basically what is going under the hood when you make requests using a browser. The response is the website, usually stored in an XML document, which is then the starting point for your subsequent queries and data extraction.\n\n\n\nWeb scraping cheat sheet\n\n\nIn the first part of this chapter, you will learn different techniques to get your hands on data. In particular, this will encompass making simple URL requests with read_html(), using session()s to navigate around on a web page, and submitting html_form()s to fill in forms on a web page. The second part will be dedicated to only choosing particular contents of the page."
  },
  {
    "objectID": "7_scraping.html#getting-started-with-rvest",
    "href": "7_scraping.html#getting-started-with-rvest",
    "title": "Chapter 7: Scraping Static Pages with rvest",
    "section": "Getting started with rvest",
    "text": "Getting started with rvest\n\n\n\n\n\n\n\n\n\n\nMaking requests\nThe most basic form of making a request is by using read_html() from the xml2 package.\n\nneeds(httr, rvest, tidyverse)\n\npage &lt;- read_html(\"https://en.wikipedia.org/wiki/Tidyverse\")\n\npage |&gt; str()\n\nList of 2\n $ node:&lt;externalptr&gt; \n $ doc :&lt;externalptr&gt; \n - attr(*, \"class\")= chr [1:2] \"xml_document\" \"xml_node\"\n\npage |&gt; as.character() |&gt; write_lines(\"wiki.html\")\n\n#page |&gt; html_text()\n\nThis is perfectly fine for making requests to static pages where you do not need to take any further action. Sometimes, however, this is not enough, and you want to accept cookies or move on the page.\n\n\nsession()s\nHowever, the slickest way to do this is by using a session(). In a session, R behaves like a normal browser, stores cookies, allows you to navigate between pages, by going session_forward() or session_back(), session_follow_link()s on the page itself or session_jump_to() a different URL, or submit form()s with session_submit().\nFirst, you start the session by simply calling session().\n\nmy_session &lt;- session(\"https://scrapethissite.com/\")\n\nSome servers may not want robots to make requests and block you for this reason. To circumnavigate this, we can set a “user agent” in a session. The user agent contains data that the server receives from us when we make the request. Hence, by adapting it we can trick the server into thinking that we are humans instead of robots. Let’s check the current user agent first:\n\nmy_session$response$request$options$useragent\n\n[1] \"libcurl/8.14.1 r-curl/7.0.0 httr/1.4.7\"\n\n\nNot very human. We can set it to a common one using the httr package (which powers rvest).\n\nuser_a &lt;- user_agent(\"Mozilla/5.0 (Macintosh; Intel Mac OS X 12_0_1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/95.0.4638.69 Safari/537.36\")\n\nsession_with_ua &lt;- session(\"https://scrapethissite.com/\", user_a)\nsession_with_ua$response$request$options$useragent\n\n[1] \"Mozilla/5.0 (Macintosh; Intel Mac OS X 12_0_1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/95.0.4638.69 Safari/537.36\"\n\n\nYou can check the response using session$response$status_code – 200 is good.\n\nmy_session$response$status_code\n\n[1] 200\n\n\nWhen you want to save a page from the session, do so using read_html().\n\npage &lt;- read_html(session_with_ua)\n\nIf you want to open a new URL, use session_jump_to().\n\nsession_with_ua &lt;- session_with_ua |&gt; \n  session_jump_to(\"https://www.scrapethissite.com/pages/\")\nsession_with_ua\n\n&lt;session&gt; https://www.scrapethissite.com/pages/\n  Status: 200\n  Type:   text/html; charset=utf-8\n  Size:   10603\n\n\nYou can also click buttons on the page using CSS selectors or XPATHs (more on them next session!):\n\nsession_with_ua &lt;- session_with_ua |&gt; \n  session_jump_to(\"https://www.scrapethissite.com/\") |&gt; \n  session_follow_link(css = \".btn-default\")\n\nNavigating to &lt;/pages/&gt;.\n\nsession_with_ua\n\n&lt;session&gt; https://www.scrapethissite.com/pages/\n  Status: 200\n  Type:   text/html; charset=utf-8\n  Size:   10603\n\n\nWanna go back – session_back(); thereafter you can go session_forward(), too.\n\nsession_with_ua &lt;- session_with_ua |&gt; \n  session_back()\n\nsession_with_ua\n\n&lt;session&gt; https://www.scrapethissite.com/\n  Status: 200\n  Type:   text/html; charset=utf-8\n  Size:   8117\n\nsession_with_ua &lt;- session_with_ua |&gt; \n  session_forward()\n\nsession_with_ua\n\n&lt;session&gt; https://www.scrapethissite.com/pages/\n  Status: 200\n  Type:   text/html; charset=utf-8\n  Size:   10603\n\n\nYou can look at what your scraper has done with session_history().\n\nsession_with_ua |&gt; session_history()\n\n  https://www.scrapethissite.com/\n  https://www.scrapethissite.com/pages/\n  https://www.scrapethissite.com/\n- https://www.scrapethissite.com/pages/\n\n\n\n\nExercise\n\nStart a session with the tidyverse Wikipedia page. Adapt your user agent to some sort of different value. Proceed to Hadley Wickham’s page. Go back. Go forth. Jump to Pierre Bourdieu’s Wikipedia page. Check the session_history() to see if it has worked.\n\n\n\nSolution. Click to expand!\n\n\nneeds(tidyverse, rvest, httr)\ntidyverse_wiki &lt;- \"https://en.wikipedia.org/wiki/Tidyverse\"\npierre_wiki &lt;- \"https://en.wikipedia.org/wiki/Pierre_Bourdieu\"\nuser_agent &lt;- user_agent(\"Hi, I'm Felix and I'm trying to steal your data.\") #can be changed\n\n\nwiki_session &lt;- session(tidyverse_wiki, user_agent)\n\nwiki_session_jumped &lt;- wiki_session |&gt;  \n  session_jump_to(tidyverse_wiki) |&gt; \n  session_back() |&gt; \n  session_forward() |&gt; \n  session_jump_to(pierre_wiki)\n\nwiki_session_jumped |&gt; session_history()\n\n\n\n\nForms\n\n\n\n\n\n\n\n\n\nSometimes we also want to provide certain input, e.g., to provide login credentials or to scrape a website more systematically. That information is usually provided using so-called forms. A &lt;form&gt; element can contain different other elements such as text fields or check boxes. Basically, we use html_form() to extract the form, html_form_set() to define what we want to submit, and html_form_submit() to finally submit it. For a basic example, we search for something on Google.\n\ngoogle &lt;- read_html(\"http://www.google.com\")\nsearch &lt;- html_form(google) |&gt; pluck(1)\n\nsearch |&gt; str()\n\nList of 5\n $ name   : chr \"f\"\n $ method : chr \"GET\"\n $ action : chr \"http://www.google.com/search\"\n $ enctype: chr \"form\"\n $ fields :List of 10\n  ..$ ie    :List of 4\n  .. ..$ type : chr \"hidden\"\n  .. ..$ name : chr \"ie\"\n  .. ..$ value: chr \"ISO-8859-1\"\n  .. ..$ attr :List of 3\n  .. .. ..$ name : chr \"ie\"\n  .. .. ..$ value: chr \"ISO-8859-1\"\n  .. .. ..$ type : chr \"hidden\"\n  .. ..- attr(*, \"class\")= chr \"rvest_field\"\n  ..$ hl    :List of 4\n  .. ..$ type : chr \"hidden\"\n  .. ..$ name : chr \"hl\"\n  .. ..$ value: chr \"de\"\n  .. ..$ attr :List of 3\n  .. .. ..$ value: chr \"de\"\n  .. .. ..$ name : chr \"hl\"\n  .. .. ..$ type : chr \"hidden\"\n  .. ..- attr(*, \"class\")= chr \"rvest_field\"\n  ..$ source:List of 4\n  .. ..$ type : chr \"hidden\"\n  .. ..$ name : chr \"source\"\n  .. ..$ value: chr \"hp\"\n  .. ..$ attr :List of 3\n  .. .. ..$ name : chr \"source\"\n  .. .. ..$ type : chr \"hidden\"\n  .. .. ..$ value: chr \"hp\"\n  .. ..- attr(*, \"class\")= chr \"rvest_field\"\n  ..$ biw   :List of 4\n  .. ..$ type : chr \"hidden\"\n  .. ..$ name : chr \"biw\"\n  .. ..$ value: NULL\n  .. ..$ attr :List of 2\n  .. .. ..$ name: chr \"biw\"\n  .. .. ..$ type: chr \"hidden\"\n  .. ..- attr(*, \"class\")= chr \"rvest_field\"\n  ..$ bih   :List of 4\n  .. ..$ type : chr \"hidden\"\n  .. ..$ name : chr \"bih\"\n  .. ..$ value: NULL\n  .. ..$ attr :List of 2\n  .. .. ..$ name: chr \"bih\"\n  .. .. ..$ type: chr \"hidden\"\n  .. ..- attr(*, \"class\")= chr \"rvest_field\"\n  ..$ q     :List of 4\n  .. ..$ type : chr \"text\"\n  .. ..$ name : chr \"q\"\n  .. ..$ value: chr \"\"\n  .. ..$ attr :List of 8\n  .. .. ..$ class       : chr \"lst\"\n  .. .. ..$ style       : chr \"margin:0;padding:5px 8px 0 6px;vertical-align:top;color:#1f1f1f\"\n  .. .. ..$ autocomplete: chr \"off\"\n  .. .. ..$ value       : chr \"\"\n  .. .. ..$ title       : chr \"Google Suche\"\n  .. .. ..$ maxlength   : chr \"2048\"\n  .. .. ..$ name        : chr \"q\"\n  .. .. ..$ size        : chr \"57\"\n  .. ..- attr(*, \"class\")= chr \"rvest_field\"\n  ..$ btnG  :List of 4\n  .. ..$ type : chr \"submit\"\n  .. ..$ name : chr \"btnG\"\n  .. ..$ value: chr \"Google Suche\"\n  .. ..$ attr :List of 4\n  .. .. ..$ class: chr \"lsb\"\n  .. .. ..$ value: chr \"Google Suche\"\n  .. .. ..$ name : chr \"btnG\"\n  .. .. ..$ type : chr \"submit\"\n  .. ..- attr(*, \"class\")= chr \"rvest_field\"\n  ..$ btnI  :List of 4\n  .. ..$ type : chr \"submit\"\n  .. ..$ name : chr \"btnI\"\n  .. ..$ value: chr \"Auf gut GlÃck!\"\n  .. ..$ attr :List of 5\n  .. .. ..$ class: chr \"lsb\"\n  .. .. ..$ id   : chr \"tsuid_7qgMadzAHKCFxc8P58vF-Ak_1\"\n  .. .. ..$ value: chr \"Auf gut GlÃck!\"\n  .. .. ..$ name : chr \"btnI\"\n  .. .. ..$ type : chr \"submit\"\n  .. ..- attr(*, \"class\")= chr \"rvest_field\"\n  ..$ iflsig:List of 4\n  .. ..$ type : chr \"hidden\"\n  .. ..$ name : chr \"iflsig\"\n  .. ..$ value: chr \"AOw8s4IAAAAAaQy2_o38tGuu_gVjr5UVNRxpTUjlcGZo\"\n  .. ..$ attr :List of 3\n  .. .. ..$ value: chr \"AOw8s4IAAAAAaQy2_o38tGuu_gVjr5UVNRxpTUjlcGZo\"\n  .. .. ..$ name : chr \"iflsig\"\n  .. .. ..$ type : chr \"hidden\"\n  .. ..- attr(*, \"class\")= chr \"rvest_field\"\n  ..$ gbv   :List of 4\n  .. ..$ type : chr \"hidden\"\n  .. ..$ name : chr \"gbv\"\n  .. ..$ value: chr \"1\"\n  .. ..$ attr :List of 4\n  .. .. ..$ id   : chr \"gbv\"\n  .. .. ..$ name : chr \"gbv\"\n  .. .. ..$ type : chr \"hidden\"\n  .. .. ..$ value: chr \"1\"\n  .. ..- attr(*, \"class\")= chr \"rvest_field\"\n - attr(*, \"class\")= chr \"rvest_form\"\n\nsearch_something &lt;- search |&gt; html_form_set(q = \"something\")\nresp &lt;- html_form_submit(search_something, submit = \"btnG\")\nread_html(resp)\n\n{html_document}\n&lt;html lang=\"de\"&gt;\n[1] &lt;head&gt;\\n&lt;meta http-equiv=\"Content-Type\" content=\"text/html; charset=UTF-8 ...\n[2] &lt;body jsmodel=\"hspDDf \"&gt;\\n&lt;script nonce=\"STlOLFdI-hsSDpqw5gC5cA\"&gt;(functio ...\n\nvals &lt;- list(q = \"web scraping\", hl = \"fr\")\n\nsearch_1 &lt;- search |&gt; html_form_set(!!!vals)\nsearch_2 &lt;- search |&gt; html_form_set(q = \"web scraping\", hl = \"fr\")\n\nresp &lt;- html_form_submit(search_1)\nread_html(resp)\n\n{html_document}\n&lt;html lang=\"fr-DE\"&gt;\n[1] &lt;head&gt;\\n&lt;meta http-equiv=\"Content-Type\" content=\"text/html; charset=UTF-8 ...\n[2] &lt;body jsmodel=\"hspDDf \"&gt;\\n&lt;script nonce=\"LM_ClWx4I2rJ1EQ23IBmiQ\"&gt;(functio ...\n\n\nIf you are working with a session, the workflow is as follows:\n\nExtract the form.\nSet it.\nStart your session on the page with the form.\nSubmit the form using session_submit().\n\n\ngoogle_form &lt;- read_html(\"http://www.google.com\") |&gt; \n  html_form() |&gt; \n  pluck(1) #another way to do [[1]]\n\nsearch_something &lt;- google_form |&gt; html_form_set(q = \"something\")\n\ngoogle_session &lt;- session(\"http://www.google.com\") |&gt; \n  session_submit(search_something, submit = \"btnG\")\n\ngoogle_session |&gt; \n  read_html()\n\n{html_document}\n&lt;html lang=\"de\"&gt;\n[1] &lt;head&gt;\\n&lt;meta http-equiv=\"Content-Type\" content=\"text/html; charset=UTF-8 ...\n[2] &lt;body jsmodel=\"hspDDf \"&gt;\\n&lt;script nonce=\"Nfg2DWBbKCSEyznMgADJkA\"&gt;(functio ...\n\n\n\n\nExercise\n\nStart a session on “https://www.scrapethissite.com/pages/forms/”, fill out, and submit the form to search for a Hockey team called Toronto Maple Leafs. Store the resulting output in “base_session”.\n\nYou can check your code by looking at the output of base_session |&gt; read_html() |&gt; html_table() |&gt; pluck(1) and checking whether there are only Maple Leaf entries.\n\n\nSolution. Click to expand!\n\n\nurl &lt;- \"https://www.scrapethissite.com/pages/forms/\"\n\nsearch_form &lt;- read_html(url) |&gt; \n  html_form() |&gt; \n  pluck(1) #extract \n\nset_form &lt;- search_form |&gt; \n  html_form_set(q = \"Toronto Maple Leafs\") #set login form \n\nbase_session &lt;- session(url) |&gt; \n  session_submit(set_form) \n\n\n\nbase_session |&gt; \n  read_html() |&gt; \n  html_table() |&gt; \n  pluck(1)\n\n\n\n\nScraping hacks\nSome web pages are a bit fancier than the ones we have looked at so far (i.e., they use JavaScript). rvest works nicely for static web pages, but for more advanced ones you need different tools such as selenium – see chapter 7.\nA web page may sometimes give you time-outs (i.e., it doesn’t respond within a given time). This can break your loop. Wrapping your code in safely() or insistently() from the purrr package might help. The former moves on and notes down what has gone wrong, the latter keeps sending requests until it has been successful. They both work easiest if you put your scraping code in functions and wrap those with either insistently() or safely().\nSometimes a web page keeps blocking you. Consider using a proxy server.\n\nmy_proxy &lt;- httr::use_proxy(url = \"http://example.com\",\n                            user_name = \"myusername\",\n                            password = \"mypassword\",\n                            auth = \"one of basic, digest, digest_ie, gssnegotiate, ntlm, any\")\n\nmy_session &lt;- session(\"https://scrapethissite.com/\", my_proxy)\n\nFind more useful information – including the stuff we just described – and links on this GitHub page."
  },
  {
    "objectID": "7_scraping.html#extracting-data",
    "href": "7_scraping.html#extracting-data",
    "title": "Chapter 7: Scraping Static Pages with rvest",
    "section": "Extracting Data",
    "text": "Extracting Data\nIn the prior section you learned how to make calls to web pages and get responses. Now it will be all about how you can extract content from web pages in a structured way. The (in our opinion) easiest way to achieve that is by harnessing the way the web is written.\n\n\n\n\n\n\n\n\n\nBefore we start to extract data from the web, we will briefly touch upon how the web is written. This is since we will harness this structure to extract content in an automated manner. Basic commands will be shown thereafter.\n\n#install.packages(\"needs\")\nneeds::needs(janitor, polite, rvest, tidyverse)"
  },
  {
    "objectID": "7_scraping.html#html-101",
    "href": "7_scraping.html#html-101",
    "title": "Chapter 7: Scraping Static Pages with rvest",
    "section": "HTML 101",
    "text": "HTML 101\nWeb content is usually written in HTML (Hyper Text Markup Language). An HTML document is comprised of elements that are letting its content appear in a certain way.\n\n\n\nThe tree-like structure of an HTML document\n\n\nThe way these elements look is defined by so-called tags.\n\nThe opening tag is the name of the element (p in this case) in angle brackets, and the closing tag is the same with a forward slash before the name. p stands for a paragraph element and would look like this (since RMarkdown can handle HTML tags, the second line will showcase how it would appear on a web page):\n&lt;p&gt; My cat is very grumpy. &lt;p/&gt;\n\nMy cat is very grumpy.\n\nThe &lt;p&gt; tag makes sure that the text is standing by itself and that a line break is included thereafter:\n&lt;p&gt;My cat is very grumpy&lt;/p&gt;. And so is my dog. would look like this:\n\nMy cat is very grumpy\n\n. And so is my dog.\nThere do exist many types of tags indicating different kinds of elements (about 100). Every page’s content must be in an &lt;html&gt; element with two children &lt;head&gt; and &lt;body&gt;. The former contains the page title and some metadata, the latter the contents you are seeing in your browser. So-called block tags, e.g., &lt;h1&gt; (heading 1), &lt;p&gt; (paragraph), or &lt;ol&gt; (ordered list), structure the page. Inline tags (&lt;b&gt; – bold, &lt;a&gt; – link) format text inside block tags.\nYou can nest elements, e.g., if you want to make certain things bold, you can wrap text in &lt;b&gt;:\n&lt;p&gt;My cat is &lt;b&gt; very &lt;/b&gt; grumpy&lt;/p&gt;\n\nMy cat is  very  grumpy\n\nThen, the &lt;b&gt; element is considered the child of the &lt;p&gt; element.\nElements can also bear attributes:\n\nThose attributes will not appear in the actual content. Moreover, they are super-handy for us as scrapers. Here, class is the attribute name and \"editor-note\" the value. Another important attribute is id. Combined with CSS, they control the appearance of the element on the actual page. A class can be used by multiple HTML elements whereas an id is unique."
  },
  {
    "objectID": "7_scraping.html#extracting-content-in-rvest",
    "href": "7_scraping.html#extracting-content-in-rvest",
    "title": "Chapter 7: Scraping Static Pages with rvest",
    "section": "Extracting content in rvest",
    "text": "Extracting content in rvest\nTo scrape the web, the first step is to simply read in the web page. rvest then stores it in the XML format – just another format to store information. For this, we use rvest’s read_html() function.\nTo demonstrate the usage of CSS selectors, I create my own, basic web page using the rvest function minimal_html():\n\nbasic_html &lt;- minimal_html('\n  &lt;html&gt;\n  &lt;head&gt;\n    &lt;title&gt;Page title&lt;/title&gt;\n  &lt;/head&gt;\n  &lt;body&gt;\n    &lt;h1 id=\"first\"&gt;A heading&lt;/h1&gt;\n    &lt;p class=\"paragraph\"&gt;Some text &amp; &lt;b&gt;some bold text.&lt;/b&gt;&lt;/p&gt;\n    &lt;a&gt; Some more &lt;i&gt; italicized text which is not in a paragraph. &lt;/i&gt; &lt;/a&gt;\n    &lt;a class=\"paragraph\"&gt;even more text &amp; &lt;i&gt;some italicized text.&lt;/i&gt;&lt;/p&gt;\n    &lt;a id=\"link\" href=\"www.nyt.com\"&gt; The New York Times &lt;/a&gt;\n  &lt;/body&gt;\n')\n\nbasic_html\n\n{html_document}\n&lt;html&gt;\n[1] &lt;head&gt;\\n&lt;meta http-equiv=\"Content-Type\" content=\"text/html; charset=UTF-8 ...\n[2] &lt;body&gt;\\n    &lt;h1 id=\"first\"&gt;A heading&lt;/h1&gt;\\n    &lt;p class=\"paragraph\"&gt;Some  ...\n\n#https://htmledit.squarefree.com\n\nCSS is the abbreviation for cascading style sheets and is used to define the visual styling of HTML documents. CSS selectors map elements in the HTML code to the relevant styles in the CSS. Hence, they define patterns that allow us to easily select certain elements on the page. CSS selectors can be used in conjunction with the rvest function html_elements() which takes as arguments the read-in page and a CSS selector. Alternatively, you can also provide an XPath which is usually a bit more complicated and will not be covered in this tutorial.\n\np selects all &lt;p&gt; elements.\n\n\nbasic_html |&gt; html_elements(css = \"p\")\n\n{xml_nodeset (1)}\n[1] &lt;p class=\"paragraph\"&gt;Some text &amp; &lt;b&gt;some bold text.&lt;/b&gt;&lt;/p&gt;\n\n\n\n.title selects all elements that are of class “title”\n\n\nbasic_html |&gt; html_elements(css = \".title\")\n\n{xml_nodeset (0)}\n\n\nThere are no elements of class “title”. But some of class “paragraph”.\n\nbasic_html |&gt; html_elements(css = \".paragraph\")\n\n{xml_nodeset (2)}\n[1] &lt;p class=\"paragraph\"&gt;Some text &amp; &lt;b&gt;some bold text.&lt;/b&gt;&lt;/p&gt;\n[2] &lt;a class=\"paragraph\"&gt;even more text &amp; &lt;i&gt;some italicized text.&lt;/i&gt;\\n  ...\n\n\n\np.paragraph analogously takes every &lt;p&gt; element which is of class “paragraph”.\n\n\nbasic_html |&gt; html_elements(css = \"p.paragraph\")\n\n{xml_nodeset (1)}\n[1] &lt;p class=\"paragraph\"&gt;Some text &amp; &lt;b&gt;some bold text.&lt;/b&gt;&lt;/p&gt;\n\n\n\n#link scrapes elements that are of id “link”\n\n\nbasic_html |&gt; html_elements(css = \"#link\")\n\n{xml_nodeset (1)}\n[1] &lt;a id=\"link\" href=\"www.nyt.com\"&gt; The New York Times &lt;/a&gt;\n\n\nYou can also connect children with their parents by using the combinator. For instance, to extract the italicized text from “a.paragraph,” I can do “a.paragraph i”.\n\nbasic_html |&gt; html_elements(css = \"a.paragraph i\")\n\n{xml_nodeset (1)}\n[1] &lt;i&gt;some italicized text.&lt;/i&gt;\n\n\nYou can also look at the children by using html_children():\n\nbasic_html |&gt; html_elements(css = \"a.paragraph\") |&gt; html_children()\n\n{xml_nodeset (1)}\n[1] &lt;i&gt;some italicized text.&lt;/i&gt;\n\nread_html(\"https://rvest.tidyverse.org\") |&gt; \n  html_elements(\"#installation , p\")\n\n{xml_nodeset (6)}\n[1] &lt;p&gt;rvest helps you scrape (or harvest) data from web pages. It is designe ...\n[2] &lt;p&gt;If you’re scraping multiple pages, I highly recommend using rvest in c ...\n[3] &lt;h2 id=\"installation\"&gt;Installation&lt;a class=\"anchor\" aria-label=\"anchor\" h ...\n[4] &lt;p&gt;If the page contains tabular data you can convert it directly to a dat ...\n[5] &lt;p&gt;Developed by &lt;a href=\"https://hadley.nz\" class=\"external-link\"&gt;Hadley  ...\n[6] &lt;p&gt;Site built with &lt;a href=\"https://pkgdown.r-lib.org/\" class=\"external-l ...\n\n\nUnfortunately, web pages in the wild are usually not as easily readable as the small example one I came up with. Hence, I would recommend you to use the SelectorGadget – just drag it into your bookmarks list.\nIts usage could hardly be simpler:\n\nActivate it – i.e., click on the bookmark.\nClick on the content you want to scrape – the things the CSS selector selects will appear green.\nClick on the green things that you don’t want – they will turn red; click on what’s not green yet but what you want – it will turn green.\ncopy the CSS selector the gadget provides you with and paste it into the html_elements() function.\n\n\nread_html(\"https://en.wikipedia.org/wiki/Hadley_Wickham\") |&gt; \n  html_elements(css = \"p:nth-child(4)\") |&gt; \n  html_text()\n\ncharacter(0)"
  },
  {
    "objectID": "7_scraping.html#tying-it-together-scraping-html-pages-with-rvest",
    "href": "7_scraping.html#tying-it-together-scraping-html-pages-with-rvest",
    "title": "Chapter 7: Scraping Static Pages with rvest",
    "section": "Tying it Together: Scraping HTML pages with rvest",
    "text": "Tying it Together: Scraping HTML pages with rvest\n\n\n\n\n\n\n\n\n\nSo far, I have shown you how HTML is written and how to select elements. However, what we want to achieve is extracting the data the elements contained in a proper format and storing it in some sort of tibble. Therefore, we need functions that allow us to grab the data.\nThe following overview taken from the web scraping cheatsheet shows you the basic “flow” of scraping web pages plus the corresponding functions. In this tutorial, I will limit myself to rvest functions. Those are of course perfectly compatible with things, for instance, RSelenium, as long as you feed the content in XML format (i.e., by using read_html()).\n\nIn the prior chapter, I have introduced you to acquiring the contents of singular pages. Given that you now know how to choose the content you want, all that you are lacking for successful scraping is the tools to extract these contents in a proper format.\n\nhtml_text() and html_text2()\nExtracting text from HTML is easy. You use html_text() or html_text2(). The former is faster but will give you not-so-nice results. The latter will give you the text like it would be returned in a web browser.\nThe following example is taken from the documentation\n\n# To understand the difference between html_text() and html_text2()\n# take the following html:\n\nhtml &lt;- minimal_html(\n  \"&lt;p&gt;This is a paragraph.\n    This is another sentence.&lt;br&gt;This should start on a new line&lt;p/&gt;\"\n)\n\n\n# html_text() returns the raw underlying text, which includes white space\n# that would be ignored by a browser, and ignores the &lt;br&gt;\nhtml |&gt; html_element(\"p\") |&gt; html_text() |&gt; writeLines()\n\nThis is a paragraph.\n    This is another sentence.This should start on a new line\n\n\n\n# html_text2() simulates what a browser would display. Non-significant\n# white space is collapsed, and &lt;br&gt; is turned into a line break\nhtml |&gt; html_element(\"p\") |&gt; html_text2() |&gt; writeLines()\n\nThis is a paragraph. This is another sentence.\nThis should start on a new line\n\n\nA “real example” would then look like this:\n\nus_senators &lt;- read_html(\"https://en.wikipedia.org/wiki/List_of_current_United_States_senators\")\ntext &lt;- us_senators |&gt;\n  html_elements(css = \"p:nth-child(8)\") |&gt; \n  html_text2()\n\n\n\nExtracting tables\nThe general output format we strive for is a tibble. Oftentimes, data is already stored online in a table format, basically ready for us to analyze them. In the next example, I want to get a table from the Wikipedia page that contains the senators of different States in the United States I have used before. For this first, basic example, I do not use selectors for extracting the right table. You can use rvest::html_table(). It will give you a list containing all tables on this particular page. We can inspect it using str() which returns an overview of the list and the tibbles it contains.\n\ntables &lt;- us_senators |&gt; \n  html_table()\n\nstr(tables)\n\nList of 26\n $ : tibble [4 × 3] (S3: tbl_df/tbl/data.frame)\n  ..$ Affiliation: chr [1:4] \"\" \"\" \"\" \"Total\"\n  ..$ Affiliation: chr [1:4] \"Republican Party\" \"Democratic Party\" \"Independent\" \"Total\"\n  ..$ Members    : int [1:4] 53 45 2 100\n $ : tibble [11 × 1] (S3: tbl_df/tbl/data.frame)\n  ..$ X1: chr [1:11] \"This article is part of a series on the\" \"United States Senate\" \"Great Seal of the United States Senate\" \"History of the United States Senate\" ...\n $ : tibble [2 × 5] (S3: tbl_df/tbl/data.frame)\n  ..$ Office : chr [1:2] \"President of the Senate[a]\" \"President pro tempore\"\n  ..$ Party  : chr [1:2] \"Republican\" \"Republican\"\n  ..$ Officer: chr [1:2] \"JD Vance\" \"Chuck Grassley\"\n  ..$ State  : chr [1:2] \"OH[b]\" \"IA\"\n  ..$ Since  : chr [1:2] \"January 20, 2025\" \"January 3, 2025Party dean since January 3, 2019\"\n $ : tibble [8 × 4] (S3: tbl_df/tbl/data.frame)\n  ..$ Office : chr [1:8] \"Senate Majority Leader\" \"Senate Majority Whip\" \"Chair of the Senate Republican Conference\" \"Chair of the Senate Republican Policy Committee\" ...\n  ..$ Officer: chr [1:8] \"John Thune\" \"John Barrasso\" \"Tom Cotton\" \"Shelley Moore Capito\" ...\n  ..$ State  : chr [1:8] \"SD\" \"WY\" \"AR\" \"WV\" ...\n  ..$ Since  : chr [1:8] \"January 3, 2025Party leader since January 3, 2025\" \"January 3, 2025Party whip since January 3, 2025\" \"January 3, 2025\" \"January 3, 2025\" ...\n $ : tibble [14 × 4] (S3: tbl_df/tbl/data.frame)\n  ..$ Office : chr [1:14] \"Senate Minority LeaderChair of the Senate Democratic Caucus\" \"Senate Minority Whip\" \"Chair of the Senate Democratic Steering and Policy Committee\" \"Chair of the Senate Democratic Strategic Communications Committee\" ...\n  ..$ Officer: chr [1:14] \"Chuck Schumer\" \"Dick Durbin\" \"Amy Klobuchar\" \"Cory Booker\" ...\n  ..$ State  : chr [1:14] \"NY\" \"IL\" \"MN\" \"NJ\" ...\n  ..$ Since  : chr [1:14] \"January 3, 2025Party leader since January 3, 2017\" \"January 3, 2025Party whip since January 3, 2005\" \"January 3, 2025\" \"January 3, 2025\" ...\n $ : tibble [100 × 12] (S3: tbl_df/tbl/data.frame)\n  ..$ State                     : chr [1:100] \"Alabama\" \"Alabama\" \"Alaska\" \"Alaska\" ...\n  ..$ Portrait                  : logi [1:100] NA NA NA NA NA NA ...\n  ..$ Senator                   : chr [1:100] \"Tommy Tuberville\" \"Katie Britt\" \"Lisa Murkowski\" \"Dan Sullivan\" ...\n  ..$ Party                     : logi [1:100] NA NA NA NA NA NA ...\n  ..$ Party                     : chr [1:100] \"Republican\" \"Republican\" \"Republican\" \"Republican\" ...\n  ..$ Born                      : chr [1:100] \"(1954-09-18) September 18, 1954 (age 71)\" \"(1982-02-02) February 2, 1982 (age 43)\" \"(1957-05-22) May 22, 1957 (age 68)\" \"(1964-11-13) November 13, 1964 (age 60)\" ...\n  ..$ Occupation(s)             : chr [1:100] \"Investment management firm partner\\nCollege football coach\" \"Alabama Wildlife Federation Board Member\\nBusiness Council of Alabama President and CEO \\nCampaign manager\\nLaw\"| __truncated__ \"Lawyer\" \"Assistant Secretary of State for Economic and Business Affairs\\nLawyer\\nU.S. Marine Corps officer\" ...\n  ..$ Previous electiveoffice(s): chr [1:100] \"None\" \"None\" \"Alaska House of Representatives\" \"Alaska Attorney General\" ...\n  ..$ Education                 : chr [1:100] \"Southern Arkansas University (BS)\" \"University of Alabama (BS, JD)\" \"Georgetown University (AB)Willamette University (JD)\" \"Harvard University (AB)Georgetown University (MS, JD)\" ...\n  ..$ Assumed office            : chr [1:100] \"January 3, 2021\" \"January 3, 2023\" \"December 20, 2002[c]\" \"January 3, 2015\" ...\n  ..$ Class                     : chr [1:100] \"2026Class 2\" \"2028Class 3\" \"2028Class 3\" \"2026Class 2\" ...\n  ..$ Residence[4]              : chr [1:100] \"Auburn[5]\" \"Montgomery\" \"Girdwood\" \"Anchorage\" ...\n $ : tibble [3 × 3] (S3: tbl_df/tbl/data.frame)\n  ..$ vteCurrent United States senators: chr [1:3] \"President: ▌ JD Vance (R) ‧ President pro tempore: ▌ Chuck Grassley (R)\" \"AL: ▌ Tuberville (R)⎣ ▌ Britt (R)\\nAK: ▌ Murkowski (R)⎣ ▌ Sullivan (R)\\nAZ: ▌ Kelly (D)⎣ ▌ Gallego (D)\\nAR: ▌ B\"| __truncated__ \"▌ Republican: 53\\n▌ Democratic: 45\\n▌ Independent: 2\"\n  ..$ vteCurrent United States senators: chr [1:3] \"President: ▌ JD Vance (R) ‧ President pro tempore: ▌ Chuck Grassley (R)\" \"AL: ▌ Tuberville (R)⎣ ▌ Britt (R)\\nAK: ▌ Murkowski (R)⎣ ▌ Sullivan (R)\\nAZ: ▌ Kelly (D)⎣ ▌ Gallego (D)\\nAR: ▌ B\"| __truncated__ \"▌ Republican: 53\\n▌ Democratic: 45\\n▌ Independent: 2\"\n  ..$ vteCurrent United States senators: chr [1:3] \"President: ▌ JD Vance (R) ‧ President pro tempore: ▌ Chuck Grassley (R)\" \"\" \"▌ Republican: 53\\n▌ Democratic: 45\\n▌ Independent: 2\"\n $ : tibble [4 × 6] (S3: tbl_df/tbl/data.frame)\n  ..$ vteLeadership of the United States Senate: chr [1:4] \"President: JD Vance (R)President pro tempore: Chuck Grassley (R)\" \"Majority (Republican)Minority (Democratic)\\nJohn Thune (Leader)\\nJohn Barrasso (Whip)\\nTom Cotton (Conference C\"| __truncated__ \"Majority (Republican)\" \"John Thune (Leader)\\nJohn Barrasso (Whip)\\nTom Cotton (Conference Chair)\\nShelley Moore Capito (Policy Committe\"| __truncated__\n  ..$ vteLeadership of the United States Senate: chr [1:4] \"President: JD Vance (R)President pro tempore: Chuck Grassley (R)\" \"Majority (Republican)Minority (Democratic)\\nJohn Thune (Leader)\\nJohn Barrasso (Whip)\\nTom Cotton (Conference C\"| __truncated__ \"Minority (Democratic)\" \"Chuck Schumer (Leader and Caucus Chair)\\nDick Durbin (Whip)\\nAmy Klobuchar (Steering/Policy Committee Chair)\\nC\"| __truncated__\n  ..$                                          : chr [1:4] NA \"Majority (Republican)\" NA NA\n  ..$                                          : chr [1:4] NA \"Minority (Democratic)\" NA NA\n  ..$                                          : chr [1:4] NA \"John Thune (Leader)\\nJohn Barrasso (Whip)\\nTom Cotton (Conference Chair)\\nShelley Moore Capito (Policy Committe\"| __truncated__ NA NA\n  ..$                                          : chr [1:4] NA \"Chuck Schumer (Leader and Caucus Chair)\\nDick Durbin (Whip)\\nAmy Klobuchar (Steering/Policy Committee Chair)\\nC\"| __truncated__ NA NA\n $ : tibble [2 × 2] (S3: tbl_df/tbl/data.frame)\n  ..$ X1: chr [1:2] \"Majority (Republican)\" \"John Thune (Leader)\\nJohn Barrasso (Whip)\\nTom Cotton (Conference Chair)\\nShelley Moore Capito (Policy Committe\"| __truncated__\n  ..$ X2: chr [1:2] \"Minority (Democratic)\" \"Chuck Schumer (Leader and Caucus Chair)\\nDick Durbin (Whip)\\nAmy Klobuchar (Steering/Policy Committee Chair)\\nC\"| __truncated__\n $ : tibble [3 × 6] (S3: tbl_df/tbl/data.frame)\n  ..$ vteChairs and ranking members of United States Senate committees: chr [1:3] \"Chairs (Republican)Ranking members (Democratic)\\nAging (Special): Rick Scott\\nAgriculture, Nutrition and Forest\"| __truncated__ \"Chairs (Republican)\" \"Aging (Special): Rick Scott\\nAgriculture, Nutrition and Forestry: John Boozman\\nAppropriations: Susan Collins\\n\"| __truncated__\n  ..$ vteChairs and ranking members of United States Senate committees: chr [1:3] \"Chairs (Republican)Ranking members (Democratic)\\nAging (Special): Rick Scott\\nAgriculture, Nutrition and Forest\"| __truncated__ \"Ranking members (Democratic)\" \"Aging (Special): Kirsten Gillibrand\\nAgriculture, Nutrition and Forestry: Amy Klobuchar\\nAppropriations: Patty \"| __truncated__\n  ..$                                                                 : chr [1:3] \"Chairs (Republican)\" NA NA\n  ..$                                                                 : chr [1:3] \"Ranking members (Democratic)\" NA NA\n  ..$                                                                 : chr [1:3] \"Aging (Special): Rick Scott\\nAgriculture, Nutrition and Forestry: John Boozman\\nAppropriations: Susan Collins\\n\"| __truncated__ NA NA\n  ..$                                                                 : chr [1:3] \"Aging (Special): Kirsten Gillibrand\\nAgriculture, Nutrition and Forestry: Amy Klobuchar\\nAppropriations: Patty \"| __truncated__ NA NA\n $ : tibble [2 × 2] (S3: tbl_df/tbl/data.frame)\n  ..$ X1: chr [1:2] \"Chairs (Republican)\" \"Aging (Special): Rick Scott\\nAgriculture, Nutrition and Forestry: John Boozman\\nAppropriations: Susan Collins\\n\"| __truncated__\n  ..$ X2: chr [1:2] \"Ranking members (Democratic)\" \"Aging (Special): Kirsten Gillibrand\\nAgriculture, Nutrition and Forestry: Amy Klobuchar\\nAppropriations: Patty \"| __truncated__\n $ : tibble [49 × 36] (S3: tbl_df/tbl/data.frame)\n  ..$ vteUnited States Congress: chr [1:49] \"House of Representatives\\nSenate\\nJoint session\\n(118th → 119th → 120th)\\nLists of the United States Congress\" \"Members and leadersMembershipMembers\\nBy length of service\\nBy shortness of service\\nNew members\\nNon-voting me\"| __truncated__ \"Members and leaders\" \"MembershipMembers\\nBy length of service\\nBy shortness of service\\nNew members\\nNon-voting members\\nUnseated mem\"| __truncated__ ...\n  ..$ vteUnited States Congress: chr [1:49] \"House of Representatives\\nSenate\\nJoint session\\n(118th → 119th → 120th)\\nLists of the United States Congress\" \"Members and leadersMembershipMembers\\nBy length of service\\nBy shortness of service\\nNew members\\nNon-voting me\"| __truncated__ \"Members and leaders\" \"MembershipMembers\\nBy length of service\\nBy shortness of service\\nNew members\\nNon-voting members\\nUnseated mem\"| __truncated__ ...\n  ..$                          : chr [1:49] NA \"Members and leaders\" NA \"Membership\" ...\n  ..$                          : chr [1:49] NA \"Members and leaders\" NA \"Members\\nBy length of service\\nBy shortness of service\\nNew members\\nNon-voting members\\nUnseated members\\nYoun\"| __truncated__ ...\n  ..$                          : chr [1:49] NA \"MembershipMembers\\nBy length of service\\nBy shortness of service\\nNew members\\nNon-voting members\\nUnseated mem\"| __truncated__ NA \"Members\" ...\n  ..$                          : chr [1:49] NA \"MembershipMembers\\nBy length of service\\nBy shortness of service\\nNew members\\nNon-voting members\\nUnseated mem\"| __truncated__ NA \"By length of service\\nBy shortness of service\\nNew members\\nNon-voting members\\nUnseated members\\nYoungest members\" ...\n  ..$                          : chr [1:49] NA \"Membership\" NA \"Senate\" ...\n  ..$                          : chr [1:49] NA \"Members\\nBy length of service\\nBy shortness of service\\nNew members\\nNon-voting members\\nUnseated members\\nYoun\"| __truncated__ NA \"Members\\nseniority\\nDean\\nFormer\\nExpelled or censured\\nClasses\\nBorn outside the U.S.\\nResigned\\nAppointed\\nSwitched parties\" ...\n  ..$                          : chr [1:49] NA \"Members\" NA \"House\" ...\n  ..$                          : chr [1:49] NA \"By length of service\\nBy shortness of service\\nNew members\\nNon-voting members\\nUnseated members\\nYoungest members\" NA \"Members\\nseniority\\nDean\\nFormer\\nExpelled, censured, and reprimanded\\nServed a single term\\nLost re-election i\"| __truncated__ ...\n  ..$                          : chr [1:49] NA \"Senate\" NA \"Leaders\" ...\n  ..$                          : chr [1:49] NA \"Members\\nseniority\\nDean\\nFormer\\nExpelled or censured\\nClasses\\nBorn outside the U.S.\\nResigned\\nAppointed\\nSwitched parties\" NA \"Senate\\nPresident\\nlist\\nPresident pro tempore\\nlist\\nLeaders\\nDemocratic Caucus\\nChair\\nSecretary\\nPolicy Comm\"| __truncated__ ...\n  ..$                          : chr [1:49] NA \"House\" NA \"Senate\" ...\n  ..$                          : chr [1:49] NA \"Members\\nseniority\\nDean\\nFormer\\nExpelled, censured, and reprimanded\\nServed a single term\\nLost re-election i\"| __truncated__ NA \"President\\nlist\\nPresident pro tempore\\nlist\\nLeaders\\nDemocratic Caucus\\nChair\\nSecretary\\nPolicy Committee Ch\"| __truncated__ ...\n  ..$                          : chr [1:49] NA \"Leaders\" NA \"House\" ...\n  ..$                          : chr [1:49] NA \"Senate\\nPresident\\nlist\\nPresident pro tempore\\nlist\\nLeaders\\nDemocratic Caucus\\nChair\\nSecretary\\nPolicy Comm\"| __truncated__ NA \"Speaker\\nlist\\nLeaders\\nBipartisan Legal Advisory Group\\nDemocratic Caucus\\nRepublican Conference\" ...\n  ..$                          : chr [1:49] NA \"Senate\" NA \"Districts\" ...\n  ..$                          : chr [1:49] NA \"President\\nlist\\nPresident pro tempore\\nlist\\nLeaders\\nDemocratic Caucus\\nChair\\nSecretary\\nPolicy Committee Ch\"| __truncated__ NA \"List\\nApportionment\\nGerrymandering\" ...\n  ..$                          : chr [1:49] NA \"House\" NA \"Groups\" ...\n  ..$                          : chr [1:49] NA \"Speaker\\nlist\\nLeaders\\nBipartisan Legal Advisory Group\\nDemocratic Caucus\\nRepublican Conference\" NA \"Congressional caucus\\nCaucuses of the United States CongressEthnic and racial\\nAfrican-American members\\nSenate\"| __truncated__ ...\n  ..$                          : chr [1:49] NA \"Districts\" NA \"Congressional caucus\" ...\n  ..$                          : chr [1:49] NA \"List\\nApportionment\\nGerrymandering\" NA \"Caucuses of the United States Congress\" ...\n  ..$                          : chr [1:49] NA \"Groups\" NA \"Ethnic and racial\" ...\n  ..$                          : chr [1:49] NA \"Congressional caucus\\nCaucuses of the United States CongressEthnic and racial\\nAfrican-American members\\nSenate\"| __truncated__ NA \"African-American members\\nSenate\\nHouse\\nBlack Caucus\\nArab and Middle Eastern members\\nAsian Pacific American \"| __truncated__ ...\n  ..$                          : chr [1:49] NA \"Congressional caucus\" NA \"Gender and sexual identity\" ...\n  ..$                          : chr [1:49] NA \"Caucuses of the United States Congress\" NA \"LGBTQ members\\nEquality Caucus\\nWomen\\nSenate\\nHouse\\nIssues Caucus\\ncurrent House\" ...\n  ..$                          : chr [1:49] NA \"Ethnic and racial\" NA \"Occupation\" ...\n  ..$                          : chr [1:49] NA \"African-American members\\nSenate\\nHouse\\nBlack Caucus\\nArab and Middle Eastern members\\nAsian Pacific American \"| __truncated__ NA \"Physicians\" ...\n  ..$                          : chr [1:49] NA \"Gender and sexual identity\" NA \"Religion\" ...\n  ..$                          : chr [1:49] NA \"LGBTQ members\\nEquality Caucus\\nWomen\\nSenate\\nHouse\\nIssues Caucus\\ncurrent House\" NA \"Buddhist members\\nHindu members\\nJewish members\\nMormon (LDS) members\\nMuslim members\\nQuaker members\\nSikh members\" ...\n  ..$                          : chr [1:49] NA \"Occupation\" NA \"Related\" ...\n  ..$                          : chr [1:49] NA \"Physicians\" NA \"By length of service historically\\nCurrent members by wealth\\nFrom multiple states\\nDied in office\\n1790–1899\\n\"| __truncated__ ...\n  ..$                          : chr [1:49] NA \"Religion\" NA NA ...\n  ..$                          : chr [1:49] NA \"Buddhist members\\nHindu members\\nJewish members\\nMormon (LDS) members\\nMuslim members\\nQuaker members\\nSikh members\" NA NA ...\n  ..$                          : chr [1:49] NA \"Related\" NA NA ...\n  ..$                          : chr [1:49] NA \"By length of service historically\\nCurrent members by wealth\\nFrom multiple states\\nDied in office\\n1790–1899\\n\"| __truncated__ NA NA ...\n $ : tibble [16 × 32] (S3: tbl_df/tbl/data.frame)\n  ..$ Members and leaders: chr [1:16] \"MembershipMembers\\nBy length of service\\nBy shortness of service\\nNew members\\nNon-voting members\\nUnseated mem\"| __truncated__ \"Membership\" \"Members\" \"Senate\" ...\n  ..$ Members and leaders: chr [1:16] \"MembershipMembers\\nBy length of service\\nBy shortness of service\\nNew members\\nNon-voting members\\nUnseated mem\"| __truncated__ \"Members\\nBy length of service\\nBy shortness of service\\nNew members\\nNon-voting members\\nUnseated members\\nYoun\"| __truncated__ \"By length of service\\nBy shortness of service\\nNew members\\nNon-voting members\\nUnseated members\\nYoungest members\" \"Members\\nseniority\\nDean\\nFormer\\nExpelled or censured\\nClasses\\nBorn outside the U.S.\\nResigned\\nAppointed\\nSwitched parties\" ...\n  ..$                    : chr [1:16] \"Membership\" \"Members\" NA NA ...\n  ..$                    : chr [1:16] \"Members\\nBy length of service\\nBy shortness of service\\nNew members\\nNon-voting members\\nUnseated members\\nYoun\"| __truncated__ \"By length of service\\nBy shortness of service\\nNew members\\nNon-voting members\\nUnseated members\\nYoungest members\" NA NA ...\n  ..$                    : chr [1:16] \"Members\" \"Senate\" NA NA ...\n  ..$                    : chr [1:16] \"By length of service\\nBy shortness of service\\nNew members\\nNon-voting members\\nUnseated members\\nYoungest members\" \"Members\\nseniority\\nDean\\nFormer\\nExpelled or censured\\nClasses\\nBorn outside the U.S.\\nResigned\\nAppointed\\nSwitched parties\" NA NA ...\n  ..$                    : chr [1:16] \"Senate\" \"House\" NA NA ...\n  ..$                    : chr [1:16] \"Members\\nseniority\\nDean\\nFormer\\nExpelled or censured\\nClasses\\nBorn outside the U.S.\\nResigned\\nAppointed\\nSwitched parties\" \"Members\\nseniority\\nDean\\nFormer\\nExpelled, censured, and reprimanded\\nServed a single term\\nLost re-election i\"| __truncated__ NA NA ...\n  ..$                    : chr [1:16] \"House\" NA NA NA ...\n  ..$                    : chr [1:16] \"Members\\nseniority\\nDean\\nFormer\\nExpelled, censured, and reprimanded\\nServed a single term\\nLost re-election i\"| __truncated__ NA NA NA ...\n  ..$                    : chr [1:16] \"Leaders\" NA NA NA ...\n  ..$                    : chr [1:16] \"Senate\\nPresident\\nlist\\nPresident pro tempore\\nlist\\nLeaders\\nDemocratic Caucus\\nChair\\nSecretary\\nPolicy Comm\"| __truncated__ NA NA NA ...\n  ..$                    : chr [1:16] \"Senate\" NA NA NA ...\n  ..$                    : chr [1:16] \"President\\nlist\\nPresident pro tempore\\nlist\\nLeaders\\nDemocratic Caucus\\nChair\\nSecretary\\nPolicy Committee Ch\"| __truncated__ NA NA NA ...\n  ..$                    : chr [1:16] \"House\" NA NA NA ...\n  ..$                    : chr [1:16] \"Speaker\\nlist\\nLeaders\\nBipartisan Legal Advisory Group\\nDemocratic Caucus\\nRepublican Conference\" NA NA NA ...\n  ..$                    : chr [1:16] \"Districts\" NA NA NA ...\n  ..$                    : chr [1:16] \"List\\nApportionment\\nGerrymandering\" NA NA NA ...\n  ..$                    : chr [1:16] \"Groups\" NA NA NA ...\n  ..$                    : chr [1:16] \"Congressional caucus\\nCaucuses of the United States CongressEthnic and racial\\nAfrican-American members\\nSenate\"| __truncated__ NA NA NA ...\n  ..$                    : chr [1:16] \"Congressional caucus\" NA NA NA ...\n  ..$                    : chr [1:16] \"Caucuses of the United States Congress\" NA NA NA ...\n  ..$                    : chr [1:16] \"Ethnic and racial\" NA NA NA ...\n  ..$                    : chr [1:16] \"African-American members\\nSenate\\nHouse\\nBlack Caucus\\nArab and Middle Eastern members\\nAsian Pacific American \"| __truncated__ NA NA NA ...\n  ..$                    : chr [1:16] \"Gender and sexual identity\" NA NA NA ...\n  ..$                    : chr [1:16] \"LGBTQ members\\nEquality Caucus\\nWomen\\nSenate\\nHouse\\nIssues Caucus\\ncurrent House\" NA NA NA ...\n  ..$                    : chr [1:16] \"Occupation\" NA NA NA ...\n  ..$                    : chr [1:16] \"Physicians\" NA NA NA ...\n  ..$                    : chr [1:16] \"Religion\" NA NA NA ...\n  ..$                    : chr [1:16] \"Buddhist members\\nHindu members\\nJewish members\\nMormon (LDS) members\\nMuslim members\\nQuaker members\\nSikh members\" NA NA NA ...\n  ..$                    : chr [1:16] \"Related\" NA NA NA ...\n  ..$                    : chr [1:16] \"By length of service historically\\nCurrent members by wealth\\nFrom multiple states\\nDied in office\\n1790–1899\\n\"| __truncated__ NA NA NA ...\n $ : tibble [15 × 12] (S3: tbl_df/tbl/data.frame)\n  ..$ X1 : chr [1:15] \"Membership\" \"Members\" \"Senate\" \"House\" ...\n  ..$ X2 : chr [1:15] \"Members\\nBy length of service\\nBy shortness of service\\nNew members\\nNon-voting members\\nUnseated members\\nYoun\"| __truncated__ \"By length of service\\nBy shortness of service\\nNew members\\nNon-voting members\\nUnseated members\\nYoungest members\" \"Members\\nseniority\\nDean\\nFormer\\nExpelled or censured\\nClasses\\nBorn outside the U.S.\\nResigned\\nAppointed\\nSwitched parties\" \"Members\\nseniority\\nDean\\nFormer\\nExpelled, censured, and reprimanded\\nServed a single term\\nLost re-election i\"| __truncated__ ...\n  ..$ X3 : chr [1:15] \"Members\" NA NA NA ...\n  ..$ X4 : chr [1:15] \"By length of service\\nBy shortness of service\\nNew members\\nNon-voting members\\nUnseated members\\nYoungest members\" NA NA NA ...\n  ..$ X5 : chr [1:15] \"Senate\" NA NA NA ...\n  ..$ X6 : chr [1:15] \"Members\\nseniority\\nDean\\nFormer\\nExpelled or censured\\nClasses\\nBorn outside the U.S.\\nResigned\\nAppointed\\nSwitched parties\" NA NA NA ...\n  ..$ X7 : chr [1:15] \"House\" NA NA NA ...\n  ..$ X8 : chr [1:15] \"Members\\nseniority\\nDean\\nFormer\\nExpelled, censured, and reprimanded\\nServed a single term\\nLost re-election i\"| __truncated__ NA NA NA ...\n  ..$ X9 : chr [1:15] NA NA NA NA ...\n  ..$ X10: chr [1:15] NA NA NA NA ...\n  ..$ X11: chr [1:15] NA NA NA NA ...\n  ..$ X12: chr [1:15] NA NA NA NA ...\n $ : tibble [3 × 2] (S3: tbl_df/tbl/data.frame)\n  ..$ X1: chr [1:3] \"Members\" \"Senate\" \"House\"\n  ..$ X2: chr [1:3] \"By length of service\\nBy shortness of service\\nNew members\\nNon-voting members\\nUnseated members\\nYoungest members\" \"Members\\nseniority\\nDean\\nFormer\\nExpelled or censured\\nClasses\\nBorn outside the U.S.\\nResigned\\nAppointed\\nSwitched parties\" \"Members\\nseniority\\nDean\\nFormer\\nExpelled, censured, and reprimanded\\nServed a single term\\nLost re-election i\"| __truncated__\n $ : tibble [2 × 2] (S3: tbl_df/tbl/data.frame)\n  ..$ X1: chr [1:2] \"Senate\" \"House\"\n  ..$ X2: chr [1:2] \"President\\nlist\\nPresident pro tempore\\nlist\\nLeaders\\nDemocratic Caucus\\nChair\\nSecretary\\nPolicy Committee Ch\"| __truncated__ \"Speaker\\nlist\\nLeaders\\nBipartisan Legal Advisory Group\\nDemocratic Caucus\\nRepublican Conference\"\n $ : tibble [5 × 2] (S3: tbl_df/tbl/data.frame)\n  ..$ X1: chr [1:5] \"Congressional caucus\" \"Ethnic and racial\" \"Gender and sexual identity\" \"Occupation\" ...\n  ..$ X2: chr [1:5] \"Caucuses of the United States Congress\" \"African-American members\\nSenate\\nHouse\\nBlack Caucus\\nArab and Middle Eastern members\\nAsian Pacific American \"| __truncated__ \"LGBTQ members\\nEquality Caucus\\nWomen\\nSenate\\nHouse\\nIssues Caucus\\ncurrent House\" \"Physicians\" ...\n $ : tibble [10 × 20] (S3: tbl_df/tbl/data.frame)\n  ..$ Powers, privileges, procedure, committees, history, media: chr [1:10] \"Powers\\nArticle I\\nCopyright\\nCommerce (Dormant)\\nContempt of Congress\\nDeclaration of war\\nImpeachment\\nInquir\"| __truncated__ \"Powers\" \"Privileges\" \"Procedure\" ...\n  ..$ Powers, privileges, procedure, committees, history, media: chr [1:10] \"Powers\\nArticle I\\nCopyright\\nCommerce (Dormant)\\nContempt of Congress\\nDeclaration of war\\nImpeachment\\nInquir\"| __truncated__ \"Article I\\nCopyright\\nCommerce (Dormant)\\nContempt of Congress\\nDeclaration of war\\nImpeachment\\nInquiries\\nTri\"| __truncated__ \"Salaries\\nFranking\\nImmunity\" \"Act of Congress\\nlist\\nAppropriation bill\\nBill\\nBudget process\\nCensure\\nClosed sessions\\nHouse\\nSenate\\nClotu\"| __truncated__ ...\n  ..$                                                          : chr [1:10] \"Powers\" NA NA NA ...\n  ..$                                                          : chr [1:10] \"Article I\\nCopyright\\nCommerce (Dormant)\\nContempt of Congress\\nDeclaration of war\\nImpeachment\\nInquiries\\nTri\"| __truncated__ NA NA NA ...\n  ..$                                                          : chr [1:10] \"Privileges\" NA NA NA ...\n  ..$                                                          : chr [1:10] \"Salaries\\nFranking\\nImmunity\" NA NA NA ...\n  ..$                                                          : chr [1:10] \"Procedure\" NA NA NA ...\n  ..$                                                          : chr [1:10] \"Act of Congress\\nlist\\nAppropriation bill\\nBill\\nBudget process\\nCensure\\nClosed sessions\\nHouse\\nSenate\\nClotu\"| __truncated__ NA NA NA ...\n  ..$                                                          : chr [1:10] \"Senate-specific\" NA NA NA ...\n  ..$                                                          : chr [1:10] \"Advice and consent\\nBlue slip (U.S. Senate)\\nClasses\\nExecutive communication\\nExecutive session\\nFilibuster\\nJ\"| __truncated__ NA NA NA ...\n  ..$                                                          : chr [1:10] \"Committees\" NA NA NA ...\n  ..$                                                          : chr [1:10] \"Chairman and ranking member\\nOf the Whole\\nConference\\nDischarge petition\\nHearings\\nMarkup\\nOversight\\nList (J\"| __truncated__ NA NA NA ...\n  ..$                                                          : chr [1:10] \"Items\" NA NA NA ...\n  ..$                                                          : chr [1:10] \"Gavels\\nMace of the House\\nSeal of the Senate\" NA NA NA ...\n  ..$                                                          : chr [1:10] \"History\" NA NA NA ...\n  ..$                                                          : chr [1:10] \"House history\\nmemoirs\\nspeaker elections\\nSenate history\\nelection disputes\\nmemoirs\\nContinental Congress\\nFe\"| __truncated__ NA NA NA ...\n  ..$                                                          : chr [1:10] \"House history\\nmemoirs\\nspeaker elections\\nSenate history\\nelection disputes\\nmemoirs\\nContinental Congress\\nFe\"| __truncated__ NA NA NA ...\n  ..$                                                          : chr [1:10] \"House history\\nmemoirs\\nspeaker elections\\nSenate history\\nelection disputes\\nmemoirs\\nContinental Congress\\nFe\"| __truncated__ NA NA NA ...\n  ..$                                                          : chr [1:10] \"Media\" NA NA NA ...\n  ..$                                                          : chr [1:10] \"C-SPAN\\nCongressional Quarterly\\nThe Hill\\nPolitico\\nRoll Call\" NA NA NA ...\n $ : tibble [9 × 4] (S3: tbl_df/tbl/data.frame)\n  ..$ X1: chr [1:9] \"Powers\" \"Privileges\" \"Procedure\" \"Senate-specific\" ...\n  ..$ X2: chr [1:9] \"Article I\\nCopyright\\nCommerce (Dormant)\\nContempt of Congress\\nDeclaration of war\\nImpeachment\\nInquiries\\nTri\"| __truncated__ \"Salaries\\nFranking\\nImmunity\" \"Act of Congress\\nlist\\nAppropriation bill\\nBill\\nBudget process\\nCensure\\nClosed sessions\\nHouse\\nSenate\\nClotu\"| __truncated__ \"Advice and consent\\nBlue slip (U.S. Senate)\\nClasses\\nExecutive communication\\nExecutive session\\nFilibuster\\nJ\"| __truncated__ ...\n  ..$ X3: chr [1:9] NA NA NA NA ...\n  ..$ X4: chr [1:9] NA NA NA NA ...\n $ : tibble [1 × 2] (S3: tbl_df/tbl/data.frame)\n  ..$ X1: chr \"House history\\nmemoirs\\nspeaker elections\\nSenate history\\nelection disputes\\nmemoirs\\nContinental Congress\\nFe\"| __truncated__\n  ..$ X2: chr \"House history\\nmemoirs\\nspeaker elections\\nSenate history\\nelection disputes\\nmemoirs\\nContinental Congress\\nFe\"| __truncated__\n $ : tibble [16 × 32] (S3: tbl_df/tbl/data.frame)\n  ..$ Capitol Complex (Capitol Hill): chr [1:16] \"Legislativeoffices\\nCongressional staff\\nGov. Accountability Office (GAO)\\nComptroller General\\nArchitect of th\"| __truncated__ \"Legislativeoffices\" \"Offices\" \"Senate\" ...\n  ..$ Capitol Complex (Capitol Hill): chr [1:16] \"Legislativeoffices\\nCongressional staff\\nGov. Accountability Office (GAO)\\nComptroller General\\nArchitect of th\"| __truncated__ \"Congressional staff\\nGov. Accountability Office (GAO)\\nComptroller General\\nArchitect of the Capitol\\nCap. Poli\"| __truncated__ \"Senate\\nCurator\\nHistorical\\nLibraryHouse\\nCongr. Ethics\\nEmergency Planning, Preparedness, and Operations\\nInt\"| __truncated__ \"Curator\\nHistorical\\nLibrary\" ...\n  ..$                               : chr [1:16] \"Legislativeoffices\" NA \"Senate\" NA ...\n  ..$                               : chr [1:16] \"Congressional staff\\nGov. Accountability Office (GAO)\\nComptroller General\\nArchitect of the Capitol\\nCap. Poli\"| __truncated__ NA \"Curator\\nHistorical\\nLibrary\" NA ...\n  ..$                               : chr [1:16] \"Offices\" NA \"House\" NA ...\n  ..$                               : chr [1:16] \"Senate\\nCurator\\nHistorical\\nLibraryHouse\\nCongr. Ethics\\nEmergency Planning, Preparedness, and Operations\\nInt\"| __truncated__ NA \"Congr. Ethics\\nEmergency Planning, Preparedness, and Operations\\nInterparliamentary Affairs\\nLaw Revision Couns\"| __truncated__ NA ...\n  ..$                               : chr [1:16] \"Senate\" NA NA NA ...\n  ..$                               : chr [1:16] \"Curator\\nHistorical\\nLibrary\" NA NA NA ...\n  ..$                               : chr [1:16] \"House\" NA NA NA ...\n  ..$                               : chr [1:16] \"Congr. Ethics\\nEmergency Planning, Preparedness, and Operations\\nInterparliamentary Affairs\\nLaw Revision Couns\"| __truncated__ NA NA NA ...\n  ..$                               : chr [1:16] \"Employees\" NA NA NA ...\n  ..$                               : chr [1:16] \"Senate\\nSecretary\\nChaplain\\nCurator\\nHistorian\\nLibrarian\\nPages\\nParliamentarian\\nSergeant at Arms and Doorke\"| __truncated__ NA NA NA ...\n  ..$                               : chr [1:16] \"Senate\" NA NA NA ...\n  ..$                               : chr [1:16] \"Secretary\\nChaplain\\nCurator\\nHistorian\\nLibrarian\\nPages\\nParliamentarian\\nSergeant at Arms and Doorkeeper\" NA NA NA ...\n  ..$                               : chr [1:16] \"House\" NA NA NA ...\n  ..$                               : chr [1:16] \"Chaplain\\nChief Administrative Officer\\nClerk\\nDoorkeeper\\nFloor Operations\\nFloor Services Chief\\nHistorian\\nP\"| __truncated__ NA NA NA ...\n  ..$                               : chr [1:16] \"Library ofCongress\" NA NA NA ...\n  ..$                               : chr [1:16] \"Congressional Research Service\\nreports\\nCopyright Office\\nRegister of Copyrights\\nLaw Library\\nPoet Laureate\\n\"| __truncated__ NA NA NA ...\n  ..$                               : chr [1:16] \"Gov.Publishing Office\" NA NA NA ...\n  ..$                               : chr [1:16] \"Public Printer\\nCongressional Pictorial Directory\\nCongressional Record\\nOfficial Congressional Directory\\nU.S.\"| __truncated__ NA NA NA ...\n  ..$                               : chr [1:16] \"Capitol Building\" NA NA NA ...\n  ..$                               : chr [1:16] \"List of artwork at the United States Capitol complex\\nBrumidi Corridors\\nCongressional Prayer Room\\nCrypt\\nDome\"| __truncated__ NA NA NA ...\n  ..$                               : chr [1:16] \"Officebuildings\" NA NA NA ...\n  ..$                               : chr [1:16] \"Senate\\nDirksen\\nHart\\nMountains and Clouds\\nRussellHouse\\nBuilding Commission\\noffice lottery\\nCannon\\nFord\\nL\"| __truncated__ NA NA NA ...\n  ..$                               : chr [1:16] \"Senate\" NA NA NA ...\n  ..$                               : chr [1:16] \"Dirksen\\nHart\\nMountains and Clouds\\nRussell\" NA NA NA ...\n  ..$                               : chr [1:16] \"House\" NA NA NA ...\n  ..$                               : chr [1:16] \"Building Commission\\noffice lottery\\nCannon\\nFord\\nLongworth\\nO'Neill\\nRayburn\" NA NA NA ...\n  ..$                               : chr [1:16] \"Otherfacilities\" NA NA NA ...\n  ..$                               : chr [1:16] \"Botanic Garden\\nHealth and Fitness Facility\\nHouse Recording Studio\\nSenate chamber\\nOld Senate Chamber\\nOld Su\"| __truncated__ NA NA NA ...\n  ..$                               : chr [1:16] \"Related\" NA NA NA ...\n  ..$                               : chr [1:16] \"Capitol Hill\\nUnited States Capitol cornerstone laying\" NA NA NA ...\n $ : tibble [15 × 6] (S3: tbl_df/tbl/data.frame)\n  ..$ X1: chr [1:15] \"Legislativeoffices\" \"Offices\" \"Senate\" \"House\" ...\n  ..$ X2: chr [1:15] \"Congressional staff\\nGov. Accountability Office (GAO)\\nComptroller General\\nArchitect of the Capitol\\nCap. Poli\"| __truncated__ \"Senate\\nCurator\\nHistorical\\nLibraryHouse\\nCongr. Ethics\\nEmergency Planning, Preparedness, and Operations\\nInt\"| __truncated__ \"Curator\\nHistorical\\nLibrary\" \"Congr. Ethics\\nEmergency Planning, Preparedness, and Operations\\nInterparliamentary Affairs\\nLaw Revision Couns\"| __truncated__ ...\n  ..$ X3: chr [1:15] NA \"Senate\" NA NA ...\n  ..$ X4: chr [1:15] NA \"Curator\\nHistorical\\nLibrary\" NA NA ...\n  ..$ X5: chr [1:15] NA \"House\" NA NA ...\n  ..$ X6: chr [1:15] NA \"Congr. Ethics\\nEmergency Planning, Preparedness, and Operations\\nInterparliamentary Affairs\\nLaw Revision Couns\"| __truncated__ NA NA ...\n $ : tibble [2 × 2] (S3: tbl_df/tbl/data.frame)\n  ..$ X1: chr [1:2] \"Senate\" \"House\"\n  ..$ X2: chr [1:2] \"Curator\\nHistorical\\nLibrary\" \"Congr. Ethics\\nEmergency Planning, Preparedness, and Operations\\nInterparliamentary Affairs\\nLaw Revision Couns\"| __truncated__\n $ : tibble [2 × 2] (S3: tbl_df/tbl/data.frame)\n  ..$ X1: chr [1:2] \"Senate\" \"House\"\n  ..$ X2: chr [1:2] \"Secretary\\nChaplain\\nCurator\\nHistorian\\nLibrarian\\nPages\\nParliamentarian\\nSergeant at Arms and Doorkeeper\" \"Chaplain\\nChief Administrative Officer\\nClerk\\nDoorkeeper\\nFloor Operations\\nFloor Services Chief\\nHistorian\\nP\"| __truncated__\n $ : tibble [2 × 2] (S3: tbl_df/tbl/data.frame)\n  ..$ X1: chr [1:2] \"Senate\" \"House\"\n  ..$ X2: chr [1:2] \"Dirksen\\nHart\\nMountains and Clouds\\nRussell\" \"Building Commission\\noffice lottery\\nCannon\\nFord\\nLongworth\\nO'Neill\\nRayburn\"\n $ : tibble [2 × 2] (S3: tbl_df/tbl/data.frame)\n  ..$ vteOrder of precedence in the United States*: chr [1:2] \"President Donald TrumpVice President JD Vance\\nGovernor (of the state in which the event is held)\\nHouse Speake\"| __truncated__ \"*not including acting officeholders, visiting dignitaries, auxiliary executive and military personnel and most diplomats\"\n  ..$ vteOrder of precedence in the United States*: chr [1:2] \"President Donald TrumpVice President JD Vance\\nGovernor (of the state in which the event is held)\\nHouse Speake\"| __truncated__ \"*not including acting officeholders, visiting dignitaries, auxiliary executive and military personnel and most diplomats\"\n\n\nHere, the table I want is the sixth one. We can grab it by either using double square brackets – [[6]] – or purrr’s pluck(6).\n\nsenators &lt;- tables |&gt; \n  pluck(6)\n\nglimpse(senators)\n\nRows: 100\nColumns: 12\n$ State                        &lt;chr&gt; \"Alabama\", \"Alabama\", \"Alaska\", \"Alaska\",…\n$ Portrait                     &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ Senator                      &lt;chr&gt; \"Tommy Tuberville\", \"Katie Britt\", \"Lisa …\n$ Party                        &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ Party                        &lt;chr&gt; \"Republican\", \"Republican\", \"Republican\",…\n$ Born                         &lt;chr&gt; \"(1954-09-18) September 18, 1954 (age 71)…\n$ `Occupation(s)`              &lt;chr&gt; \"Investment management firm partner\\nColl…\n$ `Previous electiveoffice(s)` &lt;chr&gt; \"None\", \"None\", \"Alaska House of Represen…\n$ Education                    &lt;chr&gt; \"Southern Arkansas University (BS)\", \"Uni…\n$ `Assumed office`             &lt;chr&gt; \"January 3, 2021\", \"January 3, 2023\", \"De…\n$ Class                        &lt;chr&gt; \"2026Class 2\", \"2028Class 3\", \"2028Class …\n$ `Residence[4]`               &lt;chr&gt; \"Auburn[5]\", \"Montgomery\", \"Girdwood\", \"A…\n\n## alternative approach using css\nsenators &lt;- us_senators |&gt; \n  html_elements(css = \"#senators\") |&gt; \n  html_table() |&gt; \n  pluck(1) |&gt; \n  janitor::clean_names()\n\nYou can see that the tibble contains “dirty” names and that the party column appears twice – which will make it impossible to work with the tibble later on. Hence, I use clean_names() from the janitor package to fix that.\n\n\nExtracting attributes\nYou can also extract attributes such as links using html_attrs(). An example would be to extract the headlines and their corresponding links from r-bloggers.com.\n\nrbloggers &lt;- read_html(\"https://www.r-bloggers.com\")\n\nA quick check with the SelectorGadget told me that the element I am looking for is of class “.loop-title” and the child of it is “a”, standing for normal text. With html_attrs() I can extract the attributes. This gives me a list of named vectors containing the name of the attribute and the value:\nLinks are stored as attribute “href” – hyperlink reference. html_attr() allows me to extract the attribute’s value. Hence, building a tibble with the article’s title and its corresponding hyperlink is straight-forward now:\n\ntibble(\n  title = r_blogger_postings |&gt; html_text2(),\n  link = r_blogger_postings |&gt; html_attr(name = \"href\")\n)\n\n# A tibble: 20 × 2\n   title                                                                   link \n   &lt;chr&gt;                                                                   &lt;chr&gt;\n 1 Dimension reduction                                                     http…\n 2 Graceful Internet Packages                                              http…\n 3 A Gentle Introduction to Mathematical Simulation in R workshop          http…\n 4 Reversed                                                                http…\n 5 Faking plotly’s ‘y unified’ tooltip in ggiraph                          http…\n 6 Data centers                                                            http…\n 7 simaerep release 1.0.0                                                  http…\n 8 Highlights from Shiny in Production (2025)                              http…\n 9 maestro 0.7.0 introduces conditional pipelines                          http…\n10 Behavior-Driven Development in R Shiny: Setting Up Test Preconditions … http…\n11 An Introduction to Writing Your Own ggplot2 Geoms                       http…\n12 Country codes                                                           http…\n13 Little useless-useful R functions – Useless Pyramid of R needs          http…\n14 Ridgelines                                                              http…\n15 Taming Volatility: High-Performance Forecasting of the STOXX 600 with … http…\n16 Eight-thousanders                                                       http…\n17 Prussian Horse Kicks II: Mixed Effects Models                           http…\n18 Simplifying Interactions with Complex Widgets in shinytest2 Using Java… http…\n19 New Council Members                                                     http…\n20 Pledging My Time VII                                                    http…\n\n\nAnother approach for this would be using the polite package and its function html_attrs_dfr() which binds together all the different attributes column-wise and the different elements row-wise.\n\nrbloggers |&gt; \n  html_elements(css = \".loop-title a\") |&gt; \n  html_attrs_dfr() |&gt; \n  select(title = 3, \n         link = 1) |&gt; \n  glimpse()\n\nRows: 20\nColumns: 2\n$ title &lt;chr&gt; \"Dimension reduction\", \"Graceful Internet Packages\", \"A Gentle I…\n$ link  &lt;chr&gt; \"https://www.r-bloggers.com/2025/11/dimension-reduction/\", \"http…\n\n\n\n\nExercise\n\nDownload the links and names of the top 250 IMDb movies. Put them in a tibble with the columns rank – in numeric format (you know regexes already), title, url to IMDb entry, rating – in numeric format, number_votes – the number of votes a movie has received, in numeric format. Also, what do you notice?\n\n\n\nSolution. Click to expand!\n\n\nimdb_top250 &lt;- read_html(\"https://www.imdb.com/chart/top/?ref_=nv_mv_250\")\n\nmovies &lt;- tibble(\n  rank = imdb_top250 |&gt; \n    html_elements(\".cli-title .ipc-title__text\") |&gt; \n    html_text2() |&gt; \n    str_extract(\"^[0-9]+(?=\\\\.)\") |&gt; \n    parse_integer(),\n  title = imdb_top250 |&gt; \n    html_elements(\".cli-title .ipc-title__text\") |&gt; \n    html_text2() |&gt; \n    str_remove(\"^[0-9]+\\\\. \"),\n  url = imdb_top250 |&gt; \n    html_elements(\".cli-title a\") |&gt; \n    html_attr(\"href\") |&gt; \n    str_c(\"https://www.imdb.com\", x = _),\n  rating = imdb_top250 |&gt; \n    html_elements(\".ratingGroup--imdb-rating\") |&gt; \n    html_text() |&gt; \n    str_extract(\"[0-9]\\\\.[0-9]\") |&gt; \n    parse_double(),\n  no_votes = imdb_top250 |&gt; \n    html_elements(\".ratingGroup--imdb-rating\") |&gt; \n    html_text() |&gt; \n    str_remove(\"^[0-9]\\\\.[0-9]\") |&gt; \n    str_remove_all(\"[() ]\")\n)"
  },
  {
    "objectID": "7_scraping.html#automating-scraping",
    "href": "7_scraping.html#automating-scraping",
    "title": "Chapter 7: Scraping Static Pages with rvest",
    "section": "Automating scraping",
    "text": "Automating scraping\nWell, grabbing singular points of data from websites is nice. However, if you want to do things such as collecting large amounts of data or multiple pages, you will not be able to do this without some automation.\n\n\n\n\n\n\n\n\n\nAn example here would again be the R-bloggers page. It provides you with plenty of R-related content. If you were now eager to scrape all the articles, you would first need to acquire all the different links leading to the blog postings. Hence, you would need to navigate through the site’s pages first to acquire the links.\nIn general, there are two ways to go about this. The first is to manually create a list of URLs the scraper will visit and take the content you need, therefore not needing to identify where it needs to go next. The other one would be automatically acquiring its next destination from the page (i.e., identifying the “go on” button). Both strategies can also be nicely combined with some sort of session().\n\nLooping over pages\nFor the first approach, we need to check the URLs first. How do they change as we navigate through the pages?\n\nurl_1 &lt;- \"https://www.r-bloggers.com\"\nurl_2 &lt;- \"https://www.r-bloggers.com/page/2/\"\nurl_3 &lt;- \"https://www.r-bloggers.com/page/3/\"\n\ninitial_dist &lt;- adist(url_2, url_3, counts = TRUE) |&gt; \n  attr(\"trafos\") |&gt; \n  diag() |&gt; \n  str_locate_all(\"[^M]\")\n\n  \nstr_sub(url_2, start = initial_dist[[1]][1]-5, end = initial_dist[[1]][1]+5) # makes sense for longer urls\n\n[1] \"page/2/\"\n\nstr_sub(url_3, start = initial_dist[[1]][1]-5, end = initial_dist[[1]][1]+5)\n\n[1] \"page/3/\"\n\n\nThere is some sort of underlying pattern and we can harness that. url_1 refers to the second page, url_2 to the third. Hence, if we just combine the basic URL and, say, the numbers from 1 to 10, we could then visit all the pages (exercise 3a) and extract the content we want.\n\nurls &lt;- str_c(\"https://www.r-bloggers.com/page/\", 1:10, \"/\") # this is the stringr equivalent of paste()\nurls\n\n [1] \"https://www.r-bloggers.com/page/1/\"  \"https://www.r-bloggers.com/page/2/\" \n [3] \"https://www.r-bloggers.com/page/3/\"  \"https://www.r-bloggers.com/page/4/\" \n [5] \"https://www.r-bloggers.com/page/5/\"  \"https://www.r-bloggers.com/page/6/\" \n [7] \"https://www.r-bloggers.com/page/7/\"  \"https://www.r-bloggers.com/page/8/\" \n [9] \"https://www.r-bloggers.com/page/9/\"  \"https://www.r-bloggers.com/page/10/\"\n\n\nYou can run this in a for-loop, here’s a quick revision. For the loop to run efficiently, space for every object should be pre-allocated (i.e., you create a list beforehand, and its length can be determined by an educated guess).\n\n## THIS IS PSEUDO CODE!!!\nresult_list &lt;- vector(mode = \"list\", length = length(urls)) # pre-allocate space!!!\nstarting_link &lt;- \"https://www.r-bloggers.com/page/1/\"\n####PSEUDO CODE!!!\nfor (i in seq_along(urls)){\n  read in urls[[i]] --&gt; page &lt;- read_html(url)\n  store content of page in result_list result_list[[i]] &lt;- extract_content(page)\n}\n\nmap(urls, read_html)\n\n\n\nLetting the scraper navigate on its own\nExtracting the link on the fly is the same thing, but in the end, you need to replace the link argument with the one you extracted. You will do this in exercise 3. It is probably easiest to perform those things in a while loop, hence here is a quick revision:\nHence, our while loop in pseudo-code will look like this:\n\n## THIS IS PSEUDO CODE!!!\noutput_list &lt;- vector(mode = \"list\", length = 10L)\ni &lt;- 0\nwhile (session$response$status_code == 200 && i &lt;= 10) {\n  session(start-url)\n  i &lt;- i + 1\n  read in r-bloggers results list\n  get all stuff and store it in output_list[[i]]\n  move session to next page\n}\n\n### reminder: how to click a button in rvest\n\nsession(\"https://www.scrapethissite.com/\") |&gt; \n  session_follow_link(css = \"#nav-lessons .nav-link\") # just use selectorgadget to check for css selector of button\n\n\n\nExercise\n\nScrape 5 pages of the latest UN press releases in an automated fashion. Make sure to take breaks between requests by including Sys.sleep(2). For each iteration, store the articles and links in a tibble containing the columns title,link, and date (bonus: store it in date format). (Tip: wrap the code that extracts and stores content in a tibble in a function.)\n\n\nDo so using running numbers in the urls.\nDo so by using session() in a loop. (Note: make sure to specify css =)\n\n\n\nSolution. Click to expand!\n\n\nextract_press_releases &lt;- function(page){\n  tibble(\n    title = page |&gt; \n      html_elements(\".field__item a\") |&gt; \n      html_text2(),\n    link = page |&gt; \n      html_elements(\".field__item a\") |&gt; \n      html_attr(\"href\"),\n    date = page |&gt; \n      html_elements(\".field--type-datetime\") |&gt; \n      html_text2() |&gt; \n      as.Date(format = \"%d %B %Y\")\n  )\n  \n}\n\n\n#a\nurls &lt;- str_c(\"https://press.un.org/en/content/secretary-general/press-release?page=\", 0:4)\n\npages &lt;- map(urls, \n             \\(x){\n               Sys.sleep(2) \n               read_html(x) |&gt; \n                 extract_press_releases()\n               }\n             )\n\n#b\nun_session &lt;- session(\"https://press.un.org/en/content/secretary-general/press-release\")\ni &lt;- 1\npage_list &lt;- vector(mode = \"list\", length = 5L)\nwhile (i &lt; 6) {\n  page_list[[i]] &lt;- read_html(un_session) |&gt; \n    extract_press_releases()\n  un_session &lt;- un_session |&gt; \n    session_follow_link(css = \".me-s .page-link\")\n  i &lt;- i + 1\n  Sys.sleep(2)\n}"
  },
  {
    "objectID": "7_scraping.html#conclusion",
    "href": "7_scraping.html#conclusion",
    "title": "Chapter 7: Scraping Static Pages with rvest",
    "section": "Conclusion",
    "text": "Conclusion\nTo sum it up: when you have a good research idea that relies on Digital Trace Data that you need to collect, ask yourself the following questions:\n\nIs there some sort of data dump that I can download?\nIs there an R package for the web service?\nIf 1. == FALSE: Is there an API where I can get the data (if TRUE, use it) – next chapter.\nIf 1. == FALSE & 2. == FALSE: Is screen scraping an option and any structure in the data that you can harness?\n\nIf you have to rely on screen scraping, also ask yourself the question how you can minimize the number of requests you make to the server. Going back and forth on web pages or navigating through them might not be the best option since it requires multiple requests. The most efficient way is usually to try to get a list of URLs of some sort which you can then just loop over."
  },
  {
    "objectID": "lectures-overview.html",
    "href": "lectures-overview.html",
    "title": "Overview – week by week",
    "section": "",
    "text": "This week answers the following questions:\n\nWhat does the term CSS mean?\nWhich principles underly a new CSS?\nWhich methods does CSS encompass?\nHow do we set up our computational workstation?"
  },
  {
    "objectID": "lectures-overview.html#week-1-kick-off",
    "href": "lectures-overview.html#week-1-kick-off",
    "title": "Overview – week by week",
    "section": "",
    "text": "This week answers the following questions:\n\nWhat does the term CSS mean?\nWhich principles underly a new CSS?\nWhich methods does CSS encompass?\nHow do we set up our computational workstation?"
  },
  {
    "objectID": "lectures-overview.html#week-2-brief-intro-to-python-regexes",
    "href": "lectures-overview.html#week-2-brief-intro-to-python-regexes",
    "title": "Overview – week by week",
    "section": "Week 2: Brief Intro to Python & Regexes",
    "text": "Week 2: Brief Intro to Python & Regexes\nThis week answers the following questions:\n\nHow can we run Python in RStudio using reticulate?\nWhat are the basics of Python programming?\nWhat are regular expressions and why are they powerful?\nHow can we use stringr to work with text patterns?"
  },
  {
    "objectID": "lectures-overview.html#week-3-data-acquisition-i",
    "href": "lectures-overview.html#week-3-data-acquisition-i",
    "title": "Overview – week by week",
    "section": "Week 3: Data Acquisition I",
    "text": "Week 3: Data Acquisition I\nThis week answers the following questions:\n\nHow is the web written and structured?\nWhat are considerations in terms of law and ethics when scraping?\nHow do we acquire digital trace data via web scraping with rvest?\nWhat are CSS selectors and how do they work?"
  },
  {
    "objectID": "lectures-overview.html#week-4-data-acquisition-ii",
    "href": "lectures-overview.html#week-4-data-acquisition-ii",
    "title": "Overview – week by week",
    "section": "Week 4: Data Acquisition II",
    "text": "Week 4: Data Acquisition II\nThis week answers the following questions:\n\nHow do we scrape dynamic web pages that use JavaScript?\nHow can we interact with forms and buttons using selenium?\nWhat are APIs and how do we use them?\nHow do we make API calls with httr2?"
  },
  {
    "objectID": "lectures-overview.html#week-5-data-acquisition-iii",
    "href": "lectures-overview.html#week-5-data-acquisition-iii",
    "title": "Overview – week by week",
    "section": "Week 5: Data Acquisition III",
    "text": "Week 5: Data Acquisition III\nThis week answers the following questions:\n\nWhat is Optical Character Recognition (OCR)?\nHow can we extract text from images and PDFs?\nWhat is speech-to-text transcription?\nHow can we leverage these techniques for social science research?"
  },
  {
    "objectID": "lectures-overview.html#week-6-data-acquisition-iv",
    "href": "lectures-overview.html#week-6-data-acquisition-iv",
    "title": "Overview – week by week",
    "section": "Week 6: Data Acquisition IV",
    "text": "Week 6: Data Acquisition IV\nThis week answers the following questions:\n\nHow do we digitize text using Tesseract?\nHow do we digitize speech using OpenAI Whisper?\nWhat are best practices for data acquisition projects?\nHow do we plan our research projects?"
  },
  {
    "objectID": "lectures-overview.html#week-7-student-project-week",
    "href": "lectures-overview.html#week-7-student-project-week",
    "title": "Overview – week by week",
    "section": "Week 7: Student Project Week",
    "text": "Week 7: Student Project Week\nThis week is dedicated to working on your research projects in class.\n\nDiscuss your project ideas with peers and the instructor\nBegin data acquisition for your research\nTroubleshoot technical challenges\nForm study groups with matching research interests"
  },
  {
    "objectID": "lectures-overview.html#week-8-text-as-data-i",
    "href": "lectures-overview.html#week-8-text-as-data-i",
    "title": "Overview – week by week",
    "section": "Week 8: Text as Data I",
    "text": "Week 8: Text as Data I\nThis week answers the following questions:\n\nWhat do we mean by “text as data”?\nWhat do we mean by “bag of words”?\nHow do we perform sentiment analysis?\nWhat are TF-IDF, Named Entity Recognition (NER), and Part-of-Speech (POS) tagging?"
  },
  {
    "objectID": "lectures-overview.html#week-9-text-as-data-ii",
    "href": "lectures-overview.html#week-9-text-as-data-ii",
    "title": "Overview – week by week",
    "section": "Week 9: Text as Data II",
    "text": "Week 9: Text as Data II\nThis week answers the following questions:\n\nWhat is supervised machine learning?\nHow can we train classifiers to categorize text?\nWhat are best practices for supervised ML in social science?\nHow do we evaluate model performance?"
  },
  {
    "objectID": "lectures-overview.html#week-10-text-as-data-iii",
    "href": "lectures-overview.html#week-10-text-as-data-iii",
    "title": "Overview – week by week",
    "section": "Week 10: Text as Data III",
    "text": "Week 10: Text as Data III\nThis week answers the following questions:\n\nWhat is unsupervised machine learning?\nHow does topic modeling work?\nWhat can probabilistic topic models tell us about text corpora?\nWhen should we use unsupervised vs. supervised approaches?"
  },
  {
    "objectID": "lectures-overview.html#week-11-text-as-data-iv",
    "href": "lectures-overview.html#week-11-text-as-data-iv",
    "title": "Overview – week by week",
    "section": "Week 11: Text as Data IV",
    "text": "Week 11: Text as Data IV\nThis week answers the following questions:\n\nHow can we go beyond the “bag of words”?\nWhat is the distributional hypothesis?\nHow can we measure semantic similarity between texts?\nWhat are word embeddings and what do they capture?"
  },
  {
    "objectID": "lectures-overview.html#week-12-text-as-data-v",
    "href": "lectures-overview.html#week-12-text-as-data-v",
    "title": "Overview – week by week",
    "section": "Week 12: Text as Data V",
    "text": "Week 12: Text as Data V\nThis week answers the following questions:\n\nWhat are transformer models like BERT?\nHow do these models revolutionize text classification?\nWhat is transfer learning and why is it so powerful?\nWhat is active learning and how can it reduce annotation burden?"
  },
  {
    "objectID": "lectures-overview.html#week-13-text-as-data-vi",
    "href": "lectures-overview.html#week-13-text-as-data-vi",
    "title": "Overview – week by week",
    "section": "Week 13: Text as Data VI",
    "text": "Week 13: Text as Data VI\nThis week answers the following questions:\n\nWhat’s the latest in Natural Language Processing with Large Language Models (LLMs)?\nHow can we use LLMs for information extraction?\nWhat are local LLMs and when should we use them?\nHow do we move from codebooks to promptbooks?"
  },
  {
    "objectID": "lectures-overview.html#week-14-presentation-preparation-week",
    "href": "lectures-overview.html#week-14-presentation-preparation-week",
    "title": "Overview – week by week",
    "section": "Week 14: Presentation Preparation Week",
    "text": "Week 14: Presentation Preparation Week\nThis week is dedicated to preparing your final presentations.\n\nFinalize your analyses and preliminary results\nPrepare presentation slides (deadline: January 30, 6PM)\nReview the peer review guidelines\nPractice your 10-minute presentation"
  },
  {
    "objectID": "lectures-overview.html#week-15-presentations-wrap-up",
    "href": "lectures-overview.html#week-15-presentations-wrap-up",
    "title": "Overview – week by week",
    "section": "Week 15: Presentations & Wrap Up",
    "text": "Week 15: Presentations & Wrap Up\nThis week features peer-reviewed presentations of your research projects.\n\nPresent your research (10 minutes)\nReceive feedback from assigned peer reviewers (5 minutes)\nDiscuss next steps for your final paper\nReflect on what we’ve learned throughout the semester"
  },
  {
    "objectID": "2_r_catch-up.html",
    "href": "2_r_catch-up.html",
    "title": "Chapter 2: Brief R Recap",
    "section": "",
    "text": "I assume your familiarity with R. However, I am fully aware that nobody can have all these things avaible in their head all the time (that’s what they invented StackOverflow for, new AI helpers are also pretty good). In the following, I show some basics of how I use R (i.e., RStudio Projects, scripts, Quarto) as well as some data wrangling stuff (readr, tidyr, dplyr), visualization with ggplot2, functions, loops, and purrr. If you need more info, check out the “further links” I have added after each section. There are also exercises after each section.\nYou can find the files for this chapter in the GitHub repository.\nneeds(tidyverse, lubridate, fs, socviz)\nOne quick thing upfront: AI coding helpers have become increasingly popular. You can, for instance, use GitHub Copilot in RStudio (if you have access to it) or ChatGPT/Claude (the free versions are already pretty good). However, please note that those tools are not perfect and can produce wrong code. Hence, you need to understand what they do and check the code they provide you with. If you do not understand what a piece of code does, do not use it. If you want to learn R properly, I strongly recommend you to try to write the code yourself first and only use those tools if you get stuck."
  },
  {
    "objectID": "2_r_catch-up.html#rstudio-projects",
    "href": "2_r_catch-up.html#rstudio-projects",
    "title": "Chapter 2: Brief R Recap",
    "section": "RStudio Projects",
    "text": "RStudio Projects\n\nMotivation\nDisclaimer: those things might not be entirely clear right away. However, I am deeply convinced that it is important that you use R and RStudio properly from the start. Otherwise it won’t be as easy to re-build the right habits.\nIf you analyze data with R, one of the first things you do is to load in the data that you want to perform your analyses on. Then, you perform your analyses on them, and save the results in the (probably) same directory.\nWhen you load a data set into R, you might use the readr package and do read_csv(absolute_file_path.csv). This becomes fairly painful if you need to read in more than one data set. Then, relative paths (i.e., where you start from a certain point in your file structure, e.g., your file folder) become more useful. How you CAN go across this is to use the setwd(absolute_file_path_to_your_directory) function. Here, set stands for set and wd stands for working directory. If you are not sure about what the current working directory actually is, you can use getwd() which is the equivalent to setwd(file_path). This enables you to read in a data set – if the file is in the working directory – by only using read_csv(file_name.csv).\nHowever, if you have ever worked on an R project with other people in a group and exchanged scripts regularly, you may have encountered one of the big problems with this setwd(file_path) approach: as it only takes absolute paths like this one: “/Users/felixlennert/Library/Mobile Documents/comappleCloudDocs/phd/teaching/hhs-stockholm/fall2021/scripts/”, no other person will be able to run this script without making any changes1. Just to be clear: there are no two machines which have the exact same file structure.\nThis is where RStudio Projects come into play: they make every file path relative. The Project file (ends with .Rproj) basically sets the working directory to the folder it is in. Hence, if you want to send your work to a peer or a teacher, just send a folder which also contains the .Rproj file and they will be able to work on your project without the hassle of pasting file paths into setwd() commands.\n\n\nHow to create an RStudio Project?\nI strongly suggest that you set up a project which is dedicated to this course.\n\nIn RStudio, click File &gt;&gt; New Project…\nA window pops up which lets you select between “New Directory”, “Existing Directory”, and “Version Control.” The first option creates a new folder which is named after your project, the second one “associates a project with an existing working directory,” and the third one only applies to version control (like, for instance, GitHub) users. I suggest that you click “New Directory”.\nNow you need to specify the type of the project (Empty project, R package, or Shiny Web Application). In our case, you will need a “new project.” Hit it!\n\nThe final step is to choose the folder the project will live in. If you have already created a folder which is dedicated to this course, choose this one, and let the project live in there as a sub-directory.\nWhen you write code for our course in the future, you first open the R project – by double-clicking the .Rproj file – and then create either a new script or open a former one (e.g., by going through the “Files” tab in the respective pane which will show the right directory already.)"
  },
  {
    "objectID": "2_r_catch-up.html#r-scripts-and-quarto",
    "href": "2_r_catch-up.html#r-scripts-and-quarto",
    "title": "Chapter 2: Brief R Recap",
    "section": "R scripts and Quarto",
    "text": "R scripts and Quarto\nIn this course, you will work with two sorts of documents to store your code in: R scripts (suffix .R) and Quarto documents (suffix .qmd). In the following, I will briefly introduce you to both of them.\n\nR scripts\nThe console, where you can only execute your code, is great for experimenting with R. If you want to store it – e.g., for sharing – you need something different. This is where R scripts come in handy. When you are in RStudio, you create a new script by either clicking File &gt;&gt; New File &gt;&gt; R Script or ctrl/cmd+shift+n. There are multiple ways to run code in the script:\n\ncmd/ctrl+return (Mac/Windows) – execute entire expression and jump to next line\n\noption/alt+return (Mac/Windows) – execute entire expression and remain in line\n\ncmd/ctrl+shift+return (Mac/Windows) – execute entire script from the beginning to the end (rule: every script you hand in or send to somebody else should run smoothly from the beginning to the end)\n\nIf you want to make annotations to your code (which you should do because it makes everything easier to read and understand), just insert ‘#’ into your code. Every expression that stands to the right of the ‘#’ sign will not be executed when you run the code.\n\n\nQuarto\nA time will come where you will not just do analyses for yourself in R, but you will also have to communicate them. Let’s take a master’s thesis as an example: you need a type of document that is able to encapsulate: text (properly formatted), visualizations (tables, graphs, maybe images), and references. An RMarkdown document can do it all, plus, your entire analysis can live in there as well. So there is no need anymore for the cumbersome process of copying data from MS Excel or IBM SPSS into an MS Word table. You just tell RMarkdown what it should communicate and what not.\nIn the following, I will not provide you with an exhaustive introduction to RMarkdown. Instead, I will focus on getting you started and then referring you to better, more exhaustive resources. It is not that I am too lazy to write a big tutorial, but there are state-of-the-art tutorials and resources (which mainly come straight from people who work on the forefront of the development of these tools) which are available for free. By linking to them, I want to encourage you to get involved and dig into this stuff. So, let’s get you started!\nYou create a Quarto document file by clicking File &gt;&gt; New File &gt;&gt; Quarto Document…. Then, a window pops up that looks like this:\n\n\n\nNew Quarto\n\n\nNote that you could also do a presentation (with the beamer package), a shiny app, a website (like this one), or use templates. We will focus on simple Quarto documents. Here, you can type in a title, the name(s) of the author(s), and choose the default output format. For now you have to choose one, but later you can switch to one of the others whenever you want to.\n\nHTML is handy for lightweight, quickly rendered files, or if you want to publish it on a website.\nPDF is good if you are experienced with LaTeX and want to further modify it in terms of formatting etc., or simply want to get a more formally looking document (I use it if I need to hand in something that is supposed to be graded). If you want to knit to PDF, you need a running LaTeX version on your machine. If you do not have one, I recommend you to install tinytex. I linked installation instructions down below.\nWord puts out an MS Word document – especially handy if you collaborate with people who are either not experienced in R, like older faculty, or want some parts to be proof-read (remember the Track-Changes function?). Note that you need to have MS Word or LibreOffice installed on your machine.\n\nDid you notice the term render? The logic behind Quarto documents is that you edit them in RStudio and then render them. This means that it calls the knitr package. Thereby, all the code you include into the document is executed from scratch. If the code does not work and throws an error, the document will not knit – hence, it needs to be properly written to avoid head-scratching. The knitr package creates a markdown file (suffix: .md). This is then processed by pandoc, a universal document converter. The big advantage of this two-step approach is that it enables a wide range of output formats.\nFor your first Quarto document, choose HTML and click “OK”. Then, you see a new plain-text file which looks like this:\n\n\n\nA fresh and clean Quarto document\n\n\nThe visual editor is quite similar to what we know from word processing software such as Microsoft Word. I will run you through the features in a quick video.\n\n\nFurther links\n\nChapter on Scripts and Projects in R4DS\nMore on RStudio Projects on the posit website\nChapter on Quarto in R4DS\nAll things Quarto on its dedicated website\nYihui Xie published a manual for installing the tinytex package\n\n\n\nExercises\n\nCreate a project for this course.\nCreate a Quarto file to work on the exercises. Add the exercises and answer them in code in the document.\nRender it. Does it work?"
  },
  {
    "objectID": "2_r_catch-up.html#reading-data-into-r",
    "href": "2_r_catch-up.html#reading-data-into-r",
    "title": "Chapter 2: Brief R Recap",
    "section": "Reading data into R",
    "text": "Reading data into R\nData is typically stored in csv-files and can be read in using readr. For “normal,” comma-separated values read_csv(\"file_path\") suffices. Sometimes, a semicolon is used instead of a comma (e.g., in countries that use the commas as a decimal sign). For these files, read_csv2(\"file_path) is the way to go.\nIf you encounter other data types, you just need to find the right tidyverse package to read the data in. Their syntax will be the same, it will just be the function names that differ.\n\nFurther links\n\nthe section on reading in data in R4DS\n\n\n\nExercises\nFirst, download and extract the zip file by clicking the link. Then…\nRead them in using the right functions. Specify the parameters properly. Hints can be found in hints.md. Each file should be stored in an object, names should correspond to the file names.\nNote: this is challenging, absolutely. If you have problems, try to google the different functions and think about what the different parameters indicate. If that is to no avail, send me an e-mail. I am very happy to provide you further assistance."
  },
  {
    "objectID": "2_r_catch-up.html#tidy-data-with-tidyr",
    "href": "2_r_catch-up.html#tidy-data-with-tidyr",
    "title": "Chapter 2: Brief R Recap",
    "section": "Tidy data with tidyr",
    "text": "Tidy data with tidyr\nBefore you learn how to tidy and wrangle data, you need to know how you want your data set to actually look like, i.e., what the desired outcome of the entire process of tidying your data set is. The tidyverse is a collection of packages which share an underlying philosophy: they are tidy. This means, that they (preferably) take tidy data as inputs and output tidy data. In the following, I will, first, introduce you to the concept of tidy data as developed by Hadley Wickham (Wickham 2014). Second, tidyr is introduced (Wickham 2020b). Its goal is to provide you with functions that facilitate tidying data sets. Beyond, I will provide you some examples of how to create tibbles using functions from the tibble package (Müller, Wickham, and François 2020). Moreover, the pipe is introduced.\nPlease note that tidying and cleaning data are not equivalent: I refer to tidying data as to bringing data in a tidy format. Cleaning data, however, can encompass way more than this: parsing columns in the right format (using readr, for instance), imputation of missing values, address the problem of typos, etc.\n\nThe concept of tidy data\ndata sets can be structured in many ways. To make them tidy, they must be organized in the following way (this is taken from the R for Data Science book (Wickham and Grolemund 2016)):\n\nEach variable must have its own column.\n\nEach observation must have its own row.\n\nEach value must have its own cell.\n\nThey can even be boiled further down:\n\nPut each data set in a tibble.\nPut each variable in a column.\n\nThis can also be visually depicted:\n\n\n\nThe three rules that make a data set tidy (taken from Wickham and Grolemund 2016: 149)\n\n\nThis way of storing data has two big advantages:\n\nyou can easily access, and hence manipulate, variables as vectors\nif you perform vectorized operations on the tibble, cases are preserved.\n\n\n\nMaking messy data tidy\nSo what are the most common problems with data sets? The following list is taken from the tidyr vignette2:\n\nColumn headers are values, not variable names.\n\nVariables are stored in both rows and columns.\n\nMultiple variables are stored in one column.\n\nMultiple types of observational units are stored in the same table.\n\nA single observational unit is stored in multiple tables.\n\nI will go across the former three types of problems, because the latter two require some more advanced data wrangling techniques you haven’t learned yet (i.e., functions from the dplyr package: select(), mutate(), left_join(), among others).\nIn the following, I will provide you with examples on how this might look like and how you can address the respective problem using functions from the tidyr package. This will serve as an introduction to the two most important functions of the tidyr package: pivot_longer() and its counterpart pivot_wider(). Beyond that, separate() will be introduced as well. At the beginning of every part, I will build the tibble using functions from the tibble package. This should suffice as a quick refresher for and introduction to creating tibbles.\ntidyr has some more functions in stock. They do not necessarily relate to transforming messy data sets into tidy ones, but also serve you well for some general cleaning tasks. They will be introduced, too.\n\nColumn headers are values\nA data set of this form would look like this:\n\ntibble_value_headers &lt;- tibble(\n  manufacturer = c(\"Audi\", \"BMW\", \"Mercedes\", \"Opel\", \"VW\"),\n  `3 cyl` = sample(20, 5, replace = TRUE),\n  `4 cyl` = sample(50:100, 5, replace = TRUE),\n  `5 cyl` = sample(10, 5, replace = TRUE),\n  `6 cyl` = sample(30:50, 5, replace = TRUE),\n  `8 cyl` = sample(20:40, 5, replace = TRUE),\n  `10 cyl` = sample(10, 5, replace = TRUE),\n  `12 cyl` = sample(20, 5, replace = TRUE),\n  `16 cyl` = rep(0, 5)\n)\n\ntibble_value_headers\n\n# A tibble: 5 × 9\n  manufacturer `3 cyl` `4 cyl` `5 cyl` `6 cyl` `8 cyl` `10 cyl` `12 cyl`\n  &lt;chr&gt;          &lt;int&gt;   &lt;int&gt;   &lt;int&gt;   &lt;int&gt;   &lt;int&gt;    &lt;int&gt;    &lt;int&gt;\n1 Audi              12      65       1      48      39        8        1\n2 BMW               19      94       4      36      31        4       14\n3 Mercedes           4      79       5      36      33        6        9\n4 Opel              15      50       9      30      34        9       14\n5 VW                15      89       1      47      22        6       11\n# ℹ 1 more variable: `16 cyl` &lt;dbl&gt;\n\n\nYou can create a tibble by column using the tibble function. Column names need to be specified and linked to vectors of either the same length or length one.\nThis data set basically consists of three variables: German car manufacturer, number of cylinders, and frequency. To make the data set tidy, it has to consist of three columns depicting the three respective variables. This operation is called pivoting the non-variable columns into two-column key-value pairs. As the data set will thereafter contain fewer columns and more rows than before, it will have become longer (or taller). Hence, the tidyr function is called pivot_longer().\n\nger_car_manufacturer_longer &lt;- tibble_value_headers |&gt; \n  pivot_longer(-manufacturer, names_to = \"cylinders\", values_to = \"frequency\")\nger_car_manufacturer_longer\n\n# A tibble: 40 × 3\n   manufacturer cylinders frequency\n   &lt;chr&gt;        &lt;chr&gt;         &lt;dbl&gt;\n 1 Audi         3 cyl            12\n 2 Audi         4 cyl            65\n 3 Audi         5 cyl             1\n 4 Audi         6 cyl            48\n 5 Audi         8 cyl            39\n 6 Audi         10 cyl            8\n 7 Audi         12 cyl            1\n 8 Audi         16 cyl            0\n 9 BMW          3 cyl            19\n10 BMW          4 cyl            94\n# ℹ 30 more rows\n\n\nIn the function call, you need to specify the following: if you were not to use the pipe, the first argument would be the tibble you are manipulating. Then, you look at the column you want to keep. Here, it is the car manufacturer. This means that all columns but manufacturer will be crammed into two new ones: one will contain the columns’ names, the other one their values. How are those new column supposed to be named? That can be specified in the names_to = and values_to =arguments. Please note that you need to provide them a character vector, hence, surround your parameters with quotation marks. As a rule of thumb for all tidyverse packages: If it is a new column name you provide, surround it with quotation marks. If it is one that already exists – like, here, manufacturer, then you do not need the quotation marks.\n\n\nVariables in both rows and columns\nYou have this data set:\n\ncar_models_fuel &lt;- tribble(\n  ~manufacturer, ~model, ~cylinders, ~fuel_consumption_type, ~fuel_consumption_per_100km,\n  \"VW\", \"Golf\", 4, \"urban\", 5.2,\n  \"VW\", \"Golf\", 4, \"extra urban\", 4.5,\n  \"Opel\", \"Adam\", 4, \"urban\", 4.9,\n  \"Opel\", \"Adam\", 4, \"extra urban\", 4.1\n  )\ncar_models_fuel\n\n# A tibble: 4 × 5\n  manufacturer model cylinders fuel_consumption_type fuel_consumption_per_100km\n  &lt;chr&gt;        &lt;chr&gt;     &lt;dbl&gt; &lt;chr&gt;                                      &lt;dbl&gt;\n1 VW           Golf          4 urban                                        5.2\n2 VW           Golf          4 extra urban                                  4.5\n3 Opel         Adam          4 urban                                        4.9\n4 Opel         Adam          4 extra urban                                  4.1\n\n\nIt was created using the tribble function: tibbles can also be created by row. First, the column names need to be specified by putting a tilde (~) in front of them. Then, you can put in values separated by commas. Please note that the number of values needs to be a multiple of the number of columns.\nIn this data set, there are basically five variables: manufacturer, model, cylinders, urban fuel consumption, and extra urban fuel consumption. However, the column fuel_consumption_type does not store a variable but the names of two variables. Hence, you need to fix this to make the data set tidy. Because this encompasses reducing the number of rows, the data set becomes wider. The function to achieve this is therefore called pivot_wider() and the inverse of pivot_longer().\n\ncar_models_fuel_tidy &lt;- car_models_fuel |&gt; \n  pivot_wider(\n    names_from = fuel_consumption_type, \n    values_from = fuel_consumption_per_100km\n    )\n\ncar_models_fuel_tidy\n\n# A tibble: 2 × 5\n  manufacturer model cylinders urban `extra urban`\n  &lt;chr&gt;        &lt;chr&gt;     &lt;dbl&gt; &lt;dbl&gt;         &lt;dbl&gt;\n1 VW           Golf          4   5.2           4.5\n2 Opel         Adam          4   4.9           4.1\n\n\nHere, you only need to specify the columns you fetch the names and values from. As they both do already exist, you do not need to wrap them in quotation marks.\n\n\nMultiple variables in one column\nNow, however, there is a problem with the cylinders: their number should be depicted in a numeric vector. We could achieve this by either parsing it to a numeric vector:\n\nger_car_manufacturer_longer$cylinders &lt;- parse_number(ger_car_manufacturer_longer$cylinders)\n\nOn the other hand, we can also use a handy function from tidyr called separate() and afterwards drop the unnecessary column:\n\nger_car_manufacturer_longer_sep_cyl &lt;- ger_car_manufacturer_longer |&gt; # first, take the tibble\n  separate(cylinders, into = c(\"cylinders\", \"drop_it\"), sep = \" \") |&gt; # and then split the column \"cylinders\" into two\n  select(-drop_it) # you will learn about this in the lesson on dplyr  # and then drop one column from the tibble\n\nWarning: Expected 2 pieces. Missing pieces filled with `NA` in 40 rows [1, 2, 3, 4, 5,\n6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, ...].\n\n\nIf there are two (or actually more) relevant values in one column, you can simply let out the dropping process and easily split them into multiple columns. By default, the sep = argument divides the content by all non-alphanumeric characters (every character that is not a letter, number, or space) it contains.\nPlease note that the new column is still in character format. We can change this using as.numeric():\n\nger_car_manufacturer_longer_sep_cyl$cylinders &lt;- as.numeric(ger_car_manufacturer_longer_sep_cyl$cylinders)\n\nFurthermore, you might want to sort your data in a different manner. If you want to do this by cylinders, it would look like this:\n\narrange(ger_car_manufacturer_longer_sep_cyl, cylinders)\n\n# A tibble: 40 × 3\n   manufacturer cylinders frequency\n   &lt;chr&gt;            &lt;dbl&gt;     &lt;dbl&gt;\n 1 Audi                 3        12\n 2 BMW                  3        19\n 3 Mercedes             3         4\n 4 Opel                 3        15\n 5 VW                   3        15\n 6 Audi                 4        65\n 7 BMW                  4        94\n 8 Mercedes             4        79\n 9 Opel                 4        50\n10 VW                   4        89\n# ℹ 30 more rows\n\n\n\n\n\nInsertion: the pipe\nHave you noticed the |&gt;? That’s the pipe. It can be considered a conjunction in coding. Usually, you will use it when working with tibbles. What it does is pretty straight-forward: it takes what is on its left – the input – and provides it to the function on its right as the first argument. Hence, the code in the last chunk, which looks like this\n\narrange(ger_car_manufacturer_longer_sep_cyl, cylinders)\n\n# A tibble: 40 × 3\n   manufacturer cylinders frequency\n   &lt;chr&gt;            &lt;dbl&gt;     &lt;dbl&gt;\n 1 Audi                 3        12\n 2 BMW                  3        19\n 3 Mercedes             3         4\n 4 Opel                 3        15\n 5 VW                   3        15\n 6 Audi                 4        65\n 7 BMW                  4        94\n 8 Mercedes             4        79\n 9 Opel                 4        50\n10 VW                   4        89\n# ℹ 30 more rows\n\n\ncould have also been written like this\n\nger_car_manufacturer_longer_sep_cyl |&gt; arrange(cylinders)\n\n# A tibble: 40 × 3\n   manufacturer cylinders frequency\n   &lt;chr&gt;            &lt;dbl&gt;     &lt;dbl&gt;\n 1 Audi                 3        12\n 2 BMW                  3        19\n 3 Mercedes             3         4\n 4 Opel                 3        15\n 5 VW                   3        15\n 6 Audi                 4        65\n 7 BMW                  4        94\n 8 Mercedes             4        79\n 9 Opel                 4        50\n10 VW                   4        89\n# ℹ 30 more rows\n\n\nbecause the tibble is the first argument in the function call.\nBecause the pipe (its precedessor was %&gt;%) has really gained traction in the R community, many functions are now optimized for being used with the pipe. However, there are still some around which are not. A function for fitting a basic linear model with one dependent and one independent variable which are both stored in a tibble looks like this: lm(formula = dv ~ iv, data = tibble). Here, the tibble is not the first argument. To be able to fit a linear model in a “pipeline,” you need to employ a little hack: you can use an underscore _ as a placeholder. Here, it is important that the argument is named.\nLet’s check out the effect the number of cylinders has on the number of models:\n\nger_car_manufacturer_longer_sep_cyl |&gt; \n  lm(frequency ~ cylinders, data = _) |&gt; \n  summary()\n\n\nCall:\nlm(formula = frequency ~ cylinders, data = ger_car_manufacturer_longer_sep_cyl)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-33.174 -14.016   0.978   9.000  59.761 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  45.9783     7.6060   6.045 4.94e-07 ***\ncylinders    -2.9348     0.8438  -3.478  0.00128 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 22.17 on 38 degrees of freedom\nMultiple R-squared:  0.2415,    Adjusted R-squared:  0.2215 \nF-statistic:  12.1 on 1 and 38 DF,  p-value: 0.001282\n\n\nAs |&gt; is a bit tedious to type, a shortcut exists: shift-ctrl-m.\n\n\nSplitting and merging cells\nIf there are multiple values in one column/cell and you want to split them and put them into two rows instead of columns, tidyr offers you the separate_rows() function.\n\ngerman_cars_vec &lt;- c(Audi = \"A1, A3, A4, A5, A6, A7, A8\", \n                     BMW = \"1 Series, 2 Series, 3 Series, 4 Series, 5 Series, 6 Series, 7 Series, 8 Series\")\ngerman_cars_tbl &lt;- enframe(\n  german_cars_vec, \n  name = \"brand\", \n  value = \"model\"\n  )\n\ngerman_cars_tbl\n\n# A tibble: 2 × 2\n  brand model                                                                   \n  &lt;chr&gt; &lt;chr&gt;                                                                   \n1 Audi  A1, A3, A4, A5, A6, A7, A8                                              \n2 BMW   1 Series, 2 Series, 3 Series, 4 Series, 5 Series, 6 Series, 7 Series, 8…\n\ntidy_german_cars_tbl &lt;- german_cars_tbl |&gt; \n  separate_rows(model, sep = \", \")\n\nenframe() enables you to create a tibble from a (named) vector. It outputs a tibble with two columns (name and value by default): name contains the names of the elements (if the elements are unnamed, it contains a serial number), value the element. Both can be renamed in the function call by providing a character vector.\nIf you want to achieve the opposite, i.e., merge cells’ content, you can use the counterpart, unite(). Let’s take the following dataframe which consists of the names of the professors of the Institute for Political Science of the University of Regensburg:\n\nprofessor_names_df &lt;- data.frame(first_name = c(\"Karlfriedrich\", \"Martin\", \"Jerzy\", \"Stephan\", \"Melanie\"),\n                                 last_name = c(\"Herb\", \"Sebaldt\", \"Maćków\", \"Bierling\", \"Walter-Rogg\"))\n\nprofessor_names_tbl &lt;- professor_names_df |&gt; \n  as_tibble() |&gt; \n  unite(first_name, last_name, col = \"name\", sep = \" \", remove = TRUE, na.rm = FALSE)\n\nprofessor_names_tbl\n\n# A tibble: 5 × 1\n  name               \n  &lt;chr&gt;              \n1 Karlfriedrich Herb \n2 Martin Sebaldt     \n3 Jerzy Maćków       \n4 Stephan Bierling   \n5 Melanie Walter-Rogg\n\n\nunite() takes the tibble it should be applied to as the first argument (not necessary if you use the pipe). Then, it takes the two or more columns as arguments (actually, this is not necessary if you want to unite all columns). col = takes a character vector to specify the name of the resulting, new column. remove = TRUE indicates that the columns that are united are removed as well. You can, of course, set it to false, too. na.rm = FALSE finally indicates that missing values are not to be removed prior to the uniting process.\nHere, the final variant of creating tibbles is introduced as well: you can apply the function as_tibble() to a data frame and it will then be transformed into a tibble.\n\n\nFurther links\n\nHadley on tidy data\n\nThe two pivot_*() functions lie at the heart of tidyr. This article from the Northeastern University’s School of Journalism explains it in further detail.\n\n\n\nExercises\nBring the data sets you read into R in the “Reading data in R” section into a tidy format. Store the tidy data sets in a new object, named like the former object plus the suffix “_tidy” – e.g., books_tidy. If no tidying is needed, you do not have to create a new object. The pipe operator should be used to connect the different steps."
  },
  {
    "objectID": "2_r_catch-up.html#wrangling-data-with-dplyr",
    "href": "2_r_catch-up.html#wrangling-data-with-dplyr",
    "title": "Chapter 2: Brief R Recap",
    "section": "Wrangling data with dplyr",
    "text": "Wrangling data with dplyr\nThe last chapter showed you four things: how you get data sets into R, a couple of ways to create tibbles, how to pass data to functions using the pipe (|&gt;), and an introduction to tidy data and how to make data sets tidy using the tidyr package (Wickham 2020b). What you haven’t learned was how you can actually manipulate the data themselves. In the tidyverse framework (Wickham et al. 2019), the package which enables you to accomplish those tasks is dplyr (Wickham 2020a).\ndplyr joined the party in 2014, building upon the plyr package. The d in dplyr stands for data set and dplyr works with tibbles (or data frames) only.\nIt consists of five main functions, the “verbs”:\n\narrange() – sort values\nfilter() – pick observations\nmutate() – create new variables (columns)\nselect() – select variables\nsummarize() – create summaries from multiple values\n\nThey are joined by group_by(), a function that changes the scope on which entities the functions are applied to.\nFurthermore, diverse bind_ functions and _joins enable you to combine multiple tibbles into one. They will be introduced later.\nIn the following, I will guide you through how you can use the verbs to accomplish whatever goals which require data wrangling you might have.\nThe data set I will use here consists of the 1,000 most popular movies on IMDb which were published between 2006 and 2016 and some data on them. It was created by PromptCloud and DataStock and published on Kaggle, more information can be found here.\n\nimdb_raw &lt;- read_csv(\"data/imdb2006-2016.csv\")\n\nThe data set hasn’t been modified by me before. I will show you how I would go across it using a couple of dplyr functions.\n\nselect()\nselect enables you to select columns. Since we are dealing with tidy data, every variable has its own column.\nglimpse() provides you with an overview of the data set and its columns.\n\nglimpse(imdb_raw)\n\nRows: 1,000\nColumns: 12\n$ Rank                 &lt;dbl&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15…\n$ Title                &lt;chr&gt; \"Guardians of the Galaxy\", \"Prometheus\", \"Split\",…\n$ Genre                &lt;chr&gt; \"Action,Adventure,Sci-Fi\", \"Adventure,Mystery,Sci…\n$ Description          &lt;chr&gt; \"A group of intergalactic criminals are forced to…\n$ Director             &lt;chr&gt; \"James Gunn\", \"Ridley Scott\", \"M. Night Shyamalan…\n$ Actors               &lt;chr&gt; \"Chris Pratt, Vin Diesel, Bradley Cooper, Zoe Sal…\n$ Year                 &lt;dbl&gt; 2014, 2012, 2016, 2016, 2016, 2016, 2016, 2016, 2…\n$ `Runtime (Minutes)`  &lt;dbl&gt; 121, 124, 117, 108, 123, 103, 128, 89, 141, 116, …\n$ Rating               &lt;dbl&gt; 8.1, 7.0, 7.3, 7.2, 6.2, 6.1, 8.3, 6.4, 7.1, 7.0,…\n$ Votes                &lt;dbl&gt; 757074, 485820, 157606, 60545, 393727, 56036, 258…\n$ `Revenue (Millions)` &lt;dbl&gt; 333.13, 126.46, 138.12, 270.32, 325.02, 45.13, 15…\n$ Metascore            &lt;dbl&gt; 76, 65, 62, 59, 40, 42, 93, 71, 78, 41, 66, 74, 6…\n\n\nThe columns I want to keep are: Title, Director, Year, Runtime (Minutes), Rating, Votes, and Revenue (Millions). Furthermore, I want to rename the columns: every column’s name should be in lowercase and a regular name that does not need to be surrounded by back ticks – i.e., a name that only consists of characters, numbers, underscores, or dots.\nThis can be achieved in a couple of ways:\nFirst, by choosing the columns column by column and subsequently renaming them:\n\nimdb_raw |&gt; \n  select(Title, Director, Year, `Runtime (Minutes)`, Rating, Votes, `Revenue (Millions)`) |&gt; \n  rename(title = Title, director = Director, year = Year, runtime = `Runtime (Minutes)`, rating = Rating, votes = Votes, revenue_million = `Revenue (Millions)`) |&gt; \n  glimpse()\n\nRows: 1,000\nColumns: 7\n$ title           &lt;chr&gt; \"Guardians of the Galaxy\", \"Prometheus\", \"Split\", \"Sin…\n$ director        &lt;chr&gt; \"James Gunn\", \"Ridley Scott\", \"M. Night Shyamalan\", \"C…\n$ year            &lt;dbl&gt; 2014, 2012, 2016, 2016, 2016, 2016, 2016, 2016, 2016, …\n$ runtime         &lt;dbl&gt; 121, 124, 117, 108, 123, 103, 128, 89, 141, 116, 133, …\n$ rating          &lt;dbl&gt; 8.1, 7.0, 7.3, 7.2, 6.2, 6.1, 8.3, 6.4, 7.1, 7.0, 7.5,…\n$ votes           &lt;dbl&gt; 757074, 485820, 157606, 60545, 393727, 56036, 258682, …\n$ revenue_million &lt;dbl&gt; 333.13, 126.46, 138.12, 270.32, 325.02, 45.13, 151.06,…\n\n\nSecond, the columns can also be chosen vice versa: unnecessary columns can be dropped using a minus:\n\nimdb_raw |&gt; \n  select(-Rank, -Genre, -Description, -Actors, -Metascore) |&gt; \n  rename(title = Title, director = Director, year = Year, runtime = `Runtime (Minutes)`, rating = Rating, votes = Votes, revenue_million = `Revenue (Millions)`) |&gt; \n  glimpse()\n\nRows: 1,000\nColumns: 7\n$ title           &lt;chr&gt; \"Guardians of the Galaxy\", \"Prometheus\", \"Split\", \"Sin…\n$ director        &lt;chr&gt; \"James Gunn\", \"Ridley Scott\", \"M. Night Shyamalan\", \"C…\n$ year            &lt;dbl&gt; 2014, 2012, 2016, 2016, 2016, 2016, 2016, 2016, 2016, …\n$ runtime         &lt;dbl&gt; 121, 124, 117, 108, 123, 103, 128, 89, 141, 116, 133, …\n$ rating          &lt;dbl&gt; 8.1, 7.0, 7.3, 7.2, 6.2, 6.1, 8.3, 6.4, 7.1, 7.0, 7.5,…\n$ votes           &lt;dbl&gt; 757074, 485820, 157606, 60545, 393727, 56036, 258682, …\n$ revenue_million &lt;dbl&gt; 333.13, 126.46, 138.12, 270.32, 325.02, 45.13, 151.06,…\n\n\nColumns can also be renamed in the selecting process:\n\nimdb_raw |&gt; \n  select(title = Title, director = Director, year = Year, runtime = `Runtime (Minutes)`, rating = Rating, votes = Votes, revenue_million = `Revenue (Millions)`) |&gt; \n  glimpse()\n\nRows: 1,000\nColumns: 7\n$ title           &lt;chr&gt; \"Guardians of the Galaxy\", \"Prometheus\", \"Split\", \"Sin…\n$ director        &lt;chr&gt; \"James Gunn\", \"Ridley Scott\", \"M. Night Shyamalan\", \"C…\n$ year            &lt;dbl&gt; 2014, 2012, 2016, 2016, 2016, 2016, 2016, 2016, 2016, …\n$ runtime         &lt;dbl&gt; 121, 124, 117, 108, 123, 103, 128, 89, 141, 116, 133, …\n$ rating          &lt;dbl&gt; 8.1, 7.0, 7.3, 7.2, 6.2, 6.1, 8.3, 6.4, 7.1, 7.0, 7.5,…\n$ votes           &lt;dbl&gt; 757074, 485820, 157606, 60545, 393727, 56036, 258682, …\n$ revenue_million &lt;dbl&gt; 333.13, 126.46, 138.12, 270.32, 325.02, 45.13, 151.06,…\n\n\nYou can also make your expressions shorter by using a couple of hacks:\n: can be used to select all columns between two:\n\nimdb_raw |&gt; \n  select(Title, Director, Year:`Revenue (Millions)`) |&gt; \n  rename(title = Title, director = Director, year = Year, runtime = `Runtime (Minutes)`, rating = Rating, votes = Votes, revenue_million = `Revenue (Millions)`) |&gt; \n  glimpse()\n\nRows: 1,000\nColumns: 7\n$ title           &lt;chr&gt; \"Guardians of the Galaxy\", \"Prometheus\", \"Split\", \"Sin…\n$ director        &lt;chr&gt; \"James Gunn\", \"Ridley Scott\", \"M. Night Shyamalan\", \"C…\n$ year            &lt;dbl&gt; 2014, 2012, 2016, 2016, 2016, 2016, 2016, 2016, 2016, …\n$ runtime         &lt;dbl&gt; 121, 124, 117, 108, 123, 103, 128, 89, 141, 116, 133, …\n$ rating          &lt;dbl&gt; 8.1, 7.0, 7.3, 7.2, 6.2, 6.1, 8.3, 6.4, 7.1, 7.0, 7.5,…\n$ votes           &lt;dbl&gt; 757074, 485820, 157606, 60545, 393727, 56036, 258682, …\n$ revenue_million &lt;dbl&gt; 333.13, 126.46, 138.12, 270.32, 325.02, 45.13, 151.06,…\n\n\nstarts_with() select columns whose names start with the same character string:\n\nimdb_selected &lt;- imdb_raw |&gt; \n  select(Title, Director, Votes, Year, starts_with(\"R\")) |&gt; \n  select(-Rank) |&gt; \n  rename(title = Title, director = Director, year = Year, runtime = `Runtime (Minutes)`, rating = Rating, votes = Votes, revenue_million = `Revenue (Millions)`) |&gt; \n  glimpse()\n\nRows: 1,000\nColumns: 7\n$ title           &lt;chr&gt; \"Guardians of the Galaxy\", \"Prometheus\", \"Split\", \"Sin…\n$ director        &lt;chr&gt; \"James Gunn\", \"Ridley Scott\", \"M. Night Shyamalan\", \"C…\n$ votes           &lt;dbl&gt; 757074, 485820, 157606, 60545, 393727, 56036, 258682, …\n$ year            &lt;dbl&gt; 2014, 2012, 2016, 2016, 2016, 2016, 2016, 2016, 2016, …\n$ runtime         &lt;dbl&gt; 121, 124, 117, 108, 123, 103, 128, 89, 141, 116, 133, …\n$ rating          &lt;dbl&gt; 8.1, 7.0, 7.3, 7.2, 6.2, 6.1, 8.3, 6.4, 7.1, 7.0, 7.5,…\n$ revenue_million &lt;dbl&gt; 333.13, 126.46, 138.12, 270.32, 325.02, 45.13, 151.06,…\n\n\nAs you may have noticed, the order in the select() matters: columns will be ordered in the same order as they are chosen.\nA couple of further shortcuts for select() do exist. An overview can be found in the dplyr cheatsheet.\n\n\nfilter()\nWhereas select() enables you to choose variables (i.e., columns), filter() lets you choose observations (i.e., rows).\nIn this case, I only want movies with a revenue above $100,000,000:\n\nimdb_selected |&gt; \n  filter(revenue_million &gt; 100) |&gt; \n  glimpse()\n\nRows: 250\nColumns: 7\n$ title           &lt;chr&gt; \"Guardians of the Galaxy\", \"Prometheus\", \"Split\", \"Sin…\n$ director        &lt;chr&gt; \"James Gunn\", \"Ridley Scott\", \"M. Night Shyamalan\", \"C…\n$ votes           &lt;dbl&gt; 757074, 485820, 157606, 60545, 393727, 258682, 192177,…\n$ year            &lt;dbl&gt; 2014, 2012, 2016, 2016, 2016, 2016, 2016, 2016, 2016, …\n$ runtime         &lt;dbl&gt; 121, 124, 117, 108, 123, 128, 116, 133, 127, 133, 107,…\n$ rating          &lt;dbl&gt; 8.1, 7.0, 7.3, 7.2, 6.2, 8.3, 7.0, 7.5, 7.8, 7.9, 7.7,…\n$ revenue_million &lt;dbl&gt; 333.13, 126.46, 138.12, 270.32, 325.02, 151.06, 100.01…\n\n\nBesides, I am especially interested in the director Christopher Nolan. Therefore, I want to look at movies that were directed by him and made more than $100,000,000:\n\nimdb_selected |&gt; \n  filter(revenue_million &gt; 100 & director == \"Christopher Nolan\") |&gt; \n  glimpse()\n\nRows: 4\nColumns: 7\n$ title           &lt;chr&gt; \"Interstellar\", \"The Dark Knight\", \"Inception\", \"The D…\n$ director        &lt;chr&gt; \"Christopher Nolan\", \"Christopher Nolan\", \"Christopher…\n$ votes           &lt;dbl&gt; 1047747, 1791916, 1583625, 1222645\n$ year            &lt;dbl&gt; 2014, 2008, 2010, 2012\n$ runtime         &lt;dbl&gt; 169, 152, 148, 164\n$ rating          &lt;dbl&gt; 8.6, 9.0, 8.8, 8.5\n$ revenue_million &lt;dbl&gt; 187.99, 533.32, 292.57, 448.13\n\n\nThe following overview is taken from the dplyr cheatsheet and shows the operators you can use in filter():\n\n\n\nOverview of comparison operators\n\n\n\nExemplary application\nTo demonstrate how a real-world application of this stuff could look like, I will now provide you a brief insight into my private life and how I organize movie nights. JK. You could definitely try this at home and surprise your loved ones with such hot applications. If you are brave and surprise your latest Tinder match with an .RDS file containing suggestions for Netflix&Chill, please let me know what their response looked like.\nTonight, I will hang out with a real nerd. Probably because they (nerds have all kinds of genders) know about my faible for R, they have sent me a vector containing a couple of movies we could watch tonight:\n\nset.seed(123) # guarantees that movie_vec will always be the same thing\nmovie_vec &lt;- imdb_raw$Title[sample(1000, 10, replace = FALSE)]\nmovie_vec\n\n [1] \"Mechanic: Resurrection\" \"Denial\"                 \"The Conjuring 2\"       \n [4] \"Birth of the Dragon\"    \"Warrior\"                \"Super\"                 \n [7] \"127 Hours\"              \"Dangal\"                 \"The Infiltrator\"       \n[10] \"Maleficent\"            \n\n\nHowever, I want to make a more informed decision and decide to obtain some more information on the movies from my IMDb data set:\n\nimdb_selected |&gt; \n  filter(title %in% movie_vec) |&gt; \n  glimpse()\n\nRows: 10\nColumns: 7\n$ title           &lt;chr&gt; \"Dangal\", \"The Conjuring 2\", \"Warrior\", \"Maleficent\", …\n$ director        &lt;chr&gt; \"Nitesh Tiwari\", \"James Wan\", \"Gavin O'Connor\", \"Rober…\n$ votes           &lt;dbl&gt; 48969, 137203, 355722, 268877, 43929, 48161, 8229, 552…\n$ year            &lt;dbl&gt; 2016, 2016, 2011, 2014, 2016, 2016, 2016, 2016, 2010, …\n$ runtime         &lt;dbl&gt; 161, 134, 140, 97, 127, 98, 109, 103, 94, 96\n$ rating          &lt;dbl&gt; 8.8, 7.4, 8.2, 7.0, 7.1, 5.6, 6.6, 3.9, 7.6, 6.8\n$ revenue_million &lt;dbl&gt; 11.15, 102.46, 13.65, 241.41, 15.43, 21.20, 4.07, 93.0…\n\n\nI have convinced them to watch either one of the movies they have suggested or one directed by Christopher Nolan or one with a rating greater or equal to 8.5 and send them back this data set:\n\nimdb_selected |&gt; \n  filter(title %in% movie_vec | director == \"Christopher Nolan\" | rating &gt;= 8.5) |&gt; \n  glimpse()\n\nRows: 21\nColumns: 7\n$ title           &lt;chr&gt; \"Interstellar\", \"The Dark Knight\", \"The Prestige\", \"In…\n$ director        &lt;chr&gt; \"Christopher Nolan\", \"Christopher Nolan\", \"Christopher…\n$ votes           &lt;dbl&gt; 1047747, 1791916, 913152, 1583625, 34110, 937414, 4896…\n$ year            &lt;dbl&gt; 2014, 2008, 2006, 2010, 2016, 2006, 2016, 2012, 2014, …\n$ runtime         &lt;dbl&gt; 169, 152, 130, 148, 106, 151, 161, 164, 107, 134, 140,…\n$ rating          &lt;dbl&gt; 8.6, 9.0, 8.5, 8.8, 8.6, 8.5, 8.8, 8.5, 8.5, 7.4, 8.2,…\n$ revenue_million &lt;dbl&gt; 187.99, 533.32, 53.08, 292.57, 4.68, 132.37, 11.15, 44…\n\n\n“I deteste ‘Interstellar’,” is the response. “All right,” I say to myself, “I can easily exclude it.”\n\nimdb_selected |&gt; \n  filter(title %in% movie_vec | director == \"Christopher Nolan\" | rating &gt;= 8.5 & title != \"Interstellar\") |&gt; # if you want to negate something, put the ! in front of it\n  glimpse()\n\nRows: 21\nColumns: 7\n$ title           &lt;chr&gt; \"Interstellar\", \"The Dark Knight\", \"The Prestige\", \"In…\n$ director        &lt;chr&gt; \"Christopher Nolan\", \"Christopher Nolan\", \"Christopher…\n$ votes           &lt;dbl&gt; 1047747, 1791916, 913152, 1583625, 34110, 937414, 4896…\n$ year            &lt;dbl&gt; 2014, 2008, 2006, 2010, 2016, 2006, 2016, 2012, 2014, …\n$ runtime         &lt;dbl&gt; 169, 152, 130, 148, 106, 151, 161, 164, 107, 134, 140,…\n$ rating          &lt;dbl&gt; 8.6, 9.0, 8.5, 8.8, 8.6, 8.5, 8.8, 8.5, 8.5, 7.4, 8.2,…\n$ revenue_million &lt;dbl&gt; 187.99, 533.32, 53.08, 292.57, 4.68, 132.37, 11.15, 44…\n\n\nOh, that did not work. I should wrap them in columns:\n\nimdb_selected |&gt; \n  filter((title %in% movie_vec | director == \"Christopher Nolan\" | rating &gt;= 8.5) & title != \"Interstellar\") |&gt; \n  glimpse()\n\nRows: 20\nColumns: 7\n$ title           &lt;chr&gt; \"The Dark Knight\", \"The Prestige\", \"Inception\", \"Kimi …\n$ director        &lt;chr&gt; \"Christopher Nolan\", \"Christopher Nolan\", \"Christopher…\n$ votes           &lt;dbl&gt; 1791916, 913152, 1583625, 34110, 937414, 48969, 122264…\n$ year            &lt;dbl&gt; 2008, 2006, 2010, 2016, 2006, 2016, 2012, 2014, 2016, …\n$ runtime         &lt;dbl&gt; 152, 130, 148, 106, 151, 161, 164, 107, 134, 140, 97, …\n$ rating          &lt;dbl&gt; 9.0, 8.5, 8.8, 8.6, 8.5, 8.8, 8.5, 8.5, 7.4, 8.2, 7.0,…\n$ revenue_million &lt;dbl&gt; 533.32, 53.08, 292.57, 4.68, 132.37, 11.15, 448.13, 13…\n\n\nThey come up with a new idea: we have a Scottish evening with a movie directed by the Scottish director Gillies MacKinnon:\n\nimdb_selected |&gt; \n  filter(director == \"Gillies MacKinnon\") |&gt; \n  glimpse()\n\nRows: 1\nColumns: 7\n$ title           &lt;chr&gt; \"Whisky Galore\"\n$ director        &lt;chr&gt; \"Gillies MacKinnon\"\n$ votes           &lt;dbl&gt; 102\n$ year            &lt;dbl&gt; 2016\n$ runtime         &lt;dbl&gt; 98\n$ rating          &lt;dbl&gt; 5\n$ revenue_million &lt;dbl&gt; NA\n\n\n“Well, apparently there is a problem in the data set,” I notice. “There is an NA in the revenue column. I should probably have a further look at this.”\n\nimdb_selected |&gt; \n  filter(is.na(revenue_million)) |&gt; \n  glimpse()\n\nRows: 128\nColumns: 7\n$ title           &lt;chr&gt; \"Mindhorn\", \"Hounds of Love\", \"Paris pieds nus\", \"5- 2…\n$ director        &lt;chr&gt; \"Sean Foley\", \"Ben Young\", \"Dominique Abel\", \"Patrick …\n$ votes           &lt;dbl&gt; 2490, 1115, 222, 241, 496, 5103, 987, 35870, 149791, 7…\n$ year            &lt;dbl&gt; 2016, 2016, 2016, 2007, 2016, 2016, 2016, 2016, 2016, …\n$ runtime         &lt;dbl&gt; 89, 108, 83, 113, 73, 91, 130, 86, 133, 106, 105, 118,…\n$ rating          &lt;dbl&gt; 6.4, 6.7, 6.8, 7.1, 2.7, 5.6, 3.7, 6.8, 5.9, 7.9, 5.8,…\n$ revenue_million &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n\n\nWell, that’s quite a significant number of NAs. I will need to exclude these cases:\n\nimdb_selected |&gt; \n  filter(!is.na(revenue_million)) |&gt; \n  glimpse()\n\nRows: 872\nColumns: 7\n$ title           &lt;chr&gt; \"Guardians of the Galaxy\", \"Prometheus\", \"Split\", \"Sin…\n$ director        &lt;chr&gt; \"James Gunn\", \"Ridley Scott\", \"M. Night Shyamalan\", \"C…\n$ votes           &lt;dbl&gt; 757074, 485820, 157606, 60545, 393727, 56036, 258682, …\n$ year            &lt;dbl&gt; 2014, 2012, 2016, 2016, 2016, 2016, 2016, 2016, 2016, …\n$ runtime         &lt;dbl&gt; 121, 124, 117, 108, 123, 103, 128, 141, 116, 133, 127,…\n$ rating          &lt;dbl&gt; 8.1, 7.0, 7.3, 7.2, 6.2, 6.1, 8.3, 7.1, 7.0, 7.5, 7.8,…\n$ revenue_million &lt;dbl&gt; 333.13, 126.46, 138.12, 270.32, 325.02, 45.13, 151.06,…\n\n\n\n\nOther possibilities to subset observations\nslice() selects rows by positions:\n\nimdb_selected |&gt; \n  slice(1:10) |&gt; \n  glimpse()\n\nRows: 10\nColumns: 7\n$ title           &lt;chr&gt; \"Guardians of the Galaxy\", \"Prometheus\", \"Split\", \"Sin…\n$ director        &lt;chr&gt; \"James Gunn\", \"Ridley Scott\", \"M. Night Shyamalan\", \"C…\n$ votes           &lt;dbl&gt; 757074, 485820, 157606, 60545, 393727, 56036, 258682, …\n$ year            &lt;dbl&gt; 2014, 2012, 2016, 2016, 2016, 2016, 2016, 2016, 2016, …\n$ runtime         &lt;dbl&gt; 121, 124, 117, 108, 123, 103, 128, 89, 141, 116\n$ rating          &lt;dbl&gt; 8.1, 7.0, 7.3, 7.2, 6.2, 6.1, 8.3, 6.4, 7.1, 7.0\n$ revenue_million &lt;dbl&gt; 333.13, 126.46, 138.12, 270.32, 325.02, 45.13, 151.06,…\n\n\n\nimdb_selected |&gt; \n  slice_min(revenue_million, n = 10) |&gt; \n  glimpse()\n\nRows: 10\nColumns: 7\n$ title           &lt;chr&gt; \"A Kind of Murder\", \"Dead Awake\", \"Wakefield\", \"Loveso…\n$ director        &lt;chr&gt; \"Andy Goddard\", \"Phillip Guzman\", \"Robin Swicord\", \"So…\n$ votes           &lt;dbl&gt; 3305, 523, 291, 616, 80415, 10220, 36091, 54027, 4155,…\n$ year            &lt;dbl&gt; 2016, 2016, 2016, 2016, 2014, 2015, 2010, 2012, 2015, …\n$ runtime         &lt;dbl&gt; 95, 99, 106, 84, 102, 101, 98, 95, 93, 110\n$ rating          &lt;dbl&gt; 5.2, 4.7, 7.5, 6.4, 7.2, 5.9, 6.5, 6.9, 5.6, 5.9\n$ revenue_million &lt;dbl&gt; 0.00, 0.01, 0.01, 0.01, 0.01, 0.01, 0.02, 0.02, 0.02, …\n\n\ndistinct removes duplicate rows:\n\nimdb_selected |&gt; \n  distinct(director) |&gt; \n  glimpse()\n\nRows: 644\nColumns: 1\n$ director &lt;chr&gt; \"James Gunn\", \"Ridley Scott\", \"M. Night Shyamalan\", \"Christop…\n\n\nBy default, it will remove all other columns apart from the one(s) you have specified. You can avoid that by setting .keep_all = TRUE:\n\nimdb_selected |&gt; \n  distinct(title, .keep_all = TRUE) |&gt; \n  glimpse()\n\nRows: 999\nColumns: 7\n$ title           &lt;chr&gt; \"Guardians of the Galaxy\", \"Prometheus\", \"Split\", \"Sin…\n$ director        &lt;chr&gt; \"James Gunn\", \"Ridley Scott\", \"M. Night Shyamalan\", \"C…\n$ votes           &lt;dbl&gt; 757074, 485820, 157606, 60545, 393727, 56036, 258682, …\n$ year            &lt;dbl&gt; 2014, 2012, 2016, 2016, 2016, 2016, 2016, 2016, 2016, …\n$ runtime         &lt;dbl&gt; 121, 124, 117, 108, 123, 103, 128, 89, 141, 116, 133, …\n$ rating          &lt;dbl&gt; 8.1, 7.0, 7.3, 7.2, 6.2, 6.1, 8.3, 6.4, 7.1, 7.0, 7.5,…\n$ revenue_million &lt;dbl&gt; 333.13, 126.46, 138.12, 270.32, 325.02, 45.13, 151.06,…\n\n\nOh, interesting, there is apparently one movie which is in there twice. How could we find this movie?\n\n\n\nmutate()\nMy data set looks pretty nice already, but one flaw catches the eye: the column revenue_million should probably be converted to revenue. Hence, I need to create a new variable which contains the values from revenue_million multiplied by 1,000,000 and drop the now obsolete revenue_million.\n\nimdb_selected |&gt; \n  mutate(revenue = revenue_million * 1000000) |&gt; \n  select(-revenue_million) |&gt; \n  glimpse()\n\nRows: 1,000\nColumns: 7\n$ title    &lt;chr&gt; \"Guardians of the Galaxy\", \"Prometheus\", \"Split\", \"Sing\", \"Su…\n$ director &lt;chr&gt; \"James Gunn\", \"Ridley Scott\", \"M. Night Shyamalan\", \"Christop…\n$ votes    &lt;dbl&gt; 757074, 485820, 157606, 60545, 393727, 56036, 258682, 2490, 7…\n$ year     &lt;dbl&gt; 2014, 2012, 2016, 2016, 2016, 2016, 2016, 2016, 2016, 2016, 2…\n$ runtime  &lt;dbl&gt; 121, 124, 117, 108, 123, 103, 128, 89, 141, 116, 133, 127, 13…\n$ rating   &lt;dbl&gt; 8.1, 7.0, 7.3, 7.2, 6.2, 6.1, 8.3, 6.4, 7.1, 7.0, 7.5, 7.8, 7…\n$ revenue  &lt;dbl&gt; 333130000, 126460000, 138120000, 270320000, 325020000, 451300…\n\n\nThe structure of the mutate() call looks like this: first, you need to provide the name of the new variable. If the variable exists already, it will be replaced. Second, the equal sign tells R what the new variable should contain. Third, a function that outputs a vector which is as long as the tibble has rows or 1.\nIf we want to drop all other columns and just keep the new one: transmute() drops all the original columns.\n\nimdb_selected |&gt; \n  transmute(revenue = revenue_million * 1000000) |&gt; \n  glimpse()\n\nRows: 1,000\nColumns: 1\n$ revenue &lt;dbl&gt; 333130000, 126460000, 138120000, 270320000, 325020000, 4513000…\n\n\nmutate() uses so-called window functions. They take one vector of values and return another vector of values. An overview – again, from the cheat sheet:\n\n\n\nWindow functions\n\n\nAnother feature of dplyr, which is useful in combination with mutate(), is case_when().\ncase_when() can for instance be used to create binary indicator variables. In this example I want it to be 0 if the movie was made before 2010 and 1 if not. case_when() works like this: first, you provide a condition (e.g., year &lt; 2010). Second, you provide what the output should be if the condition is met (here, 0). Third, you can provide as many conditions as you want. Finally, you can provide a default value using TRUE ~ value. If none of the conditions are met, the default value will be assigned.\n\nimdb_selected |&gt; \n  mutate(indicator = case_when(year &lt; 2010 ~ 0,\n                               year &gt;= 2010 ~ 1,\n                               TRUE ~ 2)) |&gt; \n  glimpse()\n\nRows: 1,000\nColumns: 8\n$ title           &lt;chr&gt; \"Guardians of the Galaxy\", \"Prometheus\", \"Split\", \"Sin…\n$ director        &lt;chr&gt; \"James Gunn\", \"Ridley Scott\", \"M. Night Shyamalan\", \"C…\n$ votes           &lt;dbl&gt; 757074, 485820, 157606, 60545, 393727, 56036, 258682, …\n$ year            &lt;dbl&gt; 2014, 2012, 2016, 2016, 2016, 2016, 2016, 2016, 2016, …\n$ runtime         &lt;dbl&gt; 121, 124, 117, 108, 123, 103, 128, 89, 141, 116, 133, …\n$ rating          &lt;dbl&gt; 8.1, 7.0, 7.3, 7.2, 6.2, 6.1, 8.3, 6.4, 7.1, 7.0, 7.5,…\n$ revenue_million &lt;dbl&gt; 333.13, 126.46, 138.12, 270.32, 325.02, 45.13, 151.06,…\n$ indicator       &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, …\n\n\nKeep in mind that you can throw any function into mutate() as long as it is vectorized and the output has the same length as the tibble or 1.\ncase_when() also has a sibling called case_match(). It is used when you want to create a new variable based on the values of a categorical variable. It works similar to case_when(), but instead of providing conditions, you provide the exact values you want to match. case_match() provides a cleaner syntax when you’re matching exact values. It’s particularly useful when you want to recode or map specific values to new ones.\n\nimdb_selected |&gt; \n  mutate(\n    # Match specific years to decades\n    decade = case_match(\n      year,\n      2006:2009 ~ \"2000s\",\n      2010:2016 ~ \"2010s\",\n      .default = \"Unknown\"\n    )\n  ) |&gt; \n  count(decade)\n\n# A tibble: 2 × 2\n  decade     n\n  &lt;chr&gt;  &lt;int&gt;\n1 2000s    200\n2 2010s    800\n\n\nYou can also use case_match() with character values:\n\nimdb_selected |&gt; \n  mutate(\n    director_type = case_match(\n      director,\n      c(\"Christopher Nolan\", \"Steven Spielberg\", \"Martin Scorsese\") ~ \"Famous\",\n      .default = \"Other\"\n    )\n  ) |&gt; \n  count(director_type)\n\n# A tibble: 2 × 2\n  director_type     n\n  &lt;chr&gt;         &lt;int&gt;\n1 Famous           14\n2 Other           986\n\n\nKey differences between case_when() and case_match():\n\nSyntax: case_match() uses the value to match on the left side, while case_when() uses conditions\nUse case: case_match() is for exact matching, case_when() is for complex conditions\nPerformance: case_match() can be faster for simple value matching\nReadability: case_match() is often cleaner when recoding variables\n\n\n\nsummarize(), group_by(), and reframe()\nWhen you analyze data, you often want to compare entities according to some sort of summary statistic. This means that you, first, need to split up your data set into certain groups which share one or more characteristics, and, second, collapse the rows together into single-row summaries. The former challenge is accomplished using group_by() whose argument is one or more variables, the latter requires the summarize() function. This function works similar to mutate() but uses summary functions – which take a vector of multiple values and return a single value – instead of window functions – which return a vector of the same length as the input.\nLet me provide you an example.\nI am interested in the director’s average ratings:\n\nimdb_selected |&gt; \n  group_by(director, year) |&gt; \n  summarize(avg_rating = mean(rating),\n            avg_revenue = mean(revenue_million, na.rm = TRUE))\n\n`summarise()` has grouped output by 'director'. You can override using the\n`.groups` argument.\n\n\n# A tibble: 987 × 4\n# Groups:   director [644]\n   director             year avg_rating avg_revenue\n   &lt;chr&gt;               &lt;dbl&gt;      &lt;dbl&gt;       &lt;dbl&gt;\n 1 Aamir Khan           2007        8.5        1.2 \n 2 Abdellatif Kechiche  2013        7.8        2.2 \n 3 Adam Leon            2016        6.5      NaN   \n 4 Adam McKay           2006        6.6      148.  \n 5 Adam McKay           2008        6.9      100.  \n 6 Adam McKay           2010        6.7      119.  \n 7 Adam McKay           2015        7.8       70.2 \n 8 Adam Shankman        2007        6.7      119.  \n 9 Adam Shankman        2012        5.9       38.5 \n10 Adam Wingard         2014        6.7        0.32\n# ℹ 977 more rows\n\n\nIn general, summarize() always works like this: first, you change the scope from the entire tibble to different groups. Then, you calculate your summary. If you then want to further manipulate your data or calculate something else based on the new summary, you need to call ungroup().\nYou can see the summary functions below:\n\n\n\nSummary functions in R\n\n\nAnother handy function akin to this is count(). It counts all occurrences of a singular value in the tibble.\nIf I were interested in how many movies of the different directors have made it into the data set, I could use this code:\n\nimdb_selected |&gt; \n  count(director)\n\n# A tibble: 644 × 2\n   director                n\n   &lt;chr&gt;               &lt;int&gt;\n 1 Aamir Khan              1\n 2 Abdellatif Kechiche     1\n 3 Adam Leon               1\n 4 Adam McKay              4\n 5 Adam Shankman           2\n 6 Adam Wingard            2\n 7 Afonso Poyart           1\n 8 Aisling Walsh           1\n 9 Akan Satayev            1\n10 Akiva Schaffer          1\n# ℹ 634 more rows\n\n\nWhile summarize() is powerful, it has a limitation: it always returns exactly one row per group. Sometimes you need more flexibility - that’s where reframe() comes in. Introduced in dplyr 1.1.0, reframe() allows you to return any number of rows per group.\nWith reframe(), we can for instance calculate the rating quantiles per director:\n\nimdb_selected |&gt; \n  group_by(director) |&gt; \n  reframe(\n    rating_quantiles = quantile(rating, probs = c(0.25, 0.5, 0.75)),\n    quantile = rep(c(0.25, 0.5, 0.75))\n  ) |&gt; \n    ungroup()\n\n# A tibble: 1,932 × 3\n   director            rating_quantiles quantile\n   &lt;chr&gt;                          &lt;dbl&gt;    &lt;dbl&gt;\n 1 Aamir Khan                      8.5      0.25\n 2 Aamir Khan                      8.5      0.5 \n 3 Aamir Khan                      8.5      0.75\n 4 Abdellatif Kechiche             7.8      0.25\n 5 Abdellatif Kechiche             7.8      0.5 \n 6 Abdellatif Kechiche             7.8      0.75\n 7 Adam Leon                       6.5      0.25\n 8 Adam Leon                       6.5      0.5 \n 9 Adam Leon                       6.5      0.75\n10 Adam McKay                      6.68     0.25\n# ℹ 1,922 more rows\n\n\nThis example calculates the 25th, 50th, and 75th percentiles of ratings. Each director will have one row with their average rating and a list of quantiles.\nWhen to use reframe() vs summarize():\nUse summarize() when you want:\n\nOne summary value per group (mean, sum, count, etc.)\nA single row of results per group\n\nUse reframe() when you need:\n\nMultiple rows per group\nTo return quantiles, ranges, or other multi-value summaries\nMore flexibility in your output structure\n\nNote that both functions return a grouped tibble, so you may want to ungroup() afterwards if you’re doing further operations.\n\n\narrange()\nFinally, you can also sort values using arrange(). In the last section, I was interested in directors’ respective average ratings. The values were ordered according to their name (hence, “Aamir Khan” was first). In this case, the order dos not make too much sense, because the first name does not say too much about the director’s ratings. Therefore, I want to sort them according to their average ratings:\n\nimdb_selected |&gt; \n  group_by(director) |&gt; \n  summarize(avg_rating = mean(rating)) |&gt; \n  arrange(avg_rating)\n\n# A tibble: 644 × 2\n   director           avg_rating\n   &lt;chr&gt;                   &lt;dbl&gt;\n 1 Jason Friedberg           1.9\n 2 James Wong                2.7\n 3 Shawn Burkett             2.7\n 4 Jonathan Holbrook         3.2\n 5 Femi Oyeniran             3.5\n 6 Micheal Bafaro            3.5\n 7 Jeffrey G. Hunt           3.7\n 8 Rolfe Kanefsky            3.9\n 9 Joey Curtis               4  \n10 Sam Taylor-Johnson        4.1\n# ℹ 634 more rows\n\n\nAll right, Jason Friedberg is apparently the director of the worst rated movie in my data set. But it would be more handy, if they were arranged in descending order. I can use desc() for this:\n\nimdb_selected |&gt; \n  group_by(director) |&gt; \n  summarize(avg_rating = mean(rating)) |&gt; \n  arrange(-avg_rating)\n\n# A tibble: 644 × 2\n   director                         avg_rating\n   &lt;chr&gt;                                 &lt;dbl&gt;\n 1 Nitesh Tiwari                          8.8 \n 2 Christopher Nolan                      8.68\n 3 Makoto Shinkai                         8.6 \n 4 Olivier Nakache                        8.6 \n 5 Aamir Khan                             8.5 \n 6 Florian Henckel von Donnersmarck       8.5 \n 7 Damien Chazelle                        8.4 \n 8 Naoko Yamada                           8.4 \n 9 Amber Tamblyn                          8.3 \n10 Lee Unkrich                            8.3 \n# ℹ 634 more rows\n\n\nChapeau, Nitesh Tiwari!\n\n\nIntroducing joins\nThe last session showed you three things: how you get data sets into R, a couple of ways to create tibbles, and an introduction to tidy data and how to make data sets tidy using the tidyr package. As you may recall from the last session, it was not able to solve the last two problems with only the tools tidyr offers. In particular, the problems were:\n\nMultiple types of observational units are stored in the same table.\nA single observational unit is stored in multiple tables.\n\nBoth problems need some different kind of tools: joins. Joins can be used to merge tibbles together. This tutorial, again, builds heavily on the R for Data Science book (Wickham and Grolemund 2016)\n\nMultiple types of units are in the same table\nLet’s look at the following data set. It contains the billboard charts in 2000 and was obtained from the tidyr GitHub repo. The example below is taken from the tidyr vignette which can be loaded using vignette(\"tidy-data\", package = \"tidyr\").\n\nload(\"data/billboard.rda\")\n\n\nglimpse(billboard)\n\nRows: 317\nColumns: 79\n$ artist       &lt;chr&gt; \"2 Pac\", \"2Ge+her\", \"3 Doors Down\", \"3 Doors Down\", \"504 …\n$ track        &lt;chr&gt; \"Baby Don't Cry (Keep...\", \"The Hardest Part Of ...\", \"Kr…\n$ date.entered &lt;date&gt; 2000-02-26, 2000-09-02, 2000-04-08, 2000-10-21, 2000-04-…\n$ wk1          &lt;dbl&gt; 87, 91, 81, 76, 57, 51, 97, 84, 59, 76, 84, 57, 50, 71, 7…\n$ wk2          &lt;dbl&gt; 82, 87, 70, 76, 34, 39, 97, 62, 53, 76, 84, 47, 39, 51, 6…\n$ wk3          &lt;dbl&gt; 72, 92, 68, 72, 25, 34, 96, 51, 38, 74, 75, 45, 30, 28, 5…\n$ wk4          &lt;dbl&gt; 77, NA, 67, 69, 17, 26, 95, 41, 28, 69, 73, 29, 28, 18, 4…\n$ wk5          &lt;dbl&gt; 87, NA, 66, 67, 17, 26, 100, 38, 21, 68, 73, 23, 21, 13, …\n$ wk6          &lt;dbl&gt; 94, NA, 57, 65, 31, 19, NA, 35, 18, 67, 69, 18, 19, 13, 3…\n$ wk7          &lt;dbl&gt; 99, NA, 54, 55, 36, 2, NA, 35, 16, 61, 68, 11, 20, 11, 34…\n$ wk8          &lt;dbl&gt; NA, NA, 53, 59, 49, 2, NA, 38, 14, 58, 65, 9, 17, 1, 29, …\n$ wk9          &lt;dbl&gt; NA, NA, 51, 62, 53, 3, NA, 38, 12, 57, 73, 9, 17, 1, 27, …\n$ wk10         &lt;dbl&gt; NA, NA, 51, 61, 57, 6, NA, 36, 10, 59, 83, 11, 17, 2, 30,…\n$ wk11         &lt;dbl&gt; NA, NA, 51, 61, 64, 7, NA, 37, 9, 66, 92, 1, 17, 2, 36, N…\n$ wk12         &lt;dbl&gt; NA, NA, 51, 59, 70, 22, NA, 37, 8, 68, NA, 1, 3, 3, 37, N…\n$ wk13         &lt;dbl&gt; NA, NA, 47, 61, 75, 29, NA, 38, 6, 61, NA, 1, 3, 3, 39, N…\n$ wk14         &lt;dbl&gt; NA, NA, 44, 66, 76, 36, NA, 49, 1, 67, NA, 1, 7, 4, 49, N…\n$ wk15         &lt;dbl&gt; NA, NA, 38, 72, 78, 47, NA, 61, 2, 59, NA, 4, 10, 12, 57,…\n$ wk16         &lt;dbl&gt; NA, NA, 28, 76, 85, 67, NA, 63, 2, 63, NA, 8, 17, 11, 63,…\n$ wk17         &lt;dbl&gt; NA, NA, 22, 75, 92, 66, NA, 62, 2, 67, NA, 12, 25, 13, 65…\n$ wk18         &lt;dbl&gt; NA, NA, 18, 67, 96, 84, NA, 67, 2, 71, NA, 22, 29, 15, 68…\n$ wk19         &lt;dbl&gt; NA, NA, 18, 73, NA, 93, NA, 83, 3, 79, NA, 23, 29, 18, 79…\n$ wk20         &lt;dbl&gt; NA, NA, 14, 70, NA, 94, NA, 86, 4, 89, NA, 43, 40, 20, 86…\n$ wk21         &lt;dbl&gt; NA, NA, 12, NA, NA, NA, NA, NA, 5, NA, NA, 44, 43, 30, NA…\n$ wk22         &lt;dbl&gt; NA, NA, 7, NA, NA, NA, NA, NA, 5, NA, NA, NA, 50, 40, NA,…\n$ wk23         &lt;dbl&gt; NA, NA, 6, NA, NA, NA, NA, NA, 6, NA, NA, NA, NA, 39, NA,…\n$ wk24         &lt;dbl&gt; NA, NA, 6, NA, NA, NA, NA, NA, 9, NA, NA, NA, NA, 44, NA,…\n$ wk25         &lt;dbl&gt; NA, NA, 6, NA, NA, NA, NA, NA, 13, NA, NA, NA, NA, NA, NA…\n$ wk26         &lt;dbl&gt; NA, NA, 5, NA, NA, NA, NA, NA, 14, NA, NA, NA, NA, NA, NA…\n$ wk27         &lt;dbl&gt; NA, NA, 5, NA, NA, NA, NA, NA, 16, NA, NA, NA, NA, NA, NA…\n$ wk28         &lt;dbl&gt; NA, NA, 4, NA, NA, NA, NA, NA, 23, NA, NA, NA, NA, NA, NA…\n$ wk29         &lt;dbl&gt; NA, NA, 4, NA, NA, NA, NA, NA, 22, NA, NA, NA, NA, NA, NA…\n$ wk30         &lt;dbl&gt; NA, NA, 4, NA, NA, NA, NA, NA, 33, NA, NA, NA, NA, NA, NA…\n$ wk31         &lt;dbl&gt; NA, NA, 4, NA, NA, NA, NA, NA, 36, NA, NA, NA, NA, NA, NA…\n$ wk32         &lt;dbl&gt; NA, NA, 3, NA, NA, NA, NA, NA, 43, NA, NA, NA, NA, NA, NA…\n$ wk33         &lt;dbl&gt; NA, NA, 3, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ wk34         &lt;dbl&gt; NA, NA, 3, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ wk35         &lt;dbl&gt; NA, NA, 4, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ wk36         &lt;dbl&gt; NA, NA, 5, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ wk37         &lt;dbl&gt; NA, NA, 5, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ wk38         &lt;dbl&gt; NA, NA, 9, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ wk39         &lt;dbl&gt; NA, NA, 9, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ wk40         &lt;dbl&gt; NA, NA, 15, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ wk41         &lt;dbl&gt; NA, NA, 14, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ wk42         &lt;dbl&gt; NA, NA, 13, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ wk43         &lt;dbl&gt; NA, NA, 14, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ wk44         &lt;dbl&gt; NA, NA, 16, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ wk45         &lt;dbl&gt; NA, NA, 17, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ wk46         &lt;dbl&gt; NA, NA, 21, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ wk47         &lt;dbl&gt; NA, NA, 22, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ wk48         &lt;dbl&gt; NA, NA, 24, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ wk49         &lt;dbl&gt; NA, NA, 28, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ wk50         &lt;dbl&gt; NA, NA, 33, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ wk51         &lt;dbl&gt; NA, NA, 42, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ wk52         &lt;dbl&gt; NA, NA, 42, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ wk53         &lt;dbl&gt; NA, NA, 49, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ wk54         &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ wk55         &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ wk56         &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ wk57         &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ wk58         &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ wk59         &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ wk60         &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ wk61         &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ wk62         &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ wk63         &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ wk64         &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ wk65         &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ wk66         &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ wk67         &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ wk68         &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ wk69         &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ wk70         &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ wk71         &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ wk72         &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ wk73         &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ wk74         &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ wk75         &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ wk76         &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n\n\nHere, you can immediately see the problem: it contains two types of observations: songs and ranks. Hence, the data set needs to be split up. However, there should be a pointer from the rank data set to the song data set. First, I add an ID column to song_tbl. Then, I can add it to rank_tbl and drop the unnecessary columns which contain the name of the artist and the track.\n\nsong_tbl &lt;- billboard |&gt; \n  rowid_to_column(\"song_id\") |&gt; \n  distinct(artist, track, .keep_all = TRUE) |&gt; \n  select(song_id:track)\n\nglimpse(song_tbl)\n\nRows: 317\nColumns: 3\n$ song_id &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18,…\n$ artist  &lt;chr&gt; \"2 Pac\", \"2Ge+her\", \"3 Doors Down\", \"3 Doors Down\", \"504 Boyz\"…\n$ track   &lt;chr&gt; \"Baby Don't Cry (Keep...\", \"The Hardest Part Of ...\", \"Krypton…\n\n\n\nrank_tbl &lt;- billboard |&gt; \n  pivot_longer(cols = starts_with(\"wk\"), \n               names_to = \"week\", \n               names_prefix = \"wk\", \n               values_to = \"rank\") |&gt; \n  mutate(week = as.numeric(week),\n         date = date.entered + (week-1) * 7) |&gt; \n  drop_na() |&gt; \n  left_join(song_tbl, by = c(\"artist\", \"track\")) |&gt; \n  select(song_id, date, week, rank)\n\nglimpse(rank_tbl)\n\nRows: 5,307\nColumns: 4\n$ song_id &lt;int&gt; 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,…\n$ date    &lt;date&gt; 2000-02-26, 2000-03-04, 2000-03-11, 2000-03-18, 2000-03-25, 2…\n$ week    &lt;dbl&gt; 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1…\n$ rank    &lt;dbl&gt; 87, 82, 72, 77, 87, 94, 99, 91, 87, 92, 81, 70, 68, 67, 66, 57…\n\n\n\n\nOne unit is in multiple tables\nFor this example, I have split up a data set from the socviz package containing data on the 2016 elections in the U.S. according to census region and stored them in a folder. I can scrape the file names in the folder and read it into a list in an automated manner. (Note that the functions used to read the files in in an automated fashion are beyond the scope of this course. They come from the fs (Hester, Wickham, and Csárdi 2021) and the purrr package (Henry and Wickham 2020).)3\n\nfile_list &lt;- dir_ls(path = \"data/socviz_us\") |&gt; \n  map(read_csv,\n      col_types = cols(\n        id = col_double(),\n        name = col_character(),\n        state = col_character(),\n        census_region = col_character(),\n        pop_dens = col_character(),\n        pop_dens4 = col_character(),\n        pop_dens6 = col_character(),\n        pct_black = col_character(),\n        pop = col_double(),\n        female = col_double(),\n        white = col_double(),\n        black = col_double(),\n        travel_time = col_double(),\n        land_area = col_double(),\n        hh_income = col_double(),\n        su_gun4 = col_character(),\n        su_gun6 = col_character(),\n        fips = col_double(),\n        votes_dem_2016 = col_double(),\n        votes_gop_2016 = col_double(),\n        total_votes_2016 = col_double(),\n        per_dem_2016 = col_double(),\n        per_gop_2016 = col_double(),\n        diff_2016 = col_double(),\n        per_dem_2012 = col_double(),\n        per_gop_2012 = col_double(),\n        diff_2012 = col_double(),\n        winner = col_character(),\n        partywinner16 = col_character(),\n        winner12 = col_character(),\n        partywinner12 = col_character(),\n        flipped = col_character()\n))\n\nThe list now consists of four tibbles in a list which need to be bound together. You can achieve this using list_rbind(). Its counterpart is list_cbind() which binds columns together. It matches rows by position.\n\nelection_data &lt;- file_list |&gt; list_rbind()\nglimpse(election_data)\n\nRows: 3,141\nColumns: 32\n$ id               &lt;dbl&gt; 17001, 17003, 17005, 17007, 17009, 17011, 17013, 1701…\n$ name             &lt;chr&gt; \"Adams County\", \"Alexander County\", \"Bond County\", \"B…\n$ state            &lt;chr&gt; \"IL\", \"IL\", \"IL\", \"IL\", \"IL\", \"IL\", \"IL\", \"IL\", \"IL\",…\n$ census_region    &lt;chr&gt; \"Midwest\", \"Midwest\", \"Midwest\", \"Midwest\", \"Midwest\"…\n$ pop_dens         &lt;chr&gt; \"[   50,  100)\", \"[   10,   50)\", \"[   10,   50)\", \"[…\n$ pop_dens4        &lt;chr&gt; \"[ 45,  118)\", \"[ 17,   45)\", \"[ 45,  118)\", \"[118,71…\n$ pop_dens6        &lt;chr&gt; \"[ 45,   82)\", \"[ 25,   45)\", \"[ 45,   82)\", \"[ 82,  …\n$ pct_black        &lt;chr&gt; \"[ 2.0, 5.0)\", \"[25.0,50.0)\", \"[ 5.0,10.0)\", \"[ 2.0, …\n$ pop              &lt;dbl&gt; 66988, 7492, 17269, 53869, 6832, 33840, 4956, 14715, …\n$ female           &lt;dbl&gt; 51.3, 49.5, 47.5, 50.2, 35.5, 51.0, 49.7, 50.1, 49.1,…\n$ white            &lt;dbl&gt; 93.7, 60.6, 90.9, 93.2, 78.6, 96.8, 98.8, 96.7, 93.2,…\n$ black            &lt;dbl&gt; 3.7, 36.1, 6.5, 2.6, 19.1, 0.8, 0.3, 1.1, 4.4, 12.8, …\n$ travel_time      &lt;dbl&gt; 16.6, 25.6, 23.6, 30.1, 18.9, 20.4, 39.6, 23.8, 22.2,…\n$ land_area        &lt;dbl&gt; 855.20, 235.51, 380.28, 280.72, 305.61, 869.03, 253.8…\n$ hh_income        &lt;dbl&gt; 45073, 26972, 48163, 60893, 42194, 48977, 50436, 4798…\n$ su_gun4          &lt;chr&gt; \"[ 0, 5)\", \"[ 5, 8)\", \"[ 0, 5)\", \"[ 0, 5)\", \"[ 0, 5)\"…\n$ su_gun6          &lt;chr&gt; \"[ 4, 7)\", \"[ 7, 8)\", \"[ 4, 7)\", \"[ 0, 4)\", \"[ 0, 4)\"…\n$ fips             &lt;dbl&gt; 17001, 17003, 17005, 17007, 17009, 17011, 17013, 1701…\n$ votes_dem_2016   &lt;dbl&gt; 7633, 1262, 2066, 8952, 475, 6010, 739, 2437, 1617, 4…\n$ votes_gop_2016   &lt;dbl&gt; 22732, 1496, 4884, 12261, 1776, 9264, 1719, 4428, 321…\n$ total_votes_2016 &lt;dbl&gt; 31770, 2820, 7462, 22604, 2336, 16303, 2556, 7354, 50…\n$ per_dem_2016     &lt;dbl&gt; 0.2402581, 0.4475177, 0.2768695, 0.3960361, 0.2033390…\n$ per_gop_2016     &lt;dbl&gt; 0.7155178, 0.5304965, 0.6545162, 0.5424261, 0.7602740…\n$ diff_2016        &lt;dbl&gt; 15099, 234, 2818, 3309, 1301, 3254, 980, 1991, 1599, …\n$ per_dem_2012     &lt;dbl&gt; 0.3152466, 0.5610873, 0.4122471, 0.4625697, 0.3331922…\n$ per_gop_2012     &lt;dbl&gt; 0.6670705, 0.4248927, 0.5591853, 0.5195706, 0.6397121…\n$ diff_2012        &lt;dbl&gt; 10744, 476, 1075, 1216, 724, 33, 360, 107, 657, 5292,…\n$ winner           &lt;chr&gt; \"Trump\", \"Trump\", \"Trump\", \"Trump\", \"Trump\", \"Trump\",…\n$ partywinner16    &lt;chr&gt; \"Republican\", \"Republican\", \"Republican\", \"Republican…\n$ winner12         &lt;chr&gt; \"Romney\", \"Obama\", \"Romney\", \"Romney\", \"Romney\", \"Rom…\n$ partywinner12    &lt;chr&gt; \"Republican\", \"Democrat\", \"Republican\", \"Republican\",…\n$ flipped          &lt;chr&gt; \"No\", \"Yes\", \"No\", \"No\", \"No\", \"No\", \"No\", \"Yes\", \"No…\n\n\nHowever, the topic of this script is different joins. The dplyr package offers six different joins: left_join(), right_join(), inner_join(), full_join(), semi_join(), and anti_join(). The former four are mutating joins, they add columns. The latter two can be used to filter rows in a data set. Below is an overview from the dplyr cheat sheet:\n\n\n\nOverview of the different joins\n\n\nIn the following, I will illustrate this using the election data. I split up the data set into three: data on the elections 2016 and 2012, and demographic data. The column they have in common is the county’s respective name.\n\nelection_data16 &lt;- election_data |&gt; \n  select(name, state, votes_dem_2016:diff_2016, winner, partywinner16)\n\nelection_data12 &lt;- election_data |&gt; \n  select(name, state, per_dem_2012:partywinner12)\n\ndemographic_data &lt;- election_data |&gt; \n  select(name, state, pop:hh_income) |&gt; \n  slice(1:2000) #you will see later why I do this\n\n\n\nleft_join() and right_join()\nIf we want to add the demographic data to the election data 2016, we can use a left_join() or a right_join(). The former adds all columns of y to x, the latter all columns of x to y. Here, I want to add the demographic data to the election data 2016. Therefore, I use a left_join():\n\nelection_data16 |&gt; \n  left_join(demographic_data)\n\nJoining with `by = join_by(name, state)`\n\n\n# A tibble: 3,141 × 17\n   name        state votes_dem_2016 votes_gop_2016 total_votes_2016 per_dem_2016\n   &lt;chr&gt;       &lt;chr&gt;          &lt;dbl&gt;          &lt;dbl&gt;            &lt;dbl&gt;        &lt;dbl&gt;\n 1 Adams Coun… IL              7633          22732            31770        0.240\n 2 Alexander … IL              1262           1496             2820        0.448\n 3 Bond County IL              2066           4884             7462        0.277\n 4 Boone Coun… IL              8952          12261            22604        0.396\n 5 Brown Coun… IL               475           1776             2336        0.203\n 6 Bureau Cou… IL              6010           9264            16303        0.369\n 7 Calhoun Co… IL               739           1719             2556        0.289\n 8 Carroll Co… IL              2437           4428             7354        0.331\n 9 Cass County IL              1617           3216             5054        0.320\n10 Champaign … IL             49694          33235            89196        0.557\n# ℹ 3,131 more rows\n# ℹ 11 more variables: per_gop_2016 &lt;dbl&gt;, diff_2016 &lt;dbl&gt;, winner &lt;chr&gt;,\n#   partywinner16 &lt;chr&gt;, pop &lt;dbl&gt;, female &lt;dbl&gt;, white &lt;dbl&gt;, black &lt;dbl&gt;,\n#   travel_time &lt;dbl&gt;, land_area &lt;dbl&gt;, hh_income &lt;dbl&gt;\n\n\nIf the column that both data sets have in common has the same name, there’s no need to provide it. If this is not the case, you need to provide it in a character vector:\n\nelection_data16 |&gt; \n  rename(county = name) |&gt; \n  right_join(demographic_data, by = join_by(\"county\" == \"name\"))\n\nWarning in right_join(rename(election_data16, county = name), demographic_data, : Detected an unexpected many-to-many relationship between `x` and `y`.\nℹ Row 1 of `x` matches multiple rows in `y`.\nℹ Row 1 of `y` matches multiple rows in `x`.\nℹ If a many-to-many relationship is expected, set `relationship =\n  \"many-to-many\"` to silence this warning.\n\n\n# A tibble: 10,348 × 18\n   county    state.x votes_dem_2016 votes_gop_2016 total_votes_2016 per_dem_2016\n   &lt;chr&gt;     &lt;chr&gt;            &lt;dbl&gt;          &lt;dbl&gt;            &lt;dbl&gt;        &lt;dbl&gt;\n 1 Adams Co… IL                7633          22732            31770        0.240\n 2 Adams Co… IL                7633          22732            31770        0.240\n 3 Adams Co… IL                7633          22732            31770        0.240\n 4 Adams Co… IL                7633          22732            31770        0.240\n 5 Adams Co… IL                7633          22732            31770        0.240\n 6 Adams Co… IL                7633          22732            31770        0.240\n 7 Adams Co… IL                7633          22732            31770        0.240\n 8 Adams Co… IL                7633          22732            31770        0.240\n 9 Adams Co… IL                7633          22732            31770        0.240\n10 Alexande… IL                1262           1496             2820        0.448\n# ℹ 10,338 more rows\n# ℹ 12 more variables: per_gop_2016 &lt;dbl&gt;, diff_2016 &lt;dbl&gt;, winner &lt;chr&gt;,\n#   partywinner16 &lt;chr&gt;, state.y &lt;chr&gt;, pop &lt;dbl&gt;, female &lt;dbl&gt;, white &lt;dbl&gt;,\n#   black &lt;dbl&gt;, travel_time &lt;dbl&gt;, land_area &lt;dbl&gt;, hh_income &lt;dbl&gt;\n\n\nHere, the problem is that the same counties exist in different states. Therefore, all combinations are returned. Hence, I need to specify two arguments: the county’s name and state.\n\nelection_data16 |&gt; \n  rename(county = name) |&gt; \n  right_join(demographic_data, by = join_by(\"county\" == \"name\", \"state\"))\n\n# A tibble: 2,000 × 17\n   county      state votes_dem_2016 votes_gop_2016 total_votes_2016 per_dem_2016\n   &lt;chr&gt;       &lt;chr&gt;          &lt;dbl&gt;          &lt;dbl&gt;            &lt;dbl&gt;        &lt;dbl&gt;\n 1 Adams Coun… IL              7633          22732            31770        0.240\n 2 Alexander … IL              1262           1496             2820        0.448\n 3 Bond County IL              2066           4884             7462        0.277\n 4 Boone Coun… IL              8952          12261            22604        0.396\n 5 Brown Coun… IL               475           1776             2336        0.203\n 6 Bureau Cou… IL              6010           9264            16303        0.369\n 7 Calhoun Co… IL               739           1719             2556        0.289\n 8 Carroll Co… IL              2437           4428             7354        0.331\n 9 Cass County IL              1617           3216             5054        0.320\n10 Champaign … IL             49694          33235            89196        0.557\n# ℹ 1,990 more rows\n# ℹ 11 more variables: per_gop_2016 &lt;dbl&gt;, diff_2016 &lt;dbl&gt;, winner &lt;chr&gt;,\n#   partywinner16 &lt;chr&gt;, pop &lt;dbl&gt;, female &lt;dbl&gt;, white &lt;dbl&gt;, black &lt;dbl&gt;,\n#   travel_time &lt;dbl&gt;, land_area &lt;dbl&gt;, hh_income &lt;dbl&gt;\n\n\nLeft joins return all rows which are in x. If a column is in x but not in y, an NA will be included at this position. Right joins work vice versa and return all rows which are in y.\n\n\ninner_join()\nAn inner_join() returns all rows which are in x and y.\n\nelection_data16 |&gt; \n  inner_join(demographic_data)\n\nJoining with `by = join_by(name, state)`\n\n\n# A tibble: 2,000 × 17\n   name        state votes_dem_2016 votes_gop_2016 total_votes_2016 per_dem_2016\n   &lt;chr&gt;       &lt;chr&gt;          &lt;dbl&gt;          &lt;dbl&gt;            &lt;dbl&gt;        &lt;dbl&gt;\n 1 Adams Coun… IL              7633          22732            31770        0.240\n 2 Alexander … IL              1262           1496             2820        0.448\n 3 Bond County IL              2066           4884             7462        0.277\n 4 Boone Coun… IL              8952          12261            22604        0.396\n 5 Brown Coun… IL               475           1776             2336        0.203\n 6 Bureau Cou… IL              6010           9264            16303        0.369\n 7 Calhoun Co… IL               739           1719             2556        0.289\n 8 Carroll Co… IL              2437           4428             7354        0.331\n 9 Cass County IL              1617           3216             5054        0.320\n10 Champaign … IL             49694          33235            89196        0.557\n# ℹ 1,990 more rows\n# ℹ 11 more variables: per_gop_2016 &lt;dbl&gt;, diff_2016 &lt;dbl&gt;, winner &lt;chr&gt;,\n#   partywinner16 &lt;chr&gt;, pop &lt;dbl&gt;, female &lt;dbl&gt;, white &lt;dbl&gt;, black &lt;dbl&gt;,\n#   travel_time &lt;dbl&gt;, land_area &lt;dbl&gt;, hh_income &lt;dbl&gt;\n\n\n\n\nfull_join()\nA full_join() returns rows and columns from both x and y.\n\nelection_data16 |&gt; \n  full_join(demographic_data)\n\nJoining with `by = join_by(name, state)`\n\n\n# A tibble: 3,141 × 17\n   name        state votes_dem_2016 votes_gop_2016 total_votes_2016 per_dem_2016\n   &lt;chr&gt;       &lt;chr&gt;          &lt;dbl&gt;          &lt;dbl&gt;            &lt;dbl&gt;        &lt;dbl&gt;\n 1 Adams Coun… IL              7633          22732            31770        0.240\n 2 Alexander … IL              1262           1496             2820        0.448\n 3 Bond County IL              2066           4884             7462        0.277\n 4 Boone Coun… IL              8952          12261            22604        0.396\n 5 Brown Coun… IL               475           1776             2336        0.203\n 6 Bureau Cou… IL              6010           9264            16303        0.369\n 7 Calhoun Co… IL               739           1719             2556        0.289\n 8 Carroll Co… IL              2437           4428             7354        0.331\n 9 Cass County IL              1617           3216             5054        0.320\n10 Champaign … IL             49694          33235            89196        0.557\n# ℹ 3,131 more rows\n# ℹ 11 more variables: per_gop_2016 &lt;dbl&gt;, diff_2016 &lt;dbl&gt;, winner &lt;chr&gt;,\n#   partywinner16 &lt;chr&gt;, pop &lt;dbl&gt;, female &lt;dbl&gt;, white &lt;dbl&gt;, black &lt;dbl&gt;,\n#   travel_time &lt;dbl&gt;, land_area &lt;dbl&gt;, hh_income &lt;dbl&gt;\n\n\n\n\nsemi_join()\nFiltering joins only keep the cases from x, no data set is added.\nThe semi_join() returns all rows from x with matching values in y. You can compare it to a right_join() but without adding the columns of y.\n\nelection_data16 |&gt; \n  semi_join(demographic_data)\n\nJoining with `by = join_by(name, state)`\n\n\n# A tibble: 2,000 × 10\n   name        state votes_dem_2016 votes_gop_2016 total_votes_2016 per_dem_2016\n   &lt;chr&gt;       &lt;chr&gt;          &lt;dbl&gt;          &lt;dbl&gt;            &lt;dbl&gt;        &lt;dbl&gt;\n 1 Adams Coun… IL              7633          22732            31770        0.240\n 2 Alexander … IL              1262           1496             2820        0.448\n 3 Bond County IL              2066           4884             7462        0.277\n 4 Boone Coun… IL              8952          12261            22604        0.396\n 5 Brown Coun… IL               475           1776             2336        0.203\n 6 Bureau Cou… IL              6010           9264            16303        0.369\n 7 Calhoun Co… IL               739           1719             2556        0.289\n 8 Carroll Co… IL              2437           4428             7354        0.331\n 9 Cass County IL              1617           3216             5054        0.320\n10 Champaign … IL             49694          33235            89196        0.557\n# ℹ 1,990 more rows\n# ℹ 4 more variables: per_gop_2016 &lt;dbl&gt;, diff_2016 &lt;dbl&gt;, winner &lt;chr&gt;,\n#   partywinner16 &lt;chr&gt;\n\n\n\n\nanti_join()\nanti_join() returns all rows from x with no matching rows in y.\n\nelection_data16 |&gt; \n  anti_join(demographic_data)\n\nJoining with `by = join_by(name, state)`\n\n\n# A tibble: 1,141 × 10\n   name        state votes_dem_2016 votes_gop_2016 total_votes_2016 per_dem_2016\n   &lt;chr&gt;       &lt;chr&gt;          &lt;dbl&gt;          &lt;dbl&gt;            &lt;dbl&gt;        &lt;dbl&gt;\n 1 Onslow Cou… NC             17156          36342            55364        0.310\n 2 Orange Cou… NC             59105          18373            79830        0.740\n 3 Pamlico Co… NC              2427           4225             6772        0.358\n 4 Pasquotank… NC              8455           8082            16964        0.498\n 5 Pender Cou… NC              9086          17317            27072        0.336\n 6 Perquimans… NC              2291           4143             6595        0.347\n 7 Person Cou… NC              7772          11116            19303        0.403\n 8 Pitt County NC             40967          35191            78264        0.523\n 9 Polk County NC              3715           6738            10723        0.346\n10 Randolph C… NC             13074          49156            63615        0.206\n# ℹ 1,131 more rows\n# ℹ 4 more variables: per_gop_2016 &lt;dbl&gt;, diff_2016 &lt;dbl&gt;, winner &lt;chr&gt;,\n#   partywinner16 &lt;chr&gt;\n\n\n\n\n\nbind_rows() and bind_cols()\nBinding tibbles together is made easy using the bind_*() functions. bind_rows() binds them together by rows, bind_cols() by columns. For the former, it is important that column names are matching. Otherwise, the non-matching ones will be added as separate columns and NAs introduced. IDs can be added by using the .id = argument, where the name of the id column can be specified.\n\nelection_data16 |&gt; \n  semi_join(demographic_data) |&gt; \n  bind_rows(election_data16 |&gt;\n              anti_join(demographic_data),\n            .id = \"id\")\n\nJoining with `by = join_by(name, state)`\nJoining with `by = join_by(name, state)`\n\n\n# A tibble: 3,141 × 11\n   id    name  state votes_dem_2016 votes_gop_2016 total_votes_2016 per_dem_2016\n   &lt;chr&gt; &lt;chr&gt; &lt;chr&gt;          &lt;dbl&gt;          &lt;dbl&gt;            &lt;dbl&gt;        &lt;dbl&gt;\n 1 1     Adam… IL              7633          22732            31770        0.240\n 2 1     Alex… IL              1262           1496             2820        0.448\n 3 1     Bond… IL              2066           4884             7462        0.277\n 4 1     Boon… IL              8952          12261            22604        0.396\n 5 1     Brow… IL               475           1776             2336        0.203\n 6 1     Bure… IL              6010           9264            16303        0.369\n 7 1     Calh… IL               739           1719             2556        0.289\n 8 1     Carr… IL              2437           4428             7354        0.331\n 9 1     Cass… IL              1617           3216             5054        0.320\n10 1     Cham… IL             49694          33235            89196        0.557\n# ℹ 3,131 more rows\n# ℹ 4 more variables: per_gop_2016 &lt;dbl&gt;, diff_2016 &lt;dbl&gt;, winner &lt;chr&gt;,\n#   partywinner16 &lt;chr&gt;\n\n\nFor bind_cols(), the length has to be the same. Duplicated column names will be changed.\n\nelection_data12 |&gt; bind_cols(election_data16)\n\nNew names:\n• `name` -&gt; `name...1`\n• `state` -&gt; `state...2`\n• `winner` -&gt; `winner...6`\n• `partywinner16` -&gt; `partywinner16...7`\n• `name` -&gt; `name...10`\n• `state` -&gt; `state...11`\n• `winner` -&gt; `winner...18`\n• `partywinner16` -&gt; `partywinner16...19`\n\n\n# A tibble: 3,141 × 19\n   name...1         state...2 per_dem_2012 per_gop_2012 diff_2012 winner...6\n   &lt;chr&gt;            &lt;chr&gt;            &lt;dbl&gt;        &lt;dbl&gt;     &lt;dbl&gt; &lt;chr&gt;     \n 1 Adams County     IL               0.315        0.667     10744 Trump     \n 2 Alexander County IL               0.561        0.425       476 Trump     \n 3 Bond County      IL               0.412        0.559      1075 Trump     \n 4 Boone County     IL               0.463        0.520      1216 Trump     \n 5 Brown County     IL               0.333        0.640       724 Trump     \n 6 Bureau County    IL               0.489        0.491        33 Trump     \n 7 Calhoun County   IL               0.419        0.559       360 Trump     \n 8 Carroll County   IL               0.496        0.482       107 Trump     \n 9 Cass County      IL               0.422        0.557       657 Trump     \n10 Champaign County IL               0.520        0.452      5292 Clinton   \n# ℹ 3,131 more rows\n# ℹ 13 more variables: partywinner16...7 &lt;chr&gt;, winner12 &lt;chr&gt;,\n#   partywinner12 &lt;chr&gt;, name...10 &lt;chr&gt;, state...11 &lt;chr&gt;,\n#   votes_dem_2016 &lt;dbl&gt;, votes_gop_2016 &lt;dbl&gt;, total_votes_2016 &lt;dbl&gt;,\n#   per_dem_2016 &lt;dbl&gt;, per_gop_2016 &lt;dbl&gt;, diff_2016 &lt;dbl&gt;, winner...18 &lt;chr&gt;,\n#   partywinner16...19 &lt;chr&gt;\n\n\n\n\nFurther links\n\nChapter in R4DS\nMore on window functions in the vignette: vignette(\"window-functions\")\nAgain, the cheatsheet\nA tutorial on YouTube\nAnother introduction can be found here.\nThe chapter in R4DS has some nice diagrams.\nYou can also consult the introverse package if you need help with the packages covered here – introverse::show_topics(\"dplyr\") will give you an overview of dplyr’s functions, and get_help(\"name of function\") will help you with the respective function.\n\n\n\nExercises\nOpen the IMDb file.\n\nFind the duplicated movie. How could you go across this?\nWhich director has made the longest movie?\nWhat’s the highest ranked movie?\nWhich movie got the most votes?\nWhich movie had the biggest revenue in 2016?\nHow much revenue did the movies in the data set make each year in total?\nFilter movies following some conditions:\n\nMore runtime than the average runtime (hint: you could also use mutate() before).\nMovies directed by J. J. Abrams.\nMore votes than the median of all of the votes.\nThe movies which have the most common value (the mode) in terms of rating (mode() does exist but will not work in the way you might like it to work – run the script below and use the my_mode function).\n\n\n\n## helper function for mode\n\nmy_mode &lt;- function(x){ \n    ta = table(x)\n    tam = max(ta)\n    if (all(ta == tam))\n         mod = NA\n    else\n         if(is.numeric(x))\n    mod = as.numeric(names(ta)[ta == tam])\n    else\n         mod = names(ta)[ta == tam]\n    return(mod)\n}"
  },
  {
    "objectID": "2_r_catch-up.html#visualization",
    "href": "2_r_catch-up.html#visualization",
    "title": "Chapter 2: Brief R Recap",
    "section": "Visualizations with ggplot2",
    "text": "Visualizations with ggplot2\n\n“The purpose of visualization is insight, not pictures.” – Ben A. Shneiderman\n\nIn R, the dominant package for visualizing data is ggplot2 which belongs to the tidyverse.\n\nThe “layered grammar of graphics”\nggplot2 works with tibbles and the data needs to be in a tidy format. It builds graphics using “the layered grammar of graphics.” (Wickham 2010)\n\npublishers &lt;- read_csv(\"data/publishers_with_places.csv\")\n  \npublishers_filtered &lt;- publishers |&gt; \n  group_by(city) |&gt; \n  filter(n() &gt; 5) |&gt; \n  drop_na()\n\nThis implies that you start with a base layer – the initial ggplot2 call.\n\npublishers_filtered |&gt; \nggplot()\n\n\n\n\n\n\n\n\nThe initial call produces an empty coordinate system. It can be filled with additional layers.\n\nggplot(data = publishers_filtered) +\n  geom_bar(aes(x = city)) \n\n\n\n\n\n\n\n\nUnlike the remainder of the tidyverse, ggplot2 uses a + instead of the pipe |&gt;. If you use the pipe by accident, it will not work and an (informative) error message will appear.\n\n# ggplot(data = publishers_filtered) |&gt; \n#   geom_bar(aes(x = city)) \n\n\n\nThe layers\nIn general, a call looks like this:\nAs you might have seen above, I provided the data in the initial ggplot call. Then, when I added the layer – the geom_bar() for a bar plot – I had to provide the mapping – which variables I wanted to plot – using aes(). This is referred to as the aesthetics. In my case, I wanted the cities to be projected to the x-axis. Since I was using geom_bar to create a bar plot, the number of occurrences of the respective cities were automatically counted and depicted on the y-axis. There are more geom_* functions and they all create different plots. Whether you can use them or not depends on the data you have at hand and/or the number of variables you want to plot. In the following, I will give you a brief overview of the most important geoms.\n\nOne variable\nIf you only want to display one variable, the x- or y-axis, as you choose, will depict the variable’s value. The counterpart will display the frequency or density of those values.\n\nOne variable – discrete\nHere, the only possible kind of visualization is a bar plot as shown above. If the visualization should look more fancy, e.g., with colored bars, you have several arguments at hand. If they should not be different for different kinds of data, they need to be specified outside the aes(). There are always different arguments and you can look them up using ?&lt;GEOM_FUNCTION&gt; and then looking at the Aesthetics section. Apart from that, you can also look at the ggplot2 cheatsheet.\n\nggplot(data = publishers_filtered) +\n  geom_bar(aes(x = city), fill = \"blue\") \n\n\n\n\n\n\n\n\n\n\nOne variable – continuous\nIf you want to display a continuous variable’s distribution of values, you can use a histogram. Its geom_* function is geom_histogram():\n\nbillboard &lt;- read_csv(\"data/billboard.csv\")\n\nRows: 317 Columns: 79\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr   (2): artist, track\ndbl  (65): wk1, wk2, wk3, wk4, wk5, wk6, wk7, wk8, wk9, wk10, wk11, wk12, wk...\nlgl  (11): wk66, wk67, wk68, wk69, wk70, wk71, wk72, wk73, wk74, wk75, wk76\ndate  (1): date.entered\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nsong_tbl &lt;- billboard |&gt; \n  distinct(artist, track) |&gt; \n  mutate(song_id = row_number())\n\nrank_tbl &lt;- billboard |&gt; \n  pivot_longer(cols = starts_with(\"wk\"), \n               names_to = \"week\", \n               names_prefix = \"wk\", \n               values_to = \"rank\") |&gt; \n  mutate(week = as.numeric(week),\n         date = date.entered + (week-1) * 7) |&gt; \n  drop_na() |&gt; \n  left_join(song_tbl, by = c(\"artist\", \"track\")) |&gt; \n  select(song_id, date, week, rank)\n\nHow does the distribution of songs over the weeks look like?\n\nggplot(data = rank_tbl) +\n  geom_histogram(aes(x = week))\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\n\nA smoothed histogram is geom_density():\n\nggplot(data = rank_tbl) +\n  geom_density(aes(x = week))\n\n\n\n\n\n\n\n\n\n\n\nTwo variables\nIn the majority of cases, you will want to display the relationship between two variables, one on the x- and the other one on the y-axis.\n\nBoth continuous\n\ncounty_data_midwest &lt;- socviz::county_data |&gt; \n  filter(census_region == \"Midwest\") |&gt; \n  drop_na()\n\nIf both variables are continuous, the easiest option is to use a scatter plot.\n\nggplot(data = county_data_midwest) +\n  geom_point(aes(x = per_dem_2016, y = per_gop_2016))\n\n\n\n\n\n\n\n\nIf you don’t like dots, the shape = argument allows you to change the shape of the data points. There are also other arguments to change, for instance, transparency (alpha =) or size (size =). Find an overview of the allowed aesthetic specifications here.\n\nggplot(data = county_data_midwest) +\n  geom_point(aes(x = per_dem_2016, y = per_gop_2016), \n             shape = \"cross\", \n             size = 2)\n\n\n\n\n\n\n\n\nHere, it might make sense to color the points according to a categorical variable (state, in this case). If so, a legend is added which maps the colors to their respective values.\n\nggplot(data = county_data_midwest) +\n  geom_point(aes(x = per_dem_2016, y = per_gop_2016)) \n\n\n\n\n\n\n\n\nSince I look at the relationship between votes for the Republicans and the Democrats, and the U.S. is a two-party system, there is a fairly clear relationship between them both. This can also be depicted using geom_smooth():\n\nggplot(data = county_data_midwest) +\n  geom_smooth(aes(x = per_dem_2016, y = per_gop_2016, color = state))\n\n`geom_smooth()` using method = 'loess' and formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\nHere, color = state has a different effect: each dimension of the categorical variable gets its own line.\nIf you do not want it to be smoothed, just use geom_line().\n\nggplot(data = county_data_midwest) +\n  geom_line(aes(x = per_dem_2016, y = per_gop_2016), color = \"grey\") \n\n\n\n\n\n\n\n\n\n\nDiscrete X, continuous Y\nIn this case, different categories of data will be put on the x-axis and some of their properties will be displayed on the y-axis. The probably most prominent example for this type of plot is a box plot:\n\nggplot(data = county_data_midwest) +\n  geom_boxplot(aes(x = state, y = per_gop_2016))\n\n\n\n\n\n\n\n\n\n\nBoth discrete\nIt is rarely the case that you want to depict two categorical variables in one plot. If so, you can use geom_jitter(). It is related to geom_point(). The difference is that with geom_jitter(), a little bit of noise is added to the dots, making them appear distinct.\n\nggplot(data = county_data_midwest) +\n  geom_jitter(aes(x = state, y = winner))\n\n\n\n\n\n\n\n\nAs opposed to:\n\nggplot(data = county_data_midwest) +\n  geom_point(aes(x = state, y = winner))\n\n\n\n\n\n\n\n\n\n\n\n\nMaking graphs “publishable”\nSo far, I have only added one layer to the plot. This suffices for the most basic visualizations. The good thing about R and RMarkdown is, however, that you can write entire publications only using their means. Hence, the plots need to look awesome. This section is dedicated to how you can achieve this. First, I will touch upon how you can make them look good using scales. labs() allow you to add titles, captions, and axis labels. Finally, facet_* allows you to plot multiple plots into one.\n\nScales\nScales can be used to take control of how the data’s values are mapped to the aesthetic’s visual values. You can find a more exhaustive tutorial on them here.\n\nscale_*_continuous – for dealing with continuous values. (you can find an exhaustive list of colors in R here)\n\n\nggplot(data = county_data_midwest) +\n  geom_point(aes(x = per_dem_2016, y = per_gop_2016, color = white)) +\n  scale_x_continuous(limits = c(0, 1)) +\n  scale_y_continuous(limits = c(0, 1)) +\n  scale_color_gradient(low = \"green\",\n                       high = \"red\")\n\n\n\n\n\n\n\n\n\nscale_*_discrete – for dealing with discrete values\nscale_*_manual – manually mapping discrete values to visual values\n\n\nsocviz::county_data |&gt; \n  filter(state %in% c(\"IA\", \"IL\", \"IN\", \"KS\")) |&gt; \n  ggplot() +\n    geom_point(aes(x = per_dem_2016, y = per_gop_2016, color = state)) +\n    scale_color_manual(values = c(\"IA\" = \"blue\", \n                                  \"IL\" = \"green\", \n                                  \"IN\" = \"red\", \n                                  \"KS\" = \"purple\"),\n                       name = \"State\",\n                       labels = c(\"Iowa\", \"Illinois\", \"Indiana\", \"Kansas\")) \n\nWarning: Removed 4 rows containing missing values or values outside the scale range\n(`geom_point()`).\n\n\n\n\n\n\n\n\n\n\n\nAdding titles, captions, etc.\nNow you have modified the scales and colors – there is a lot more to be modified if you want to – but you have not added a meaningful title, a nice caption (where were the data obtained?), and the axes do not have proper names, too. This can be achieved using labs() (which is the abbreviation for labels).\n\nsocviz::county_data |&gt; \n  filter(state %in% c(\"IA\", \"IL\", \"IN\", \"KS\")) |&gt; \n  ggplot() +\n    geom_point(aes(x = per_dem_2016, y = per_gop_2016, color = state)) +\n    scale_color_manual(values = c(\"IA\" = \"blue\", \n                                  \"IL\" = \"green\", \n                                  \"IN\" = \"red\", \n                                  \"KS\" = \"purple\"),\n                       name = \"State\",\n                       breaks = waiver(),\n                       labels = c(\"Iowa\", \"Illinois\", \"Indiana\", \"Kansas\")) +\n    scale_x_continuous(limits = c(0, 1)) +\n    scale_y_continuous(limits = c(0, 1)) +\n    ggtitle(\"Relationship between percentages of votes for Democrats and Republicans in selected states in the Midwest\") +\n    xlab(\"Percentage of votes for the Democrats in 2016\") +\n    ylab(\"Percentage of votes for the Republicans in 2016\") \n\nWarning: Removed 4 rows containing missing values or values outside the scale range\n(`geom_point()`).\n\n\n\n\n\n\n\n\n\nWell, that doesn’t look good, the title is too long. Inserting \\n – for new line – will do the trick.\n\nsocviz::county_data |&gt; \n  filter(state %in% c(\"IA\", \"IL\", \"IN\", \"KS\")) |&gt; \n  ggplot() +\n    geom_point(aes(x = per_dem_2016, y = per_gop_2016, color = state)) +\n    scale_color_manual(values = c(\"IA\" = \"blue\", \"IL\" = \"green\", \"IN\" = \"red\", \"KS\" = \"purple\"),\n                      name = \"State\",\n                      breaks = waiver(),\n                      labels = c(\"Iowa\", \"Illinois\", \"Indiana\", \"Kansas\")) +\n    scale_x_continuous(limits = c(0, 1)) +\n    scale_y_continuous(limits = c(0, 1)) +\n    ggtitle(\"Relationship between percentages of votes for Democrats \\nand Republicans in selected states in the Midwest\") +\n    xlab(\"Percentage of votes for the Democrats in 2016\") +\n    ylab(\"Percentage of votes for the Republicans in 2016\") \n\nWarning: Removed 4 rows containing missing values or values outside the scale range\n(`geom_point()`).\n\n\n\n\n\n\n\n\n\nHowever, providing it with three different layers just for labeling is pretty tedious. This is where labs() comes in handy.\n\nsocviz::county_data |&gt; \n  filter(state %in% c(\"IA\", \"IL\", \"IN\", \"KS\")) |&gt; \n  ggplot() +\n    geom_point(aes(x = per_dem_2016, y = per_gop_2016, color = state)) +\n    scale_color_manual(values = c(\"IA\" = \"blue\", \"IL\" = \"green\", \"IN\" = \"red\", \"KS\" = \"purple\"),\n                      name = \"State\",\n                      breaks = waiver(),\n                      labels = c(\"Iowa\", \"Illinois\", \"Indiana\", \"Kansas\")) +\n    scale_x_continuous(limits = c(0, 1)) +\n    scale_y_continuous(limits = c(0, 1)) +\n    labs(title = \"Relationship between percentages of votes for Democrats \\nand Republicans in selected states in the Midwest\",\n         caption = \"Data obtained from the socviz R package\",\n         x = \"Percentage of votes for the Democrats in 2016\",\n         y = \"Percentage of votes for the Republicans in 2016\") \n\nWarning: Removed 4 rows containing missing values or values outside the scale range\n(`geom_point()`).\n\n\n\n\n\n\n\n\n\n\n\nFacets\nThe original data set consists of four different census regions. If I were to compare them, I could color them accordingly.\n\nsocviz::county_data |&gt; \n  drop_na() |&gt; \n  ggplot() +\n    geom_point(aes(x = per_dem_2016, y = per_gop_2016, color = census_region)) +\n    scale_x_continuous(limits = c(0, 1)) +\n    scale_y_continuous(limits = c(0, 1)) +\n    scale_color_discrete()\n\n\n\n\n\n\n\n\nDespite the coloring according to the different states, it is still hard to assess whether there really are differences. Apart from that, I would like to assess the impact the percentage of white people in the population has. This would be easier if I put them into individual graphs. I can achieve this using so-called facets. Facets enable me to divide the plot into subplots based on categorical variables. facet_wrap() puts them into a rectangular layout. The categorical variable needs to be provided prefixed with a tilde ~, nrow determines the number of rows.\n\nsocviz::county_data |&gt; \n  drop_na() |&gt; \n  ggplot() +\n    geom_point(aes(x = per_dem_2016, y = per_gop_2016, color = white)) +\n    scale_x_continuous(limits = c(0, 1)) +\n    scale_y_continuous(limits = c(0, 1)) +\n    scale_color_gradient(low = \"green\",\n                         high = \"red\") +\n    facet_wrap(vars(census_region),\n               nrow = 2)\n\n\n\n\n\n\n\n\nApart from that, I can also spread it out using two different variables. Here, I will look at differences in the distribution of whites in the counties split up by who won in 2016 and 2012. This can be achieved using facet_grid(categorical_variable_1~categorical_variable_2). The former one will be put into rows, the latter into columns.\n\nsocviz::county_data |&gt; \n  drop_na() |&gt; \n  ggplot() +\n    geom_point(aes(x = per_dem_2016, y = per_gop_2016, color = white)) +\n    scale_x_continuous(limits = c(0, 1)) +\n    scale_y_continuous(limits = c(0, 1)) +\n    scale_color_gradient(low = \"green\",\n                         high = \"red\") +\n    facet_grid(winner~winner12)\n\n\n\n\n\n\n\n\nIf you want to facet using only one variable, put a dot at where the other variable would stand otherwise…\n\nsocviz::county_data |&gt; \n  drop_na() |&gt; \n  ggplot() +\n    geom_point(aes(x = per_dem_2016, y = per_gop_2016, color = white)) +\n    scale_x_continuous(limits = c(0, 1)) +\n    scale_y_continuous(limits = c(0, 1)) +\n    scale_color_gradient(low = \"green\",\n                         high = \"red\") +\n    facet_grid(.~winner)\n\n\n\n\n\n\n\n\n… or just use facet_wrap().\n\n\n\nExporting graphics\nIf you include the graphics in an RMarkdown document, make sure you use the proper chunk options (i.e., {r echo=FALSE, message=FALSE, warning=FALSE}).\nIf you, however, want to export it and put it into an MS Word document or so, you can just use the ggsave() function. By default, it just takes the last plot that has been created and saves it to a path that needs to be specified. If it contains a file extension, ggsave() just uses this one.\n\nggplot(mtcars, aes(mpg, wt)) +\n  geom_point()\n\nggsave(\"mtcars.pdf\", device = \"pdf\") #save it to pdf\nggsave(\"mtcars.png\") #save it to png\n\nggsave(\"mtcars.pdf\", width = 4, height = 4) #specify width and height -- in inches by default\nggsave(\"mtcars.pdf\", width = 20, height = 20, units = \"cm\") #change unit using the units argument\n\n\n\nFurther readings\n\nggplot2 cheatsheet.\nggplot2 – the book.\nThe graphic cookbook for R.\nAnother tutorial.\nA full-on online course by Kieran Healy (comes with an R package as well).\nNeed some inspiration? Check out the graph gallery.\nThe ggsave() function in further detail.\nYou can also consult the introverse package. introverse::show_topics(\"ggplot2\") will give you overviews of the respective package’s functions, and get_help(\"name of function\") will help you with the respective function.\n\n\n\nExercises\nUse the IMDb file.\nTry to think about how you could answer the following questions graphically. If you fail, take a look at the hints.\n\nDo higher rated movies generate more revenue?\n\nPlot revenue and rating as a scatter plot.\nDo you think there is a correlation? How could you make stronger claims about it? Maybe even graphically?\nInterpret the plot.\nAdd a nice title and labels.\n\nHow evenly are the different years’ movies represented? (Why would it be pointless to make claims about the productivity of directors?)\n\nMake a bar plot.\nInterpret the plot.\nAdd a nice title and labels.\n\nWhich year was the best for cinema fetishists? (When could they watch the most highest rated movies?)\n\nMake a box plot.\nInterpret the plot.\nAdd a nice title and labels."
  },
  {
    "objectID": "2_r_catch-up.html#iteration",
    "href": "2_r_catch-up.html#iteration",
    "title": "Chapter 2: Brief R Recap",
    "section": "Iteration",
    "text": "Iteration\nWe also will work with lists. Lists can contain elements of different lengths (which distinguishes them from tibbles). This makes them especially suitable for web scraping. Other than (atomic) vectors they are not just vectorized since they can contain elements of all different kinds of format.\nTo iterate over lists, we have the map() family from the purrr package, which applies functions over lists. pluck() extracts elements from the list.\n\nraw_list &lt;- list(first_element = 1:4, 4:6, 10:42)\nstr(raw_list) # shows you the elements of the list\n\nList of 3\n $ first_element: int [1:4] 1 2 3 4\n $              : int [1:3] 4 5 6\n $              : int [1:33] 10 11 12 13 14 15 16 17 18 19 ...\n\nmap(raw_list, mean)\n\n$first_element\n[1] 2.5\n\n[[2]]\n[1] 5\n\n[[3]]\n[1] 26\n\nmap(raw_list, ~{mean(.x) |&gt; sqrt()})\n\n$first_element\n[1] 1.581139\n\n[[2]]\n[1] 2.236068\n\n[[3]]\n[1] 5.09902\n\nmap_dbl(raw_list, mean) # by specifying the type of output, you can reduce the list\n\nfirst_element                             \n          2.5           5.0          26.0 \n\nraw_list |&gt; pluck(1) == raw_list |&gt; pluck(\"first_element\")\n\n[1] TRUE TRUE TRUE TRUE\n\n\nThis can also be achieved using a loop. Here, you use an index to loop over objects and do something to their elements. Typically, you create an empty list before and put the new output at the respective new position.\n\nnew_list &lt;- vector(mode = \"list\", length = length(raw_list))\nfor (i in seq_along(raw_list)){\n  new_list[[i]] &lt;- mean(raw_list[[i]])\n}"
  },
  {
    "objectID": "2_r_catch-up.html#functionalprogramming",
    "href": "2_r_catch-up.html#functionalprogramming",
    "title": "Chapter 2: Brief R Recap",
    "section": "Flow Control, Functional programming, and iterations",
    "text": "Flow Control, Functional programming, and iterations\nSo far, you have learned heaps of data wrangling and analyses, but no real customization of R. This will change now, as you will be introduced to functions. Furthermore, the operations have only been applied to one singular object (read vector or data.frame/tibble). Iteration means that you perform the same operation on multiple objects/data sets/you name it.\nToday’s session will all be about following the DRY principle. DRY stands for Don’t Repeat Yourself.\n“Why not?,” you may ask. Well, the problem with copy-and-pasting code is that you have to change all the variable names in every instance of your code. RStudio has a nice Search-and-Replace function which might facilitate that, but this practice still bears the danger of writing code that contains errors. This is where you will need to make use of the tools that R offers to iterate over a couple of elements, perform operations on them, and return the results. An example:\n\nexample_strings &lt;- c(\"this\", \"is\", \"how\", \"a\", \"for\", \"loop\", \"works\")\n\nfor (i in seq_along(example_strings)) {\n  print(example_strings[[i]])\n}\n\n[1] \"this\"\n[1] \"is\"\n[1] \"how\"\n[1] \"a\"\n[1] \"for\"\n[1] \"loop\"\n[1] \"works\"\n\n\nAnother option – from the tidyverse – is the purrr package:\n\nwalk(example_strings, print)\n\n[1] \"this\"\n[1] \"is\"\n[1] \"how\"\n[1] \"a\"\n[1] \"for\"\n[1] \"loop\"\n[1] \"works\"\n\n\nSo, what has this code done? In both cases, it has taken the function print() and applied it to every element of our vector. Copying-and-pasting would have looked like this:\n\nprint(example_strings[[1]])\n\n[1] \"this\"\n\nprint(example_strings[[2]])\n\n[1] \"is\"\n\nprint(example_strings[[3]])\n\n[1] \"how\"\n\nprint(example_strings[[4]])\n\n[1] \"a\"\n\nprint(example_strings[[5]])\n\n[1] \"for\"\n\nprint(example_strings[[6]])\n\n[1] \"loop\"\n\nprint(example_strings[[7]])\n\n[1] \"works\"\n\nprint(example_strings[[7]])\n\n[1] \"works\"\n\n\nDamn, I pasted the last instance twice. In this case, the mistake is obvious, but oftentimes it is not.\nIn the following, I will provide you a more extensive introduction into conditional statements, functions, loops, and the purrr (and it’s parallelized counter-part furrr) package.\n\nFlow control\nSometimes you want your code to only run in specific cases. For mutate(), I have already showed you conditional imputation of values with case_when(). A more generalized approach for conditionally running code in R are if statements. They look as follows:\n\nif (conditional_statement evaluates to TRUE) {\n  do_something\n}\n\nThey also have an extension – if…else:\n\nif (conditional_statement evaluates to TRUE) {\n  do_something\n} else {\n  do_something_else\n}\n\nImagine that I want R to tell me whether a number it draws is smaller than or equal to five:\n\nset.seed(1234)\nx &lt;- sample(10, 1)\n\nif (x &lt;= 5) {\n  print(\"x is smaller than or equals 5\")\n} \n\nIn this case, x is 3, so the if statement returns something. If this is not the case, nothing happens:\n\nset.seed(12345)\nx &lt;- sample(10, 1)\n\nif (x &lt;= 5) {\n  print(\"x is smaller than or equals 5\")\n}\n\n[1] \"x is smaller than or equals 5\"\n\n\nNow I could extend it by another if statement:\n\nset.seed(1234)\n\nx &lt;- sample(10, 1)\n\nif (x &lt;= 5) {\n  print(\"x is smaller than or equals 5\")\n}\nif (x &gt; 5) {\n  print(\"x is greater than 5\")\n}\n\n[1] \"x is greater than 5\"\n\n\nHere, x is 10, so only the second if statement returns something.\nBut the else allows me to take a shortcut and write it more concisely:\n\nif (x &lt;= 5) {\n  print(\"x is smaller than or equals 5\")\n} else {\n  print(\"x is greater than 5\")\n}\n\n[1] \"x is greater than 5\"\n\n\nPlease note that the condition inside the if statement needs to be a vector of type logical (hence, either TRUE or FALSE). Apart from that, only vectors of length 1 are allowed. The following will not work:\n\nif (c(TRUE, FALSE, TRUE)) {\n  print(\"example\")\n} #This will throw an error!!!\n\n\n\nFunctions\nSo far, every call you have made within R contained a function. Even the most basic operations, such as c() for building vectors, rely on functions. Functions are the verbs of R, they do something to your objects. Hence, you as someone who obeys the principles of DRY can make good use of them. Whenever you need to copy code to perform certain tasks to an object, you can also put those tasks into a function and just provide the function with the objects.\nImagine you want to rescale some variables in a tibble (an example I took from the OG version of R4DS (Wickham and Grolemund 2016)):\n\nset.seed(1234)\n\ndf &lt;- tibble(\n  a = rnorm(10),\n  b = rnorm(10),\n  c = rnorm(10),\n  d = rnorm(10)\n)\n\ndf$a &lt;- (df$a - min(df$a, na.rm = TRUE)) / \n  (max(df$a, na.rm = TRUE) - min(df$a, na.rm = TRUE))\ndf$b &lt;- (df$b - min(df$b, na.rm = TRUE)) / \n  (max(df$b, na.rm = TRUE) - min(df$b, na.rm = TRUE))\ndf$c &lt;- (df$c - min(df$c, na.rm = TRUE)) / \n  (max(df$c, na.rm = TRUE) - min(df$c, na.rm = TRUE))\ndf$d &lt;- (df$d - min(df$d, na.rm = TRUE)) / \n  (max(df$d, na.rm = TRUE) - min(df$d, na.rm = TRUE))\n\nGiven that you now know how to loop over the tibble, you can certainly reduce the amount of copy-pasting here.\n\ndf &lt;- tibble(\n  a = rnorm(10),\n  b = rnorm(10),\n  c = rnorm(10),\n  d = rnorm(10)\n)\n\nfor (i in seq_along(df)) {\n  df[[i]] &lt;- (df[[i]] - min(df[[i]], na.rm = TRUE)) / \n  (max(df[[i]], na.rm = TRUE) - min(df[[i]], na.rm = TRUE))\n}\n\nHowever, the operation within the loop is generalizable: it always only takes a vector of numeric values as input, performs some actions on them and returns another vector of the same length, but rescaled into a range from 0 to 1. Hence, the operation fulfills the requirements for putting it into a function.\nDoing so has some advantages:\n\nIf an error occurs, you can simply change the function in one place – when you define it – instead of changing all the occurrences in your code\nIt will certainly make your code easier to read – rescale0to1 is a more concise description than (x - min(x, na.rm = TRUE)) / (max(x, na.rm = TRUE) - min(x, na.rm = TRUE)) (–&gt; you see what I did here? I already replaced the arguments with a generic variable. You can use it to write the function yourself.)\n\n\nWriting your own functions\nWhen you define functions in R, you need to follow a certain structure:\n\nfunction_name &lt;- function(argument_1, argument_2, argument_n) {\n  function_body\n}\n\n\nThe function_name is the thing you will call (e.g., mean()). In general, it should be a verb, it should be concise, and it should be in_snakecase.\nThe arguments are what you need to provide the function with (e.g., mean(1:10)).\nThe function body contains the operations which are performed to the arguments. It can contain other functions as well – which need to be defined beforehand (e.g., sum(1:10) / length(1:10))). It is advisable to split up the function body into as little pieces as you can.\n\n\n\nAn example: Roulette\nIn the following, I will guide you through a quick example on how you could use functions to play an extremely basic game of Roulette with R. You provide it with two values (how much you bet and which number you choose) and R takes care of the rest.\nSo what does the function need to do? First, it needs to draw a number between 0 and 36. Second, it needs to compare the bet and its corresponding number. Third, it needs to return the respective result.\n\nplay_roulette &lt;- function(bet, number) {\n  draw &lt;- sample(0:36, 1)\n  tibble(\n    winning_number = draw,\n    your_number = number,\n    your_bet = bet,\n    your_return = if (number == draw) {\n      bet * 36\n    } else {\n      0\n    }\n  )\n}\n\nplay_roulette(bet = 1, number = 35)\n\n# A tibble: 1 × 4\n  winning_number your_number your_bet your_return\n           &lt;int&gt;       &lt;dbl&gt;    &lt;dbl&gt;       &lt;dbl&gt;\n1             15          35        1           0\n\n\nBut how to make sure that I do not bet on a number which I cannot bet on (i.e., numbers greater than 36)? Or, put differently, how to forbid values? Use stop(). Besides, how to set default values for the arguments? Just use argument = default.\n\nplay_roulette_restricted &lt;- function(bet = 1, number) {\n  if (number &gt; 36) stop(\"You can only bet on numbers between 0 and 36.\")\n  draw &lt;- sample(0:36, 1)\n  tibble(\n    winning_number = draw,\n    your_number = number,\n    your_bet = bet,\n    your_return = if (number == draw) {\n      bet * 36\n    } else {\n      0\n    }\n  )\n  #return(tbl_return)\n}\nplay_roulette_restricted(number = 3)\n\n# A tibble: 1 × 4\n  winning_number your_number your_bet your_return\n           &lt;int&gt;       &lt;dbl&gt;    &lt;dbl&gt;       &lt;dbl&gt;\n1              1           3        1           0\n\n\nThe function returns the results of the last call, i.e., the tibble. If you want to be more concrete about what it should return – or make an earlier return – use return(). The function will stop as soon as it hits a return() statement.\n\nplay_roulette_basic &lt;- function(bet = 1, number) {\n  if (number &gt; 36) stop(\"You can only bet on numbers between 0 and 36.\")\n  draw &lt;- sample(0:36, 1)\n  if (number == draw) {\n    return(str_c(\"Nice, you won\", as.character(bet * 36), \"Dollars\", sep = \" \"))\n  } else {\n    return(\"I'm sorry, you lost.\")\n  }\n}\nplay_roulette_basic(number = 35)\n\n[1] \"I'm sorry, you lost.\"\n\n\n\n\nFunctional programming with tidyverse functions\nThe majority of dplyr verbs uses so-called tidy evaluation which is a framework for controlling how expressions and variables in your code are evaluated by the tidyverse functions. The two main things here are data masking and tidy selection. The former facilitates computing on values within the data set and refers to functions such as filter(), where you can just type in variable names instead of tediously typing name_of_df$var_name. The latter aims to facilitate working with the columns in the data set. It is provided by the tidyselect package and allows you, for instance, to work with code such as tbl |&gt; select(starts_with(\"a\")). More examples can be acquired using ?dplyr_tidy_select.\nI will not go into detail here but rather stick to what implications this has to you. If you are interested in the theoretical underpinnings, read the chapter on “Metaprogramming” in Advanced R by Hadley Wickham.\nIf your function takes a user-supplied variable as an argument, you need to consider this arguments in the pipeline. For instance, the following function calculates the mean, median, and standard deviation of a variable.\n\nmy_summary &lt;- function(tbl, var) {\n  tbl |&gt; \n    summarize(\n      mean = mean({{ var }}),\n      median = median({{ var }}),\n      sd = sd({{ var }})\n    )\n}\n\nmtcars |&gt; my_summary(cyl) \n\n    mean median       sd\n1 6.1875      6 1.785922\n\n\nIf the variable names are supplied in a character vector, you need all_of():\n\nsummarize_mean &lt;- function(data, vars) {\n  data |&gt; summarize(n = n(), across({{ vars }}, mean))\n}\n\nmtcars |&gt; \n  group_by(cyl) |&gt; \n  summarize_mean(all_of(c(\"hp\", \"mpg\"))) |&gt; \n  glimpse()\n\nRows: 3\nColumns: 4\n$ cyl &lt;dbl&gt; 4, 6, 8\n$ n   &lt;int&gt; 11, 7, 14\n$ hp  &lt;dbl&gt; 82.63636, 122.28571, 209.21429\n$ mpg &lt;dbl&gt; 26.66364, 19.74286, 15.10000\n\n\nAnother handy thing is changing the variable names in the output depending on the input names. Here, you can use glue syntax and :=:\n\nmy_summary_w_names &lt;- function(tbl, var){\n  tbl |&gt; \n    summarize(\n      \"mean_{{ var }}\" := mean({{ var }}),\n      \"median_{{ var }}\" := median({{ var }}),\n      \"sd_{{ var }}\" := sd({{ var }})\n    )\n}\n\nmtcars |&gt; my_summary_w_names(cyl)\n\n  mean_cyl median_cyl   sd_cyl\n1   6.1875          6 1.785922\n\n\nFind more on programming with dplyr in this vignette.\n\n\nFurther readings\nIf you want to learn more about functional programming, check out the following resources:\n\nThe R4DS chapter\nA basic tutorial\nA book chapter about control-flow and functions\nHadley on functional programming\n\n\n\n\nIteration\nStrictly speaking, there are three kinds of loops: for, repeat, and while. I will touch upon for and while, because they are more straight-forward than repeat. repeat loops will repeat a task until you tell it to stop by hitting the escape button or adding a condition up front. Interactive programming – sitting in front of your machine and hitting the escape button to break a loop – is no desired practice and while loops have internalized the condition already. Hence, repeat loops do not appear to have any advantage and I leave them out deliberately.\n\nfor loops\nfor loops are the sort of loops you will have to work with more often as they allow you to loop over a predefined number of elements. For this sake, I will briefly revise how you index vectors, lists, and tibbles.\nThe ith element of a vector can be accessed by using either [[i]] or [i].\nThe ith element of a list can be obtained by using [[i]] – [i] would return a sub-list instead of the element. The second element of the ith element in a list (if it were a vector or a list) can be obtained using [[i]][[2]] etc.\nThe ith column of a tibble can be accessed as a vector using [[i]]. The second value of the ith column of a tibble can be accessed using [[i]][[2]]\nHow does that matter for for loops? Remember the example I showed you in the beginning? All a for loop does is iterating over a vector of values and imputing them instead of a placeholder.\n\nexample_strings &lt;- c(\"this\", \"is\", \"how\", \"a\", \"for\", \"loop\", \"works\")\n\nfor (i in example_strings) {\n  print(i)\n}\n\n[1] \"this\"\n[1] \"is\"\n[1] \"how\"\n[1] \"a\"\n[1] \"for\"\n[1] \"loop\"\n[1] \"works\"\n\n\nFor a more general approach, you can also loop over the indices of the vector using seq_along() which creates a sequence along a vector.\n\nseq_along(example_strings) # seq_along looks like this\n\n[1] 1 2 3 4 5 6 7\n\n\nThis is especially useful if you want to modify the elements of a vector or a tibble.\n\nfor (i in seq_along(example_strings)) {\n  print(example_strings[[i]])\n}\n\n[1] \"this\"\n[1] \"is\"\n[1] \"how\"\n[1] \"a\"\n[1] \"for\"\n[1] \"loop\"\n[1] \"works\"\n\n#Hence, the first iteration looks like this.\nprint(example_strings[[seq_along(example_strings)[[1]]]])\n\n[1] \"this\"\n\n# translates to\nprint(example_strings[[1]])\n\n[1] \"this\"\n\n\nNow that you have seen the general approach for using a for loop, how can you use them in practice for data manipulation? Whenever you use a for loop, you need to follow a three step approach:\n\nOutput: In the beginning, you need to create a vector that we can fill with output. You also need to determine the length of the vector in the beginning. This is due to efficiency: if you were to grow the vector by every iteration (using c), the loop becomes very slow. This is especially important if you work with large data sets. An example for creating an empty vector of a certain length is output &lt;- vector(mode = \"numeric\", length = length_of_output).\nSequence: i in seq_along(variable) tells the for loop what to loop over.\n\nBody: The actual code. Performs the operation on the respective instance and stores the resulting value in the pre-defined output vector at position i.\n\nfor loops are considered slow. They are not, at least not if you stick to the following rules:\n\nAlways pre-allocate space – make sure that R does not have to expand your objects\nDo as much as you can outside the loop – every operation inside the loop will be repeated every time the loop is repeated\n\nIn general, you will come across three different problems with for loops.\n\nModifying an existing object\nLength of output is unknown\nSequences are of unknown length\n\n\nModifying the existing object\nSometimes you want to modify an existing object rather than creating a new one. This is useful when working with large datasets or when you need to update values in place.\nBasic example: Standardizing columns Let’s say you have a dataset with test scores that you want to standardize (mean = 0, sd = 1):\n\nscores &lt;- tibble(\n  student_id = 1:5,\n  math = c(85, 92, 78, 88, 95),\n  science = c(90, 85, 80, 92, 88),\n  english = c(88, 90, 85, 86, 92)\n)\n\nfor (col in c(\"math\", \"science\", \"english\")) {\n  scores[[col]] &lt;- (scores[[col]] - mean(scores[[col]])) / sd(scores[[col]])\n}\n\nscores |&gt; \n  summarize(across(c(math, science, english), \n                   list(mean = mean, sd = sd)))\n\n# A tibble: 1 × 6\n  math_mean math_sd science_mean science_sd english_mean english_sd\n      &lt;dbl&gt;   &lt;dbl&gt;        &lt;dbl&gt;      &lt;dbl&gt;        &lt;dbl&gt;      &lt;dbl&gt;\n1  8.88e-16       1     7.22e-17          1    -9.77e-16          1\n\n\n\n\nLength of output is unknown\nSometimes, you do not know how long your output object is. This is, for instance, if you simulate vectors of random length. Normally, you would just put the values into a vector. However, if you do not know the length, then you would have to ask R to grow the vector every iteration. But this is extremely inefficient.\nFor this, the solution is lists. You always know how many iterations your loop will have. Hence, you can create a list of this exact length and then just store the results in the list (as lists do not care about the length of the singular elements). Afterwards, you can unlist() or flatten_*() the list into a vector.\n\na_list &lt;- vector(mode = \"list\", length = 10L)\n\nfor (i in seq_along(a_list)) {\n  len &lt;- sample(1:10, 1)\n  a_list[[i]] &lt;- rnorm(len)\n}\n\na_list |&gt; \n  unlist() # or unlist(a_list)\n\n [1]  0.69760871  0.54999735 -0.40273198 -0.19159377 -1.19452788 -0.05315882\n [7] -1.43192024 -2.01016571  0.33832922  0.65128696  2.43315152  1.19133821\n[13]  0.92244282  0.62109737  0.35633348 -0.47471847  0.06599349 -0.50247778\n[19]  2.18711916 -0.58172745  0.70008023  1.49217658 -0.05210512 -0.19593462\n[25] -0.64906975 -1.10976723  0.84927420 -0.01394090  0.16863694  0.86926335\n[31] -0.79866986 -0.50375053  2.31559832 -0.69220912  0.49335047 -0.05760147\n[37]  1.82420830  0.08005964 -0.63140930 -1.51328812 -0.63609983  0.22630153\n[43]  1.01369035 -1.17194831  0.66871433 -1.65010093 -0.36585225 -0.31611833\n[49] -1.94824605  0.92005752 -0.62287159 -0.17827861  0.78695133 -0.58054783\n[55]  0.91825114\n\n\nIf we wanted to add the information in a tibble, we could add it during the run and use bind_rows() afterwards.\n\na_list &lt;- vector(mode = \"list\", length = 10L)\n\nfor (i in seq_along(a_list)) {\n  len &lt;- sample(1:10, 1)\n  a_list[[i]] &lt;- list(\n    run = i,\n    values = rnorm(len)\n  )\n}\n\ndf &lt;- a_list |&gt; \n  bind_rows()\n\ndf\n\n# A tibble: 55 × 2\n     run  values\n   &lt;int&gt;   &lt;dbl&gt;\n 1     1  0.700 \n 2     1 -1.20  \n 3     1 -0.499 \n 4     2  0.0976\n 5     3 -0.119 \n 6     3  2.39  \n 7     3  0.735 \n 8     3  0.474 \n 9     3 -0.234 \n10     3 -0.854 \n# ℹ 45 more rows\n\n\n\n\nUnknown sequence length\nSometimes, you also do not know how long your input sequence is. Instead, you want to loop until a certain condition is met. This is for instance the case when looping across multiple pages in web-scraping. Here, while loops come in handy (but this is the only use case I could think of).\nThe basic structure of while loops is as follows:\n\nwhile (condition) {\n  code\n}\n\nWhat could an example look like?4 The following loop keeps running until three heads appeared in a row and the condition is met.\nPlease note that both vectors which are to be modified within the loop – indicator and head – need to be created beforehand. If I had not created head beforehand, the loop would not have started because there would not have been any vector to assess the length.\n\nindicator &lt;- 0\nhead &lt;- c()\nwhile (length(head) &lt; 3) {\n  if (sample(2, 1) == 1) {\n    x &lt;- \"head\"\n  } else {\n    x &lt;- \"tail\"\n  }\n  if (x == \"head\") {\n    head &lt;- c(head, 1)\n  } else {\n    length(head) &lt;- 0\n  }\n  indicator &lt;- indicator + 1\n}\n\nIn this case, you still want to pre-allocate space. Hence, you could also use a list here. You can just do a very long list and afterwards cut it down to size using purrr::compact().\n\nindicator &lt;- 0\nvalues &lt;- vector(mode = \"list\", length = 1000)\nhead &lt;- c()\nwhile (length(head) &lt; 3) {\n  if (sample(2, 1) == 1) {\n    x &lt;- \"head\"\n  } else {\n    x &lt;- \"tail\"\n  }\n  if (x == \"head\") {\n    head &lt;- c(head, 1)\n  } else {\n    length(head) &lt;- 0\n  }\n  values[[indicator + 1]] &lt;- x\n  indicator &lt;- indicator + 1\n}\n\nlength(values)\n\n[1] 1000\n\nvalues |&gt; tail(5) #last 5 values\n\n[[1]]\nNULL\n\n[[2]]\nNULL\n\n[[3]]\nNULL\n\n[[4]]\nNULL\n\n[[5]]\nNULL\n\nvalues |&gt; compact() #removes all NULL elements\n\n[[1]]\n[1] \"tail\"\n\n[[2]]\n[1] \"head\"\n\n[[3]]\n[1] \"head\"\n\n[[4]]\n[1] \"tail\"\n\n[[5]]\n[1] \"head\"\n\n[[6]]\n[1] \"head\"\n\n[[7]]\n[1] \"head\"\n\n\n\n\n\npurrr::map()\nLoops are good because they make everything very explicit. However, it is often tedious to type. The purrr package provides functions which enable you to iterate over vectors, data frames/tibbles, and lists. Apart from that, it has a lot of functions to work with lists as well. I will only cover the former functions. If you are interested in using purrr for working with lists, check out this extensive tutorial by Jenny Bryan.\nIn the beginning of this chapter, I used the walk() function. This function is related to map() as it iterates over a vector and applies a function to its respective elements. The difference is that walk() doesn’t store the results, map() does.\n\nThe basics\nThe structure of the map() function looks like this:\n\nmap(vector or list, function(, if you need it, additional arguments of function))\n\nmap() always returns a list.\nIf you want the output to be in a different format, there are different, type-specific map() functions.\n\nmap_dfr() returns a data frame – by binding the rows\nmap_dfc() returns a data frame – by binding the columns\nmap_dbl() returns a double vector\nmap_chr() returns a character vector\nmap_lgl() returns a logical vector\n\nIn the following I will demonstrate the function of map() with a simple example. The basic vector I will map over is:\n\nexample_dbl &lt;- c(1.5, 1.3, 1.8, 1.9, 2.3)\n\nIn the first example, I just add 10 to the vector. In order to do so, I first need to create a function which adds 10.\n\nadd_10 &lt;- function(x) {\n  x + 10\n}\n\n\nmap(example_dbl, add_10)\n\n[[1]]\n[1] 11.5\n\n[[2]]\n[1] 11.3\n\n[[3]]\n[1] 11.8\n\n[[4]]\n[1] 11.9\n\n[[5]]\n[1] 12.3\n\n\n\nmap_dbl(example_dbl, add_10)\n\n[1] 11.5 11.3 11.8 11.9 12.3\n\n\n\nmap_chr(example_dbl, add_10) # does not make sense though\n\nWarning: Automatic coercion from double to character was deprecated in purrr 1.0.0.\nℹ Please use an explicit call to `as.character()` within `map_chr()` instead.\n\n\n[1] \"11.500000\" \"11.300000\" \"11.800000\" \"11.900000\" \"12.300000\"\n\n\n\n\nAnonymous functions\nIn the former example, I did specify the function beforehand. map() also allows you to define the function within the call using a so-called anonymous function \\(x). The function’s argument is pre-defined (x in this case, but could be any placeholder) which stands for the respective input.\n\nmap_dbl(example_dbl, \\(x){\n  x + 10\n  })\n\n[1] 11.5 11.3 11.8 11.9 12.3\n\n\nYou can also map across tibbles. Here, you iterate over columns. For instance, calculating a mean for each column of the cars_tbl would have looked like this in purrr:\n\ncars_tbl &lt;- mtcars\nmap(cars_tbl, mean)\n\n$mpg\n[1] 20.09062\n\n$cyl\n[1] 6.1875\n\n$disp\n[1] 230.7219\n\n$hp\n[1] 146.6875\n\n$drat\n[1] 3.596563\n\n$wt\n[1] 3.21725\n\n$qsec\n[1] 17.84875\n\n$vs\n[1] 0.4375\n\n$am\n[1] 0.40625\n\n$gear\n[1] 3.6875\n\n$carb\n[1] 2.8125\n\n\nWhen I put it into a tibble, names are preserved:\n\nmap_dfc(cars_tbl, mean)\n\n# A tibble: 1 × 11\n    mpg   cyl  disp    hp  drat    wt  qsec    vs    am  gear  carb\n  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1  20.1  6.19  231.  147.  3.60  3.22  17.8 0.438 0.406  3.69  2.81\n\n\n\n\nMapping over multiple arguments\nSometimes you want to apply things to multiple arguments. Think for example of the sample()function. It requires at least two arguments: the size of the sample you draw and the element space x you draw the sample from.\n\nmap2(10, 1:5, sample, replace = TRUE)\n\n[[1]]\n[1] 4\n\n[[2]]\n[1]  1 10\n\n[[3]]\n[1]  7  6 10\n\n[[4]]\n[1] 1 6 6 6\n\n[[5]]\n[1] 7 5 5 5 6\n\n\nHowever, the map2() functions do not provide you with the possibility to control the type of output you get. You can take care of this using flatten_*().\n\nmap2(10, 5, sample) |&gt; flatten_dbl()\n\n[1] 6 4 8 3 2\n\n\nIf you provide it with a vector which is longer than 1, map2() will not perform the operation on every possible combination of the two vectors. Instead, it iterates over both vectors simultaneously, hence, the first iteration uses the first two values, the second iteration the second two values etc. Also note that it matches the arguments by position, not by name, hence the second argument is the size of the sample, the first one the element space.\n\nmap2(c(10, 5), c(5, 3), sample) \n\n[[1]]\n[1]  7  8  4  5 10\n\n[[2]]\n[1] 1 3 5\n\n\nIf you want to use an anonymous function, you can do so as well:\n\nmap2(c(10, 5), c(5, 3), \\(x, y) sample(x, size = y))\n\n[[1]]\n[1] 4 8 6 7 2\n\n[[2]]\n[1] 5 1 3\n\n\nIf you want to map over more than two arguments, pmap() is the way to go. If you work with functions which need multiple values as arguments, you can store the vectors containing the respective values in a tibble. You should name the columns according to the function’s arguments.\nAn example here is drawing numbers from a normal distribution – rnorm(). The function takes three arguments: n– the number of values to be drawn, mean, and sd.\n\ntibble(\n  n = 10,\n  mean = 1:10,\n  sd = 0.5\n) |&gt; \n  pmap(rnorm)\n\n[[1]]\n [1] 0.2762588 1.2662280 0.4966849 1.3585467 0.7492659 0.7907689 0.3105248\n [8] 1.1213886 1.4226768 0.1782507\n\n[[2]]\n [1] 2.509489 2.476223 2.410380 2.813266 2.116919 2.392606 1.324271 1.782913\n [9] 1.659243 2.718527\n\n[[3]]\n [1] 3.433201 2.123642 2.645378 3.158825 3.418090 4.271263 3.200257 3.017893\n [9] 3.141365 2.606872\n\n[[4]]\n [1] 3.914835 4.595926 4.682905 3.619700 3.513134 4.954899 3.123541 4.477846\n [9] 5.167031 4.550836\n\n[[5]]\n [1] 5.545990 5.142692 4.220136 5.427874 5.213967 4.856378 4.899412 5.450255\n [9] 3.873000 4.740156\n\n[[6]]\n [1] 5.818541 6.971764 6.147575 6.582609 6.121836 6.226723 6.257705 5.418025\n [9] 5.531128 6.076174\n\n[[7]]\n [1] 6.859280 6.594688 6.866800 7.426123 6.291120 6.845510 7.212836 6.980094\n [9] 6.177029 7.468289\n\n[[8]]\n [1] 8.743606 8.803838 8.125447 8.136227 8.075560 8.486074 8.504599 7.792865\n [9] 7.557125 8.727168\n\n[[9]]\n [1] 8.815799 9.599489 9.429286 9.243450 8.937363 9.010900 8.082863 9.765383\n [9] 9.820104 8.174236\n\n[[10]]\n [1] 10.015095  9.715463 10.305483 10.754284  9.661376 10.500636 10.617799\n [8] 10.823392  9.387472  9.728401\n\n\nIf you want to use an anonymous function, you can do so as well:\n\ntibble(\n  n = 10,\n  mean = 1:10,\n  sd = 0.5\n) |&gt; \n  pmap(\\(n, mean, sd) rnorm(n, mean, sd))\n\n[[1]]\n [1] 0.7772323 0.0416125 0.9735931 0.9834894 1.0114624 0.3249466 1.0569058\n [8] 1.3214937 1.1249126 0.9573270\n\n[[2]]\n [1] 1.4034810 2.1781413 2.0860438 2.9868643 1.4047264 1.5553486 1.5861139\n [8] 1.3575352 1.3621371 0.7242431\n\n[[3]]\n [1] 4.093959 2.798665 4.107978 1.874788 3.051627 3.409510 3.433766 3.728983\n [9] 2.355771 2.556102\n\n[[4]]\n [1] 2.433150 4.199967 4.212392 4.328054 4.488375 4.602977 4.691167 4.146277\n [9] 4.189498 4.097553\n\n[[5]]\n [1] 5.140349 5.092283 4.738515 5.529182 4.269838 5.013457 4.620869 4.823738\n [9] 4.207710 4.723280\n\n[[6]]\n [1] 6.245906 5.058408 5.516441 5.472807 6.025419 5.685291 6.462158 6.550718\n [9] 6.566605 5.717003\n\n[[7]]\n [1] 7.087744 6.923719 6.899486 6.571321 7.224902 6.843166 7.430276 6.926348\n [9] 6.838748 6.860724\n\n[[8]]\n [1] 8.402492 7.871721 7.946986 8.426621 8.797195 8.227491 7.582142 8.157361\n [9] 8.107146 7.558428\n\n[[9]]\n [1] 9.694184 9.786892 9.286632 9.995288 8.535659 9.185741 8.114063 9.860151\n [9] 8.876233 8.891865\n\n[[10]]\n [1] 10.696122 11.047684 10.039567 10.655035  9.739268  9.559926  9.317054\n [8] 10.097944  9.665217 10.051768\n\n\n\n\nSpeeding up with furrr\nIf you work with large data sets or have to perform a lot of iterations, you might want to speed up your code. The furrr package provides the same functionality as purrr, but allows for parallelization. This means that it can split up the tasks and distribute them across multiple CPU cores.\nIts functionalities are the same as in purrr, just with a future_ prefix. In order to use it, you need to set up a plan first. Here, I use multisession, which works on all platforms (Windows, Mac, Linux). If you work on a Linux machine, you can also use multicore, which is faster.\n\nneeds(furrr)\nplan(multisession) #set up parallelization\nfuture_map_dbl(example_dbl, add_10)\n\n[1] 11.5 11.3 11.8 11.9 12.3\n\n\nNote that speed benefits are not apparent when working with small data sets or few iterations. The overhead of setting up parallel processes can outweigh the benefits. However, if you work with large data sets or have to perform a lot of iterations, you will see a speed increase.\nLet’s make add_10 slow and benchmark furrr and purrr using the tictoc package. I have set the sleep time to 0.5 seconds to make the difference more apparent. My laptop has 8 cores, hence I create 24 tasks which will be distributed across the 8 workers (3 tasks per worker).\n\nneeds(tictoc)\n\n# Create more tasks than workers\nexample_long &lt;- 1:24 \n\nadd_10_slow &lt;- function(x) {\n  Sys.sleep(0.5)  # Shorter sleep time\n  x + 10\n}\n\n# Sequential version\ntic(\"Sequential (purrr)\")\nresult_seq &lt;- map_dbl(example_long, add_10_slow)\ntoc()\n\nSequential (purrr): 12.158 sec elapsed\n\n# Parallel version\ntic(\"Parallel (furrr)\")\nresult_par &lt;- future_map_dbl(example_long, add_10_slow)\ntoc()\n\nParallel (furrr): 3.219 sec elapsed\n\n\nYou can see that the parallel version is much faster than the sequential one. However, the speed increase is not linear. This is due to the overhead of setting up parallel processes. Setting up worker processes, transferring data between them, and collecting results all take time. With my 0.5 second tasks, this overhead becomes a significant fraction of the total runtime. Also, following Amdahl’s Law, not everything can be parallelized. Some parts like initial setup and final result collection must run sequentially. This creates a fundamental limit on speedup. Finally, there are system constraints, as my CPU shares resources with other processes, memory bandwidth can become a bottleneck, and modern CPUs can’t maintain peak single-core performance across all cores simultaneously.\nSo, when should we use furrr?\n\nWhen you have a large number of tasks that can be executed independently.\nWhen each task takes a significant amount of time to complete.\nWhen you have access to a multi-core machine.\n\nWhen should we avoid furrr?\n\nWhen tasks are very quick to execute (the overhead of parallelization may outweigh the benefits).\nWhen tasks depend on each other (parallelization won’t help).\nWhen working in an environment where parallel processing is restricted (e.g., some cloud services or shared servers).\nWhen debugging (parallel code can be harder to debug).\n\n\n\n\nFurther links\n\nChapter about loops in Hands-on Programming with R\nOn control flow\nA basic introduction to purrr::map\nThe corresponding chapter in R4DS"
  },
  {
    "objectID": "2_r_catch-up.html#footnotes",
    "href": "2_r_catch-up.html#footnotes",
    "title": "Chapter 2: Brief R Recap",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nThis becomes especially painful if you teach R to your students and have to grade 20 submissions and, hence, have to paste your personal directory’s file path into each of these submissions.↩︎\nwhich can be found here or using vignette(\"tidy-data\", package = \"tidyr\")↩︎\nIf you want to run the code on your machine, download the files behind the following links and store them in a folder called socviz_us which is again stored in a folder named data which lives in the same folder as the .qmd file.↩︎\nI have taken this example from the R for Data Science book. I hardly ever work with while loops. The only use case from my day-to-day work is web-scraping, where I want to loop over pages until a certain threshold is reached. Therefore, I could not really come up with an example myself.↩︎"
  },
  {
    "objectID": "lectures-week_1.html",
    "href": "lectures-week_1.html",
    "title": "Week 1: What Is Computational Social Science (CSS)?",
    "section": "",
    "text": "This lecture answers the following questions:"
  },
  {
    "objectID": "lectures-week_1.html#slides",
    "href": "lectures-week_1.html#slides",
    "title": "Week 1: What Is Computational Social Science (CSS)?",
    "section": "Slides",
    "text": "Slides\nPlease click here to download the latest version of the slides.\n\n\n\nAlternatively, read them here (probably not the best if you’re visiting this page on a mobile device):"
  },
  {
    "objectID": "lectures-week_2.html",
    "href": "lectures-week_2.html",
    "title": "Week 1: What Is Computational Social Science (CSS)?",
    "section": "",
    "text": "This week, you will learn the answers to the following questions:"
  },
  {
    "objectID": "lectures-week_2.html#slides",
    "href": "lectures-week_2.html#slides",
    "title": "Week 1: What Is Computational Social Science (CSS)?",
    "section": "Slides",
    "text": "Slides\nThere are no slides, just code script."
  },
  {
    "objectID": "lectures-week_4.html",
    "href": "lectures-week_4.html",
    "title": "Week 4: selenium and APIs",
    "section": "",
    "text": "This week answers the following questions:"
  },
  {
    "objectID": "lectures-week_4.html#slides",
    "href": "lectures-week_4.html#slides",
    "title": "Week 4: selenium and APIs",
    "section": "Slides",
    "text": "Slides\nThere are no slides for Tuesday, you can look at the ones from the week before, just the R script.\nThursday’s slides can be found here.\n\n\n\nAlternatively, read them here (probably not the best if you’re visiting this page on a mobile device):"
  }
]