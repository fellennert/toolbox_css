[
  {
    "objectID": "6_stringr_regex.html",
    "href": "6_stringr_regex.html",
    "title": "Chapter 3: stringr and RegExes",
    "section": "",
    "text": "needs(tidyverse, rvest)\nWhen working with data, a significant number of variables will be in some sort of text format. When you want to manipulate these variables, an easy approach would be exporting the data to MS Excel and then just performing those manipulations by hand. This is very time-consuming, though, and, hence, we rather recommend the R way which scales well and works fast for data sets of varying sizes.\nQuick reminder: a string is an element of a character vector and can be created by simply wrapping some text in quotation marks:\nstring &lt;- \"Hi, how are you doing?\"\nvector_of_strings &lt;- c(\"Hi, how are you doing?\", \"I'm doing well, HBY?\", \"Me too, thanks for asking.\")\nNote that you can either wrap your text in double quotation marks and use single ones in the string and vice versa:\nsingle_ones &lt;- \"what's up\"\ndouble_ones &lt;- 'he said: \"I am fine\"'\nThe stringr package (Wickham 2019) contains a multitude of commands (49 in total) that can be used to achieve a couple of things, mainly manipulating character vectors, and finding and matching patterns. These goals can also be achieved with base R functions, but stringr’s advantage is its consistency. The makers of stringr describe it as\nEvery stringr function starts with str_ – which facilitates finding the proper command: just type str_ and RStudio’s auto-suggest function should take care of the rest (if it doesn’t pop up by itself, you can trigger it by hitting the tab key). Also, they take a vector of strings as their first argument, which facilitates using them in a |&gt;-pipeline and adding them to a mutate()-call.\nOne important component of stringr functions is regular expressions which will be introduced later as well."
  },
  {
    "objectID": "6_stringr_regex.html#basic-manipulations",
    "href": "6_stringr_regex.html#basic-manipulations",
    "title": "Chapter 3: stringr and RegExes",
    "section": "Basic manipulations",
    "text": "Basic manipulations\nIn the following, we will introduce you to several different operations that can be performed on strings.\n\nChanging the case of the words\nA basic operation is changing words’ cases.\n\nstr_to_lower(vector_of_strings)\n\n[1] \"hi, how are you doing?\"     \"i'm doing well, hby?\"      \n[3] \"me too, thanks for asking.\"\n\nstr_to_upper(vector_of_strings)\n\n[1] \"HI, HOW ARE YOU DOING?\"     \"I'M DOING WELL, HBY?\"      \n[3] \"ME TOO, THANKS FOR ASKING.\"\n\nstr_to_title(vector_of_strings)\n\n[1] \"Hi, How Are You Doing?\"     \"I'm Doing Well, Hby?\"      \n[3] \"Me Too, Thanks For Asking.\"\n\nstr_to_sentence(vector_of_strings)\n\n[1] \"Hi, how are you doing?\"     \"I'm doing well, hby?\"      \n[3] \"Me too, thanks for asking.\"\n\n\n\n\nDetermining a string’s length\nDetermining the string’s number of characters goes as follows:\n\nstr_length(vector_of_strings)\n\n[1] 22 20 26\n\n\n\n\nExtracting particular characters\nCharacters can be extracted (by position) using str_sub\n\nstr_sub(vector_of_strings, start = 1, end = 5) # extracting first to fifth character\n\n[1] \"Hi, h\" \"I'm d\" \"Me to\"\n\nstr_sub(vector_of_strings, start = -5, end = -1) # extracting fifth-to-last to last character\n\n[1] \"oing?\" \" HBY?\" \"king.\"\n\n\nYou can also use str_sub() to replace strings. E.g., to replace the last character by a full stop, you can do the following:\n\nstr_sub(vector_of_strings, start = -1) &lt;- \".\"\nvector_of_strings\n\n[1] \"Hi, how are you doing.\"     \"I'm doing well, HBY.\"      \n[3] \"Me too, thanks for asking.\"\n\n\nHowever, in everyday use, you would probably go with str_replace() and regular expressions.\n\n\nConcatenating strings\nSimilar to how c() puts together different elements (or vectors of length 1) and other vectors into a single vector, str_c() can be used to concatenate several strings into a single string. This can, for instance, be used to write some birthday invitations.\n\nnames &lt;- c(\"Inger\", \"Peter\", \"Kalle\", \"Ingrid\")\n\nstr_c(\"Hi\", names, \"I hope you're doing well. As per this letter, I invite you to my birthday party.\")\n\n[1] \"HiIngerI hope you're doing well. As per this letter, I invite you to my birthday party.\" \n[2] \"HiPeterI hope you're doing well. As per this letter, I invite you to my birthday party.\" \n[3] \"HiKalleI hope you're doing well. As per this letter, I invite you to my birthday party.\" \n[4] \"HiIngridI hope you're doing well. As per this letter, I invite you to my birthday party.\"\n\n\nWell, this looks kind of ugly, as there are no spaces, and commas are lacking as well. You can fix that by determining a separator using the sep argument.\n\nstr_c(\"Hi\", names, \"I hope you're doing well. As per this letter, I invite you to my birthday party.\", sep = \", \")\n\n[1] \"Hi, Inger, I hope you're doing well. As per this letter, I invite you to my birthday party.\" \n[2] \"Hi, Peter, I hope you're doing well. As per this letter, I invite you to my birthday party.\" \n[3] \"Hi, Kalle, I hope you're doing well. As per this letter, I invite you to my birthday party.\" \n[4] \"Hi, Ingrid, I hope you're doing well. As per this letter, I invite you to my birthday party.\"\n\n\nYou could also collapse the strings contained in a vector together into one single string using the collapse argument.\n\nstr_c(names, collapse = \", \")\n\n[1] \"Inger, Peter, Kalle, Ingrid\"\n\n\n\n\nRepetition\nRepeating (or duplicating) strings is performed using str_dup(). The function takes two arguments: the string to be duplicated and the number of times.\n\nstr_dup(\"felix\", 2)\n\n[1] \"felixfelix\"\n\nstr_dup(\"felix\", 1:3)\n\n[1] \"felix\"           \"felixfelix\"      \"felixfelixfelix\"\n\nstr_dup(names, 2)\n\n[1] \"IngerInger\"   \"PeterPeter\"   \"KalleKalle\"   \"IngridIngrid\"\n\nstr_dup(names, 1:4)\n\n[1] \"Inger\"                    \"PeterPeter\"              \n[3] \"KalleKalleKalle\"          \"IngridIngridIngridIngrid\"\n\n\n\n\nRemoving unnecessary whitespaces\nOften text contains unnecessary whitespaces.\n\nunnecessary_whitespaces &lt;- c(\"    on the left\", \"on the right    \", \"    on both sides   \", \"   literally    everywhere  \")\n\nRemoving the ones at the beginning or the end of a string can be accomplished using str_trim().\n\nstr_trim(unnecessary_whitespaces, side = \"left\")\n\n[1] \"on the left\"               \"on the right    \"         \n[3] \"on both sides   \"          \"literally    everywhere  \"\n\nstr_trim(unnecessary_whitespaces, side = \"right\")\n\n[1] \"    on the left\"            \"on the right\"              \n[3] \"    on both sides\"          \"   literally    everywhere\"\n\nstr_trim(unnecessary_whitespaces, side = \"both\") # the default option\n\n[1] \"on the left\"             \"on the right\"           \n[3] \"on both sides\"           \"literally    everywhere\"\n\n\nstr_trim() could not fix the last string though, where unnecessary whitespaces were also present in between words. Here, str_squish is more appropriate. It removes leading or trailing whitespaces as well as duplicated ones in between words.\n\nstr_squish(unnecessary_whitespaces)\n\n[1] \"on the left\"          \"on the right\"         \"on both sides\"       \n[4] \"literally everywhere\"\n\n\n\n\nFurther links\n\nR for Data Science chapter on stringr\nThe stringr cheatsheet.\n\n\n\nExercises\n\nRun the following code that downloads movies from IMDb. Clean up the column “year” in the resulting film data set. Think about how you could do it with str_sub(). Could you also use it for the dot in the “rank” column?\n\n\nneeds(rvest, tidyverse)\nimdb_top250 &lt;- read_html(\"https://www.imdb.com/chart/top/?ref_=nv_mv_250\")\n\nmovies &lt;- tibble(\n  title_raw = imdb_top250 |&gt; \n    html_elements(\".cli-title .ipc-title__text\") |&gt; \n    html_text2(),\n  year_raw = imdb_top250 |&gt; \n    html_elements(\".cli-title-metadata\") |&gt; \n    html_text2()\n) |&gt; \n  separate(title_raw, sep = \" \", into = c(\"rank\", \"title\"), extra = \"merge\")\n\n\n\nSolution. Click to expand!\n\n\nmovies_clean &lt;- movies |&gt; \n  mutate(year = str_sub(year_raw, start = 1, end = 4) |&gt; as.double(),\n         rank = str_sub(rank, start = -4, end = -2) |&gt; as.integer())\n\n\n\nConvert the following sentence to different cases:\n\n\nsentence &lt;- \"The quick brown fox jumps over the lazy dog.\"\n\n\n\nSolution. Click to expand!\n\n\nstr_to_lower(sentence)\nstr_to_sentence(sentence)\nstr_to_title(sentence)\nstr_to_upper(sentence)\n\n\n\nWhat’s the length of the following string?\n\n\ntext &lt;- \"I enjoy studying Sociology at Leipzig University.\"\n\n\n\nSolution. Click to expand!\n\n\nstr_length(text)\n\n\n\nUsing the following vectors, create a full sentence:\n\n\nstart &lt;- \"I am a large language model and I am\"\nattributes &lt;- c(\"powerful.\", \"dumb.\", \"worse at coding than your instructor.\")\nend &lt;- \"Haha, do you really think I asked ChatGPT to give you these exercises?\"\nps &lt;- \"(Of course I did, I am lazy AF.)\"\n\n\n\nSolution. Click to expand!\n\n\nstr_c(start, attributes, end, ps, sep = \" \")"
  },
  {
    "objectID": "6_stringr_regex.html#regular-expressions",
    "href": "6_stringr_regex.html#regular-expressions",
    "title": "Chapter 3: stringr and RegExes",
    "section": "Regular expressions",
    "text": "Regular expressions\nUp to now, you have been introduced to the more basic functions of the stringr package. Those are useful, for sure, yet limited. However, to make use of the full potential of stringr, you will first have to acquaint yourself with regular expressions (also often abbreviated as “RegEx” with plural “RegExes”).\nThose regular expressions are patterns that can be used to describe certain strings. Exemplary use cases of RegExes are the identification of phone numbers, email addresses, or whether a password you choose on a web page consists of enough characters, an uppercase character, and at least one special character. Hence, if you want to replace certain words with another one, you can write the proper RegEx and it will identify the strings you want to replace, and the stringr functions (i.e., str_replace()) will take care of the rest.\nBefore you dive into RegExes, beware that they are quite complicated at the beginning1. Yet, mastering them is very rewarding and will pay off in the future.\n\nLiteral characters\nThe most basic RegEx patterns consist of literal characters only. str_view() tells you which parts of a string match a pattern is present in the element.\n\nfive_largest_cities &lt;- c(\"Stockholm\", \"Göteborg\", \"Malmö\", \"Uppsala\", \"Västerås\")\n\nNote that RegExes are case-sensitive.\n\nstr_view(five_largest_cities, \"stockholm\", match = NA, html = TRUE)\n\n\n\n\n\n\nstr_view(five_largest_cities, \"Stockholm\", match = NA, html = TRUE)\n\n\n\n\n\nThey also match parts of words:\n\nstr_view(five_largest_cities, \"borg\", match = NA, html = TRUE)\n\n\n\n\n\nMoreover, they are “greedy,” they only match the first occurrence. str_locate() locates the pattern. Look at Stockholm – we should have two matches here:\n\nstr_locate(five_largest_cities, \"o\") |&gt; \n  as_tibble() |&gt; \n  mutate(city = five_largest_cities)\n\n# A tibble: 5 × 3\n  start   end city     \n  &lt;int&gt; &lt;int&gt; &lt;chr&gt;    \n1     3     3 Stockholm\n2     6     6 Göteborg \n3    NA    NA Malmö    \n4    NA    NA Uppsala  \n5    NA    NA Västerås \n\n\nThis can be addressed in the stringr package by using str_._all() functions.\n\nstr_locate_all(five_largest_cities, \"o\") |&gt; \n  map2(five_largest_cities, \\(x, y) x |&gt; \n         as_tibble() |&gt; \n         mutate(city = y)) |&gt; \n  bind_rows()\n\n# A tibble: 3 × 3\n  start   end city     \n  &lt;int&gt; &lt;int&gt; &lt;chr&gt;    \n1     3     3 Stockholm\n2     7     7 Stockholm\n3     6     6 Göteborg \n\n\nIf you want to match multiple literal characters (or words, for that sake), you can connect them using the | meta character (more on meta characters later).\n\nstr_view(five_largest_cities, \"Stockholm|Göteborg\", match = NA, html = TRUE)\n\n\n\n\n\nEvery letter of the English alphabet (or number/or combination of those) can serve as a literal character. Those literal characters match themselves. This is, however, not the case with the other sort of characters, so-called meta characters.\n\n\nMetacharacters\nWhen using RegExes, the following characters are considered meta characters and have a special meaning:\n. \\ | ( ) { } [ ] ^ $ - * + ?\n\nThe wildcard\nDid you notice how we used the dot to refer to the entirety of the str_._all() functions? This is basically what the . meta-character does: it matches every character except for a new line. The first call extracts all function names from the stringr package, the second one shows the matches (i.e., the elements of the vector where it can find the pattern).\n\nstringr_functions &lt;- ls(\"package:stringr\")\n\nstr_detect(stringr_functions, \"str_._all\")\n\n [1] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE\n[13] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE\n[25] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE\n[37] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE\n[49] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE\n[61] FALSE FALSE\n\n\nWell, as you can see, there are none. This is because the . can only replace one character. We need some sort of multiplier to find them. The ones available are:\n\n? – zero or one\n* – zero or more\n+ – one or more\n{n} – exactly n\n{n,} – n or more\n{n,m} – between n and m\n\nIn our case, the appropriate one is +:\n\nstr_detect(stringr_functions, \"str_.+_all\")\n\n [1] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE\n[13] FALSE FALSE FALSE FALSE FALSE  TRUE FALSE FALSE FALSE FALSE FALSE FALSE\n[25] FALSE FALSE  TRUE FALSE  TRUE FALSE FALSE FALSE FALSE  TRUE FALSE  TRUE\n[37] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE  TRUE FALSE FALSE\n[49] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE  TRUE FALSE FALSE FALSE\n[61] FALSE FALSE\n\n\nHowever, what if you want to match the character “.”? This problem might come up when searching for clock time. A naive RegEx might look like this:\n\nvectors_with_time &lt;- c(\"13500\", \"13M00\", \"13.00\")\n\nstr_detect(vectors_with_time, \"13.00\")\n\n[1] TRUE TRUE TRUE\n\n\nYet, it matches everything. We need some sort of literal dot. Here, the metacharacter \\ comes in handy. By putting \\ in front of the metacharacter that we want to be treated as literal – the . in our case – the . loses its special meaning and is interpreted as a literal character. This procedure is referred to as “escaping.” Hence, \\ is also referred to as the “escape character.” Note that, in R, you will need to escape \\ as well, and therefore in code escaping will look like this: \\\\..\n\nstr_detect(vectors_with_time, \"13\\\\.00\")\n\n[1] FALSE FALSE  TRUE\n\n\n\n\n\nSets of characters\nYou can also define sets of multiple characters using the [ ] meta characters. This can be used to define multiple possible characters that can appear in the same place.\n\nsp_ce &lt;- c(\"spice\", \"space\")\n\nstr_view(sp_ce, \"sp[ai]ce\", match = NA, html = TRUE)\n\n\n\n\n\nYou can also define certain ranges of characters using the - metacharacter:\nSame holds for numbers:\n\namerican_phone_number &lt;- \"(555) 555-1234\"\n\nstr_view(american_phone_number, \"\\\\([:digit:]{3}\\\\) [0-9]{3}-[0-9]{4}\", match = NA, html = TRUE)\n\n\n\n\n\nThere are also predefined sets of characters, for instance, digits or letters, which are called character classes. You can find them on the stringr cheatsheet.\nFurthermore, you can put almost every meta character inside the square brackets without escaping them. This does not apply to the caret (^) in the first position, the dash -, the closing square bracket ], and the backslash \\.\n\nstr_view(vector_of_strings, \"[.]\", match = NA, html = TRUE)\n\n\n\n\n\n\nNegating sets of characters\nSometimes you will also want to exclude certain sets of characters or words. To achieve this, you can use the ^ meta character at the beginning of the range or set you are defining.\n\nstr_view(sp_ce, \"sp[^i]ce\", match = NA, html = TRUE)\n\n\n\n\n\n\n\n\nAnchors\nThere is also a way to define whether you want the pattern to be present in the beginning ^ or at the end $ of a string. sentences are a couple of (i.e., 720) predefined example sentences. If we were now interested in the number of sentences that begin with a “the,” we could write the following RegEx:\n\nshortened_sentences &lt;- sentences[1:10]\n\nstr_view(shortened_sentences, \"^The\", match = NA, html = TRUE)\n\n\n\n\n\nIf we wanted to know how many start with a “The” and end with a full stop, we could do this one:\n\nstr_view(shortened_sentences, \"^The.+\\\\.$\", match = NA, html = TRUE)\n\n\n\n\n\n\nBoundaries\nNote that right now, the RegEx also matches the sentence which starts with a “These.” To address this, we need to tell the machine that it should only accept a “The” if there starts a new word thereafter. In RegEx syntax, this is done using so-called boundaries. Those are defined as \\b as a word boundary and \\B as no word boundary. (Note that you will need an additional escape character as you will have to escape the escape character itself.)\nIn my example, we would include the former if we were to search for sentences that begin with a single “The” and the latter if we were to search for sentences that begin with a word that starts with a “The” but are not “The” – such as “These.”\n\nstr_view(shortened_sentences, \"^The\\\\b.+\\\\.$\", match = NA, html = TRUE) \n\n\n\n\nstr_view(shortened_sentences, \"^The\\\\B.+\\\\.$\", match = NA, html = TRUE) \n\n\n\n\n\n\n\nLookarounds\nA final common task is to extract certain words or values based on what comes before or after them. Look at the following example:\n\nheights &lt;- c(\"1m30cm\", \"2m01cm\", \"3m10cm\")\n\nHere, to identify the height in meters, the first task is to identify all the numbers that are followed by an “m”. The RegEx syntax for this looks like this: A(?=pattern) with A being the entity that is supposed to be found (hence, in this case, [0-9]+).\n\nstr_view(heights, \"[0-9]+(?=m)\", match = NA, html = TRUE)\n\n\n\n\n\nThe second step now is to identify the centimeters. This could of course be achieved using the same RegEx and replacing m with cm. However, we can also harness a so-called negative look ahead A(?!pattern), a so-called look behind (?&lt;=pattern)A. The negative counterpart, the negative look behind (?&lt;!pattern)A could be used to extract the meters.\nThe negative lookahead returns everything that is not followed by the defined pattern. The look behind returns everything that is preceded by the pattern, the negative look behind returns everything that is not preceded by the pattern.\nIn the following, we demonstrate how you could extract the centimeters using negative look ahead and look behind.\n\nstr_view(heights, \"[0-9]+(?!m)\", match = NA, html = TRUE) # negative look ahead\n\n\n\n\n\n\nstr_view(heights, \"(?&lt;=m)[0-9]+\", match = NA, html = TRUE) # look behind\n\n\n\n\n\n\n\n\nFurther links\n\nR for Data Science chapter on RegExes\nA YouTube video on RegExes by Johns Hopkins professor Roger Peng.\nAnd a chapter by Roger Peng.\nA website for practicing RegExes.\n\n\n\nExercises\n\nWrite a RegEx for Swedish mobile numbers. Test it with str_detect(\"+46 71-738 25 33\", \"[insert your RegEx here]\").\n\n\n\nSolution. Click to expand!\n\n\nstr_detect(\"+46 71-738 25 33\", \"\\\\+46 [0-9]{2}\\\\-[0-9]{3} [0-9]{2} [0-9]{2}\")\n\n\n\nGiven the vector c(\"apple\", \"banana\", \"cherry\", \"date\", \"elderberry\"), use a regular expression to identify fruits that contain the letter “a” exactly three times.\n\n\n\nSolution. Click to expand!\n\n\nfruits &lt;- c(\"apple\", \"banana\", \"cherry\", \"date\", \"elderberry\")\nstr_detect(fruits, \"a[^a]*a(&lt;=[^a]|\\\\b)\")\n\n\n\nGiven the sentence vector c(\"The cat sat on the mat.\", \"Mat is what it sat on.\", \"On the mat, it sat.\"), write a regular expression to identify sentences that start with “The” and end with “mat.”.\n\n\n\nSolution. Click to expand!\n\n\ncats &lt;- c(\"The cat sat on the mat.\", \"Mat is what it sat on.\", \"On the mat, it sat.\")\nstr_detect(cats, \"^The.*mat.$\")\n\n\n\nExtract all email addresses from the following vector: c(\"john.doe@example.com\", \"alice_smith@company.net\", \"r.user@domain.org\", \"I am @ the office RN\", \"facebook.com\").\n\n\n\nSolution. Click to expand!\n\n\naddresses &lt;- c(\"john.doe@example.com\", \"alice_smith@company.net\", \"r.user@domain.org\", \"I am @ the office RN\", \"facebook.com\")\n\nstr_detect(addresses, \"[a-z.\\\\_]+\\\\@[a-z]+\\\\.[a-z]+\")\n\n\n\nCheck a vector of passwords for strength. A strong password should have at least 8 characters, include an uppercase and a lowercase letter, a number, and a special character (e.g., !@#$%^&*).\n\n\n\nSolution. Click to expand!\n\n\npassword &lt;- c(\"Hi!123456\")\n\nif (str_detect(password, \"[A-Z]{1,}\") &\n    str_detect(password, \"[a-z]{1,}\") &\n    str_detect(password, \"[0-9]{1,}\") &\n    str_detect(password, \"[\\\\!\\\\@\\\\#\\\\$\\\\%\\\\^\\\\&\\\\*]{1,}\") &\n    str_length(password) &gt; 7){\n  \"strong password\"\n}else{\n  \"weak password\"\n}\n\n\n\nFrom “The theme of this theater is therapeutic.”, extract all words that start with “the” but are not followed by “me”.\n\n\n\nSolution. Click to expand!\n\n\nsentence &lt;- \"The theme of this theater is therapeutic.\" |&gt; str_to_lower()\nstr_extract_all(sentence, \"\\\\bthe(?!me)\\\\w*\\\\b\")"
  },
  {
    "objectID": "6_stringr_regex.html#more-advanced-string-manipulation",
    "href": "6_stringr_regex.html#more-advanced-string-manipulation",
    "title": "Chapter 3: stringr and RegExes",
    "section": "More advanced string manipulation",
    "text": "More advanced string manipulation\nNow that you have learned about RegExes, you can unleash the full power of stringr.\nThe basic syntax of a stringr function looks as follows: str_.*(string, regex(\"\")). Some stringr functions also have the suffix _all which implies that they operate not only on the first match (“greedy”) but on every match.\nTo demonstrate the different functions, we will again rely on the subset of example sentences.\n\nDetect matches\nstr_detect can be used to determine whether a certain pattern is present in the string.\n\nstr_detect(shortened_sentences, \"The\\\\b\")\n\n [1]  TRUE FALSE FALSE FALSE FALSE  TRUE  TRUE  TRUE FALSE FALSE\n\n\nThis also works very well in a dplyr::filter() call. Finding all action movies in the IMDB data set can be solved like this:\n\nimdb_raw &lt;- read_csv(\"https://www.dropbox.com/s/81o3zzdkw737vt0/imdb2006-2016.csv?dl=1\")\n\nRows: 1000 Columns: 12\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (5): Title, Genre, Description, Director, Actors\ndbl (7): Rank, Year, Runtime (Minutes), Rating, Votes, Revenue (Millions), M...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nimdb_raw |&gt; \n  filter(str_detect(Genre, \"Action\"))\n\n# A tibble: 303 × 12\n    Rank Title       Genre Description Director Actors  Year `Runtime (Minutes)`\n   &lt;dbl&gt; &lt;chr&gt;       &lt;chr&gt; &lt;chr&gt;       &lt;chr&gt;    &lt;chr&gt;  &lt;dbl&gt;               &lt;dbl&gt;\n 1     1 Guardians … Acti… A group of… James G… Chris…  2014                 121\n 2     5 Suicide Sq… Acti… A secret g… David A… Will …  2016                 123\n 3     6 The Great … Acti… European m… Yimou Z… Matt …  2016                 103\n 4     9 The Lost C… Acti… A true-lif… James G… Charl…  2016                 141\n 5    13 Rogue One   Acti… The Rebel … Gareth … Felic…  2016                 133\n 6    15 Colossal    Acti… Gloria is … Nacho V… Anne …  2016                 109\n 7    18 Jason Bour… Acti… The CIA's … Paul Gr… Matt …  2016                 123\n 8    25 Independen… Acti… Two decade… Roland … Liam …  2016                 120\n 9    27 Bahubali: … Acti… In ancient… S.S. Ra… Prabh…  2015                 159\n10    30 Assassin's… Acti… When Callu… Justin … Micha…  2016                 115\n# ℹ 293 more rows\n# ℹ 4 more variables: Rating &lt;dbl&gt;, Votes &lt;dbl&gt;, `Revenue (Millions)` &lt;dbl&gt;,\n#   Metascore &lt;dbl&gt;\n\n\nIf you want to know whether there are multiple matches present in each string, you can use str_count. Here, it might be advisable to set the ignore_case option to TRUE:\n\nstr_count(shortened_sentences, regex(\"the\\\\b\", ignore_case = TRUE))\n\n [1] 2 2 1 0 0 1 2 1 0 0\n\n\nIf you want to locate the match in the string, use str_locate. This returns a matrix, which is a vector of multiple dimensions.\n\nstr_locate(shortened_sentences, regex(\"The\\\\b\", ignore_case = TRUE))\n\n      start end\n [1,]     1   3\n [2,]     6   8\n [3,]    19  21\n [4,]    NA  NA\n [5,]    NA  NA\n [6,]     1   3\n [7,]     1   3\n [8,]     1   3\n [9,]    NA  NA\n[10,]    NA  NA\n\n\nMoreover, this is a good example for the greediness of stringr functions. Hence, it is advisable to use str_locate_all which returns a list with one matrix for each element of the original vector:\n\nstr_locate_all(shortened_sentences, regex(\"The\\\\b\", ignore_case = TRUE)) |&gt; pluck(1)\n\n     start end\n[1,]     1   3\n[2,]    25  27\n\n\n\n\nMutating strings\nMutating strings usually implies the replacement of certain elements (e.g., words) with other elements (or removing them, which is a special case of replacing them with nothing). In stringr this is performed using str_replace(string, pattern, replacement) and str_replace_all(string, pattern, replacement).\nIf we wanted, for instance, to replace the first occurrence of “m” letters with “meters,” we would go about this the following way:\n\nstr_replace(heights, \"m\", \"meters\")\n\n[1] \"1meters30cm\" \"2meters01cm\" \"3meters10cm\"\n\n\nNote that str_replace_all would have lead to the following outcome:\n\nstr_replace_all(heights, \"m\", \"meters\")\n\n[1] \"1meters30cmeters\" \"2meters01cmeters\" \"3meters10cmeters\"\n\n\nHowever, we also want to replace the “cm” with “centimeters,” hence, we can harness another feature of str_replace_all(), providing multiple replacements:\n\nstr_replace_all(heights, c(\"m\" = \"meters\", \"cm\" = \"centimeters\"))\n\n[1] \"1meters30centimeterseters\" \"2meters01centimeterseters\"\n[3] \"3meters10centimeterseters\"\n\n\nWhat becomes obvious is that a “simple” RegEx containing just literal characters more often than not does not suffice. It will be your task to fix this. And while on it, you can also address the meter/meters problem – a “1” needs meter instead of meters. Another feature is that the replacements are performed in order. You can harness this for solving the problem.\n\n\nExtracting text\nstr_extract(_all)() can be used to extract matching strings. In the mtcars data set, the first word describes the car brand. Here, we harness another RegEx, the \\\\w which stands for any word character. Its opponent is \\\\W for any non-word character.\n\nmtcars |&gt; \n  rownames_to_column(var = \"car_model\") |&gt; \n  transmute(manufacturer = str_extract(car_model, \"^\\\\w+\\\\b\")) |&gt; \n  head(6)\n\n  manufacturer\n1        Mazda\n2        Mazda\n3       Datsun\n4       Hornet\n5       Hornet\n6      Valiant\n\n\n\n\nSplit vectors\nAnother use case here would have been to split it into two columns: manufacturer and model. One approach would be to use str_split(). This function splits the string at every occurrence of the predefined pattern. In this example, we use a word boundary as the pattern:\n\nmanufacturer_model &lt;- rownames(mtcars)\nstr_split(manufacturer_model, \"\\\\b\") |&gt; \n  head()\n\n[[1]]\n[1] \"\"      \"Mazda\" \" \"     \"RX4\"   \"\"     \n\n[[2]]\n[1] \"\"      \"Mazda\" \" \"     \"RX4\"   \" \"     \"Wag\"   \"\"     \n\n[[3]]\n[1] \"\"       \"Datsun\" \" \"      \"710\"    \"\"      \n\n[[4]]\n[1] \"\"       \"Hornet\" \" \"      \"4\"      \" \"      \"Drive\"  \"\"      \n\n[[5]]\n[1] \"\"           \"Hornet\"     \" \"          \"Sportabout\" \"\"          \n\n[[6]]\n[1] \"\"        \"Valiant\" \"\"       \n\n\nThis outputs a list containing the different singular words/special characters. This doesn’t make sense in this case. Here, however, the structure of the string is always roughly the same: “\\[manufacturer\\]\\[ \\]\\[model description\\]”. Moreover, the manufacturer is only one word. Hence, the task can be fixed by splitting the string after the first word, which should indicate the manufacturer. This can be accomplished using str_split_fixed(). Fixed means that the number of splits is predefined. This returns a matrix that can easily become a tibble.\n\nstr_split_fixed(manufacturer_model, \"(?&lt;=\\\\w)\\\\b\", n = 2) |&gt; \n  as_tibble() |&gt; \n  rename(manufacturer = V1,\n         model = V2) |&gt; \n  mutate(model = str_squish(model))\n\nWarning: The `x` argument of `as_tibble.matrix()` must have unique column names if\n`.name_repair` is omitted as of tibble 2.0.0.\nℹ Using compatibility `.name_repair`.\n\n\n# A tibble: 32 × 2\n   manufacturer model       \n   &lt;chr&gt;        &lt;chr&gt;       \n 1 Mazda        \"RX4\"       \n 2 Mazda        \"RX4 Wag\"   \n 3 Datsun       \"710\"       \n 4 Hornet       \"4 Drive\"   \n 5 Hornet       \"Sportabout\"\n 6 Valiant      \"\"          \n 7 Duster       \"360\"       \n 8 Merc         \"240D\"      \n 9 Merc         \"230\"       \n10 Merc         \"280\"       \n# ℹ 22 more rows\n\n\n\n\nFurther links\nLook at the “Further links” provided above.\n\n\nExercises\n\nRun the following code that downloads movies from IMDb. Create a tibble with the two columns “rank” and “title” by extracting the respective part of the raw title.\n\n\nneeds(rvest, tidyverse)\nimdb_top250 &lt;- read_html(\"https://www.imdb.com/chart/top/?ref_=nv_mv_250\")\n\nraw_title &lt;- imdb_top250 |&gt; \n    html_elements(\".cli-title .ipc-title__text\") |&gt; \n    html_text2()\n\n\n\nSolution. Click to expand!\n\n\ntibble(\n  rank = raw_title |&gt; str_extract(\"^[0-9]{1,3}\") |&gt; as.integer(),\n  title = raw_title |&gt; str_remove(\"^[0-9]{1,3}\\\\. \")\n)\n\n\n\nReplace m and cm appropriately in the vector of heights.\n\n\nheights &lt;- c(\"1m30cm\", \"2m01cm\", \"3m10cm\")\n\n\n\nSolution. Click to expand!\n\n\nstr_replace_all(heights, c(\"(?&lt;=[2-9]{1})m\" = \"meters\", \n                           \"(?&lt;=[0-9]{2})m\" = \"meters\", \n                           \"(?&lt;=1)m\" = \"meter\", \n                           \"(?&lt;=01)cm$\" = \"centimeter\", \n                           \"cm$\" = \"centimeters\"))\n\n\n\nRun the following code and clean up the resulting table.\n\n\nneeds(rvest, janitor, lubridate, tidyverse)\n\nsenator_table_raw &lt;- read_html(\"https://en.wikipedia.org/wiki/List_of_current_United_States_senators\") |&gt; \n  html_elements(css = \"#senators\") |&gt; \n  html_table() |&gt; \n  pluck(1) |&gt; \n  clean_names() |&gt; \n  select(state, senator, party = party_2, born, occupations = occupation_s, assumed_office)\n\n\nRemove the footnotes in the “party” column.\n\n\n\nSolution. Click to expand!\n\n\nsenator_table_party_cleaned &lt;- senator_table_raw |&gt; \n  mutate(party = str_remove_all(party, \"\\\\[.\\\\]|\\\\(.+\\\\)\"))\n\n\n\nBring their date of birth (“born”) in proper shape.\n\n\n\nSolution. Click to expand!\n\n\nsenator_table_born_party_cleaned &lt;- senator_table_party_cleaned |&gt; \n  mutate(born = str_extract(born, \"19[0-9]{2}\\\\-[01][0-9]\\\\-[0-3][0-9]\") |&gt; ymd())\n\n\n\nBonus: fix their “occupation” by separating the single jobs (combine look-ahead and -behind for that.)\n\n\n\nSolution. Click to expand!\n\n\nsenator_table_cleaned &lt;- senator_table_born_party_cleaned |&gt; \n  mutate(occupation_clean = str_replace_all(occupations, c(\"(?&lt;=[a-z])(?=[A-Z])\" = \"; \", \"CEO\" = \"CEO \")) |&gt; \n           str_squish())"
  },
  {
    "objectID": "6_stringr_regex.html#footnotes",
    "href": "6_stringr_regex.html#footnotes",
    "title": "Chapter 3: stringr and RegExes",
    "section": "Footnotes",
    "text": "Footnotes\n\n\ncomment from Felix: “honestly, I was quite overwhelmed when I encountered them first”↩︎"
  },
  {
    "objectID": "lectures-week_1.html",
    "href": "lectures-week_1.html",
    "title": "Week 1: What Is Computational Social Science (CSS)?",
    "section": "",
    "text": "This lecture answers the following questions:"
  },
  {
    "objectID": "lectures-week_1.html#slides",
    "href": "lectures-week_1.html#slides",
    "title": "Week 1: What Is Computational Social Science (CSS)?",
    "section": "Slides",
    "text": "Slides\nPlease click here to download the latest version of the slides.\n\n\n\nAlternatively, read it here (probably not the best if you’re visiting this page on a mobile device):"
  },
  {
    "objectID": "2_r_catch-up.html",
    "href": "2_r_catch-up.html",
    "title": "Chapter 2: Brief R Recap",
    "section": "",
    "text": "I assume your familiarity with R. However, I am fully aware that nobody can have all these things avaible in their head all the time (that’s what they invented StackOverflow for, new AI helpers are also pretty good). In the following, I show some basics of how I use R (i.e., RStudio Projects, scripts, Quarto) as well as some data wrangling stuff (readr, tidyr, dplyr), visualization with ggplot2, functions, loops, and purrr. If you need more info, check out the “further links” I have added after each section. There are also exercises after each section.\nYou can find the files for this chapter in the GitHub repository.\nneeds(tidyverse, lubridate, fs, socviz)\nOne quick thing upfront: AI coding helpers have become increasingly popular. You can, for instance, use GitHub Copilot in RStudio (if you have access to it) or ChatGPT/Claude (the free versions are already pretty good). However, please note that those tools are not perfect and can produce wrong code. Hence, you need to understand what they do and check the code they provide you with. If you do not understand what a piece of code does, do not use it. If you want to learn R properly, I strongly recommend you to try to write the code yourself first and only use those tools if you get stuck."
  },
  {
    "objectID": "2_r_catch-up.html#rstudio-projects",
    "href": "2_r_catch-up.html#rstudio-projects",
    "title": "Chapter 2: Brief R Recap",
    "section": "RStudio Projects",
    "text": "RStudio Projects\n\nMotivation\nDisclaimer: those things might not be entirely clear right away. However, I am deeply convinced that it is important that you use R and RStudio properly from the start. Otherwise it won’t be as easy to re-build the right habits.\nIf you analyze data with R, one of the first things you do is to load in the data that you want to perform your analyses on. Then, you perform your analyses on them, and save the results in the (probably) same directory.\nWhen you load a data set into R, you might use the readr package and do read_csv(absolute_file_path.csv). This becomes fairly painful if you need to read in more than one data set. Then, relative paths (i.e., where you start from a certain point in your file structure, e.g., your file folder) become more useful. How you CAN go across this is to use the setwd(absolute_file_path_to_your_directory) function. Here, set stands for set and wd stands for working directory. If you are not sure about what the current working directory actually is, you can use getwd() which is the equivalent to setwd(file_path). This enables you to read in a data set – if the file is in the working directory – by only using read_csv(file_name.csv).\nHowever, if you have ever worked on an R project with other people in a group and exchanged scripts regularly, you may have encountered one of the big problems with this setwd(file_path) approach: as it only takes absolute paths like this one: “/Users/felixlennert/Library/Mobile Documents/comappleCloudDocs/phd/teaching/hhs-stockholm/fall2021/scripts/”, no other person will be able to run this script without making any changes1. Just to be clear: there are no two machines which have the exact same file structure.\nThis is where RStudio Projects come into play: they make every file path relative. The Project file (ends with .Rproj) basically sets the working directory to the folder it is in. Hence, if you want to send your work to a peer or a teacher, just send a folder which also contains the .Rproj file and they will be able to work on your project without the hassle of pasting file paths into setwd() commands.\n\n\nHow to create an RStudio Project?\nI strongly suggest that you set up a project which is dedicated to this course.\n\nIn RStudio, click File &gt;&gt; New Project…\nA window pops up which lets you select between “New Directory”, “Existing Directory”, and “Version Control.” The first option creates a new folder which is named after your project, the second one “associates a project with an existing working directory,” and the third one only applies to version control (like, for instance, GitHub) users. I suggest that you click “New Directory”.\nNow you need to specify the type of the project (Empty project, R package, or Shiny Web Application). In our case, you will need a “new project.” Hit it!\n\nThe final step is to choose the folder the project will live in. If you have already created a folder which is dedicated to this course, choose this one, and let the project live in there as a sub-directory.\nWhen you write code for our course in the future, you first open the R project – by double-clicking the .Rproj file – and then create either a new script or open a former one (e.g., by going through the “Files” tab in the respective pane which will show the right directory already.)"
  },
  {
    "objectID": "2_r_catch-up.html#r-scripts-and-quarto",
    "href": "2_r_catch-up.html#r-scripts-and-quarto",
    "title": "Chapter 2: Brief R Recap",
    "section": "R scripts and Quarto",
    "text": "R scripts and Quarto\nIn this course, you will work with two sorts of documents to store your code in: R scripts (suffix .R) and Quarto documents (suffix .qmd). In the following, I will briefly introduce you to both of them.\n\nR scripts\nThe console, where you can only execute your code, is great for experimenting with R. If you want to store it – e.g., for sharing – you need something different. This is where R scripts come in handy. When you are in RStudio, you create a new script by either clicking File &gt;&gt; New File &gt;&gt; R Script or ctrl/cmd+shift+n. There are multiple ways to run code in the script:\n\ncmd/ctrl+return (Mac/Windows) – execute entire expression and jump to next line\n\noption/alt+return (Mac/Windows) – execute entire expression and remain in line\n\ncmd/ctrl+shift+return (Mac/Windows) – execute entire script from the beginning to the end (rule: every script you hand in or send to somebody else should run smoothly from the beginning to the end)\n\nIf you want to make annotations to your code (which you should do because it makes everything easier to read and understand), just insert ‘#’ into your code. Every expression that stands to the right of the ‘#’ sign will not be executed when you run the code.\n\n\nQuarto\nA time will come where you will not just do analyses for yourself in R, but you will also have to communicate them. Let’s take a master’s thesis as an example: you need a type of document that is able to encapsulate: text (properly formatted), visualizations (tables, graphs, maybe images), and references. An RMarkdown document can do it all, plus, your entire analysis can live in there as well. So there is no need anymore for the cumbersome process of copying data from MS Excel or IBM SPSS into an MS Word table. You just tell RMarkdown what it should communicate and what not.\nIn the following, I will not provide you with an exhaustive introduction to RMarkdown. Instead, I will focus on getting you started and then referring you to better, more exhaustive resources. It is not that I am too lazy to write a big tutorial, but there are state-of-the-art tutorials and resources (which mainly come straight from people who work on the forefront of the development of these tools) which are available for free. By linking to them, I want to encourage you to get involved and dig into this stuff. So, let’s get you started!\nYou create a Quarto document file by clicking File &gt;&gt; New File &gt;&gt; Quarto Document…. Then, a window pops up that looks like this:\n\n\n\nNew Quarto\n\n\nNote that you could also do a presentation (with the beamer package), a shiny app, a website (like this one), or use templates. We will focus on simple Quarto documents. Here, you can type in a title, the name(s) of the author(s), and choose the default output format. For now you have to choose one, but later you can switch to one of the others whenever you want to.\n\nHTML is handy for lightweight, quickly rendered files, or if you want to publish it on a website.\nPDF is good if you are experienced with LaTeX and want to further modify it in terms of formatting etc., or simply want to get a more formally looking document (I use it if I need to hand in something that is supposed to be graded). If you want to knit to PDF, you need a running LaTeX version on your machine. If you do not have one, I recommend you to install tinytex. I linked installation instructions down below.\nWord puts out an MS Word document – especially handy if you collaborate with people who are either not experienced in R, like older faculty, or want some parts to be proof-read (remember the Track-Changes function?). Note that you need to have MS Word or LibreOffice installed on your machine.\n\nDid you notice the term render? The logic behind Quarto documents is that you edit them in RStudio and then render them. This means that it calls the knitr package. Thereby, all the code you include into the document is executed from scratch. If the code does not work and throws an error, the document will not knit – hence, it needs to be properly written to avoid head-scratching. The knitr package creates a markdown file (suffix: .md). This is then processed by pandoc, a universal document converter. The big advantage of this two-step approach is that it enables a wide range of output formats.\nFor your first Quarto document, choose HTML and click “OK”. Then, you see a new plain-text file which looks like this:\n\n\n\nA fresh and clean Quarto document\n\n\nThe visual editor is quite similar to what we know from word processing software such as Microsoft Word. I will run you through the features in a quick video.\n\n\nFurther links\n\nChapter on Scripts and Projects in R4DS\nMore on RStudio Projects on the posit website\nChapter on Quarto in R4DS\nAll things Quarto on its dedicated website\nYihui Xie published a manual for installing the tinytex package\n\n\n\nExercises\n\nCreate a project for this course.\nCreate a Quarto file to work on the exercises. Add the exercises and answer them in code in the document.\nRender it. Does it work?"
  },
  {
    "objectID": "2_r_catch-up.html#reading-data-into-r",
    "href": "2_r_catch-up.html#reading-data-into-r",
    "title": "Chapter 2: Brief R Recap",
    "section": "Reading data into R",
    "text": "Reading data into R\nData is typically stored in csv-files and can be read in using readr. For “normal,” comma-separated values read_csv(\"file_path\") suffices. Sometimes, a semicolon is used instead of a comma (e.g., in countries that use the commas as a decimal sign). For these files, read_csv2(\"file_path) is the way to go.\nIf you encounter other data types, you just need to find the right tidyverse package to read the data in. Their syntax will be the same, it will just be the function names that differ.\n\nFurther links\n\nthe section on reading in data in R4DS\n\n\n\nExercises\nFirst, download and extract the zip file by clicking the link. Then…\nRead them in using the right functions. Specify the parameters properly. Hints can be found in hints.md. Each file should be stored in an object, names should correspond to the file names.\nNote: this is challenging, absolutely. If you have problems, try to google the different functions and think about what the different parameters indicate. If that is to no avail, send me an e-mail. I am very happy to provide you further assistance."
  },
  {
    "objectID": "2_r_catch-up.html#tidy-data-with-tidyr",
    "href": "2_r_catch-up.html#tidy-data-with-tidyr",
    "title": "Chapter 2: Brief R Recap",
    "section": "Tidy data with tidyr",
    "text": "Tidy data with tidyr\nBefore you learn how to tidy and wrangle data, you need to know how you want your data set to actually look like, i.e., what the desired outcome of the entire process of tidying your data set is. The tidyverse is a collection of packages which share an underlying philosophy: they are tidy. This means, that they (preferably) take tidy data as inputs and output tidy data. In the following, I will, first, introduce you to the concept of tidy data as developed by Hadley Wickham (Wickham 2014). Second, tidyr is introduced (Wickham 2020b). Its goal is to provide you with functions that facilitate tidying data sets. Beyond, I will provide you some examples of how to create tibbles using functions from the tibble package (Müller, Wickham, and François 2020). Moreover, the pipe is introduced.\nPlease note that tidying and cleaning data are not equivalent: I refer to tidying data as to bringing data in a tidy format. Cleaning data, however, can encompass way more than this: parsing columns in the right format (using readr, for instance), imputation of missing values, address the problem of typos, etc.\n\nThe concept of tidy data\ndata sets can be structured in many ways. To make them tidy, they must be organized in the following way (this is taken from the R for Data Science book (Wickham and Grolemund 2016)):\n\nEach variable must have its own column.\n\nEach observation must have its own row.\n\nEach value must have its own cell.\n\nThey can even be boiled further down:\n\nPut each data set in a tibble.\nPut each variable in a column.\n\nThis can also be visually depicted:\n\n\n\nThe three rules that make a data set tidy (taken from Wickham and Grolemund 2016: 149)\n\n\nThis way of storing data has two big advantages:\n\nyou can easily access, and hence manipulate, variables as vectors\nif you perform vectorized operations on the tibble, cases are preserved.\n\n\n\nMaking messy data tidy\nSo what are the most common problems with data sets? The following list is taken from the tidyr vignette2:\n\nColumn headers are values, not variable names.\n\nVariables are stored in both rows and columns.\n\nMultiple variables are stored in one column.\n\nMultiple types of observational units are stored in the same table.\n\nA single observational unit is stored in multiple tables.\n\nI will go across the former three types of problems, because the latter two require some more advanced data wrangling techniques you haven’t learned yet (i.e., functions from the dplyr package: select(), mutate(), left_join(), among others).\nIn the following, I will provide you with examples on how this might look like and how you can address the respective problem using functions from the tidyr package. This will serve as an introduction to the two most important functions of the tidyr package: pivot_longer() and its counterpart pivot_wider(). Beyond that, separate() will be introduced as well. At the beginning of every part, I will build the tibble using functions from the tibble package. This should suffice as a quick refresher for and introduction to creating tibbles.\ntidyr has some more functions in stock. They do not necessarily relate to transforming messy data sets into tidy ones, but also serve you well for some general cleaning tasks. They will be introduced, too.\n\nColumn headers are values\nA data set of this form would look like this:\n\ntibble_value_headers &lt;- tibble(\n  manufacturer = c(\"Audi\", \"BMW\", \"Mercedes\", \"Opel\", \"VW\"),\n  `3 cyl` = sample(20, 5, replace = TRUE),\n  `4 cyl` = sample(50:100, 5, replace = TRUE),\n  `5 cyl` = sample(10, 5, replace = TRUE),\n  `6 cyl` = sample(30:50, 5, replace = TRUE),\n  `8 cyl` = sample(20:40, 5, replace = TRUE),\n  `10 cyl` = sample(10, 5, replace = TRUE),\n  `12 cyl` = sample(20, 5, replace = TRUE),\n  `16 cyl` = rep(0, 5)\n)\n\ntibble_value_headers\n\n# A tibble: 5 × 9\n  manufacturer `3 cyl` `4 cyl` `5 cyl` `6 cyl` `8 cyl` `10 cyl` `12 cyl`\n  &lt;chr&gt;          &lt;int&gt;   &lt;int&gt;   &lt;int&gt;   &lt;int&gt;   &lt;int&gt;    &lt;int&gt;    &lt;int&gt;\n1 Audi              12      65       1      48      39        8        1\n2 BMW               19      94       4      36      31        4       14\n3 Mercedes           4      79       5      36      33        6        9\n4 Opel              15      50       9      30      34        9       14\n5 VW                15      89       1      47      22        6       11\n# ℹ 1 more variable: `16 cyl` &lt;dbl&gt;\n\n\nYou can create a tibble by column using the tibble function. Column names need to be specified and linked to vectors of either the same length or length one.\nThis data set basically consists of three variables: German car manufacturer, number of cylinders, and frequency. To make the data set tidy, it has to consist of three columns depicting the three respective variables. This operation is called pivoting the non-variable columns into two-column key-value pairs. As the data set will thereafter contain fewer columns and more rows than before, it will have become longer (or taller). Hence, the tidyr function is called pivot_longer().\n\nger_car_manufacturer_longer &lt;- tibble_value_headers |&gt; \n  pivot_longer(-manufacturer, names_to = \"cylinders\", values_to = \"frequency\")\nger_car_manufacturer_longer\n\n# A tibble: 40 × 3\n   manufacturer cylinders frequency\n   &lt;chr&gt;        &lt;chr&gt;         &lt;dbl&gt;\n 1 Audi         3 cyl            12\n 2 Audi         4 cyl            65\n 3 Audi         5 cyl             1\n 4 Audi         6 cyl            48\n 5 Audi         8 cyl            39\n 6 Audi         10 cyl            8\n 7 Audi         12 cyl            1\n 8 Audi         16 cyl            0\n 9 BMW          3 cyl            19\n10 BMW          4 cyl            94\n# ℹ 30 more rows\n\n\nIn the function call, you need to specify the following: if you were not to use the pipe, the first argument would be the tibble you are manipulating. Then, you look at the column you want to keep. Here, it is the car manufacturer. This means that all columns but manufacturer will be crammed into two new ones: one will contain the columns’ names, the other one their values. How are those new column supposed to be named? That can be specified in the names_to = and values_to =arguments. Please note that you need to provide them a character vector, hence, surround your parameters with quotation marks. As a rule of thumb for all tidyverse packages: If it is a new column name you provide, surround it with quotation marks. If it is one that already exists – like, here, manufacturer, then you do not need the quotation marks.\n\n\nVariables in both rows and columns\nYou have this data set:\n\ncar_models_fuel &lt;- tribble(\n  ~manufacturer, ~model, ~cylinders, ~fuel_consumption_type, ~fuel_consumption_per_100km,\n  \"VW\", \"Golf\", 4, \"urban\", 5.2,\n  \"VW\", \"Golf\", 4, \"extra urban\", 4.5,\n  \"Opel\", \"Adam\", 4, \"urban\", 4.9,\n  \"Opel\", \"Adam\", 4, \"extra urban\", 4.1\n  )\ncar_models_fuel\n\n# A tibble: 4 × 5\n  manufacturer model cylinders fuel_consumption_type fuel_consumption_per_100km\n  &lt;chr&gt;        &lt;chr&gt;     &lt;dbl&gt; &lt;chr&gt;                                      &lt;dbl&gt;\n1 VW           Golf          4 urban                                        5.2\n2 VW           Golf          4 extra urban                                  4.5\n3 Opel         Adam          4 urban                                        4.9\n4 Opel         Adam          4 extra urban                                  4.1\n\n\nIt was created using the tribble function: tibbles can also be created by row. First, the column names need to be specified by putting a tilde (~) in front of them. Then, you can put in values separated by commas. Please note that the number of values needs to be a multiple of the number of columns.\nIn this data set, there are basically five variables: manufacturer, model, cylinders, urban fuel consumption, and extra urban fuel consumption. However, the column fuel_consumption_type does not store a variable but the names of two variables. Hence, you need to fix this to make the data set tidy. Because this encompasses reducing the number of rows, the data set becomes wider. The function to achieve this is therefore called pivot_wider() and the inverse of pivot_longer().\n\ncar_models_fuel_tidy &lt;- car_models_fuel |&gt; \n  pivot_wider(\n    names_from = fuel_consumption_type, \n    values_from = fuel_consumption_per_100km\n    )\n\ncar_models_fuel_tidy\n\n# A tibble: 2 × 5\n  manufacturer model cylinders urban `extra urban`\n  &lt;chr&gt;        &lt;chr&gt;     &lt;dbl&gt; &lt;dbl&gt;         &lt;dbl&gt;\n1 VW           Golf          4   5.2           4.5\n2 Opel         Adam          4   4.9           4.1\n\n\nHere, you only need to specify the columns you fetch the names and values from. As they both do already exist, you do not need to wrap them in quotation marks.\n\n\nMultiple variables in one column\nNow, however, there is a problem with the cylinders: their number should be depicted in a numeric vector. We could achieve this by either parsing it to a numeric vector:\n\nger_car_manufacturer_longer$cylinders &lt;- parse_number(ger_car_manufacturer_longer$cylinders)\n\nOn the other hand, we can also use a handy function from tidyr called separate() and afterwards drop the unnecessary column:\n\nger_car_manufacturer_longer_sep_cyl &lt;- ger_car_manufacturer_longer |&gt; # first, take the tibble\n  separate(cylinders, into = c(\"cylinders\", \"drop_it\"), sep = \" \") |&gt; # and then split the column \"cylinders\" into two\n  select(-drop_it) # you will learn about this in the lesson on dplyr  # and then drop one column from the tibble\n\nWarning: Expected 2 pieces. Missing pieces filled with `NA` in 40 rows [1, 2, 3, 4, 5,\n6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, ...].\n\n\nIf there are two (or actually more) relevant values in one column, you can simply let out the dropping process and easily split them into multiple columns. By default, the sep = argument divides the content by all non-alphanumeric characters (every character that is not a letter, number, or space) it contains.\nPlease note that the new column is still in character format. We can change this using as.numeric():\n\nger_car_manufacturer_longer_sep_cyl$cylinders &lt;- as.numeric(ger_car_manufacturer_longer_sep_cyl$cylinders)\n\nFurthermore, you might want to sort your data in a different manner. If you want to do this by cylinders, it would look like this:\n\narrange(ger_car_manufacturer_longer_sep_cyl, cylinders)\n\n# A tibble: 40 × 3\n   manufacturer cylinders frequency\n   &lt;chr&gt;            &lt;dbl&gt;     &lt;dbl&gt;\n 1 Audi                 3        12\n 2 BMW                  3        19\n 3 Mercedes             3         4\n 4 Opel                 3        15\n 5 VW                   3        15\n 6 Audi                 4        65\n 7 BMW                  4        94\n 8 Mercedes             4        79\n 9 Opel                 4        50\n10 VW                   4        89\n# ℹ 30 more rows\n\n\n\n\n\nInsertion: the pipe\nHave you noticed the |&gt;? That’s the pipe. It can be considered a conjunction in coding. Usually, you will use it when working with tibbles. What it does is pretty straight-forward: it takes what is on its left – the input – and provides it to the function on its right as the first argument. Hence, the code in the last chunk, which looks like this\n\narrange(ger_car_manufacturer_longer_sep_cyl, cylinders)\n\n# A tibble: 40 × 3\n   manufacturer cylinders frequency\n   &lt;chr&gt;            &lt;dbl&gt;     &lt;dbl&gt;\n 1 Audi                 3        12\n 2 BMW                  3        19\n 3 Mercedes             3         4\n 4 Opel                 3        15\n 5 VW                   3        15\n 6 Audi                 4        65\n 7 BMW                  4        94\n 8 Mercedes             4        79\n 9 Opel                 4        50\n10 VW                   4        89\n# ℹ 30 more rows\n\n\ncould have also been written like this\n\nger_car_manufacturer_longer_sep_cyl |&gt; arrange(cylinders)\n\n# A tibble: 40 × 3\n   manufacturer cylinders frequency\n   &lt;chr&gt;            &lt;dbl&gt;     &lt;dbl&gt;\n 1 Audi                 3        12\n 2 BMW                  3        19\n 3 Mercedes             3         4\n 4 Opel                 3        15\n 5 VW                   3        15\n 6 Audi                 4        65\n 7 BMW                  4        94\n 8 Mercedes             4        79\n 9 Opel                 4        50\n10 VW                   4        89\n# ℹ 30 more rows\n\n\nbecause the tibble is the first argument in the function call.\nBecause the pipe (its precedessor was %&gt;%) has really gained traction in the R community, many functions are now optimized for being used with the pipe. However, there are still some around which are not. A function for fitting a basic linear model with one dependent and one independent variable which are both stored in a tibble looks like this: lm(formula = dv ~ iv, data = tibble). Here, the tibble is not the first argument. To be able to fit a linear model in a “pipeline,” you need to employ a little hack: you can use an underscore _ as a placeholder. Here, it is important that the argument is named.\nLet’s check out the effect the number of cylinders has on the number of models:\n\nger_car_manufacturer_longer_sep_cyl |&gt; \n  lm(frequency ~ cylinders, data = _) |&gt; \n  summary()\n\n\nCall:\nlm(formula = frequency ~ cylinders, data = ger_car_manufacturer_longer_sep_cyl)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-33.174 -14.016   0.978   9.000  59.761 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  45.9783     7.6060   6.045 4.94e-07 ***\ncylinders    -2.9348     0.8438  -3.478  0.00128 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 22.17 on 38 degrees of freedom\nMultiple R-squared:  0.2415,    Adjusted R-squared:  0.2215 \nF-statistic:  12.1 on 1 and 38 DF,  p-value: 0.001282\n\n\nAs |&gt; is a bit tedious to type, a shortcut exists: shift-ctrl-m.\n\n\nSplitting and merging cells\nIf there are multiple values in one column/cell and you want to split them and put them into two rows instead of columns, tidyr offers you the separate_rows() function.\n\ngerman_cars_vec &lt;- c(Audi = \"A1, A3, A4, A5, A6, A7, A8\", \n                     BMW = \"1 Series, 2 Series, 3 Series, 4 Series, 5 Series, 6 Series, 7 Series, 8 Series\")\ngerman_cars_tbl &lt;- enframe(\n  german_cars_vec, \n  name = \"brand\", \n  value = \"model\"\n  )\n\ngerman_cars_tbl\n\n# A tibble: 2 × 2\n  brand model                                                                   \n  &lt;chr&gt; &lt;chr&gt;                                                                   \n1 Audi  A1, A3, A4, A5, A6, A7, A8                                              \n2 BMW   1 Series, 2 Series, 3 Series, 4 Series, 5 Series, 6 Series, 7 Series, 8…\n\ntidy_german_cars_tbl &lt;- german_cars_tbl |&gt; \n  separate_rows(model, sep = \", \")\n\nenframe() enables you to create a tibble from a (named) vector. It outputs a tibble with two columns (name and value by default): name contains the names of the elements (if the elements are unnamed, it contains a serial number), value the element. Both can be renamed in the function call by providing a character vector.\nIf you want to achieve the opposite, i.e., merge cells’ content, you can use the counterpart, unite(). Let’s take the following dataframe which consists of the names of the professors of the Institute for Political Science of the University of Regensburg:\n\nprofessor_names_df &lt;- data.frame(first_name = c(\"Karlfriedrich\", \"Martin\", \"Jerzy\", \"Stephan\", \"Melanie\"),\n                                 last_name = c(\"Herb\", \"Sebaldt\", \"Maćków\", \"Bierling\", \"Walter-Rogg\"))\n\nprofessor_names_tbl &lt;- professor_names_df |&gt; \n  as_tibble() |&gt; \n  unite(first_name, last_name, col = \"name\", sep = \" \", remove = TRUE, na.rm = FALSE)\n\nprofessor_names_tbl\n\n# A tibble: 5 × 1\n  name               \n  &lt;chr&gt;              \n1 Karlfriedrich Herb \n2 Martin Sebaldt     \n3 Jerzy Maćków       \n4 Stephan Bierling   \n5 Melanie Walter-Rogg\n\n\nunite() takes the tibble it should be applied to as the first argument (not necessary if you use the pipe). Then, it takes the two or more columns as arguments (actually, this is not necessary if you want to unite all columns). col = takes a character vector to specify the name of the resulting, new column. remove = TRUE indicates that the columns that are united are removed as well. You can, of course, set it to false, too. na.rm = FALSE finally indicates that missing values are not to be removed prior to the uniting process.\nHere, the final variant of creating tibbles is introduced as well: you can apply the function as_tibble() to a data frame and it will then be transformed into a tibble.\n\n\nFurther links\n\nHadley on tidy data\n\nThe two pivot_*() functions lie at the heart of tidyr. This article from the Northeastern University’s School of Journalism explains it in further detail.\n\n\n\nExercises\nBring the data sets you read into R in the “Reading data in R” section into a tidy format. Store the tidy data sets in a new object, named like the former object plus the suffix “_tidy” – e.g., books_tidy. If no tidying is needed, you do not have to create a new object. The pipe operator should be used to connect the different steps."
  },
  {
    "objectID": "2_r_catch-up.html#wrangling-data-with-dplyr",
    "href": "2_r_catch-up.html#wrangling-data-with-dplyr",
    "title": "Chapter 2: Brief R Recap",
    "section": "Wrangling data with dplyr",
    "text": "Wrangling data with dplyr\nThe last chapter showed you four things: how you get data sets into R, a couple of ways to create tibbles, how to pass data to functions using the pipe (|&gt;), and an introduction to tidy data and how to make data sets tidy using the tidyr package (Wickham 2020b). What you haven’t learned was how you can actually manipulate the data themselves. In the tidyverse framework (Wickham et al. 2019), the package which enables you to accomplish those tasks is dplyr (Wickham 2020a).\ndplyr joined the party in 2014, building upon the plyr package. The d in dplyr stands for data set and dplyr works with tibbles (or data frames) only.\nIt consists of five main functions, the “verbs”:\n\narrange() – sort values\nfilter() – pick observations\nmutate() – create new variables (columns)\nselect() – select variables\nsummarize() – create summaries from multiple values\n\nThey are joined by group_by(), a function that changes the scope on which entities the functions are applied to.\nFurthermore, diverse bind_ functions and _joins enable you to combine multiple tibbles into one. They will be introduced later.\nIn the following, I will guide you through how you can use the verbs to accomplish whatever goals which require data wrangling you might have.\nThe data set I will use here consists of the 1,000 most popular movies on IMDb which were published between 2006 and 2016 and some data on them. It was created by PromptCloud and DataStock and published on Kaggle, more information can be found here.\n\nimdb_raw &lt;- read_csv(\"data/imdb2006-2016.csv\")\n\nThe data set hasn’t been modified by me before. I will show you how I would go across it using a couple of dplyr functions.\n\nselect()\nselect enables you to select columns. Since we are dealing with tidy data, every variable has its own column.\nglimpse() provides you with an overview of the data set and its columns.\n\nglimpse(imdb_raw)\n\nRows: 1,000\nColumns: 12\n$ Rank                 &lt;dbl&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15…\n$ Title                &lt;chr&gt; \"Guardians of the Galaxy\", \"Prometheus\", \"Split\",…\n$ Genre                &lt;chr&gt; \"Action,Adventure,Sci-Fi\", \"Adventure,Mystery,Sci…\n$ Description          &lt;chr&gt; \"A group of intergalactic criminals are forced to…\n$ Director             &lt;chr&gt; \"James Gunn\", \"Ridley Scott\", \"M. Night Shyamalan…\n$ Actors               &lt;chr&gt; \"Chris Pratt, Vin Diesel, Bradley Cooper, Zoe Sal…\n$ Year                 &lt;dbl&gt; 2014, 2012, 2016, 2016, 2016, 2016, 2016, 2016, 2…\n$ `Runtime (Minutes)`  &lt;dbl&gt; 121, 124, 117, 108, 123, 103, 128, 89, 141, 116, …\n$ Rating               &lt;dbl&gt; 8.1, 7.0, 7.3, 7.2, 6.2, 6.1, 8.3, 6.4, 7.1, 7.0,…\n$ Votes                &lt;dbl&gt; 757074, 485820, 157606, 60545, 393727, 56036, 258…\n$ `Revenue (Millions)` &lt;dbl&gt; 333.13, 126.46, 138.12, 270.32, 325.02, 45.13, 15…\n$ Metascore            &lt;dbl&gt; 76, 65, 62, 59, 40, 42, 93, 71, 78, 41, 66, 74, 6…\n\n\nThe columns I want to keep are: Title, Director, Year, Runtime (Minutes), Rating, Votes, and Revenue (Millions). Furthermore, I want to rename the columns: every column’s name should be in lowercase and a regular name that does not need to be surrounded by back ticks – i.e., a name that only consists of characters, numbers, underscores, or dots.\nThis can be achieved in a couple of ways:\nFirst, by choosing the columns column by column and subsequently renaming them:\n\nimdb_raw |&gt; \n  select(Title, Director, Year, `Runtime (Minutes)`, Rating, Votes, `Revenue (Millions)`) |&gt; \n  rename(title = Title, director = Director, year = Year, runtime = `Runtime (Minutes)`, rating = Rating, votes = Votes, revenue_million = `Revenue (Millions)`) |&gt; \n  glimpse()\n\nRows: 1,000\nColumns: 7\n$ title           &lt;chr&gt; \"Guardians of the Galaxy\", \"Prometheus\", \"Split\", \"Sin…\n$ director        &lt;chr&gt; \"James Gunn\", \"Ridley Scott\", \"M. Night Shyamalan\", \"C…\n$ year            &lt;dbl&gt; 2014, 2012, 2016, 2016, 2016, 2016, 2016, 2016, 2016, …\n$ runtime         &lt;dbl&gt; 121, 124, 117, 108, 123, 103, 128, 89, 141, 116, 133, …\n$ rating          &lt;dbl&gt; 8.1, 7.0, 7.3, 7.2, 6.2, 6.1, 8.3, 6.4, 7.1, 7.0, 7.5,…\n$ votes           &lt;dbl&gt; 757074, 485820, 157606, 60545, 393727, 56036, 258682, …\n$ revenue_million &lt;dbl&gt; 333.13, 126.46, 138.12, 270.32, 325.02, 45.13, 151.06,…\n\n\nSecond, the columns can also be chosen vice versa: unnecessary columns can be dropped using a minus:\n\nimdb_raw |&gt; \n  select(-Rank, -Genre, -Description, -Actors, -Metascore) |&gt; \n  rename(title = Title, director = Director, year = Year, runtime = `Runtime (Minutes)`, rating = Rating, votes = Votes, revenue_million = `Revenue (Millions)`) |&gt; \n  glimpse()\n\nRows: 1,000\nColumns: 7\n$ title           &lt;chr&gt; \"Guardians of the Galaxy\", \"Prometheus\", \"Split\", \"Sin…\n$ director        &lt;chr&gt; \"James Gunn\", \"Ridley Scott\", \"M. Night Shyamalan\", \"C…\n$ year            &lt;dbl&gt; 2014, 2012, 2016, 2016, 2016, 2016, 2016, 2016, 2016, …\n$ runtime         &lt;dbl&gt; 121, 124, 117, 108, 123, 103, 128, 89, 141, 116, 133, …\n$ rating          &lt;dbl&gt; 8.1, 7.0, 7.3, 7.2, 6.2, 6.1, 8.3, 6.4, 7.1, 7.0, 7.5,…\n$ votes           &lt;dbl&gt; 757074, 485820, 157606, 60545, 393727, 56036, 258682, …\n$ revenue_million &lt;dbl&gt; 333.13, 126.46, 138.12, 270.32, 325.02, 45.13, 151.06,…\n\n\nColumns can also be renamed in the selecting process:\n\nimdb_raw |&gt; \n  select(title = Title, director = Director, year = Year, runtime = `Runtime (Minutes)`, rating = Rating, votes = Votes, revenue_million = `Revenue (Millions)`) |&gt; \n  glimpse()\n\nRows: 1,000\nColumns: 7\n$ title           &lt;chr&gt; \"Guardians of the Galaxy\", \"Prometheus\", \"Split\", \"Sin…\n$ director        &lt;chr&gt; \"James Gunn\", \"Ridley Scott\", \"M. Night Shyamalan\", \"C…\n$ year            &lt;dbl&gt; 2014, 2012, 2016, 2016, 2016, 2016, 2016, 2016, 2016, …\n$ runtime         &lt;dbl&gt; 121, 124, 117, 108, 123, 103, 128, 89, 141, 116, 133, …\n$ rating          &lt;dbl&gt; 8.1, 7.0, 7.3, 7.2, 6.2, 6.1, 8.3, 6.4, 7.1, 7.0, 7.5,…\n$ votes           &lt;dbl&gt; 757074, 485820, 157606, 60545, 393727, 56036, 258682, …\n$ revenue_million &lt;dbl&gt; 333.13, 126.46, 138.12, 270.32, 325.02, 45.13, 151.06,…\n\n\nYou can also make your expressions shorter by using a couple of hacks:\n: can be used to select all columns between two:\n\nimdb_raw |&gt; \n  select(Title, Director, Year:`Revenue (Millions)`) |&gt; \n  rename(title = Title, director = Director, year = Year, runtime = `Runtime (Minutes)`, rating = Rating, votes = Votes, revenue_million = `Revenue (Millions)`) |&gt; \n  glimpse()\n\nRows: 1,000\nColumns: 7\n$ title           &lt;chr&gt; \"Guardians of the Galaxy\", \"Prometheus\", \"Split\", \"Sin…\n$ director        &lt;chr&gt; \"James Gunn\", \"Ridley Scott\", \"M. Night Shyamalan\", \"C…\n$ year            &lt;dbl&gt; 2014, 2012, 2016, 2016, 2016, 2016, 2016, 2016, 2016, …\n$ runtime         &lt;dbl&gt; 121, 124, 117, 108, 123, 103, 128, 89, 141, 116, 133, …\n$ rating          &lt;dbl&gt; 8.1, 7.0, 7.3, 7.2, 6.2, 6.1, 8.3, 6.4, 7.1, 7.0, 7.5,…\n$ votes           &lt;dbl&gt; 757074, 485820, 157606, 60545, 393727, 56036, 258682, …\n$ revenue_million &lt;dbl&gt; 333.13, 126.46, 138.12, 270.32, 325.02, 45.13, 151.06,…\n\n\nstarts_with() select columns whose names start with the same character string:\n\nimdb_selected &lt;- imdb_raw |&gt; \n  select(Title, Director, Votes, Year, starts_with(\"R\")) |&gt; \n  select(-Rank) |&gt; \n  rename(title = Title, director = Director, year = Year, runtime = `Runtime (Minutes)`, rating = Rating, votes = Votes, revenue_million = `Revenue (Millions)`) |&gt; \n  glimpse()\n\nRows: 1,000\nColumns: 7\n$ title           &lt;chr&gt; \"Guardians of the Galaxy\", \"Prometheus\", \"Split\", \"Sin…\n$ director        &lt;chr&gt; \"James Gunn\", \"Ridley Scott\", \"M. Night Shyamalan\", \"C…\n$ votes           &lt;dbl&gt; 757074, 485820, 157606, 60545, 393727, 56036, 258682, …\n$ year            &lt;dbl&gt; 2014, 2012, 2016, 2016, 2016, 2016, 2016, 2016, 2016, …\n$ runtime         &lt;dbl&gt; 121, 124, 117, 108, 123, 103, 128, 89, 141, 116, 133, …\n$ rating          &lt;dbl&gt; 8.1, 7.0, 7.3, 7.2, 6.2, 6.1, 8.3, 6.4, 7.1, 7.0, 7.5,…\n$ revenue_million &lt;dbl&gt; 333.13, 126.46, 138.12, 270.32, 325.02, 45.13, 151.06,…\n\n\nAs you may have noticed, the order in the select() matters: columns will be ordered in the same order as they are chosen.\nA couple of further shortcuts for select() do exist. An overview can be found in the dplyr cheatsheet.\n\n\nfilter()\nWhereas select() enables you to choose variables (i.e., columns), filter() lets you choose observations (i.e., rows).\nIn this case, I only want movies with a revenue above $100,000,000:\n\nimdb_selected |&gt; \n  filter(revenue_million &gt; 100) |&gt; \n  glimpse()\n\nRows: 250\nColumns: 7\n$ title           &lt;chr&gt; \"Guardians of the Galaxy\", \"Prometheus\", \"Split\", \"Sin…\n$ director        &lt;chr&gt; \"James Gunn\", \"Ridley Scott\", \"M. Night Shyamalan\", \"C…\n$ votes           &lt;dbl&gt; 757074, 485820, 157606, 60545, 393727, 258682, 192177,…\n$ year            &lt;dbl&gt; 2014, 2012, 2016, 2016, 2016, 2016, 2016, 2016, 2016, …\n$ runtime         &lt;dbl&gt; 121, 124, 117, 108, 123, 128, 116, 133, 127, 133, 107,…\n$ rating          &lt;dbl&gt; 8.1, 7.0, 7.3, 7.2, 6.2, 8.3, 7.0, 7.5, 7.8, 7.9, 7.7,…\n$ revenue_million &lt;dbl&gt; 333.13, 126.46, 138.12, 270.32, 325.02, 151.06, 100.01…\n\n\nBesides, I am especially interested in the director Christopher Nolan. Therefore, I want to look at movies that were directed by him and made more than $100,000,000:\n\nimdb_selected |&gt; \n  filter(revenue_million &gt; 100 & director == \"Christopher Nolan\") |&gt; \n  glimpse()\n\nRows: 4\nColumns: 7\n$ title           &lt;chr&gt; \"Interstellar\", \"The Dark Knight\", \"Inception\", \"The D…\n$ director        &lt;chr&gt; \"Christopher Nolan\", \"Christopher Nolan\", \"Christopher…\n$ votes           &lt;dbl&gt; 1047747, 1791916, 1583625, 1222645\n$ year            &lt;dbl&gt; 2014, 2008, 2010, 2012\n$ runtime         &lt;dbl&gt; 169, 152, 148, 164\n$ rating          &lt;dbl&gt; 8.6, 9.0, 8.8, 8.5\n$ revenue_million &lt;dbl&gt; 187.99, 533.32, 292.57, 448.13\n\n\nThe following overview is taken from the dplyr cheatsheet and shows the operators you can use in filter():\n\n\n\nOverview of comparison operators\n\n\n\nExemplary application\nTo demonstrate how a real-world application of this stuff could look like, I will now provide you a brief insight into my private life and how I organize movie nights. JK. You could definitely try this at home and surprise your loved ones with such hot applications. If you are brave and surprise your latest Tinder match with an .RDS file containing suggestions for Netflix&Chill, please let me know what their response looked like.\nTonight, I will hang out with a real nerd. Probably because they (nerds have all kinds of genders) know about my faible for R, they have sent me a vector containing a couple of movies we could watch tonight:\n\nset.seed(123) # guarantees that movie_vec will always be the same thing\nmovie_vec &lt;- imdb_raw$Title[sample(1000, 10, replace = FALSE)]\nmovie_vec\n\n [1] \"Mechanic: Resurrection\" \"Denial\"                 \"The Conjuring 2\"       \n [4] \"Birth of the Dragon\"    \"Warrior\"                \"Super\"                 \n [7] \"127 Hours\"              \"Dangal\"                 \"The Infiltrator\"       \n[10] \"Maleficent\"            \n\n\nHowever, I want to make a more informed decision and decide to obtain some more information on the movies from my IMDb data set:\n\nimdb_selected |&gt; \n  filter(title %in% movie_vec) |&gt; \n  glimpse()\n\nRows: 10\nColumns: 7\n$ title           &lt;chr&gt; \"Dangal\", \"The Conjuring 2\", \"Warrior\", \"Maleficent\", …\n$ director        &lt;chr&gt; \"Nitesh Tiwari\", \"James Wan\", \"Gavin O'Connor\", \"Rober…\n$ votes           &lt;dbl&gt; 48969, 137203, 355722, 268877, 43929, 48161, 8229, 552…\n$ year            &lt;dbl&gt; 2016, 2016, 2011, 2014, 2016, 2016, 2016, 2016, 2010, …\n$ runtime         &lt;dbl&gt; 161, 134, 140, 97, 127, 98, 109, 103, 94, 96\n$ rating          &lt;dbl&gt; 8.8, 7.4, 8.2, 7.0, 7.1, 5.6, 6.6, 3.9, 7.6, 6.8\n$ revenue_million &lt;dbl&gt; 11.15, 102.46, 13.65, 241.41, 15.43, 21.20, 4.07, 93.0…\n\n\nI have convinced them to watch either one of the movies they have suggested or one directed by Christopher Nolan or one with a rating greater or equal to 8.5 and send them back this data set:\n\nimdb_selected |&gt; \n  filter(title %in% movie_vec | director == \"Christopher Nolan\" | rating &gt;= 8.5) |&gt; \n  glimpse()\n\nRows: 21\nColumns: 7\n$ title           &lt;chr&gt; \"Interstellar\", \"The Dark Knight\", \"The Prestige\", \"In…\n$ director        &lt;chr&gt; \"Christopher Nolan\", \"Christopher Nolan\", \"Christopher…\n$ votes           &lt;dbl&gt; 1047747, 1791916, 913152, 1583625, 34110, 937414, 4896…\n$ year            &lt;dbl&gt; 2014, 2008, 2006, 2010, 2016, 2006, 2016, 2012, 2014, …\n$ runtime         &lt;dbl&gt; 169, 152, 130, 148, 106, 151, 161, 164, 107, 134, 140,…\n$ rating          &lt;dbl&gt; 8.6, 9.0, 8.5, 8.8, 8.6, 8.5, 8.8, 8.5, 8.5, 7.4, 8.2,…\n$ revenue_million &lt;dbl&gt; 187.99, 533.32, 53.08, 292.57, 4.68, 132.37, 11.15, 44…\n\n\n“I deteste ‘Interstellar’,” is the response. “All right,” I say to myself, “I can easily exclude it.”\n\nimdb_selected |&gt; \n  filter(title %in% movie_vec | director == \"Christopher Nolan\" | rating &gt;= 8.5 & title != \"Interstellar\") |&gt; # if you want to negate something, put the ! in front of it\n  glimpse()\n\nRows: 21\nColumns: 7\n$ title           &lt;chr&gt; \"Interstellar\", \"The Dark Knight\", \"The Prestige\", \"In…\n$ director        &lt;chr&gt; \"Christopher Nolan\", \"Christopher Nolan\", \"Christopher…\n$ votes           &lt;dbl&gt; 1047747, 1791916, 913152, 1583625, 34110, 937414, 4896…\n$ year            &lt;dbl&gt; 2014, 2008, 2006, 2010, 2016, 2006, 2016, 2012, 2014, …\n$ runtime         &lt;dbl&gt; 169, 152, 130, 148, 106, 151, 161, 164, 107, 134, 140,…\n$ rating          &lt;dbl&gt; 8.6, 9.0, 8.5, 8.8, 8.6, 8.5, 8.8, 8.5, 8.5, 7.4, 8.2,…\n$ revenue_million &lt;dbl&gt; 187.99, 533.32, 53.08, 292.57, 4.68, 132.37, 11.15, 44…\n\n\nOh, that did not work. I should wrap them in columns:\n\nimdb_selected |&gt; \n  filter((title %in% movie_vec | director == \"Christopher Nolan\" | rating &gt;= 8.5) & title != \"Interstellar\") |&gt; \n  glimpse()\n\nRows: 20\nColumns: 7\n$ title           &lt;chr&gt; \"The Dark Knight\", \"The Prestige\", \"Inception\", \"Kimi …\n$ director        &lt;chr&gt; \"Christopher Nolan\", \"Christopher Nolan\", \"Christopher…\n$ votes           &lt;dbl&gt; 1791916, 913152, 1583625, 34110, 937414, 48969, 122264…\n$ year            &lt;dbl&gt; 2008, 2006, 2010, 2016, 2006, 2016, 2012, 2014, 2016, …\n$ runtime         &lt;dbl&gt; 152, 130, 148, 106, 151, 161, 164, 107, 134, 140, 97, …\n$ rating          &lt;dbl&gt; 9.0, 8.5, 8.8, 8.6, 8.5, 8.8, 8.5, 8.5, 7.4, 8.2, 7.0,…\n$ revenue_million &lt;dbl&gt; 533.32, 53.08, 292.57, 4.68, 132.37, 11.15, 448.13, 13…\n\n\nThey come up with a new idea: we have a Scottish evening with a movie directed by the Scottish director Gillies MacKinnon:\n\nimdb_selected |&gt; \n  filter(director == \"Gillies MacKinnon\") |&gt; \n  glimpse()\n\nRows: 1\nColumns: 7\n$ title           &lt;chr&gt; \"Whisky Galore\"\n$ director        &lt;chr&gt; \"Gillies MacKinnon\"\n$ votes           &lt;dbl&gt; 102\n$ year            &lt;dbl&gt; 2016\n$ runtime         &lt;dbl&gt; 98\n$ rating          &lt;dbl&gt; 5\n$ revenue_million &lt;dbl&gt; NA\n\n\n“Well, apparently there is a problem in the data set,” I notice. “There is an NA in the revenue column. I should probably have a further look at this.”\n\nimdb_selected |&gt; \n  filter(is.na(revenue_million)) |&gt; \n  glimpse()\n\nRows: 128\nColumns: 7\n$ title           &lt;chr&gt; \"Mindhorn\", \"Hounds of Love\", \"Paris pieds nus\", \"5- 2…\n$ director        &lt;chr&gt; \"Sean Foley\", \"Ben Young\", \"Dominique Abel\", \"Patrick …\n$ votes           &lt;dbl&gt; 2490, 1115, 222, 241, 496, 5103, 987, 35870, 149791, 7…\n$ year            &lt;dbl&gt; 2016, 2016, 2016, 2007, 2016, 2016, 2016, 2016, 2016, …\n$ runtime         &lt;dbl&gt; 89, 108, 83, 113, 73, 91, 130, 86, 133, 106, 105, 118,…\n$ rating          &lt;dbl&gt; 6.4, 6.7, 6.8, 7.1, 2.7, 5.6, 3.7, 6.8, 5.9, 7.9, 5.8,…\n$ revenue_million &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n\n\nWell, that’s quite a significant number of NAs. I will need to exclude these cases:\n\nimdb_selected |&gt; \n  filter(!is.na(revenue_million)) |&gt; \n  glimpse()\n\nRows: 872\nColumns: 7\n$ title           &lt;chr&gt; \"Guardians of the Galaxy\", \"Prometheus\", \"Split\", \"Sin…\n$ director        &lt;chr&gt; \"James Gunn\", \"Ridley Scott\", \"M. Night Shyamalan\", \"C…\n$ votes           &lt;dbl&gt; 757074, 485820, 157606, 60545, 393727, 56036, 258682, …\n$ year            &lt;dbl&gt; 2014, 2012, 2016, 2016, 2016, 2016, 2016, 2016, 2016, …\n$ runtime         &lt;dbl&gt; 121, 124, 117, 108, 123, 103, 128, 141, 116, 133, 127,…\n$ rating          &lt;dbl&gt; 8.1, 7.0, 7.3, 7.2, 6.2, 6.1, 8.3, 7.1, 7.0, 7.5, 7.8,…\n$ revenue_million &lt;dbl&gt; 333.13, 126.46, 138.12, 270.32, 325.02, 45.13, 151.06,…\n\n\n\n\nOther possibilities to subset observations\nslice() selects rows by positions:\n\nimdb_selected |&gt; \n  slice(1:10) |&gt; \n  glimpse()\n\nRows: 10\nColumns: 7\n$ title           &lt;chr&gt; \"Guardians of the Galaxy\", \"Prometheus\", \"Split\", \"Sin…\n$ director        &lt;chr&gt; \"James Gunn\", \"Ridley Scott\", \"M. Night Shyamalan\", \"C…\n$ votes           &lt;dbl&gt; 757074, 485820, 157606, 60545, 393727, 56036, 258682, …\n$ year            &lt;dbl&gt; 2014, 2012, 2016, 2016, 2016, 2016, 2016, 2016, 2016, …\n$ runtime         &lt;dbl&gt; 121, 124, 117, 108, 123, 103, 128, 89, 141, 116\n$ rating          &lt;dbl&gt; 8.1, 7.0, 7.3, 7.2, 6.2, 6.1, 8.3, 6.4, 7.1, 7.0\n$ revenue_million &lt;dbl&gt; 333.13, 126.46, 138.12, 270.32, 325.02, 45.13, 151.06,…\n\n\n\nimdb_selected |&gt; \n  slice_min(revenue_million, n = 10) |&gt; \n  glimpse()\n\nRows: 10\nColumns: 7\n$ title           &lt;chr&gt; \"A Kind of Murder\", \"Dead Awake\", \"Wakefield\", \"Loveso…\n$ director        &lt;chr&gt; \"Andy Goddard\", \"Phillip Guzman\", \"Robin Swicord\", \"So…\n$ votes           &lt;dbl&gt; 3305, 523, 291, 616, 80415, 10220, 36091, 54027, 4155,…\n$ year            &lt;dbl&gt; 2016, 2016, 2016, 2016, 2014, 2015, 2010, 2012, 2015, …\n$ runtime         &lt;dbl&gt; 95, 99, 106, 84, 102, 101, 98, 95, 93, 110\n$ rating          &lt;dbl&gt; 5.2, 4.7, 7.5, 6.4, 7.2, 5.9, 6.5, 6.9, 5.6, 5.9\n$ revenue_million &lt;dbl&gt; 0.00, 0.01, 0.01, 0.01, 0.01, 0.01, 0.02, 0.02, 0.02, …\n\n\ndistinct removes duplicate rows:\n\nimdb_selected |&gt; \n  distinct(director) |&gt; \n  glimpse()\n\nRows: 644\nColumns: 1\n$ director &lt;chr&gt; \"James Gunn\", \"Ridley Scott\", \"M. Night Shyamalan\", \"Christop…\n\n\nBy default, it will remove all other columns apart from the one(s) you have specified. You can avoid that by setting .keep_all = TRUE:\n\nimdb_selected |&gt; \n  distinct(title, .keep_all = TRUE) |&gt; \n  glimpse()\n\nRows: 999\nColumns: 7\n$ title           &lt;chr&gt; \"Guardians of the Galaxy\", \"Prometheus\", \"Split\", \"Sin…\n$ director        &lt;chr&gt; \"James Gunn\", \"Ridley Scott\", \"M. Night Shyamalan\", \"C…\n$ votes           &lt;dbl&gt; 757074, 485820, 157606, 60545, 393727, 56036, 258682, …\n$ year            &lt;dbl&gt; 2014, 2012, 2016, 2016, 2016, 2016, 2016, 2016, 2016, …\n$ runtime         &lt;dbl&gt; 121, 124, 117, 108, 123, 103, 128, 89, 141, 116, 133, …\n$ rating          &lt;dbl&gt; 8.1, 7.0, 7.3, 7.2, 6.2, 6.1, 8.3, 6.4, 7.1, 7.0, 7.5,…\n$ revenue_million &lt;dbl&gt; 333.13, 126.46, 138.12, 270.32, 325.02, 45.13, 151.06,…\n\n\nOh, interesting, there is apparently one movie which is in there twice. How could we find this movie?\n\n\n\nmutate()\nMy data set looks pretty nice already, but one flaw catches the eye: the column revenue_million should probably be converted to revenue. Hence, I need to create a new variable which contains the values from revenue_million multiplied by 1,000,000 and drop the now obsolete revenue_million.\n\nimdb_selected |&gt; \n  mutate(revenue = revenue_million * 1000000) |&gt; \n  select(-revenue_million) |&gt; \n  glimpse()\n\nRows: 1,000\nColumns: 7\n$ title    &lt;chr&gt; \"Guardians of the Galaxy\", \"Prometheus\", \"Split\", \"Sing\", \"Su…\n$ director &lt;chr&gt; \"James Gunn\", \"Ridley Scott\", \"M. Night Shyamalan\", \"Christop…\n$ votes    &lt;dbl&gt; 757074, 485820, 157606, 60545, 393727, 56036, 258682, 2490, 7…\n$ year     &lt;dbl&gt; 2014, 2012, 2016, 2016, 2016, 2016, 2016, 2016, 2016, 2016, 2…\n$ runtime  &lt;dbl&gt; 121, 124, 117, 108, 123, 103, 128, 89, 141, 116, 133, 127, 13…\n$ rating   &lt;dbl&gt; 8.1, 7.0, 7.3, 7.2, 6.2, 6.1, 8.3, 6.4, 7.1, 7.0, 7.5, 7.8, 7…\n$ revenue  &lt;dbl&gt; 333130000, 126460000, 138120000, 270320000, 325020000, 451300…\n\n\nThe structure of the mutate() call looks like this: first, you need to provide the name of the new variable. If the variable exists already, it will be replaced. Second, the equal sign tells R what the new variable should contain. Third, a function that outputs a vector which is as long as the tibble has rows or 1.\nIf we want to drop all other columns and just keep the new one: transmute() drops all the original columns.\n\nimdb_selected |&gt; \n  transmute(revenue = revenue_million * 1000000) |&gt; \n  glimpse()\n\nRows: 1,000\nColumns: 1\n$ revenue &lt;dbl&gt; 333130000, 126460000, 138120000, 270320000, 325020000, 4513000…\n\n\nmutate() uses so-called window functions. They take one vector of values and return another vector of values. An overview – again, from the cheat sheet:\n\n\n\nWindow functions\n\n\nAnother feature of dplyr, which is useful in combination with mutate(), is case_when().\ncase_when() can for instance be used to create binary indicator variables. In this example I want it to be 0 if the movie was made before 2010 and 1 if not. case_when() works like this: first, you provide a condition (e.g., year &lt; 2010). Second, you provide what the output should be if the condition is met (here, 0). Third, you can provide as many conditions as you want. Finally, you can provide a default value using TRUE ~ value. If none of the conditions are met, the default value will be assigned.\n\nimdb_selected |&gt; \n  mutate(indicator = case_when(year &lt; 2010 ~ 0,\n                               year &gt;= 2010 ~ 1,\n                               TRUE ~ 2)) |&gt; \n  glimpse()\n\nRows: 1,000\nColumns: 8\n$ title           &lt;chr&gt; \"Guardians of the Galaxy\", \"Prometheus\", \"Split\", \"Sin…\n$ director        &lt;chr&gt; \"James Gunn\", \"Ridley Scott\", \"M. Night Shyamalan\", \"C…\n$ votes           &lt;dbl&gt; 757074, 485820, 157606, 60545, 393727, 56036, 258682, …\n$ year            &lt;dbl&gt; 2014, 2012, 2016, 2016, 2016, 2016, 2016, 2016, 2016, …\n$ runtime         &lt;dbl&gt; 121, 124, 117, 108, 123, 103, 128, 89, 141, 116, 133, …\n$ rating          &lt;dbl&gt; 8.1, 7.0, 7.3, 7.2, 6.2, 6.1, 8.3, 6.4, 7.1, 7.0, 7.5,…\n$ revenue_million &lt;dbl&gt; 333.13, 126.46, 138.12, 270.32, 325.02, 45.13, 151.06,…\n$ indicator       &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, …\n\n\nKeep in mind that you can throw any function into mutate() as long as it is vectorized and the output has the same length as the tibble or 1.\ncase_when() also has a sibling called case_match(). It is used when you want to create a new variable based on the values of a categorical variable. It works similar to case_when(), but instead of providing conditions, you provide the exact values you want to match. case_match() provides a cleaner syntax when you’re matching exact values. It’s particularly useful when you want to recode or map specific values to new ones.\n\nimdb_selected |&gt; \n  mutate(\n    # Match specific years to decades\n    decade = case_match(\n      year,\n      2006:2009 ~ \"2000s\",\n      2010:2016 ~ \"2010s\",\n      .default = \"Unknown\"\n    )\n  ) |&gt; \n  count(decade)\n\n# A tibble: 2 × 2\n  decade     n\n  &lt;chr&gt;  &lt;int&gt;\n1 2000s    200\n2 2010s    800\n\n\nYou can also use case_match() with character values:\n\nimdb_selected |&gt; \n  mutate(\n    director_type = case_match(\n      director,\n      c(\"Christopher Nolan\", \"Steven Spielberg\", \"Martin Scorsese\") ~ \"Famous\",\n      .default = \"Other\"\n    )\n  ) |&gt; \n  count(director_type)\n\n# A tibble: 2 × 2\n  director_type     n\n  &lt;chr&gt;         &lt;int&gt;\n1 Famous           14\n2 Other           986\n\n\nKey differences between case_when() and case_match():\n\nSyntax: case_match() uses the value to match on the left side, while case_when() uses conditions\nUse case: case_match() is for exact matching, case_when() is for complex conditions\nPerformance: case_match() can be faster for simple value matching\nReadability: case_match() is often cleaner when recoding variables\n\n\n\nsummarize(), group_by(), and reframe()\nWhen you analyze data, you often want to compare entities according to some sort of summary statistic. This means that you, first, need to split up your data set into certain groups which share one or more characteristics, and, second, collapse the rows together into single-row summaries. The former challenge is accomplished using group_by() whose argument is one or more variables, the latter requires the summarize() function. This function works similar to mutate() but uses summary functions – which take a vector of multiple values and return a single value – instead of window functions – which return a vector of the same length as the input.\nLet me provide you an example.\nI am interested in the director’s average ratings:\n\nimdb_selected |&gt; \n  group_by(director, year) |&gt; \n  summarize(avg_rating = mean(rating),\n            avg_revenue = mean(revenue_million, na.rm = TRUE))\n\n`summarise()` has grouped output by 'director'. You can override using the\n`.groups` argument.\n\n\n# A tibble: 987 × 4\n# Groups:   director [644]\n   director             year avg_rating avg_revenue\n   &lt;chr&gt;               &lt;dbl&gt;      &lt;dbl&gt;       &lt;dbl&gt;\n 1 Aamir Khan           2007        8.5        1.2 \n 2 Abdellatif Kechiche  2013        7.8        2.2 \n 3 Adam Leon            2016        6.5      NaN   \n 4 Adam McKay           2006        6.6      148.  \n 5 Adam McKay           2008        6.9      100.  \n 6 Adam McKay           2010        6.7      119.  \n 7 Adam McKay           2015        7.8       70.2 \n 8 Adam Shankman        2007        6.7      119.  \n 9 Adam Shankman        2012        5.9       38.5 \n10 Adam Wingard         2014        6.7        0.32\n# ℹ 977 more rows\n\n\nIn general, summarize() always works like this: first, you change the scope from the entire tibble to different groups. Then, you calculate your summary. If you then want to further manipulate your data or calculate something else based on the new summary, you need to call ungroup().\nYou can see the summary functions below:\n\n\n\nSummary functions in R\n\n\nAnother handy function akin to this is count(). It counts all occurrences of a singular value in the tibble.\nIf I were interested in how many movies of the different directors have made it into the data set, I could use this code:\n\nimdb_selected |&gt; \n  count(director)\n\n# A tibble: 644 × 2\n   director                n\n   &lt;chr&gt;               &lt;int&gt;\n 1 Aamir Khan              1\n 2 Abdellatif Kechiche     1\n 3 Adam Leon               1\n 4 Adam McKay              4\n 5 Adam Shankman           2\n 6 Adam Wingard            2\n 7 Afonso Poyart           1\n 8 Aisling Walsh           1\n 9 Akan Satayev            1\n10 Akiva Schaffer          1\n# ℹ 634 more rows\n\n\nWhile summarize() is powerful, it has a limitation: it always returns exactly one row per group. Sometimes you need more flexibility - that’s where reframe() comes in. Introduced in dplyr 1.1.0, reframe() allows you to return any number of rows per group.\nWith reframe(), we can for instance calculate the rating quantiles per director:\n\nimdb_selected |&gt; \n  group_by(director) |&gt; \n  reframe(\n    rating_quantiles = quantile(rating, probs = c(0.25, 0.5, 0.75)),\n    quantile = rep(c(0.25, 0.5, 0.75))\n  ) |&gt; \n    ungroup()\n\n# A tibble: 1,932 × 3\n   director            rating_quantiles quantile\n   &lt;chr&gt;                          &lt;dbl&gt;    &lt;dbl&gt;\n 1 Aamir Khan                      8.5      0.25\n 2 Aamir Khan                      8.5      0.5 \n 3 Aamir Khan                      8.5      0.75\n 4 Abdellatif Kechiche             7.8      0.25\n 5 Abdellatif Kechiche             7.8      0.5 \n 6 Abdellatif Kechiche             7.8      0.75\n 7 Adam Leon                       6.5      0.25\n 8 Adam Leon                       6.5      0.5 \n 9 Adam Leon                       6.5      0.75\n10 Adam McKay                      6.68     0.25\n# ℹ 1,922 more rows\n\n\nThis example calculates the 25th, 50th, and 75th percentiles of ratings. Each director will have one row with their average rating and a list of quantiles.\nWhen to use reframe() vs summarize():\nUse summarize() when you want:\n\nOne summary value per group (mean, sum, count, etc.)\nA single row of results per group\n\nUse reframe() when you need:\n\nMultiple rows per group\nTo return quantiles, ranges, or other multi-value summaries\nMore flexibility in your output structure\n\nNote that both functions return a grouped tibble, so you may want to ungroup() afterwards if you’re doing further operations.\n\n\narrange()\nFinally, you can also sort values using arrange(). In the last section, I was interested in directors’ respective average ratings. The values were ordered according to their name (hence, “Aamir Khan” was first). In this case, the order dos not make too much sense, because the first name does not say too much about the director’s ratings. Therefore, I want to sort them according to their average ratings:\n\nimdb_selected |&gt; \n  group_by(director) |&gt; \n  summarize(avg_rating = mean(rating)) |&gt; \n  arrange(avg_rating)\n\n# A tibble: 644 × 2\n   director           avg_rating\n   &lt;chr&gt;                   &lt;dbl&gt;\n 1 Jason Friedberg           1.9\n 2 James Wong                2.7\n 3 Shawn Burkett             2.7\n 4 Jonathan Holbrook         3.2\n 5 Femi Oyeniran             3.5\n 6 Micheal Bafaro            3.5\n 7 Jeffrey G. Hunt           3.7\n 8 Rolfe Kanefsky            3.9\n 9 Joey Curtis               4  \n10 Sam Taylor-Johnson        4.1\n# ℹ 634 more rows\n\n\nAll right, Jason Friedberg is apparently the director of the worst rated movie in my data set. But it would be more handy, if they were arranged in descending order. I can use desc() for this:\n\nimdb_selected |&gt; \n  group_by(director) |&gt; \n  summarize(avg_rating = mean(rating)) |&gt; \n  arrange(-avg_rating)\n\n# A tibble: 644 × 2\n   director                         avg_rating\n   &lt;chr&gt;                                 &lt;dbl&gt;\n 1 Nitesh Tiwari                          8.8 \n 2 Christopher Nolan                      8.68\n 3 Makoto Shinkai                         8.6 \n 4 Olivier Nakache                        8.6 \n 5 Aamir Khan                             8.5 \n 6 Florian Henckel von Donnersmarck       8.5 \n 7 Damien Chazelle                        8.4 \n 8 Naoko Yamada                           8.4 \n 9 Amber Tamblyn                          8.3 \n10 Lee Unkrich                            8.3 \n# ℹ 634 more rows\n\n\nChapeau, Nitesh Tiwari!\n\n\nIntroducing joins\nThe last session showed you three things: how you get data sets into R, a couple of ways to create tibbles, and an introduction to tidy data and how to make data sets tidy using the tidyr package. As you may recall from the last session, it was not able to solve the last two problems with only the tools tidyr offers. In particular, the problems were:\n\nMultiple types of observational units are stored in the same table.\nA single observational unit is stored in multiple tables.\n\nBoth problems need some different kind of tools: joins. Joins can be used to merge tibbles together. This tutorial, again, builds heavily on the R for Data Science book (Wickham and Grolemund 2016)\n\nMultiple types of units are in the same table\nLet’s look at the following data set. It contains the billboard charts in 2000 and was obtained from the tidyr GitHub repo. The example below is taken from the tidyr vignette which can be loaded using vignette(\"tidy-data\", package = \"tidyr\").\n\nload(\"data/billboard.rda\")\n\n\nglimpse(billboard)\n\nRows: 317\nColumns: 79\n$ artist       &lt;chr&gt; \"2 Pac\", \"2Ge+her\", \"3 Doors Down\", \"3 Doors Down\", \"504 …\n$ track        &lt;chr&gt; \"Baby Don't Cry (Keep...\", \"The Hardest Part Of ...\", \"Kr…\n$ date.entered &lt;date&gt; 2000-02-26, 2000-09-02, 2000-04-08, 2000-10-21, 2000-04-…\n$ wk1          &lt;dbl&gt; 87, 91, 81, 76, 57, 51, 97, 84, 59, 76, 84, 57, 50, 71, 7…\n$ wk2          &lt;dbl&gt; 82, 87, 70, 76, 34, 39, 97, 62, 53, 76, 84, 47, 39, 51, 6…\n$ wk3          &lt;dbl&gt; 72, 92, 68, 72, 25, 34, 96, 51, 38, 74, 75, 45, 30, 28, 5…\n$ wk4          &lt;dbl&gt; 77, NA, 67, 69, 17, 26, 95, 41, 28, 69, 73, 29, 28, 18, 4…\n$ wk5          &lt;dbl&gt; 87, NA, 66, 67, 17, 26, 100, 38, 21, 68, 73, 23, 21, 13, …\n$ wk6          &lt;dbl&gt; 94, NA, 57, 65, 31, 19, NA, 35, 18, 67, 69, 18, 19, 13, 3…\n$ wk7          &lt;dbl&gt; 99, NA, 54, 55, 36, 2, NA, 35, 16, 61, 68, 11, 20, 11, 34…\n$ wk8          &lt;dbl&gt; NA, NA, 53, 59, 49, 2, NA, 38, 14, 58, 65, 9, 17, 1, 29, …\n$ wk9          &lt;dbl&gt; NA, NA, 51, 62, 53, 3, NA, 38, 12, 57, 73, 9, 17, 1, 27, …\n$ wk10         &lt;dbl&gt; NA, NA, 51, 61, 57, 6, NA, 36, 10, 59, 83, 11, 17, 2, 30,…\n$ wk11         &lt;dbl&gt; NA, NA, 51, 61, 64, 7, NA, 37, 9, 66, 92, 1, 17, 2, 36, N…\n$ wk12         &lt;dbl&gt; NA, NA, 51, 59, 70, 22, NA, 37, 8, 68, NA, 1, 3, 3, 37, N…\n$ wk13         &lt;dbl&gt; NA, NA, 47, 61, 75, 29, NA, 38, 6, 61, NA, 1, 3, 3, 39, N…\n$ wk14         &lt;dbl&gt; NA, NA, 44, 66, 76, 36, NA, 49, 1, 67, NA, 1, 7, 4, 49, N…\n$ wk15         &lt;dbl&gt; NA, NA, 38, 72, 78, 47, NA, 61, 2, 59, NA, 4, 10, 12, 57,…\n$ wk16         &lt;dbl&gt; NA, NA, 28, 76, 85, 67, NA, 63, 2, 63, NA, 8, 17, 11, 63,…\n$ wk17         &lt;dbl&gt; NA, NA, 22, 75, 92, 66, NA, 62, 2, 67, NA, 12, 25, 13, 65…\n$ wk18         &lt;dbl&gt; NA, NA, 18, 67, 96, 84, NA, 67, 2, 71, NA, 22, 29, 15, 68…\n$ wk19         &lt;dbl&gt; NA, NA, 18, 73, NA, 93, NA, 83, 3, 79, NA, 23, 29, 18, 79…\n$ wk20         &lt;dbl&gt; NA, NA, 14, 70, NA, 94, NA, 86, 4, 89, NA, 43, 40, 20, 86…\n$ wk21         &lt;dbl&gt; NA, NA, 12, NA, NA, NA, NA, NA, 5, NA, NA, 44, 43, 30, NA…\n$ wk22         &lt;dbl&gt; NA, NA, 7, NA, NA, NA, NA, NA, 5, NA, NA, NA, 50, 40, NA,…\n$ wk23         &lt;dbl&gt; NA, NA, 6, NA, NA, NA, NA, NA, 6, NA, NA, NA, NA, 39, NA,…\n$ wk24         &lt;dbl&gt; NA, NA, 6, NA, NA, NA, NA, NA, 9, NA, NA, NA, NA, 44, NA,…\n$ wk25         &lt;dbl&gt; NA, NA, 6, NA, NA, NA, NA, NA, 13, NA, NA, NA, NA, NA, NA…\n$ wk26         &lt;dbl&gt; NA, NA, 5, NA, NA, NA, NA, NA, 14, NA, NA, NA, NA, NA, NA…\n$ wk27         &lt;dbl&gt; NA, NA, 5, NA, NA, NA, NA, NA, 16, NA, NA, NA, NA, NA, NA…\n$ wk28         &lt;dbl&gt; NA, NA, 4, NA, NA, NA, NA, NA, 23, NA, NA, NA, NA, NA, NA…\n$ wk29         &lt;dbl&gt; NA, NA, 4, NA, NA, NA, NA, NA, 22, NA, NA, NA, NA, NA, NA…\n$ wk30         &lt;dbl&gt; NA, NA, 4, NA, NA, NA, NA, NA, 33, NA, NA, NA, NA, NA, NA…\n$ wk31         &lt;dbl&gt; NA, NA, 4, NA, NA, NA, NA, NA, 36, NA, NA, NA, NA, NA, NA…\n$ wk32         &lt;dbl&gt; NA, NA, 3, NA, NA, NA, NA, NA, 43, NA, NA, NA, NA, NA, NA…\n$ wk33         &lt;dbl&gt; NA, NA, 3, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ wk34         &lt;dbl&gt; NA, NA, 3, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ wk35         &lt;dbl&gt; NA, NA, 4, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ wk36         &lt;dbl&gt; NA, NA, 5, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ wk37         &lt;dbl&gt; NA, NA, 5, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ wk38         &lt;dbl&gt; NA, NA, 9, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ wk39         &lt;dbl&gt; NA, NA, 9, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ wk40         &lt;dbl&gt; NA, NA, 15, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ wk41         &lt;dbl&gt; NA, NA, 14, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ wk42         &lt;dbl&gt; NA, NA, 13, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ wk43         &lt;dbl&gt; NA, NA, 14, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ wk44         &lt;dbl&gt; NA, NA, 16, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ wk45         &lt;dbl&gt; NA, NA, 17, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ wk46         &lt;dbl&gt; NA, NA, 21, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ wk47         &lt;dbl&gt; NA, NA, 22, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ wk48         &lt;dbl&gt; NA, NA, 24, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ wk49         &lt;dbl&gt; NA, NA, 28, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ wk50         &lt;dbl&gt; NA, NA, 33, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ wk51         &lt;dbl&gt; NA, NA, 42, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ wk52         &lt;dbl&gt; NA, NA, 42, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ wk53         &lt;dbl&gt; NA, NA, 49, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ wk54         &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ wk55         &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ wk56         &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ wk57         &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ wk58         &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ wk59         &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ wk60         &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ wk61         &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ wk62         &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ wk63         &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ wk64         &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ wk65         &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ wk66         &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ wk67         &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ wk68         &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ wk69         &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ wk70         &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ wk71         &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ wk72         &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ wk73         &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ wk74         &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ wk75         &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ wk76         &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n\n\nHere, you can immediately see the problem: it contains two types of observations: songs and ranks. Hence, the data set needs to be split up. However, there should be a pointer from the rank data set to the song data set. First, I add an ID column to song_tbl. Then, I can add it to rank_tbl and drop the unnecessary columns which contain the name of the artist and the track.\n\nsong_tbl &lt;- billboard |&gt; \n  rowid_to_column(\"song_id\") |&gt; \n  distinct(artist, track, .keep_all = TRUE) |&gt; \n  select(song_id:track)\n\nglimpse(song_tbl)\n\nRows: 317\nColumns: 3\n$ song_id &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18,…\n$ artist  &lt;chr&gt; \"2 Pac\", \"2Ge+her\", \"3 Doors Down\", \"3 Doors Down\", \"504 Boyz\"…\n$ track   &lt;chr&gt; \"Baby Don't Cry (Keep...\", \"The Hardest Part Of ...\", \"Krypton…\n\n\n\nrank_tbl &lt;- billboard |&gt; \n  pivot_longer(cols = starts_with(\"wk\"), \n               names_to = \"week\", \n               names_prefix = \"wk\", \n               values_to = \"rank\") |&gt; \n  mutate(week = as.numeric(week),\n         date = date.entered + (week-1) * 7) |&gt; \n  drop_na() |&gt; \n  left_join(song_tbl, by = c(\"artist\", \"track\")) |&gt; \n  select(song_id, date, week, rank)\n\nglimpse(rank_tbl)\n\nRows: 5,307\nColumns: 4\n$ song_id &lt;int&gt; 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,…\n$ date    &lt;date&gt; 2000-02-26, 2000-03-04, 2000-03-11, 2000-03-18, 2000-03-25, 2…\n$ week    &lt;dbl&gt; 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1…\n$ rank    &lt;dbl&gt; 87, 82, 72, 77, 87, 94, 99, 91, 87, 92, 81, 70, 68, 67, 66, 57…\n\n\n\n\nOne unit is in multiple tables\nFor this example, I have split up a data set from the socviz package containing data on the 2016 elections in the U.S. according to census region and stored them in a folder. I can scrape the file names in the folder and read it into a list in an automated manner. (Note that the functions used to read the files in in an automated fashion are beyond the scope of this course. They come from the fs (Hester, Wickham, and Csárdi 2021) and the purrr package (Henry and Wickham 2020).)3\n\nfile_list &lt;- dir_ls(path = \"data/socviz_us\") |&gt; \n  map(read_csv,\n      col_types = cols(\n        id = col_double(),\n        name = col_character(),\n        state = col_character(),\n        census_region = col_character(),\n        pop_dens = col_character(),\n        pop_dens4 = col_character(),\n        pop_dens6 = col_character(),\n        pct_black = col_character(),\n        pop = col_double(),\n        female = col_double(),\n        white = col_double(),\n        black = col_double(),\n        travel_time = col_double(),\n        land_area = col_double(),\n        hh_income = col_double(),\n        su_gun4 = col_character(),\n        su_gun6 = col_character(),\n        fips = col_double(),\n        votes_dem_2016 = col_double(),\n        votes_gop_2016 = col_double(),\n        total_votes_2016 = col_double(),\n        per_dem_2016 = col_double(),\n        per_gop_2016 = col_double(),\n        diff_2016 = col_double(),\n        per_dem_2012 = col_double(),\n        per_gop_2012 = col_double(),\n        diff_2012 = col_double(),\n        winner = col_character(),\n        partywinner16 = col_character(),\n        winner12 = col_character(),\n        partywinner12 = col_character(),\n        flipped = col_character()\n))\n\nThe list now consists of four tibbles in a list which need to be bound together. You can achieve this using list_rbind(). Its counterpart is list_cbind() which binds columns together. It matches rows by position.\n\nelection_data &lt;- file_list |&gt; list_rbind()\nglimpse(election_data)\n\nRows: 3,141\nColumns: 32\n$ id               &lt;dbl&gt; 17001, 17003, 17005, 17007, 17009, 17011, 17013, 1701…\n$ name             &lt;chr&gt; \"Adams County\", \"Alexander County\", \"Bond County\", \"B…\n$ state            &lt;chr&gt; \"IL\", \"IL\", \"IL\", \"IL\", \"IL\", \"IL\", \"IL\", \"IL\", \"IL\",…\n$ census_region    &lt;chr&gt; \"Midwest\", \"Midwest\", \"Midwest\", \"Midwest\", \"Midwest\"…\n$ pop_dens         &lt;chr&gt; \"[   50,  100)\", \"[   10,   50)\", \"[   10,   50)\", \"[…\n$ pop_dens4        &lt;chr&gt; \"[ 45,  118)\", \"[ 17,   45)\", \"[ 45,  118)\", \"[118,71…\n$ pop_dens6        &lt;chr&gt; \"[ 45,   82)\", \"[ 25,   45)\", \"[ 45,   82)\", \"[ 82,  …\n$ pct_black        &lt;chr&gt; \"[ 2.0, 5.0)\", \"[25.0,50.0)\", \"[ 5.0,10.0)\", \"[ 2.0, …\n$ pop              &lt;dbl&gt; 66988, 7492, 17269, 53869, 6832, 33840, 4956, 14715, …\n$ female           &lt;dbl&gt; 51.3, 49.5, 47.5, 50.2, 35.5, 51.0, 49.7, 50.1, 49.1,…\n$ white            &lt;dbl&gt; 93.7, 60.6, 90.9, 93.2, 78.6, 96.8, 98.8, 96.7, 93.2,…\n$ black            &lt;dbl&gt; 3.7, 36.1, 6.5, 2.6, 19.1, 0.8, 0.3, 1.1, 4.4, 12.8, …\n$ travel_time      &lt;dbl&gt; 16.6, 25.6, 23.6, 30.1, 18.9, 20.4, 39.6, 23.8, 22.2,…\n$ land_area        &lt;dbl&gt; 855.20, 235.51, 380.28, 280.72, 305.61, 869.03, 253.8…\n$ hh_income        &lt;dbl&gt; 45073, 26972, 48163, 60893, 42194, 48977, 50436, 4798…\n$ su_gun4          &lt;chr&gt; \"[ 0, 5)\", \"[ 5, 8)\", \"[ 0, 5)\", \"[ 0, 5)\", \"[ 0, 5)\"…\n$ su_gun6          &lt;chr&gt; \"[ 4, 7)\", \"[ 7, 8)\", \"[ 4, 7)\", \"[ 0, 4)\", \"[ 0, 4)\"…\n$ fips             &lt;dbl&gt; 17001, 17003, 17005, 17007, 17009, 17011, 17013, 1701…\n$ votes_dem_2016   &lt;dbl&gt; 7633, 1262, 2066, 8952, 475, 6010, 739, 2437, 1617, 4…\n$ votes_gop_2016   &lt;dbl&gt; 22732, 1496, 4884, 12261, 1776, 9264, 1719, 4428, 321…\n$ total_votes_2016 &lt;dbl&gt; 31770, 2820, 7462, 22604, 2336, 16303, 2556, 7354, 50…\n$ per_dem_2016     &lt;dbl&gt; 0.2402581, 0.4475177, 0.2768695, 0.3960361, 0.2033390…\n$ per_gop_2016     &lt;dbl&gt; 0.7155178, 0.5304965, 0.6545162, 0.5424261, 0.7602740…\n$ diff_2016        &lt;dbl&gt; 15099, 234, 2818, 3309, 1301, 3254, 980, 1991, 1599, …\n$ per_dem_2012     &lt;dbl&gt; 0.3152466, 0.5610873, 0.4122471, 0.4625697, 0.3331922…\n$ per_gop_2012     &lt;dbl&gt; 0.6670705, 0.4248927, 0.5591853, 0.5195706, 0.6397121…\n$ diff_2012        &lt;dbl&gt; 10744, 476, 1075, 1216, 724, 33, 360, 107, 657, 5292,…\n$ winner           &lt;chr&gt; \"Trump\", \"Trump\", \"Trump\", \"Trump\", \"Trump\", \"Trump\",…\n$ partywinner16    &lt;chr&gt; \"Republican\", \"Republican\", \"Republican\", \"Republican…\n$ winner12         &lt;chr&gt; \"Romney\", \"Obama\", \"Romney\", \"Romney\", \"Romney\", \"Rom…\n$ partywinner12    &lt;chr&gt; \"Republican\", \"Democrat\", \"Republican\", \"Republican\",…\n$ flipped          &lt;chr&gt; \"No\", \"Yes\", \"No\", \"No\", \"No\", \"No\", \"No\", \"Yes\", \"No…\n\n\nHowever, the topic of this script is different joins. The dplyr package offers six different joins: left_join(), right_join(), inner_join(), full_join(), semi_join(), and anti_join(). The former four are mutating joins, they add columns. The latter two can be used to filter rows in a data set. Below is an overview from the dplyr cheat sheet:\n\n\n\nOverview of the different joins\n\n\nIn the following, I will illustrate this using the election data. I split up the data set into three: data on the elections 2016 and 2012, and demographic data. The column they have in common is the county’s respective name.\n\nelection_data16 &lt;- election_data |&gt; \n  select(name, state, votes_dem_2016:diff_2016, winner, partywinner16)\n\nelection_data12 &lt;- election_data |&gt; \n  select(name, state, per_dem_2012:partywinner12)\n\ndemographic_data &lt;- election_data |&gt; \n  select(name, state, pop:hh_income) |&gt; \n  slice(1:2000) #you will see later why I do this\n\n\n\nleft_join() and right_join()\nIf we want to add the demographic data to the election data 2016, we can use a left_join() or a right_join(). The former adds all columns of y to x, the latter all columns of x to y. Here, I want to add the demographic data to the election data 2016. Therefore, I use a left_join():\n\nelection_data16 |&gt; \n  left_join(demographic_data)\n\nJoining with `by = join_by(name, state)`\n\n\n# A tibble: 3,141 × 17\n   name        state votes_dem_2016 votes_gop_2016 total_votes_2016 per_dem_2016\n   &lt;chr&gt;       &lt;chr&gt;          &lt;dbl&gt;          &lt;dbl&gt;            &lt;dbl&gt;        &lt;dbl&gt;\n 1 Adams Coun… IL              7633          22732            31770        0.240\n 2 Alexander … IL              1262           1496             2820        0.448\n 3 Bond County IL              2066           4884             7462        0.277\n 4 Boone Coun… IL              8952          12261            22604        0.396\n 5 Brown Coun… IL               475           1776             2336        0.203\n 6 Bureau Cou… IL              6010           9264            16303        0.369\n 7 Calhoun Co… IL               739           1719             2556        0.289\n 8 Carroll Co… IL              2437           4428             7354        0.331\n 9 Cass County IL              1617           3216             5054        0.320\n10 Champaign … IL             49694          33235            89196        0.557\n# ℹ 3,131 more rows\n# ℹ 11 more variables: per_gop_2016 &lt;dbl&gt;, diff_2016 &lt;dbl&gt;, winner &lt;chr&gt;,\n#   partywinner16 &lt;chr&gt;, pop &lt;dbl&gt;, female &lt;dbl&gt;, white &lt;dbl&gt;, black &lt;dbl&gt;,\n#   travel_time &lt;dbl&gt;, land_area &lt;dbl&gt;, hh_income &lt;dbl&gt;\n\n\nIf the column that both data sets have in common has the same name, there’s no need to provide it. If this is not the case, you need to provide it in a character vector:\n\nelection_data16 |&gt; \n  rename(county = name) |&gt; \n  right_join(demographic_data, by = join_by(\"county\" == \"name\"))\n\nWarning in right_join(rename(election_data16, county = name), demographic_data, : Detected an unexpected many-to-many relationship between `x` and `y`.\nℹ Row 1 of `x` matches multiple rows in `y`.\nℹ Row 1 of `y` matches multiple rows in `x`.\nℹ If a many-to-many relationship is expected, set `relationship =\n  \"many-to-many\"` to silence this warning.\n\n\n# A tibble: 10,348 × 18\n   county    state.x votes_dem_2016 votes_gop_2016 total_votes_2016 per_dem_2016\n   &lt;chr&gt;     &lt;chr&gt;            &lt;dbl&gt;          &lt;dbl&gt;            &lt;dbl&gt;        &lt;dbl&gt;\n 1 Adams Co… IL                7633          22732            31770        0.240\n 2 Adams Co… IL                7633          22732            31770        0.240\n 3 Adams Co… IL                7633          22732            31770        0.240\n 4 Adams Co… IL                7633          22732            31770        0.240\n 5 Adams Co… IL                7633          22732            31770        0.240\n 6 Adams Co… IL                7633          22732            31770        0.240\n 7 Adams Co… IL                7633          22732            31770        0.240\n 8 Adams Co… IL                7633          22732            31770        0.240\n 9 Adams Co… IL                7633          22732            31770        0.240\n10 Alexande… IL                1262           1496             2820        0.448\n# ℹ 10,338 more rows\n# ℹ 12 more variables: per_gop_2016 &lt;dbl&gt;, diff_2016 &lt;dbl&gt;, winner &lt;chr&gt;,\n#   partywinner16 &lt;chr&gt;, state.y &lt;chr&gt;, pop &lt;dbl&gt;, female &lt;dbl&gt;, white &lt;dbl&gt;,\n#   black &lt;dbl&gt;, travel_time &lt;dbl&gt;, land_area &lt;dbl&gt;, hh_income &lt;dbl&gt;\n\n\nHere, the problem is that the same counties exist in different states. Therefore, all combinations are returned. Hence, I need to specify two arguments: the county’s name and state.\n\nelection_data16 |&gt; \n  rename(county = name) |&gt; \n  right_join(demographic_data, by = join_by(\"county\" == \"name\", \"state\"))\n\n# A tibble: 2,000 × 17\n   county      state votes_dem_2016 votes_gop_2016 total_votes_2016 per_dem_2016\n   &lt;chr&gt;       &lt;chr&gt;          &lt;dbl&gt;          &lt;dbl&gt;            &lt;dbl&gt;        &lt;dbl&gt;\n 1 Adams Coun… IL              7633          22732            31770        0.240\n 2 Alexander … IL              1262           1496             2820        0.448\n 3 Bond County IL              2066           4884             7462        0.277\n 4 Boone Coun… IL              8952          12261            22604        0.396\n 5 Brown Coun… IL               475           1776             2336        0.203\n 6 Bureau Cou… IL              6010           9264            16303        0.369\n 7 Calhoun Co… IL               739           1719             2556        0.289\n 8 Carroll Co… IL              2437           4428             7354        0.331\n 9 Cass County IL              1617           3216             5054        0.320\n10 Champaign … IL             49694          33235            89196        0.557\n# ℹ 1,990 more rows\n# ℹ 11 more variables: per_gop_2016 &lt;dbl&gt;, diff_2016 &lt;dbl&gt;, winner &lt;chr&gt;,\n#   partywinner16 &lt;chr&gt;, pop &lt;dbl&gt;, female &lt;dbl&gt;, white &lt;dbl&gt;, black &lt;dbl&gt;,\n#   travel_time &lt;dbl&gt;, land_area &lt;dbl&gt;, hh_income &lt;dbl&gt;\n\n\nLeft joins return all rows which are in x. If a column is in x but not in y, an NA will be included at this position. Right joins work vice versa and return all rows which are in y.\n\n\ninner_join()\nAn inner_join() returns all rows which are in x and y.\n\nelection_data16 |&gt; \n  inner_join(demographic_data)\n\nJoining with `by = join_by(name, state)`\n\n\n# A tibble: 2,000 × 17\n   name        state votes_dem_2016 votes_gop_2016 total_votes_2016 per_dem_2016\n   &lt;chr&gt;       &lt;chr&gt;          &lt;dbl&gt;          &lt;dbl&gt;            &lt;dbl&gt;        &lt;dbl&gt;\n 1 Adams Coun… IL              7633          22732            31770        0.240\n 2 Alexander … IL              1262           1496             2820        0.448\n 3 Bond County IL              2066           4884             7462        0.277\n 4 Boone Coun… IL              8952          12261            22604        0.396\n 5 Brown Coun… IL               475           1776             2336        0.203\n 6 Bureau Cou… IL              6010           9264            16303        0.369\n 7 Calhoun Co… IL               739           1719             2556        0.289\n 8 Carroll Co… IL              2437           4428             7354        0.331\n 9 Cass County IL              1617           3216             5054        0.320\n10 Champaign … IL             49694          33235            89196        0.557\n# ℹ 1,990 more rows\n# ℹ 11 more variables: per_gop_2016 &lt;dbl&gt;, diff_2016 &lt;dbl&gt;, winner &lt;chr&gt;,\n#   partywinner16 &lt;chr&gt;, pop &lt;dbl&gt;, female &lt;dbl&gt;, white &lt;dbl&gt;, black &lt;dbl&gt;,\n#   travel_time &lt;dbl&gt;, land_area &lt;dbl&gt;, hh_income &lt;dbl&gt;\n\n\n\n\nfull_join()\nA full_join() returns rows and columns from both x and y.\n\nelection_data16 |&gt; \n  full_join(demographic_data)\n\nJoining with `by = join_by(name, state)`\n\n\n# A tibble: 3,141 × 17\n   name        state votes_dem_2016 votes_gop_2016 total_votes_2016 per_dem_2016\n   &lt;chr&gt;       &lt;chr&gt;          &lt;dbl&gt;          &lt;dbl&gt;            &lt;dbl&gt;        &lt;dbl&gt;\n 1 Adams Coun… IL              7633          22732            31770        0.240\n 2 Alexander … IL              1262           1496             2820        0.448\n 3 Bond County IL              2066           4884             7462        0.277\n 4 Boone Coun… IL              8952          12261            22604        0.396\n 5 Brown Coun… IL               475           1776             2336        0.203\n 6 Bureau Cou… IL              6010           9264            16303        0.369\n 7 Calhoun Co… IL               739           1719             2556        0.289\n 8 Carroll Co… IL              2437           4428             7354        0.331\n 9 Cass County IL              1617           3216             5054        0.320\n10 Champaign … IL             49694          33235            89196        0.557\n# ℹ 3,131 more rows\n# ℹ 11 more variables: per_gop_2016 &lt;dbl&gt;, diff_2016 &lt;dbl&gt;, winner &lt;chr&gt;,\n#   partywinner16 &lt;chr&gt;, pop &lt;dbl&gt;, female &lt;dbl&gt;, white &lt;dbl&gt;, black &lt;dbl&gt;,\n#   travel_time &lt;dbl&gt;, land_area &lt;dbl&gt;, hh_income &lt;dbl&gt;\n\n\n\n\nsemi_join()\nFiltering joins only keep the cases from x, no data set is added.\nThe semi_join() returns all rows from x with matching values in y. You can compare it to a right_join() but without adding the columns of y.\n\nelection_data16 |&gt; \n  semi_join(demographic_data)\n\nJoining with `by = join_by(name, state)`\n\n\n# A tibble: 2,000 × 10\n   name        state votes_dem_2016 votes_gop_2016 total_votes_2016 per_dem_2016\n   &lt;chr&gt;       &lt;chr&gt;          &lt;dbl&gt;          &lt;dbl&gt;            &lt;dbl&gt;        &lt;dbl&gt;\n 1 Adams Coun… IL              7633          22732            31770        0.240\n 2 Alexander … IL              1262           1496             2820        0.448\n 3 Bond County IL              2066           4884             7462        0.277\n 4 Boone Coun… IL              8952          12261            22604        0.396\n 5 Brown Coun… IL               475           1776             2336        0.203\n 6 Bureau Cou… IL              6010           9264            16303        0.369\n 7 Calhoun Co… IL               739           1719             2556        0.289\n 8 Carroll Co… IL              2437           4428             7354        0.331\n 9 Cass County IL              1617           3216             5054        0.320\n10 Champaign … IL             49694          33235            89196        0.557\n# ℹ 1,990 more rows\n# ℹ 4 more variables: per_gop_2016 &lt;dbl&gt;, diff_2016 &lt;dbl&gt;, winner &lt;chr&gt;,\n#   partywinner16 &lt;chr&gt;\n\n\n\n\nanti_join()\nanti_join() returns all rows from x with no matching rows in y.\n\nelection_data16 |&gt; \n  anti_join(demographic_data)\n\nJoining with `by = join_by(name, state)`\n\n\n# A tibble: 1,141 × 10\n   name        state votes_dem_2016 votes_gop_2016 total_votes_2016 per_dem_2016\n   &lt;chr&gt;       &lt;chr&gt;          &lt;dbl&gt;          &lt;dbl&gt;            &lt;dbl&gt;        &lt;dbl&gt;\n 1 Onslow Cou… NC             17156          36342            55364        0.310\n 2 Orange Cou… NC             59105          18373            79830        0.740\n 3 Pamlico Co… NC              2427           4225             6772        0.358\n 4 Pasquotank… NC              8455           8082            16964        0.498\n 5 Pender Cou… NC              9086          17317            27072        0.336\n 6 Perquimans… NC              2291           4143             6595        0.347\n 7 Person Cou… NC              7772          11116            19303        0.403\n 8 Pitt County NC             40967          35191            78264        0.523\n 9 Polk County NC              3715           6738            10723        0.346\n10 Randolph C… NC             13074          49156            63615        0.206\n# ℹ 1,131 more rows\n# ℹ 4 more variables: per_gop_2016 &lt;dbl&gt;, diff_2016 &lt;dbl&gt;, winner &lt;chr&gt;,\n#   partywinner16 &lt;chr&gt;\n\n\n\n\n\nbind_rows() and bind_cols()\nBinding tibbles together is made easy using the bind_*() functions. bind_rows() binds them together by rows, bind_cols() by columns. For the former, it is important that column names are matching. Otherwise, the non-matching ones will be added as separate columns and NAs introduced. IDs can be added by using the .id = argument, where the name of the id column can be specified.\n\nelection_data16 |&gt; \n  semi_join(demographic_data) |&gt; \n  bind_rows(election_data16 |&gt;\n              anti_join(demographic_data),\n            .id = \"id\")\n\nJoining with `by = join_by(name, state)`\nJoining with `by = join_by(name, state)`\n\n\n# A tibble: 3,141 × 11\n   id    name  state votes_dem_2016 votes_gop_2016 total_votes_2016 per_dem_2016\n   &lt;chr&gt; &lt;chr&gt; &lt;chr&gt;          &lt;dbl&gt;          &lt;dbl&gt;            &lt;dbl&gt;        &lt;dbl&gt;\n 1 1     Adam… IL              7633          22732            31770        0.240\n 2 1     Alex… IL              1262           1496             2820        0.448\n 3 1     Bond… IL              2066           4884             7462        0.277\n 4 1     Boon… IL              8952          12261            22604        0.396\n 5 1     Brow… IL               475           1776             2336        0.203\n 6 1     Bure… IL              6010           9264            16303        0.369\n 7 1     Calh… IL               739           1719             2556        0.289\n 8 1     Carr… IL              2437           4428             7354        0.331\n 9 1     Cass… IL              1617           3216             5054        0.320\n10 1     Cham… IL             49694          33235            89196        0.557\n# ℹ 3,131 more rows\n# ℹ 4 more variables: per_gop_2016 &lt;dbl&gt;, diff_2016 &lt;dbl&gt;, winner &lt;chr&gt;,\n#   partywinner16 &lt;chr&gt;\n\n\nFor bind_cols(), the length has to be the same. Duplicated column names will be changed.\n\nelection_data12 |&gt; bind_cols(election_data16)\n\nNew names:\n• `name` -&gt; `name...1`\n• `state` -&gt; `state...2`\n• `winner` -&gt; `winner...6`\n• `partywinner16` -&gt; `partywinner16...7`\n• `name` -&gt; `name...10`\n• `state` -&gt; `state...11`\n• `winner` -&gt; `winner...18`\n• `partywinner16` -&gt; `partywinner16...19`\n\n\n# A tibble: 3,141 × 19\n   name...1         state...2 per_dem_2012 per_gop_2012 diff_2012 winner...6\n   &lt;chr&gt;            &lt;chr&gt;            &lt;dbl&gt;        &lt;dbl&gt;     &lt;dbl&gt; &lt;chr&gt;     \n 1 Adams County     IL               0.315        0.667     10744 Trump     \n 2 Alexander County IL               0.561        0.425       476 Trump     \n 3 Bond County      IL               0.412        0.559      1075 Trump     \n 4 Boone County     IL               0.463        0.520      1216 Trump     \n 5 Brown County     IL               0.333        0.640       724 Trump     \n 6 Bureau County    IL               0.489        0.491        33 Trump     \n 7 Calhoun County   IL               0.419        0.559       360 Trump     \n 8 Carroll County   IL               0.496        0.482       107 Trump     \n 9 Cass County      IL               0.422        0.557       657 Trump     \n10 Champaign County IL               0.520        0.452      5292 Clinton   \n# ℹ 3,131 more rows\n# ℹ 13 more variables: partywinner16...7 &lt;chr&gt;, winner12 &lt;chr&gt;,\n#   partywinner12 &lt;chr&gt;, name...10 &lt;chr&gt;, state...11 &lt;chr&gt;,\n#   votes_dem_2016 &lt;dbl&gt;, votes_gop_2016 &lt;dbl&gt;, total_votes_2016 &lt;dbl&gt;,\n#   per_dem_2016 &lt;dbl&gt;, per_gop_2016 &lt;dbl&gt;, diff_2016 &lt;dbl&gt;, winner...18 &lt;chr&gt;,\n#   partywinner16...19 &lt;chr&gt;\n\n\n\n\nFurther links\n\nChapter in R4DS\nMore on window functions in the vignette: vignette(\"window-functions\")\nAgain, the cheatsheet\nA tutorial on YouTube\nAnother introduction can be found here.\nThe chapter in R4DS has some nice diagrams.\nYou can also consult the introverse package if you need help with the packages covered here – introverse::show_topics(\"dplyr\") will give you an overview of dplyr’s functions, and get_help(\"name of function\") will help you with the respective function.\n\n\n\nExercises\nOpen the IMDb file.\n\nFind the duplicated movie. How could you go across this?\nWhich director has made the longest movie?\nWhat’s the highest ranked movie?\nWhich movie got the most votes?\nWhich movie had the biggest revenue in 2016?\nHow much revenue did the movies in the data set make each year in total?\nFilter movies following some conditions:\n\nMore runtime than the average runtime (hint: you could also use mutate() before).\nMovies directed by J. J. Abrams.\nMore votes than the median of all of the votes.\nThe movies which have the most common value (the mode) in terms of rating (mode() does exist but will not work in the way you might like it to work – run the script below and use the my_mode function).\n\n\n\n## helper function for mode\n\nmy_mode &lt;- function(x){ \n    ta = table(x)\n    tam = max(ta)\n    if (all(ta == tam))\n         mod = NA\n    else\n         if(is.numeric(x))\n    mod = as.numeric(names(ta)[ta == tam])\n    else\n         mod = names(ta)[ta == tam]\n    return(mod)\n}"
  },
  {
    "objectID": "2_r_catch-up.html#visualization",
    "href": "2_r_catch-up.html#visualization",
    "title": "Chapter 2: Brief R Recap",
    "section": "Visualizations with ggplot2",
    "text": "Visualizations with ggplot2\n\n“The purpose of visualization is insight, not pictures.” – Ben A. Shneiderman\n\nIn R, the dominant package for visualizing data is ggplot2 which belongs to the tidyverse.\n\nThe “layered grammar of graphics”\nggplot2 works with tibbles and the data needs to be in a tidy format. It builds graphics using “the layered grammar of graphics.” (Wickham 2010)\n\npublishers &lt;- read_csv(\"data/publishers_with_places.csv\")\n  \npublishers_filtered &lt;- publishers |&gt; \n  group_by(city) |&gt; \n  filter(n() &gt; 5) |&gt; \n  drop_na()\n\nThis implies that you start with a base layer – the initial ggplot2 call.\n\npublishers_filtered |&gt; \nggplot()\n\n\n\n\n\n\n\n\nThe initial call produces an empty coordinate system. It can be filled with additional layers.\n\nggplot(data = publishers_filtered) +\n  geom_bar(aes(x = city)) \n\n\n\n\n\n\n\n\nUnlike the remainder of the tidyverse, ggplot2 uses a + instead of the pipe |&gt;. If you use the pipe by accident, it will not work and an (informative) error message will appear.\n\n# ggplot(data = publishers_filtered) |&gt; \n#   geom_bar(aes(x = city)) \n\n\n\nThe layers\nIn general, a call looks like this:\nAs you might have seen above, I provided the data in the initial ggplot call. Then, when I added the layer – the geom_bar() for a bar plot – I had to provide the mapping – which variables I wanted to plot – using aes(). This is referred to as the aesthetics. In my case, I wanted the cities to be projected to the x-axis. Since I was using geom_bar to create a bar plot, the number of occurrences of the respective cities were automatically counted and depicted on the y-axis. There are more geom_* functions and they all create different plots. Whether you can use them or not depends on the data you have at hand and/or the number of variables you want to plot. In the following, I will give you a brief overview of the most important geoms.\n\nOne variable\nIf you only want to display one variable, the x- or y-axis, as you choose, will depict the variable’s value. The counterpart will display the frequency or density of those values.\n\nOne variable – discrete\nHere, the only possible kind of visualization is a bar plot as shown above. If the visualization should look more fancy, e.g., with colored bars, you have several arguments at hand. If they should not be different for different kinds of data, they need to be specified outside the aes(). There are always different arguments and you can look them up using ?&lt;GEOM_FUNCTION&gt; and then looking at the Aesthetics section. Apart from that, you can also look at the ggplot2 cheatsheet.\n\nggplot(data = publishers_filtered) +\n  geom_bar(aes(x = city), fill = \"blue\") \n\n\n\n\n\n\n\n\n\n\nOne variable – continuous\nIf you want to display a continuous variable’s distribution of values, you can use a histogram. Its geom_* function is geom_histogram():\n\nbillboard &lt;- read_csv(\"data/billboard.csv\")\n\nRows: 317 Columns: 79\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr   (2): artist, track\ndbl  (65): wk1, wk2, wk3, wk4, wk5, wk6, wk7, wk8, wk9, wk10, wk11, wk12, wk...\nlgl  (11): wk66, wk67, wk68, wk69, wk70, wk71, wk72, wk73, wk74, wk75, wk76\ndate  (1): date.entered\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nsong_tbl &lt;- billboard |&gt; \n  distinct(artist, track) |&gt; \n  mutate(song_id = row_number())\n\nrank_tbl &lt;- billboard |&gt; \n  pivot_longer(cols = starts_with(\"wk\"), \n               names_to = \"week\", \n               names_prefix = \"wk\", \n               values_to = \"rank\") |&gt; \n  mutate(week = as.numeric(week),\n         date = date.entered + (week-1) * 7) |&gt; \n  drop_na() |&gt; \n  left_join(song_tbl, by = c(\"artist\", \"track\")) |&gt; \n  select(song_id, date, week, rank)\n\nHow does the distribution of songs over the weeks look like?\n\nggplot(data = rank_tbl) +\n  geom_histogram(aes(x = week))\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\n\nA smoothed histogram is geom_density():\n\nggplot(data = rank_tbl) +\n  geom_density(aes(x = week))\n\n\n\n\n\n\n\n\n\n\n\nTwo variables\nIn the majority of cases, you will want to display the relationship between two variables, one on the x- and the other one on the y-axis.\n\nBoth continuous\n\ncounty_data_midwest &lt;- socviz::county_data |&gt; \n  filter(census_region == \"Midwest\") |&gt; \n  drop_na()\n\nIf both variables are continuous, the easiest option is to use a scatter plot.\n\nggplot(data = county_data_midwest) +\n  geom_point(aes(x = per_dem_2016, y = per_gop_2016))\n\n\n\n\n\n\n\n\nIf you don’t like dots, the shape = argument allows you to change the shape of the data points. There are also other arguments to change, for instance, transparency (alpha =) or size (size =). Find an overview of the allowed aesthetic specifications here.\n\nggplot(data = county_data_midwest) +\n  geom_point(aes(x = per_dem_2016, y = per_gop_2016), \n             shape = \"cross\", \n             size = 2)\n\n\n\n\n\n\n\n\nHere, it might make sense to color the points according to a categorical variable (state, in this case). If so, a legend is added which maps the colors to their respective values.\n\nggplot(data = county_data_midwest) +\n  geom_point(aes(x = per_dem_2016, y = per_gop_2016)) \n\n\n\n\n\n\n\n\nSince I look at the relationship between votes for the Republicans and the Democrats, and the U.S. is a two-party system, there is a fairly clear relationship between them both. This can also be depicted using geom_smooth():\n\nggplot(data = county_data_midwest) +\n  geom_smooth(aes(x = per_dem_2016, y = per_gop_2016, color = state))\n\n`geom_smooth()` using method = 'loess' and formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\nHere, color = state has a different effect: each dimension of the categorical variable gets its own line.\nIf you do not want it to be smoothed, just use geom_line().\n\nggplot(data = county_data_midwest) +\n  geom_line(aes(x = per_dem_2016, y = per_gop_2016), color = \"grey\") \n\n\n\n\n\n\n\n\n\n\nDiscrete X, continuous Y\nIn this case, different categories of data will be put on the x-axis and some of their properties will be displayed on the y-axis. The probably most prominent example for this type of plot is a box plot:\n\nggplot(data = county_data_midwest) +\n  geom_boxplot(aes(x = state, y = per_gop_2016))\n\n\n\n\n\n\n\n\n\n\nBoth discrete\nIt is rarely the case that you want to depict two categorical variables in one plot. If so, you can use geom_jitter(). It is related to geom_point(). The difference is that with geom_jitter(), a little bit of noise is added to the dots, making them appear distinct.\n\nggplot(data = county_data_midwest) +\n  geom_jitter(aes(x = state, y = winner))\n\n\n\n\n\n\n\n\nAs opposed to:\n\nggplot(data = county_data_midwest) +\n  geom_point(aes(x = state, y = winner))\n\n\n\n\n\n\n\n\n\n\n\n\nMaking graphs “publishable”\nSo far, I have only added one layer to the plot. This suffices for the most basic visualizations. The good thing about R and RMarkdown is, however, that you can write entire publications only using their means. Hence, the plots need to look awesome. This section is dedicated to how you can achieve this. First, I will touch upon how you can make them look good using scales. labs() allow you to add titles, captions, and axis labels. Finally, facet_* allows you to plot multiple plots into one.\n\nScales\nScales can be used to take control of how the data’s values are mapped to the aesthetic’s visual values. You can find a more exhaustive tutorial on them here.\n\nscale_*_continuous – for dealing with continuous values. (you can find an exhaustive list of colors in R here)\n\n\nggplot(data = county_data_midwest) +\n  geom_point(aes(x = per_dem_2016, y = per_gop_2016, color = white)) +\n  scale_x_continuous(limits = c(0, 1)) +\n  scale_y_continuous(limits = c(0, 1)) +\n  scale_color_gradient(low = \"green\",\n                       high = \"red\")\n\n\n\n\n\n\n\n\n\nscale_*_discrete – for dealing with discrete values\nscale_*_manual – manually mapping discrete values to visual values\n\n\nsocviz::county_data |&gt; \n  filter(state %in% c(\"IA\", \"IL\", \"IN\", \"KS\")) |&gt; \n  ggplot() +\n    geom_point(aes(x = per_dem_2016, y = per_gop_2016, color = state)) +\n    scale_color_manual(values = c(\"IA\" = \"blue\", \n                                  \"IL\" = \"green\", \n                                  \"IN\" = \"red\", \n                                  \"KS\" = \"purple\"),\n                       name = \"State\",\n                       labels = c(\"Iowa\", \"Illinois\", \"Indiana\", \"Kansas\")) \n\nWarning: Removed 4 rows containing missing values or values outside the scale range\n(`geom_point()`).\n\n\n\n\n\n\n\n\n\n\n\nAdding titles, captions, etc.\nNow you have modified the scales and colors – there is a lot more to be modified if you want to – but you have not added a meaningful title, a nice caption (where were the data obtained?), and the axes do not have proper names, too. This can be achieved using labs() (which is the abbreviation for labels).\n\nsocviz::county_data |&gt; \n  filter(state %in% c(\"IA\", \"IL\", \"IN\", \"KS\")) |&gt; \n  ggplot() +\n    geom_point(aes(x = per_dem_2016, y = per_gop_2016, color = state)) +\n    scale_color_manual(values = c(\"IA\" = \"blue\", \n                                  \"IL\" = \"green\", \n                                  \"IN\" = \"red\", \n                                  \"KS\" = \"purple\"),\n                       name = \"State\",\n                       breaks = waiver(),\n                       labels = c(\"Iowa\", \"Illinois\", \"Indiana\", \"Kansas\")) +\n    scale_x_continuous(limits = c(0, 1)) +\n    scale_y_continuous(limits = c(0, 1)) +\n    ggtitle(\"Relationship between percentages of votes for Democrats and Republicans in selected states in the Midwest\") +\n    xlab(\"Percentage of votes for the Democrats in 2016\") +\n    ylab(\"Percentage of votes for the Republicans in 2016\") \n\nWarning: Removed 4 rows containing missing values or values outside the scale range\n(`geom_point()`).\n\n\n\n\n\n\n\n\n\nWell, that doesn’t look good, the title is too long. Inserting \\n – for new line – will do the trick.\n\nsocviz::county_data |&gt; \n  filter(state %in% c(\"IA\", \"IL\", \"IN\", \"KS\")) |&gt; \n  ggplot() +\n    geom_point(aes(x = per_dem_2016, y = per_gop_2016, color = state)) +\n    scale_color_manual(values = c(\"IA\" = \"blue\", \"IL\" = \"green\", \"IN\" = \"red\", \"KS\" = \"purple\"),\n                      name = \"State\",\n                      breaks = waiver(),\n                      labels = c(\"Iowa\", \"Illinois\", \"Indiana\", \"Kansas\")) +\n    scale_x_continuous(limits = c(0, 1)) +\n    scale_y_continuous(limits = c(0, 1)) +\n    ggtitle(\"Relationship between percentages of votes for Democrats \\nand Republicans in selected states in the Midwest\") +\n    xlab(\"Percentage of votes for the Democrats in 2016\") +\n    ylab(\"Percentage of votes for the Republicans in 2016\") \n\nWarning: Removed 4 rows containing missing values or values outside the scale range\n(`geom_point()`).\n\n\n\n\n\n\n\n\n\nHowever, providing it with three different layers just for labeling is pretty tedious. This is where labs() comes in handy.\n\nsocviz::county_data |&gt; \n  filter(state %in% c(\"IA\", \"IL\", \"IN\", \"KS\")) |&gt; \n  ggplot() +\n    geom_point(aes(x = per_dem_2016, y = per_gop_2016, color = state)) +\n    scale_color_manual(values = c(\"IA\" = \"blue\", \"IL\" = \"green\", \"IN\" = \"red\", \"KS\" = \"purple\"),\n                      name = \"State\",\n                      breaks = waiver(),\n                      labels = c(\"Iowa\", \"Illinois\", \"Indiana\", \"Kansas\")) +\n    scale_x_continuous(limits = c(0, 1)) +\n    scale_y_continuous(limits = c(0, 1)) +\n    labs(title = \"Relationship between percentages of votes for Democrats \\nand Republicans in selected states in the Midwest\",\n         caption = \"Data obtained from the socviz R package\",\n         x = \"Percentage of votes for the Democrats in 2016\",\n         y = \"Percentage of votes for the Republicans in 2016\") \n\nWarning: Removed 4 rows containing missing values or values outside the scale range\n(`geom_point()`).\n\n\n\n\n\n\n\n\n\n\n\nFacets\nThe original data set consists of four different census regions. If I were to compare them, I could color them accordingly.\n\nsocviz::county_data |&gt; \n  drop_na() |&gt; \n  ggplot() +\n    geom_point(aes(x = per_dem_2016, y = per_gop_2016, color = census_region)) +\n    scale_x_continuous(limits = c(0, 1)) +\n    scale_y_continuous(limits = c(0, 1)) +\n    scale_color_discrete()\n\n\n\n\n\n\n\n\nDespite the coloring according to the different states, it is still hard to assess whether there really are differences. Apart from that, I would like to assess the impact the percentage of white people in the population has. This would be easier if I put them into individual graphs. I can achieve this using so-called facets. Facets enable me to divide the plot into subplots based on categorical variables. facet_wrap() puts them into a rectangular layout. The categorical variable needs to be provided prefixed with a tilde ~, nrow determines the number of rows.\n\nsocviz::county_data |&gt; \n  drop_na() |&gt; \n  ggplot() +\n    geom_point(aes(x = per_dem_2016, y = per_gop_2016, color = white)) +\n    scale_x_continuous(limits = c(0, 1)) +\n    scale_y_continuous(limits = c(0, 1)) +\n    scale_color_gradient(low = \"green\",\n                         high = \"red\") +\n    facet_wrap(vars(census_region),\n               nrow = 2)\n\n\n\n\n\n\n\n\nApart from that, I can also spread it out using two different variables. Here, I will look at differences in the distribution of whites in the counties split up by who won in 2016 and 2012. This can be achieved using facet_grid(categorical_variable_1~categorical_variable_2). The former one will be put into rows, the latter into columns.\n\nsocviz::county_data |&gt; \n  drop_na() |&gt; \n  ggplot() +\n    geom_point(aes(x = per_dem_2016, y = per_gop_2016, color = white)) +\n    scale_x_continuous(limits = c(0, 1)) +\n    scale_y_continuous(limits = c(0, 1)) +\n    scale_color_gradient(low = \"green\",\n                         high = \"red\") +\n    facet_grid(winner~winner12)\n\n\n\n\n\n\n\n\nIf you want to facet using only one variable, put a dot at where the other variable would stand otherwise…\n\nsocviz::county_data |&gt; \n  drop_na() |&gt; \n  ggplot() +\n    geom_point(aes(x = per_dem_2016, y = per_gop_2016, color = white)) +\n    scale_x_continuous(limits = c(0, 1)) +\n    scale_y_continuous(limits = c(0, 1)) +\n    scale_color_gradient(low = \"green\",\n                         high = \"red\") +\n    facet_grid(.~winner)\n\n\n\n\n\n\n\n\n… or just use facet_wrap().\n\n\n\nExporting graphics\nIf you include the graphics in an RMarkdown document, make sure you use the proper chunk options (i.e., {r echo=FALSE, message=FALSE, warning=FALSE}).\nIf you, however, want to export it and put it into an MS Word document or so, you can just use the ggsave() function. By default, it just takes the last plot that has been created and saves it to a path that needs to be specified. If it contains a file extension, ggsave() just uses this one.\n\nggplot(mtcars, aes(mpg, wt)) +\n  geom_point()\n\nggsave(\"mtcars.pdf\", device = \"pdf\") #save it to pdf\nggsave(\"mtcars.png\") #save it to png\n\nggsave(\"mtcars.pdf\", width = 4, height = 4) #specify width and height -- in inches by default\nggsave(\"mtcars.pdf\", width = 20, height = 20, units = \"cm\") #change unit using the units argument\n\n\n\nFurther readings\n\nggplot2 cheatsheet.\nggplot2 – the book.\nThe graphic cookbook for R.\nAnother tutorial.\nA full-on online course by Kieran Healy (comes with an R package as well).\nNeed some inspiration? Check out the graph gallery.\nThe ggsave() function in further detail.\nYou can also consult the introverse package. introverse::show_topics(\"ggplot2\") will give you overviews of the respective package’s functions, and get_help(\"name of function\") will help you with the respective function.\n\n\n\nExercises\nUse the IMDb file.\nTry to think about how you could answer the following questions graphically. If you fail, take a look at the hints.\n\nDo higher rated movies generate more revenue?\n\nPlot revenue and rating as a scatter plot.\nDo you think there is a correlation? How could you make stronger claims about it? Maybe even graphically?\nInterpret the plot.\nAdd a nice title and labels.\n\nHow evenly are the different years’ movies represented? (Why would it be pointless to make claims about the productivity of directors?)\n\nMake a bar plot.\nInterpret the plot.\nAdd a nice title and labels.\n\nWhich year was the best for cinema fetishists? (When could they watch the most highest rated movies?)\n\nMake a box plot.\nInterpret the plot.\nAdd a nice title and labels."
  },
  {
    "objectID": "2_r_catch-up.html#iteration",
    "href": "2_r_catch-up.html#iteration",
    "title": "Chapter 2: Brief R Recap",
    "section": "Iteration",
    "text": "Iteration\nWe also will work with lists. Lists can contain elements of different lengths (which distinguishes them from tibbles). This makes them especially suitable for web scraping. Other than (atomic) vectors they are not just vectorized since they can contain elements of all different kinds of format.\nTo iterate over lists, we have the map() family from the purrr package, which applies functions over lists. pluck() extracts elements from the list.\n\nraw_list &lt;- list(first_element = 1:4, 4:6, 10:42)\nstr(raw_list) # shows you the elements of the list\n\nList of 3\n $ first_element: int [1:4] 1 2 3 4\n $              : int [1:3] 4 5 6\n $              : int [1:33] 10 11 12 13 14 15 16 17 18 19 ...\n\nmap(raw_list, mean)\n\n$first_element\n[1] 2.5\n\n[[2]]\n[1] 5\n\n[[3]]\n[1] 26\n\nmap(raw_list, ~{mean(.x) |&gt; sqrt()})\n\n$first_element\n[1] 1.581139\n\n[[2]]\n[1] 2.236068\n\n[[3]]\n[1] 5.09902\n\nmap_dbl(raw_list, mean) # by specifying the type of output, you can reduce the list\n\nfirst_element                             \n          2.5           5.0          26.0 \n\nraw_list |&gt; pluck(1) == raw_list |&gt; pluck(\"first_element\")\n\n[1] TRUE TRUE TRUE TRUE\n\n\nThis can also be achieved using a loop. Here, you use an index to loop over objects and do something to their elements. Typically, you create an empty list before and put the new output at the respective new position.\n\nnew_list &lt;- vector(mode = \"list\", length = length(raw_list))\nfor (i in seq_along(raw_list)){\n  new_list[[i]] &lt;- mean(raw_list[[i]])\n}"
  },
  {
    "objectID": "2_r_catch-up.html#functionalprogramming",
    "href": "2_r_catch-up.html#functionalprogramming",
    "title": "Chapter 2: Brief R Recap",
    "section": "Flow Control, Functional programming, and iterations",
    "text": "Flow Control, Functional programming, and iterations\nSo far, you have learned heaps of data wrangling and analyses, but no real customization of R. This will change now, as you will be introduced to functions. Furthermore, the operations have only been applied to one singular object (read vector or data.frame/tibble). Iteration means that you perform the same operation on multiple objects/data sets/you name it.\nToday’s session will all be about following the DRY principle. DRY stands for Don’t Repeat Yourself.\n“Why not?,” you may ask. Well, the problem with copy-and-pasting code is that you have to change all the variable names in every instance of your code. RStudio has a nice Search-and-Replace function which might facilitate that, but this practice still bears the danger of writing code that contains errors. This is where you will need to make use of the tools that R offers to iterate over a couple of elements, perform operations on them, and return the results. An example:\n\nexample_strings &lt;- c(\"this\", \"is\", \"how\", \"a\", \"for\", \"loop\", \"works\")\n\nfor (i in seq_along(example_strings)) {\n  print(example_strings[[i]])\n}\n\n[1] \"this\"\n[1] \"is\"\n[1] \"how\"\n[1] \"a\"\n[1] \"for\"\n[1] \"loop\"\n[1] \"works\"\n\n\nAnother option – from the tidyverse – is the purrr package:\n\nwalk(example_strings, print)\n\n[1] \"this\"\n[1] \"is\"\n[1] \"how\"\n[1] \"a\"\n[1] \"for\"\n[1] \"loop\"\n[1] \"works\"\n\n\nSo, what has this code done? In both cases, it has taken the function print() and applied it to every element of our vector. Copying-and-pasting would have looked like this:\n\nprint(example_strings[[1]])\n\n[1] \"this\"\n\nprint(example_strings[[2]])\n\n[1] \"is\"\n\nprint(example_strings[[3]])\n\n[1] \"how\"\n\nprint(example_strings[[4]])\n\n[1] \"a\"\n\nprint(example_strings[[5]])\n\n[1] \"for\"\n\nprint(example_strings[[6]])\n\n[1] \"loop\"\n\nprint(example_strings[[7]])\n\n[1] \"works\"\n\nprint(example_strings[[7]])\n\n[1] \"works\"\n\n\nDamn, I pasted the last instance twice. In this case, the mistake is obvious, but oftentimes it is not.\nIn the following, I will provide you a more extensive introduction into conditional statements, functions, loops, and the purrr (and it’s parallelized counter-part furrr) package.\n\nFlow control\nSometimes you want your code to only run in specific cases. For mutate(), I have already showed you conditional imputation of values with case_when(). A more generalized approach for conditionally running code in R are if statements. They look as follows:\n\nif (conditional_statement evaluates to TRUE) {\n  do_something\n}\n\nThey also have an extension – if…else:\n\nif (conditional_statement evaluates to TRUE) {\n  do_something\n} else {\n  do_something_else\n}\n\nImagine that I want R to tell me whether a number it draws is smaller than or equal to five:\n\nset.seed(1234)\nx &lt;- sample(10, 1)\n\nif (x &lt;= 5) {\n  print(\"x is smaller than or equals 5\")\n} \n\nIn this case, x is 3, so the if statement returns something. If this is not the case, nothing happens:\n\nset.seed(12345)\nx &lt;- sample(10, 1)\n\nif (x &lt;= 5) {\n  print(\"x is smaller than or equals 5\")\n}\n\n[1] \"x is smaller than or equals 5\"\n\n\nNow I could extend it by another if statement:\n\nset.seed(1234)\n\nx &lt;- sample(10, 1)\n\nif (x &lt;= 5) {\n  print(\"x is smaller than or equals 5\")\n}\nif (x &gt; 5) {\n  print(\"x is greater than 5\")\n}\n\n[1] \"x is greater than 5\"\n\n\nHere, x is 10, so only the second if statement returns something.\nBut the else allows me to take a shortcut and write it more concisely:\n\nif (x &lt;= 5) {\n  print(\"x is smaller than or equals 5\")\n} else {\n  print(\"x is greater than 5\")\n}\n\n[1] \"x is greater than 5\"\n\n\nPlease note that the condition inside the if statement needs to be a vector of type logical (hence, either TRUE or FALSE). Apart from that, only vectors of length 1 are allowed. The following will not work:\n\nif (c(TRUE, FALSE, TRUE)) {\n  print(\"example\")\n} #This will throw an error!!!\n\n\n\nFunctions\nSo far, every call you have made within R contained a function. Even the most basic operations, such as c() for building vectors, rely on functions. Functions are the verbs of R, they do something to your objects. Hence, you as someone who obeys the principles of DRY can make good use of them. Whenever you need to copy code to perform certain tasks to an object, you can also put those tasks into a function and just provide the function with the objects.\nImagine you want to rescale some variables in a tibble (an example I took from the OG version of R4DS (Wickham and Grolemund 2016)):\n\nset.seed(1234)\n\ndf &lt;- tibble(\n  a = rnorm(10),\n  b = rnorm(10),\n  c = rnorm(10),\n  d = rnorm(10)\n)\n\ndf$a &lt;- (df$a - min(df$a, na.rm = TRUE)) / \n  (max(df$a, na.rm = TRUE) - min(df$a, na.rm = TRUE))\ndf$b &lt;- (df$b - min(df$b, na.rm = TRUE)) / \n  (max(df$b, na.rm = TRUE) - min(df$b, na.rm = TRUE))\ndf$c &lt;- (df$c - min(df$c, na.rm = TRUE)) / \n  (max(df$c, na.rm = TRUE) - min(df$c, na.rm = TRUE))\ndf$d &lt;- (df$d - min(df$d, na.rm = TRUE)) / \n  (max(df$d, na.rm = TRUE) - min(df$d, na.rm = TRUE))\n\nGiven that you now know how to loop over the tibble, you can certainly reduce the amount of copy-pasting here.\n\ndf &lt;- tibble(\n  a = rnorm(10),\n  b = rnorm(10),\n  c = rnorm(10),\n  d = rnorm(10)\n)\n\nfor (i in seq_along(df)) {\n  df[[i]] &lt;- (df[[i]] - min(df[[i]], na.rm = TRUE)) / \n  (max(df[[i]], na.rm = TRUE) - min(df[[i]], na.rm = TRUE))\n}\n\nHowever, the operation within the loop is generalizable: it always only takes a vector of numeric values as input, performs some actions on them and returns another vector of the same length, but rescaled into a range from 0 to 1. Hence, the operation fulfills the requirements for putting it into a function.\nDoing so has some advantages:\n\nIf an error occurs, you can simply change the function in one place – when you define it – instead of changing all the occurrences in your code\nIt will certainly make your code easier to read – rescale0to1 is a more concise description than (x - min(x, na.rm = TRUE)) / (max(x, na.rm = TRUE) - min(x, na.rm = TRUE)) (–&gt; you see what I did here? I already replaced the arguments with a generic variable. You can use it to write the function yourself.)\n\n\nWriting your own functions\nWhen you define functions in R, you need to follow a certain structure:\n\nfunction_name &lt;- function(argument_1, argument_2, argument_n) {\n  function_body\n}\n\n\nThe function_name is the thing you will call (e.g., mean()). In general, it should be a verb, it should be concise, and it should be in_snakecase.\nThe arguments are what you need to provide the function with (e.g., mean(1:10)).\nThe function body contains the operations which are performed to the arguments. It can contain other functions as well – which need to be defined beforehand (e.g., sum(1:10) / length(1:10))). It is advisable to split up the function body into as little pieces as you can.\n\n\n\nAn example: Roulette\nIn the following, I will guide you through a quick example on how you could use functions to play an extremely basic game of Roulette with R. You provide it with two values (how much you bet and which number you choose) and R takes care of the rest.\nSo what does the function need to do? First, it needs to draw a number between 0 and 36. Second, it needs to compare the bet and its corresponding number. Third, it needs to return the respective result.\n\nplay_roulette &lt;- function(bet, number) {\n  draw &lt;- sample(0:36, 1)\n  tibble(\n    winning_number = draw,\n    your_number = number,\n    your_bet = bet,\n    your_return = if (number == draw) {\n      bet * 36\n    } else {\n      0\n    }\n  )\n}\n\nplay_roulette(bet = 1, number = 35)\n\n# A tibble: 1 × 4\n  winning_number your_number your_bet your_return\n           &lt;int&gt;       &lt;dbl&gt;    &lt;dbl&gt;       &lt;dbl&gt;\n1             15          35        1           0\n\n\nBut how to make sure that I do not bet on a number which I cannot bet on (i.e., numbers greater than 36)? Or, put differently, how to forbid values? Use stop(). Besides, how to set default values for the arguments? Just use argument = default.\n\nplay_roulette_restricted &lt;- function(bet = 1, number) {\n  if (number &gt; 36) stop(\"You can only bet on numbers between 0 and 36.\")\n  draw &lt;- sample(0:36, 1)\n  tibble(\n    winning_number = draw,\n    your_number = number,\n    your_bet = bet,\n    your_return = if (number == draw) {\n      bet * 36\n    } else {\n      0\n    }\n  )\n  #return(tbl_return)\n}\nplay_roulette_restricted(number = 3)\n\n# A tibble: 1 × 4\n  winning_number your_number your_bet your_return\n           &lt;int&gt;       &lt;dbl&gt;    &lt;dbl&gt;       &lt;dbl&gt;\n1              1           3        1           0\n\n\nThe function returns the results of the last call, i.e., the tibble. If you want to be more concrete about what it should return – or make an earlier return – use return(). The function will stop as soon as it hits a return() statement.\n\nplay_roulette_basic &lt;- function(bet = 1, number) {\n  if (number &gt; 36) stop(\"You can only bet on numbers between 0 and 36.\")\n  draw &lt;- sample(0:36, 1)\n  if (number == draw) {\n    return(str_c(\"Nice, you won\", as.character(bet * 36), \"Dollars\", sep = \" \"))\n  } else {\n    return(\"I'm sorry, you lost.\")\n  }\n}\nplay_roulette_basic(number = 35)\n\n[1] \"I'm sorry, you lost.\"\n\n\n\n\nFunctional programming with tidyverse functions\nThe majority of dplyr verbs uses so-called tidy evaluation which is a framework for controlling how expressions and variables in your code are evaluated by the tidyverse functions. The two main things here are data masking and tidy selection. The former facilitates computing on values within the data set and refers to functions such as filter(), where you can just type in variable names instead of tediously typing name_of_df$var_name. The latter aims to facilitate working with the columns in the data set. It is provided by the tidyselect package and allows you, for instance, to work with code such as tbl |&gt; select(starts_with(\"a\")). More examples can be acquired using ?dplyr_tidy_select.\nI will not go into detail here but rather stick to what implications this has to you. If you are interested in the theoretical underpinnings, read the chapter on “Metaprogramming” in Advanced R by Hadley Wickham.\nIf your function takes a user-supplied variable as an argument, you need to consider this arguments in the pipeline. For instance, the following function calculates the mean, median, and standard deviation of a variable.\n\nmy_summary &lt;- function(tbl, var) {\n  tbl |&gt; \n    summarize(\n      mean = mean({{ var }}),\n      median = median({{ var }}),\n      sd = sd({{ var }})\n    )\n}\n\nmtcars |&gt; my_summary(cyl) \n\n    mean median       sd\n1 6.1875      6 1.785922\n\n\nIf the variable names are supplied in a character vector, you need all_of():\n\nsummarize_mean &lt;- function(data, vars) {\n  data |&gt; summarize(n = n(), across({{ vars }}, mean))\n}\n\nmtcars |&gt; \n  group_by(cyl) |&gt; \n  summarize_mean(all_of(c(\"hp\", \"mpg\"))) |&gt; \n  glimpse()\n\nRows: 3\nColumns: 4\n$ cyl &lt;dbl&gt; 4, 6, 8\n$ n   &lt;int&gt; 11, 7, 14\n$ hp  &lt;dbl&gt; 82.63636, 122.28571, 209.21429\n$ mpg &lt;dbl&gt; 26.66364, 19.74286, 15.10000\n\n\nAnother handy thing is changing the variable names in the output depending on the input names. Here, you can use glue syntax and :=:\n\nmy_summary_w_names &lt;- function(tbl, var){\n  tbl |&gt; \n    summarize(\n      \"mean_{{ var }}\" := mean({{ var }}),\n      \"median_{{ var }}\" := median({{ var }}),\n      \"sd_{{ var }}\" := sd({{ var }})\n    )\n}\n\nmtcars |&gt; my_summary_w_names(cyl)\n\n  mean_cyl median_cyl   sd_cyl\n1   6.1875          6 1.785922\n\n\nFind more on programming with dplyr in this vignette.\n\n\nFurther readings\nIf you want to learn more about functional programming, check out the following resources:\n\nThe R4DS chapter\nA basic tutorial\nA book chapter about control-flow and functions\nHadley on functional programming\n\n\n\n\nIteration\nStrictly speaking, there are three kinds of loops: for, repeat, and while. I will touch upon for and while, because they are more straight-forward than repeat. repeat loops will repeat a task until you tell it to stop by hitting the escape button or adding a condition up front. Interactive programming – sitting in front of your machine and hitting the escape button to break a loop – is no desired practice and while loops have internalized the condition already. Hence, repeat loops do not appear to have any advantage and I leave them out deliberately.\n\nfor loops\nfor loops are the sort of loops you will have to work with more often as they allow you to loop over a predefined number of elements. For this sake, I will briefly revise how you index vectors, lists, and tibbles.\nThe ith element of a vector can be accessed by using either [[i]] or [i].\nThe ith element of a list can be obtained by using [[i]] – [i] would return a sub-list instead of the element. The second element of the ith element in a list (if it were a vector or a list) can be obtained using [[i]][[2]] etc.\nThe ith column of a tibble can be accessed as a vector using [[i]]. The second value of the ith column of a tibble can be accessed using [[i]][[2]]\nHow does that matter for for loops? Remember the example I showed you in the beginning? All a for loop does is iterating over a vector of values and imputing them instead of a placeholder.\n\nexample_strings &lt;- c(\"this\", \"is\", \"how\", \"a\", \"for\", \"loop\", \"works\")\n\nfor (i in example_strings) {\n  print(i)\n}\n\n[1] \"this\"\n[1] \"is\"\n[1] \"how\"\n[1] \"a\"\n[1] \"for\"\n[1] \"loop\"\n[1] \"works\"\n\n\nFor a more general approach, you can also loop over the indices of the vector using seq_along() which creates a sequence along a vector.\n\nseq_along(example_strings) # seq_along looks like this\n\n[1] 1 2 3 4 5 6 7\n\n\nThis is especially useful if you want to modify the elements of a vector or a tibble.\n\nfor (i in seq_along(example_strings)) {\n  print(example_strings[[i]])\n}\n\n[1] \"this\"\n[1] \"is\"\n[1] \"how\"\n[1] \"a\"\n[1] \"for\"\n[1] \"loop\"\n[1] \"works\"\n\n#Hence, the first iteration looks like this.\nprint(example_strings[[seq_along(example_strings)[[1]]]])\n\n[1] \"this\"\n\n# translates to\nprint(example_strings[[1]])\n\n[1] \"this\"\n\n\nNow that you have seen the general approach for using a for loop, how can you use them in practice for data manipulation? Whenever you use a for loop, you need to follow a three step approach:\n\nOutput: In the beginning, you need to create a vector that we can fill with output. You also need to determine the length of the vector in the beginning. This is due to efficiency: if you were to grow the vector by every iteration (using c), the loop becomes very slow. This is especially important if you work with large data sets. An example for creating an empty vector of a certain length is output &lt;- vector(mode = \"numeric\", length = length_of_output).\nSequence: i in seq_along(variable) tells the for loop what to loop over.\n\nBody: The actual code. Performs the operation on the respective instance and stores the resulting value in the pre-defined output vector at position i.\n\nfor loops are considered slow. They are not, at least not if you stick to the following rules:\n\nAlways pre-allocate space – make sure that R does not have to expand your objects\nDo as much as you can outside the loop – every operation inside the loop will be repeated every time the loop is repeated\n\nIn general, you will come across three different problems with for loops.\n\nModifying an existing object\nLength of output is unknown\nSequences are of unknown length\n\n\nModifying the existing object\nSometimes you want to modify an existing object rather than creating a new one. This is useful when working with large datasets or when you need to update values in place.\nBasic example: Standardizing columns Let’s say you have a dataset with test scores that you want to standardize (mean = 0, sd = 1):\n\nscores &lt;- tibble(\n  student_id = 1:5,\n  math = c(85, 92, 78, 88, 95),\n  science = c(90, 85, 80, 92, 88),\n  english = c(88, 90, 85, 86, 92)\n)\n\nfor (col in c(\"math\", \"science\", \"english\")) {\n  scores[[col]] &lt;- (scores[[col]] - mean(scores[[col]])) / sd(scores[[col]])\n}\n\nscores |&gt; \n  summarize(across(c(math, science, english), \n                   list(mean = mean, sd = sd)))\n\n# A tibble: 1 × 6\n  math_mean math_sd science_mean science_sd english_mean english_sd\n      &lt;dbl&gt;   &lt;dbl&gt;        &lt;dbl&gt;      &lt;dbl&gt;        &lt;dbl&gt;      &lt;dbl&gt;\n1  8.88e-16       1     7.22e-17          1    -9.77e-16          1\n\n\n\n\nLength of output is unknown\nSometimes, you do not know how long your output object is. This is, for instance, if you simulate vectors of random length. Normally, you would just put the values into a vector. However, if you do not know the length, then you would have to ask R to grow the vector every iteration. But this is extremely inefficient.\nFor this, the solution is lists. You always know how many iterations your loop will have. Hence, you can create a list of this exact length and then just store the results in the list (as lists do not care about the length of the singular elements). Afterwards, you can unlist() or flatten_*() the list into a vector.\n\na_list &lt;- vector(mode = \"list\", length = 10L)\n\nfor (i in seq_along(a_list)) {\n  len &lt;- sample(1:10, 1)\n  a_list[[i]] &lt;- rnorm(len)\n}\n\na_list |&gt; \n  unlist() # or unlist(a_list)\n\n [1]  0.69760871  0.54999735 -0.40273198 -0.19159377 -1.19452788 -0.05315882\n [7] -1.43192024 -2.01016571  0.33832922  0.65128696  2.43315152  1.19133821\n[13]  0.92244282  0.62109737  0.35633348 -0.47471847  0.06599349 -0.50247778\n[19]  2.18711916 -0.58172745  0.70008023  1.49217658 -0.05210512 -0.19593462\n[25] -0.64906975 -1.10976723  0.84927420 -0.01394090  0.16863694  0.86926335\n[31] -0.79866986 -0.50375053  2.31559832 -0.69220912  0.49335047 -0.05760147\n[37]  1.82420830  0.08005964 -0.63140930 -1.51328812 -0.63609983  0.22630153\n[43]  1.01369035 -1.17194831  0.66871433 -1.65010093 -0.36585225 -0.31611833\n[49] -1.94824605  0.92005752 -0.62287159 -0.17827861  0.78695133 -0.58054783\n[55]  0.91825114\n\n\nIf we wanted to add the information in a tibble, we could add it during the run and use bind_rows() afterwards.\n\na_list &lt;- vector(mode = \"list\", length = 10L)\n\nfor (i in seq_along(a_list)) {\n  len &lt;- sample(1:10, 1)\n  a_list[[i]] &lt;- list(\n    run = i,\n    values = rnorm(len)\n  )\n}\n\ndf &lt;- a_list |&gt; \n  bind_rows()\n\ndf\n\n# A tibble: 55 × 2\n     run  values\n   &lt;int&gt;   &lt;dbl&gt;\n 1     1  0.700 \n 2     1 -1.20  \n 3     1 -0.499 \n 4     2  0.0976\n 5     3 -0.119 \n 6     3  2.39  \n 7     3  0.735 \n 8     3  0.474 \n 9     3 -0.234 \n10     3 -0.854 \n# ℹ 45 more rows\n\n\n\n\nUnknown sequence length\nSometimes, you also do not know how long your input sequence is. Instead, you want to loop until a certain condition is met. This is for instance the case when looping across multiple pages in web-scraping. Here, while loops come in handy (but this is the only use case I could think of).\nThe basic structure of while loops is as follows:\n\nwhile (condition) {\n  code\n}\n\nWhat could an example look like?4 The following loop keeps running until three heads appeared in a row and the condition is met.\nPlease note that both vectors which are to be modified within the loop – indicator and head – need to be created beforehand. If I had not created head beforehand, the loop would not have started because there would not have been any vector to assess the length.\n\nindicator &lt;- 0\nhead &lt;- c()\nwhile (length(head) &lt; 3) {\n  if (sample(2, 1) == 1) {\n    x &lt;- \"head\"\n  } else {\n    x &lt;- \"tail\"\n  }\n  if (x == \"head\") {\n    head &lt;- c(head, 1)\n  } else {\n    length(head) &lt;- 0\n  }\n  indicator &lt;- indicator + 1\n}\n\nIn this case, you still want to pre-allocate space. Hence, you could also use a list here. You can just do a very long list and afterwards cut it down to size using purrr::compact().\n\nindicator &lt;- 0\nvalues &lt;- vector(mode = \"list\", length = 1000)\nhead &lt;- c()\nwhile (length(head) &lt; 3) {\n  if (sample(2, 1) == 1) {\n    x &lt;- \"head\"\n  } else {\n    x &lt;- \"tail\"\n  }\n  if (x == \"head\") {\n    head &lt;- c(head, 1)\n  } else {\n    length(head) &lt;- 0\n  }\n  values[[indicator + 1]] &lt;- x\n  indicator &lt;- indicator + 1\n}\n\nlength(values)\n\n[1] 1000\n\nvalues |&gt; tail(5) #last 5 values\n\n[[1]]\nNULL\n\n[[2]]\nNULL\n\n[[3]]\nNULL\n\n[[4]]\nNULL\n\n[[5]]\nNULL\n\nvalues |&gt; compact() #removes all NULL elements\n\n[[1]]\n[1] \"tail\"\n\n[[2]]\n[1] \"head\"\n\n[[3]]\n[1] \"head\"\n\n[[4]]\n[1] \"tail\"\n\n[[5]]\n[1] \"head\"\n\n[[6]]\n[1] \"head\"\n\n[[7]]\n[1] \"head\"\n\n\n\n\n\npurrr::map()\nLoops are good because they make everything very explicit. However, it is often tedious to type. The purrr package provides functions which enable you to iterate over vectors, data frames/tibbles, and lists. Apart from that, it has a lot of functions to work with lists as well. I will only cover the former functions. If you are interested in using purrr for working with lists, check out this extensive tutorial by Jenny Bryan.\nIn the beginning of this chapter, I used the walk() function. This function is related to map() as it iterates over a vector and applies a function to its respective elements. The difference is that walk() doesn’t store the results, map() does.\n\nThe basics\nThe structure of the map() function looks like this:\n\nmap(vector or list, function(, if you need it, additional arguments of function))\n\nmap() always returns a list.\nIf you want the output to be in a different format, there are different, type-specific map() functions.\n\nmap_dfr() returns a data frame – by binding the rows\nmap_dfc() returns a data frame – by binding the columns\nmap_dbl() returns a double vector\nmap_chr() returns a character vector\nmap_lgl() returns a logical vector\n\nIn the following I will demonstrate the function of map() with a simple example. The basic vector I will map over is:\n\nexample_dbl &lt;- c(1.5, 1.3, 1.8, 1.9, 2.3)\n\nIn the first example, I just add 10 to the vector. In order to do so, I first need to create a function which adds 10.\n\nadd_10 &lt;- function(x) {\n  x + 10\n}\n\n\nmap(example_dbl, add_10)\n\n[[1]]\n[1] 11.5\n\n[[2]]\n[1] 11.3\n\n[[3]]\n[1] 11.8\n\n[[4]]\n[1] 11.9\n\n[[5]]\n[1] 12.3\n\n\n\nmap_dbl(example_dbl, add_10)\n\n[1] 11.5 11.3 11.8 11.9 12.3\n\n\n\nmap_chr(example_dbl, add_10) # does not make sense though\n\nWarning: Automatic coercion from double to character was deprecated in purrr 1.0.0.\nℹ Please use an explicit call to `as.character()` within `map_chr()` instead.\n\n\n[1] \"11.500000\" \"11.300000\" \"11.800000\" \"11.900000\" \"12.300000\"\n\n\n\n\nAnonymous functions\nIn the former example, I did specify the function beforehand. map() also allows you to define the function within the call using a so-called anonymous function \\(x). The function’s argument is pre-defined (x in this case, but could be any placeholder) which stands for the respective input.\n\nmap_dbl(example_dbl, \\(x){\n  x + 10\n  })\n\n[1] 11.5 11.3 11.8 11.9 12.3\n\n\nYou can also map across tibbles. Here, you iterate over columns. For instance, calculating a mean for each column of the cars_tbl would have looked like this in purrr:\n\ncars_tbl &lt;- mtcars\nmap(cars_tbl, mean)\n\n$mpg\n[1] 20.09062\n\n$cyl\n[1] 6.1875\n\n$disp\n[1] 230.7219\n\n$hp\n[1] 146.6875\n\n$drat\n[1] 3.596563\n\n$wt\n[1] 3.21725\n\n$qsec\n[1] 17.84875\n\n$vs\n[1] 0.4375\n\n$am\n[1] 0.40625\n\n$gear\n[1] 3.6875\n\n$carb\n[1] 2.8125\n\n\nWhen I put it into a tibble, names are preserved:\n\nmap_dfc(cars_tbl, mean)\n\n# A tibble: 1 × 11\n    mpg   cyl  disp    hp  drat    wt  qsec    vs    am  gear  carb\n  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1  20.1  6.19  231.  147.  3.60  3.22  17.8 0.438 0.406  3.69  2.81\n\n\n\n\nMapping over multiple arguments\nSometimes you want to apply things to multiple arguments. Think for example of the sample()function. It requires at least two arguments: the size of the sample you draw and the element space x you draw the sample from.\n\nmap2(10, 1:5, sample, replace = TRUE)\n\n[[1]]\n[1] 4\n\n[[2]]\n[1]  1 10\n\n[[3]]\n[1]  7  6 10\n\n[[4]]\n[1] 1 6 6 6\n\n[[5]]\n[1] 7 5 5 5 6\n\n\nHowever, the map2() functions do not provide you with the possibility to control the type of output you get. You can take care of this using flatten_*().\n\nmap2(10, 5, sample) |&gt; flatten_dbl()\n\n[1] 6 4 8 3 2\n\n\nIf you provide it with a vector which is longer than 1, map2() will not perform the operation on every possible combination of the two vectors. Instead, it iterates over both vectors simultaneously, hence, the first iteration uses the first two values, the second iteration the second two values etc. Also note that it matches the arguments by position, not by name, hence the second argument is the size of the sample, the first one the element space.\n\nmap2(c(10, 5), c(5, 3), sample) \n\n[[1]]\n[1]  7  8  4  5 10\n\n[[2]]\n[1] 1 3 5\n\n\nIf you want to use an anonymous function, you can do so as well:\n\nmap2(c(10, 5), c(5, 3), \\(x, y) sample(x, size = y))\n\n[[1]]\n[1] 4 8 6 7 2\n\n[[2]]\n[1] 5 1 3\n\n\nIf you want to map over more than two arguments, pmap() is the way to go. If you work with functions which need multiple values as arguments, you can store the vectors containing the respective values in a tibble. You should name the columns according to the function’s arguments.\nAn example here is drawing numbers from a normal distribution – rnorm(). The function takes three arguments: n– the number of values to be drawn, mean, and sd.\n\ntibble(\n  n = 10,\n  mean = 1:10,\n  sd = 0.5\n) |&gt; \n  pmap(rnorm)\n\n[[1]]\n [1] 0.2762588 1.2662280 0.4966849 1.3585467 0.7492659 0.7907689 0.3105248\n [8] 1.1213886 1.4226768 0.1782507\n\n[[2]]\n [1] 2.509489 2.476223 2.410380 2.813266 2.116919 2.392606 1.324271 1.782913\n [9] 1.659243 2.718527\n\n[[3]]\n [1] 3.433201 2.123642 2.645378 3.158825 3.418090 4.271263 3.200257 3.017893\n [9] 3.141365 2.606872\n\n[[4]]\n [1] 3.914835 4.595926 4.682905 3.619700 3.513134 4.954899 3.123541 4.477846\n [9] 5.167031 4.550836\n\n[[5]]\n [1] 5.545990 5.142692 4.220136 5.427874 5.213967 4.856378 4.899412 5.450255\n [9] 3.873000 4.740156\n\n[[6]]\n [1] 5.818541 6.971764 6.147575 6.582609 6.121836 6.226723 6.257705 5.418025\n [9] 5.531128 6.076174\n\n[[7]]\n [1] 6.859280 6.594688 6.866800 7.426123 6.291120 6.845510 7.212836 6.980094\n [9] 6.177029 7.468289\n\n[[8]]\n [1] 8.743606 8.803838 8.125447 8.136227 8.075560 8.486074 8.504599 7.792865\n [9] 7.557125 8.727168\n\n[[9]]\n [1] 8.815799 9.599489 9.429286 9.243450 8.937363 9.010900 8.082863 9.765383\n [9] 9.820104 8.174236\n\n[[10]]\n [1] 10.015095  9.715463 10.305483 10.754284  9.661376 10.500636 10.617799\n [8] 10.823392  9.387472  9.728401\n\n\nIf you want to use an anonymous function, you can do so as well:\n\ntibble(\n  n = 10,\n  mean = 1:10,\n  sd = 0.5\n) |&gt; \n  pmap(\\(n, mean, sd) rnorm(n, mean, sd))\n\n[[1]]\n [1] 0.7772323 0.0416125 0.9735931 0.9834894 1.0114624 0.3249466 1.0569058\n [8] 1.3214937 1.1249126 0.9573270\n\n[[2]]\n [1] 1.4034810 2.1781413 2.0860438 2.9868643 1.4047264 1.5553486 1.5861139\n [8] 1.3575352 1.3621371 0.7242431\n\n[[3]]\n [1] 4.093959 2.798665 4.107978 1.874788 3.051627 3.409510 3.433766 3.728983\n [9] 2.355771 2.556102\n\n[[4]]\n [1] 2.433150 4.199967 4.212392 4.328054 4.488375 4.602977 4.691167 4.146277\n [9] 4.189498 4.097553\n\n[[5]]\n [1] 5.140349 5.092283 4.738515 5.529182 4.269838 5.013457 4.620869 4.823738\n [9] 4.207710 4.723280\n\n[[6]]\n [1] 6.245906 5.058408 5.516441 5.472807 6.025419 5.685291 6.462158 6.550718\n [9] 6.566605 5.717003\n\n[[7]]\n [1] 7.087744 6.923719 6.899486 6.571321 7.224902 6.843166 7.430276 6.926348\n [9] 6.838748 6.860724\n\n[[8]]\n [1] 8.402492 7.871721 7.946986 8.426621 8.797195 8.227491 7.582142 8.157361\n [9] 8.107146 7.558428\n\n[[9]]\n [1] 9.694184 9.786892 9.286632 9.995288 8.535659 9.185741 8.114063 9.860151\n [9] 8.876233 8.891865\n\n[[10]]\n [1] 10.696122 11.047684 10.039567 10.655035  9.739268  9.559926  9.317054\n [8] 10.097944  9.665217 10.051768\n\n\n\n\nSpeeding up with furrr\nIf you work with large data sets or have to perform a lot of iterations, you might want to speed up your code. The furrr package provides the same functionality as purrr, but allows for parallelization. This means that it can split up the tasks and distribute them across multiple CPU cores.\nIts functionalities are the same as in purrr, just with a future_ prefix. In order to use it, you need to set up a plan first. Here, I use multisession, which works on all platforms (Windows, Mac, Linux). If you work on a Linux machine, you can also use multicore, which is faster.\n\nneeds(furrr)\nplan(multisession) #set up parallelization\nfuture_map_dbl(example_dbl, add_10)\n\n[1] 11.5 11.3 11.8 11.9 12.3\n\n\nNote that speed benefits are not apparent when working with small data sets or few iterations. The overhead of setting up parallel processes can outweigh the benefits. However, if you work with large data sets or have to perform a lot of iterations, you will see a speed increase.\nLet’s make add_10 slow and benchmark furrr and purrr using the tictoc package. I have set the sleep time to 0.5 seconds to make the difference more apparent. My laptop has 8 cores, hence I create 24 tasks which will be distributed across the 8 workers (3 tasks per worker).\n\nneeds(tictoc)\n\n# Create more tasks than workers\nexample_long &lt;- 1:24 \n\nadd_10_slow &lt;- function(x) {\n  Sys.sleep(0.5)  # Shorter sleep time\n  x + 10\n}\n\n# Sequential version\ntic(\"Sequential (purrr)\")\nresult_seq &lt;- map_dbl(example_long, add_10_slow)\ntoc()\n\nSequential (purrr): 12.158 sec elapsed\n\n# Parallel version\ntic(\"Parallel (furrr)\")\nresult_par &lt;- future_map_dbl(example_long, add_10_slow)\ntoc()\n\nParallel (furrr): 3.219 sec elapsed\n\n\nYou can see that the parallel version is much faster than the sequential one. However, the speed increase is not linear. This is due to the overhead of setting up parallel processes. Setting up worker processes, transferring data between them, and collecting results all take time. With my 0.5 second tasks, this overhead becomes a significant fraction of the total runtime. Also, following Amdahl’s Law, not everything can be parallelized. Some parts like initial setup and final result collection must run sequentially. This creates a fundamental limit on speedup. Finally, there are system constraints, as my CPU shares resources with other processes, memory bandwidth can become a bottleneck, and modern CPUs can’t maintain peak single-core performance across all cores simultaneously.\nSo, when should we use furrr?\n\nWhen you have a large number of tasks that can be executed independently.\nWhen each task takes a significant amount of time to complete.\nWhen you have access to a multi-core machine.\n\nWhen should we avoid furrr?\n\nWhen tasks are very quick to execute (the overhead of parallelization may outweigh the benefits).\nWhen tasks depend on each other (parallelization won’t help).\nWhen working in an environment where parallel processing is restricted (e.g., some cloud services or shared servers).\nWhen debugging (parallel code can be harder to debug).\n\n\n\n\nFurther links\n\nChapter about loops in Hands-on Programming with R\nOn control flow\nA basic introduction to purrr::map\nThe corresponding chapter in R4DS"
  },
  {
    "objectID": "2_r_catch-up.html#footnotes",
    "href": "2_r_catch-up.html#footnotes",
    "title": "Chapter 2: Brief R Recap",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nThis becomes especially painful if you teach R to your students and have to grade 20 submissions and, hence, have to paste your personal directory’s file path into each of these submissions.↩︎\nwhich can be found here or using vignette(\"tidy-data\", package = \"tidyr\")↩︎\nIf you want to run the code on your machine, download the files behind the following links and store them in a folder called socviz_us which is again stored in a folder named data which lives in the same folder as the .qmd file.↩︎\nI have taken this example from the R for Data Science book. I hardly ever work with while loops. The only use case from my day-to-day work is web-scraping, where I want to loop over pages until a certain threshold is reached. Therefore, I could not really come up with an example myself.↩︎"
  },
  {
    "objectID": "1_r_index.html",
    "href": "1_r_index.html",
    "title": "Chapter 1: Preface",
    "section": "",
    "text": "Dear student,\nif you read this script, you are either participating in one of my courses on digital methods for the social sciences, or at least interested in this topic. If you have any questions or remarks regarding this script, hit me up at felix.lennert@uni-leipzig.de.\nThis script will introduce you to techniques I regard as elementary for any aspiring (computational) social scientist: the collection of digital trace data via either scraping the web or acquiring data from application programming interfaces (APIs), the analysis of text in an automated fashion (text mining), the analysis and visualization of spatial data, and the modeling of human behavior in silico (agent-based modeling).\nThe following chapters draw heavily on packages from the tidyverse (Wickham et al. 2019) and related packages. If you have not acquired sufficient familiarity yet, you can have a look at the excellent book R for Data Science (Wickham, Çetinkaya-Rundel, and Grolemund 2023).\nI have added brief videos to each section. In these, I will briefly go through the code of the respective section and show a bit of what’s going on in there. I sometimes spontaneously elaborate a bit more on the examples at hand or show things in the data, so they may add some value. However, the script should be sufficient to provide you an understanding the concepts I introduce."
  },
  {
    "objectID": "1_r_index.html#outline",
    "href": "1_r_index.html#outline",
    "title": "Chapter 1: Preface",
    "section": "Outline",
    "text": "Outline\nThis script will unfold as follows:\nChapter 2, “Brief R Recap,” briefly introduces RStudio Projects, Quarto, tidy data and tidyr, dplyr, ggplot, functions, loops, and purrr. These techniques are vital for the things that will come next.\nChapter 3, 4, and 5 introduce Python and the reticulate package, which allows you to use Python in an R environment. It also introduces pandas, a powerful data manipulation package for Python.\nChapter 6, “stringr and RegExes,” deals with string manipulation using, you guessed it, stringr and RegExes.\nChapters 7 and 8, “Crawling the Web and Extracting Data” and “APIs,” introduce the reader to the basics of rvest, HTML, and CSS selectors and how these can be used to acquire data from the web. Moreover, I introduce the httr package and explain how you can use it to make requests to APIs.\nChapter 9, “selenium,” introduces selenium, a Python package that allows you to control a “headless browser” – this is invaluable if you want to scrape dynamic web sites. It will also feature an introduction to reticulate, an R package that allows you to use Python code in an R environment.\nChapter 10, “OCR with tesseract,” shows you how to digitize text from pdf files or images in an automated fashion using tesseract.\nChapter 11, “OpenAI whisper” focuses on the transcription of audio files. This includes diarization.\nChapter 12, “Text Preprocessing and Featurization,” touches upon the basics of bringing text into a numeric format that lends itself to quantitative analyses. It also introduces feature weighting using TF-IDF (i.e., determining which tokens matter more than others), Named-Entity Recognition, and Part-of-Speech-tagging.\nChapter 13, “Dictionary-based analysis,” covers dictionary-based text analysis.\nChapter 14, “Supervised Classification,” deals with the classification of text in a supervised manner using tidymodels.\nChapter 15, “Unsupervised Classification,” deals with the classification of text in an unsupervised manner using “classic” Laten Dirichlet Allocation, Structural Topic Models, and Seeded Topic Models.\nChapter 16, “Word Embeddings,” showcases new text analysis techniques that are based on distributional representations of words, commonly referred to as word embeddings.\nChapter 17, “BERT” demonstrates how you can use BERT for supervised classification. This script will only contain small data-sets, since these large language models require more computing power (e.g., a server with plenty of RAM as well as sufficient CPU and/or GPU power)\nChapter 18, “Local LLMs,” introduces local large language models (LLMs) and showcases how you can use them for information extraction.\nAll chapters try to deal with social scientific examples. Data sets will be provided via Dropbox, therefore the script shall run more or less out of the box. I tried to include “Further links” for the avid readers or the ones that are dissatisfied with my coverage of the content. Exercises are included, the respective solutions will be added as the course unfolds (except for the R recap, please contact me in case you are interested)."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Welcome",
    "section": "",
    "text": "This is a Quarto website for the “Forschungsseminar CSS” course at Leipzig University. It covers different techniques for the aspiring computational social scientist, hence I have dubbed it “Toolbox CSS.” You can reach me anytime at felix.lennert@uni-leipzig.de. If you’re interested in my academic work, you can visit my website.\nHere’s the official description:\nThe curriculum covers a range of topics including data management, web scraping, speech-to-text, and computational text analysis. Students will hone their R and develop skills in Python, applying these languages to real-world social science problems. The course progresses from fundamental concepts to advanced techniques, including the use of state-of-the-art AI models for text analysis.\nThe course structure consists of one lecture and one lab session per week, providing a balance of theoretical knowledge and practical application. Throughout the semester, students will benefit from hands-on coding exercises, one-on-one mentoring, and collaborative projects. The course culminates in a research paper, allowing students to apply their new skills to a topic of their choice."
  },
  {
    "objectID": "index.html#course-structure",
    "href": "index.html#course-structure",
    "title": "Welcome",
    "section": "Course Structure",
    "text": "Course Structure\nThe course consists of lectures introducing each week’s content and a course script that provides hands-on coding examples for the content. It is mostly containing R with some Python mixed in for good measure when no great R alternatives exist (e.g., for web scraping with Selenium, text classification with transformer models).\nAt the beginning of the course, students are encouraged to form groups based on research interests and general vibes. I require each student group to check in with me at the beginning of each week to report their progress (even if there’s nothing to report – no progress, no problem). This does not count towards any grade but rather serves the purpose of me receiving feedback on the learning experience (this is a new course!) – and will hopefully help me with providing more appropriate guidance.\nHere’s an overview of the topics covered:\n\n\n\n\n\n\n\n\n\nWEEK\nTITLE\nCONTENT\nINFORMAL TITLE\n\n\n\n\n1\nKick Off\nHousekeeping; Setting up workstation; R recap\nWhatever you want to know about CSS\n\n\n2\nBrief Intro to Python & Regexes\nPython basics (reticulate, data types, loops, functions, pandas); Regular expressions with stringr\nREGEXES – tame your data\n\n\n3\nData Acquisition I\nHow the web is written and ethics; rvest web scraping\nstealing data from websites without them noticing it\n\n\n4\nData Acquisition II\nDynamic pages and forms with selenium; APIs with httr2\nstealing MORE data from websites\n\n\n5\nData Acquisition III\nIntro to OCR and transcription\nmaking images and audio readable\n\n\n6\nData Acquisition IV\nOptical Character Recognition (tesseract); Speech transcription (OpenAI Whisper); Project discussion\nmaking the computer your transcription servant\n\n\n7\nStudent Project Week\nWork on projects in class\ntime to get your hands dirty\n\n\n8\nText as Data I\nBag of words; Sentiment analysis, TF-IDF, NER/POS\nbasic text analysis\n\n\n9\nText as Data II\nSupervised machine learning in theory and practice\nadvanced text analysis with training data\n\n\n10\nText as Data III\nUnsupervised ML (topic modeling); Remote counseling pre-Christmas\nfinding patterns without labels\n\n\n11\nText as Data IV\nMeasuring similarity and distributional hypothesis; Word embeddings\ncutting-edge text analysis with vector spaces\n\n\n12\nText as Data V\nSupervised learning on steroids (BERT); Active learning with BERT\nholy shit…transformer models\n\n\n13\nText as Data VI\nLLMs for information extraction; Local LLMs primer\nunleashing the power of large language models\n\n\n14\nPresentation Preparation Week\nWork on presentations (deadline Jan 30, 6PM)\npolish your masterpiece\n\n\n15\nPresentations & Wrap Up\nPeer-reviewed presentations; Course wrap-up\nshow off your work"
  },
  {
    "objectID": "index.html#syllabus",
    "href": "index.html#syllabus",
    "title": "Welcome",
    "section": "Syllabus",
    "text": "Syllabus\nPlease click here to download the latest version of the syllabus.\n\n\n\nAlternatively, read it here (probably not the best if you’re visiting this page on a mobile device):"
  },
  {
    "objectID": "3_reticulate.html",
    "href": "3_reticulate.html",
    "title": "Chapter 3: reticulate",
    "section": "",
    "text": "The reticulate package provides a comprehensive set of tools for interoperability between Python and R. It allows you to call Python from R in a variety of ways, including importing Python modules, sourcing Python scripts, and using Python interactively from R.\n\nneeds(reticulate, tidyverse)\n\n\n\nBefore you can use Python in R, you need to ensure Python is installed on your system. The reticulate package will try to find Python automatically, but you can also specify which Python to use.\nFor a consistent experience across Windows and Mac, I recommend using reticulate’s built-in miniconda installation helper:\n\ninstall_miniconda()\n\nThis will install a minimal version of conda, which is a package and environment management system that works well for both R and Python.\nI would recommend using a conda environment for managing Python packages, as it helps avoid conflicts. When creating the environment, you can specify the Python version (this is important since not all Python versions are compatible with all package versions, unlike R) and packages you need. For example, to create an environment named “toolbox_env” with the numpy package:\n\nconda_create(\"toolbox_env\", packages = c(\"python=3.9\", \"numpy\"))\n\nIf you work in Positron, you might need to go to settings and select the Python interpreter from this environment. In RStudio, this can be done by navigating to Tools -&gt; Global Options -&gt; Python and selecting the appropriate interpreter. An overview of all conda environments and their paths can be found with:\n\nconda_list()\n\n          name\n1         base\n2 selenium_env\n3  toolbox_env\n                                                                      python\n1                   /Users/felixlennert/Library/r-miniconda-arm64/bin/python\n2 /Users/felixlennert/Library/r-miniconda-arm64/envs/selenium_env/bin/python\n3  /Users/felixlennert/Library/r-miniconda-arm64/envs/toolbox_env/bin/python\n\n\nSide note: you can remove an environment with\n\nconda_remove(\"r-reticulate\")\n\n\n\n\nBefore you can get started, you need to tell reticulate to use this environment:\n\nuse_condaenv(\"toolbox_env\", required = TRUE)\n\nFurther, post-creation, you can install Python packages into this environment directly from R:\n\npy_install(c(\"pandas\", \"scikit-learn\"))\n\nIn Quarto documents, like this one, you can use Python chunks directly by using the {python} engine (i.e., by typing ```{python} instead of ```{r} when creating a code block):\n\n# This is a Python chunk\nimport pandas as pd\nimport numpy as np\n\ndata = {\n    'name': ['Alice', 'Bob', 'Charlie', 'David'],\n    'age': [25, 30, 35, 40],\n    'score': [85.5, 92.0, 78.5, 88.0]\n}\n\ndf = pd.DataFrame(data)\nprint(df)\n\n      name  age  score\n0    Alice   25   85.5\n1      Bob   30   92.0\n2  Charlie   35   78.5\n3    David   40   88.0\n\n\nThe objects created in Python chunks are accessible in R if you make them globally accessible. For example, the df DataFrame created above can be accessed in R as follows:\n\ndf_r &lt;- py$df\nprint(df_r)\n\n     name age score\n1   Alice  25  85.5\n2     Bob  30  92.0\n3 Charlie  35  78.5\n4   David  40  88.0\n\n\nHowever, note that this is only the case when knitting the document. If you run the chunks interactively, the objects won’t be available in R.\nYou can enable availability behavior while coding by running Python code directly from R using the py_run_string() function:\n\npy_run_string(\"\nimport pandas as pd\nimport numpy as np\n\ndata = {\n    'name': ['Alice', 'Bob', 'Charlie', 'David'],\n    'age': [25, 30, 35, 40],\n    'score': [85.5, 92.0, 78.5, 88.0]\n}\n\ndf = pd.DataFrame(data)\nprint(df)\n\")\n\n      name  age  score\n0    Alice   25   85.5\n1      Bob   30   92.0\n2  Charlie   35   78.5\n3    David   40   88.0\n\n# This should work\nprint(py$df)\n\n     name age score\n1   Alice  25  85.5\n2     Bob  30  92.0\n3 Charlie  35  78.5\n4   David  40  88.0\n\n\nThat’s a bit cumbersome for larger code blocks, so you can also use py_run_file() to source a Python script. Note that the output objects might differ in type when accessed from R. For example, this pandas data frame becomes a named list in R.\n\npy_run_file(\"data/create_name_tbl.py\")\n\ndata_list &lt;- py$data\ntypeof(data_list)\n\n[1] \"list\"\n\n\nThis is however easily fixable:\n\ndata_list |&gt; bind_cols()\n\n# A tibble: 4 × 3\n  name      age score\n  &lt;chr&gt;   &lt;int&gt; &lt;dbl&gt;\n1 Alice      25  85.5\n2 Bob        30  92  \n3 Charlie    35  78.5\n4 David      40  88  \n\n\nAnother way of sharing objects between R and Python is of course by writing a file to disc. You can save data frames as CSV files in R and read them into Python, or vice versa. Make sure to set index=False when saving from Python to avoid an extra index column.\n\ndf.to_csv(\"data/people.csv\", index=False)\ndf.to_csv(\"data/people_w_index.csv\", index=True)\n\n\nread_csv(\"data/people.csv\")\n\nRows: 4 Columns: 3\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (1): name\ndbl (2): age, score\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n# A tibble: 4 × 3\n  name      age score\n  &lt;chr&gt;   &lt;dbl&gt; &lt;dbl&gt;\n1 Alice      25  85.5\n2 Bob        30  92  \n3 Charlie    35  78.5\n4 David      40  88  \n\nread_csv(\"data/people_w_index.csv\")\n\nNew names:\nRows: 4 Columns: 4\n── Column specification\n──────────────────────────────────────────────────────── Delimiter: \",\" chr\n(1): name dbl (3): ...1, age, score\nℹ Use `spec()` to retrieve the full column specification for this data. ℹ\nSpecify the column types or set `show_col_types = FALSE` to quiet this message.\n• `` -&gt; `...1`\n\n\n# A tibble: 4 × 4\n   ...1 name      age score\n  &lt;dbl&gt; &lt;chr&gt;   &lt;dbl&gt; &lt;dbl&gt;\n1     0 Alice      25  85.5\n2     1 Bob        30  92  \n3     2 Charlie    35  78.5\n4     3 David      40  88  \n\n\n\n\n\n\nreticulate documentation"
  },
  {
    "objectID": "3_reticulate.html#using-python-in-r-with-reticulate",
    "href": "3_reticulate.html#using-python-in-r-with-reticulate",
    "title": "Chapter 3: reticulate",
    "section": "",
    "text": "The reticulate package provides a comprehensive set of tools for interoperability between Python and R. It allows you to call Python from R in a variety of ways, including importing Python modules, sourcing Python scripts, and using Python interactively from R.\n\nneeds(reticulate, tidyverse)\n\n\n\nBefore you can use Python in R, you need to ensure Python is installed on your system. The reticulate package will try to find Python automatically, but you can also specify which Python to use.\nFor a consistent experience across Windows and Mac, I recommend using reticulate’s built-in miniconda installation helper:\n\ninstall_miniconda()\n\nThis will install a minimal version of conda, which is a package and environment management system that works well for both R and Python.\nI would recommend using a conda environment for managing Python packages, as it helps avoid conflicts. When creating the environment, you can specify the Python version (this is important since not all Python versions are compatible with all package versions, unlike R) and packages you need. For example, to create an environment named “toolbox_env” with the numpy package:\n\nconda_create(\"toolbox_env\", packages = c(\"python=3.9\", \"numpy\"))\n\nIf you work in Positron, you might need to go to settings and select the Python interpreter from this environment. In RStudio, this can be done by navigating to Tools -&gt; Global Options -&gt; Python and selecting the appropriate interpreter. An overview of all conda environments and their paths can be found with:\n\nconda_list()\n\n          name\n1         base\n2 selenium_env\n3  toolbox_env\n                                                                      python\n1                   /Users/felixlennert/Library/r-miniconda-arm64/bin/python\n2 /Users/felixlennert/Library/r-miniconda-arm64/envs/selenium_env/bin/python\n3  /Users/felixlennert/Library/r-miniconda-arm64/envs/toolbox_env/bin/python\n\n\nSide note: you can remove an environment with\n\nconda_remove(\"r-reticulate\")\n\n\n\n\nBefore you can get started, you need to tell reticulate to use this environment:\n\nuse_condaenv(\"toolbox_env\", required = TRUE)\n\nFurther, post-creation, you can install Python packages into this environment directly from R:\n\npy_install(c(\"pandas\", \"scikit-learn\"))\n\nIn Quarto documents, like this one, you can use Python chunks directly by using the {python} engine (i.e., by typing ```{python} instead of ```{r} when creating a code block):\n\n# This is a Python chunk\nimport pandas as pd\nimport numpy as np\n\ndata = {\n    'name': ['Alice', 'Bob', 'Charlie', 'David'],\n    'age': [25, 30, 35, 40],\n    'score': [85.5, 92.0, 78.5, 88.0]\n}\n\ndf = pd.DataFrame(data)\nprint(df)\n\n      name  age  score\n0    Alice   25   85.5\n1      Bob   30   92.0\n2  Charlie   35   78.5\n3    David   40   88.0\n\n\nThe objects created in Python chunks are accessible in R if you make them globally accessible. For example, the df DataFrame created above can be accessed in R as follows:\n\ndf_r &lt;- py$df\nprint(df_r)\n\n     name age score\n1   Alice  25  85.5\n2     Bob  30  92.0\n3 Charlie  35  78.5\n4   David  40  88.0\n\n\nHowever, note that this is only the case when knitting the document. If you run the chunks interactively, the objects won’t be available in R.\nYou can enable availability behavior while coding by running Python code directly from R using the py_run_string() function:\n\npy_run_string(\"\nimport pandas as pd\nimport numpy as np\n\ndata = {\n    'name': ['Alice', 'Bob', 'Charlie', 'David'],\n    'age': [25, 30, 35, 40],\n    'score': [85.5, 92.0, 78.5, 88.0]\n}\n\ndf = pd.DataFrame(data)\nprint(df)\n\")\n\n      name  age  score\n0    Alice   25   85.5\n1      Bob   30   92.0\n2  Charlie   35   78.5\n3    David   40   88.0\n\n# This should work\nprint(py$df)\n\n     name age score\n1   Alice  25  85.5\n2     Bob  30  92.0\n3 Charlie  35  78.5\n4   David  40  88.0\n\n\nThat’s a bit cumbersome for larger code blocks, so you can also use py_run_file() to source a Python script. Note that the output objects might differ in type when accessed from R. For example, this pandas data frame becomes a named list in R.\n\npy_run_file(\"data/create_name_tbl.py\")\n\ndata_list &lt;- py$data\ntypeof(data_list)\n\n[1] \"list\"\n\n\nThis is however easily fixable:\n\ndata_list |&gt; bind_cols()\n\n# A tibble: 4 × 3\n  name      age score\n  &lt;chr&gt;   &lt;int&gt; &lt;dbl&gt;\n1 Alice      25  85.5\n2 Bob        30  92  \n3 Charlie    35  78.5\n4 David      40  88  \n\n\nAnother way of sharing objects between R and Python is of course by writing a file to disc. You can save data frames as CSV files in R and read them into Python, or vice versa. Make sure to set index=False when saving from Python to avoid an extra index column.\n\ndf.to_csv(\"data/people.csv\", index=False)\ndf.to_csv(\"data/people_w_index.csv\", index=True)\n\n\nread_csv(\"data/people.csv\")\n\nRows: 4 Columns: 3\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (1): name\ndbl (2): age, score\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n# A tibble: 4 × 3\n  name      age score\n  &lt;chr&gt;   &lt;dbl&gt; &lt;dbl&gt;\n1 Alice      25  85.5\n2 Bob        30  92  \n3 Charlie    35  78.5\n4 David      40  88  \n\nread_csv(\"data/people_w_index.csv\")\n\nNew names:\nRows: 4 Columns: 4\n── Column specification\n──────────────────────────────────────────────────────── Delimiter: \",\" chr\n(1): name dbl (3): ...1, age, score\nℹ Use `spec()` to retrieve the full column specification for this data. ℹ\nSpecify the column types or set `show_col_types = FALSE` to quiet this message.\n• `` -&gt; `...1`\n\n\n# A tibble: 4 × 4\n   ...1 name      age score\n  &lt;dbl&gt; &lt;chr&gt;   &lt;dbl&gt; &lt;dbl&gt;\n1     0 Alice      25  85.5\n2     1 Bob        30  92  \n3     2 Charlie    35  78.5\n4     3 David      40  88  \n\n\n\n\n\n\nreticulate documentation"
  },
  {
    "objectID": "5_pandas.html",
    "href": "5_pandas.html",
    "title": "Chapter 5: pandas",
    "section": "",
    "text": "Now that you understand Python basics, let’s look at pandas – Python’s most popular library for data manipulation. If you’re familiar with R’s tidyverse (especially dplyr and tidyr), pandas will feel conceptually familiar, though the syntax differs."
  },
  {
    "objectID": "5_pandas.html#further-resources",
    "href": "5_pandas.html#further-resources",
    "title": "Chapter 5: pandas",
    "section": "Further Resources",
    "text": "Further Resources\n\nA very helpful R vs. pandas cheatsheet\nPython for Data Analysis by Wes McKinney (pandas creator)"
  },
  {
    "objectID": "syllabus/syllabus_toolboxCSS_winter2526.html",
    "href": "syllabus/syllabus_toolboxCSS_winter2526.html",
    "title": "06-002-107-3: Forschungsseminar B – Experimentelle Soziologie und Computational Social Science",
    "section": "",
    "text": "E-mail: felix.lennert@uni-leipzig.de\nCourse hours: Tuesdays and Thursdays, 15:15 – 16:45, NSG, SR 325; for exact dates, see schedule\nReadings: see schedule\nCourse materials: see website\nStudent hours: are to be set up individually via email; my office is H3 1.07; there is a multitude of valid reasons why you should come see me – some are listed here:\n\nthings are unclear and you need help with the material\nyou want to discuss a research idea\nyou have come across a cool new paper that I might deem interesting\nyou have recommendations for me in terms of general course resources/references/structure/behavior\nyou want some career advice from someone roughly your age\nyou forgot your mensa card at home and want some coffee/tea\nin case you need some free period supplies, no email is required, you can just get them at Leonie Steinbrinker’s office (I also have a key if she’s not there), H3 1.06"
  },
  {
    "objectID": "syllabus/syllabus_toolboxCSS_winter2526.html#extensions",
    "href": "syllabus/syllabus_toolboxCSS_winter2526.html#extensions",
    "title": "06-002-107-3: Forschungsseminar B – Experimentelle Soziologie und Computational Social Science",
    "section": "Extensions",
    "text": "Extensions\nExtensions can be granted for particular reasons. These involve, among others, internships and sickness. In the case of the former, please give me a quick heads-up so that I can arrange it (preferably with some sort of proof). If you need an extension for a different reason than the ones mentioned above, feel free to reach out anytime, and I will do my best to accommodate your needs."
  },
  {
    "objectID": "syllabus/syllabus_toolboxCSS_winter2526.html#expectations",
    "href": "syllabus/syllabus_toolboxCSS_winter2526.html#expectations",
    "title": "06-002-107-3: Forschungsseminar B – Experimentelle Soziologie und Computational Social Science",
    "section": "Expectations",
    "text": "Expectations\n\nThe Basics\n\nwritten in English\nfile format: PDF\nfont size 12 pt, 1.5 line spacing\nno typos, grammatical flaws, etc. (you are living in the age of helpers such as Grammarly, there are no more excuses)\nlength: between 4,000 and 8,000 words\ncite correctly and in a uniform manner. My preferred citation style is ASA. It is strongly advised to use Zotero and Quarto/Overleaf; resources can be provided upon request.\n\nStructured resembles an empirical research paper:\n\nthe introduction contains an empirical social scientific research question that is theoretically and practically motivated (i.e., showing its scientific and real-world relevance)\nthe theory section provides a brief overview of relevant prior research; clearly testable hypotheses are derived from the literature/goals for exploratory analyses are formulated\nin data and methods, the data (including acquisition strategy), as well as the analysis strategy, are described; in our case, the data consist of text, the analyses are related to the course content; data and methods need to enable valid results\nresults need to be visualized through tables and/or (gg)plots and described in the text; tables and visualizations need to be properly labeled so that they can “stand on their own”\ndiscussion of the results is performed in the light of the theoretical foundations; potential shortcomings and reach of the paper are outlined\nthe conclusion circles back to the introduction and connects it to the results; it needs to clearly answer the research question"
  },
  {
    "objectID": "syllabus/syllabus_toolboxCSS_winter2526.html#week-1-kick-off",
    "href": "syllabus/syllabus_toolboxCSS_winter2526.html#week-1-kick-off",
    "title": "06-002-107-3: Forschungsseminar B – Experimentelle Soziologie und Computational Social Science",
    "section": "Week 1: Kick Off",
    "text": "Week 1: Kick Off\n\nWelcome & Housekeeping (Tue, 14 October 2025; 15:15 – 16:45; NSG, SR 325)\nNo readings.\n\n\nSetting up your workstation (Thu, 16 October 2025; 15:15 – 16:45; NSG, SR 325)\n\nAcquire access to sc.uni-leipzig.de\nR recap (the corresponding chapters can be found in the R4DS book – _online)\n\nRMarkdown/Quarto – chapters 28 & 29\ndplyr – chapter 4\ntidyr – chapter 6\nggplot2 – chapters 2 & 10 & 11 & 12\npurrr & loops in different flavors – chapter 27\nfunctional programming – chapter 26\nset up reticulate in RStudio – online"
  },
  {
    "objectID": "syllabus/syllabus_toolboxCSS_winter2526.html#week-2-brief-intro-to-python-regexes",
    "href": "syllabus/syllabus_toolboxCSS_winter2526.html#week-2-brief-intro-to-python-regexes",
    "title": "06-002-107-3: Forschungsseminar B – Experimentelle Soziologie und Computational Social Science",
    "section": "Week 2: Brief Intro to Python & Regexes",
    "text": "Week 2: Brief Intro to Python & Regexes\n\nPython & Regexes(Tue, 21 October 2025; 15:15 – 16:45; NSG, SR 325)\n\nBrief intro to Python\n\nreticulate – how to run Python in R studio\ndata types\nloops\nfunctions\npandas\n\n\n\n\nRegular Expressions (Thu, 23 October 2025; 15:15 – 16:45; NSG, SR 325)\n\nstringr & Regular Expressions – R4DS book, online, chapters 15 & 16"
  },
  {
    "objectID": "syllabus/syllabus_toolboxCSS_winter2526.html#week-3-data-acquisition-i",
    "href": "syllabus/syllabus_toolboxCSS_winter2526.html#week-3-data-acquisition-i",
    "title": "06-002-107-3: Forschungsseminar B – Experimentelle Soziologie und Computational Social Science",
    "section": "Week 3: Data Acquisition I",
    "text": "Week 3: Data Acquisition I\n\nHow the Web is Written and Ethics (Tue, 28 October 2025; 15:15 – 16:45; NSG, SR 325)\n\nStoltz and Taylor (2024) – chapter 5\nBlog post on CSS selectors – online\nBlog posts on API calls – online\n\n\n\nrvest\n\nrvest Web scraping 101 – online"
  },
  {
    "objectID": "syllabus/syllabus_toolboxCSS_winter2526.html#week-4-data-acquisition-ii",
    "href": "syllabus/syllabus_toolboxCSS_winter2526.html#week-4-data-acquisition-ii",
    "title": "06-002-107-3: Forschungsseminar B – Experimentelle Soziologie und Computational Social Science",
    "section": "Week 4: Data Acquisition II",
    "text": "Week 4: Data Acquisition II\n\nDynamic Pages and Forms (Tue, 04 November 2025; 15:15 – 16:45; NSG, SR 325)\n\nselenium documentation – online\n\n\n\nAPIs (Thu, 13 November 2025; 15:15 – 16:45; NSG, SR 325)\n\nhttr2 documentation – online"
  },
  {
    "objectID": "syllabus/syllabus_toolboxCSS_winter2526.html#week-5-data-acquisition-iii",
    "href": "syllabus/syllabus_toolboxCSS_winter2526.html#week-5-data-acquisition-iii",
    "title": "06-002-107-3: Forschungsseminar B – Experimentelle Soziologie und Computational Social Science",
    "section": "Week 5: Data Acquisition III",
    "text": "Week 5: Data Acquisition III\n\nIntro to OCR and Transcription (Thu, 13 November 2025; 15:15 – 16:45; NSG, SR 325)\n\nStoltz and Taylor (2024) – chapter 5"
  },
  {
    "objectID": "syllabus/syllabus_toolboxCSS_winter2526.html#week-6-data-acquisition-iv",
    "href": "syllabus/syllabus_toolboxCSS_winter2526.html#week-6-data-acquisition-iv",
    "title": "06-002-107-3: Forschungsseminar B – Experimentelle Soziologie und Computational Social Science",
    "section": "Week 6: Data Acquisition IV",
    "text": "Week 6: Data Acquisition IV\n\nOptical Character Recognition and Transcription (Tue, 18 November 2025; 15:15 – 16:45; NSG, SR 325)\n\nTesseract documentation – online\nOpenAI Whisper Python package documentation – online\n\n\n\nData Acquisition Recap and Project Discussion (Thu, 20 November 2025; 15:15 – 16:45; NSG, SR 325)"
  },
  {
    "objectID": "syllabus/syllabus_toolboxCSS_winter2526.html#week-7-student-project-week",
    "href": "syllabus/syllabus_toolboxCSS_winter2526.html#week-7-student-project-week",
    "title": "06-002-107-3: Forschungsseminar B – Experimentelle Soziologie und Computational Social Science",
    "section": "Week 7: Student Project Week",
    "text": "Week 7: Student Project Week\nStudents are expected to show up to class and work on their projects."
  },
  {
    "objectID": "syllabus/syllabus_toolboxCSS_winter2526.html#week-8-text-as-data-i",
    "href": "syllabus/syllabus_toolboxCSS_winter2526.html#week-8-text-as-data-i",
    "title": "06-002-107-3: Forschungsseminar B – Experimentelle Soziologie und Computational Social Science",
    "section": "Week 8: Text as Data I",
    "text": "Week 8: Text as Data I\n\nBag of Words(Tue, 02 December 2025; 15:15 – 16:45; NSG, SR 325)\n\nEvans and Aceves (2016)\nGrimmer, Roberts, and Stewart (2022), chapters 3–5, 11, & 15\nStoltz and Taylor (2024), chapters 4–9\n\n\n\nSentiment Analysis, TF-IDF, and NER/POS (Thu, 04 December 2025; 15:15 – 16:45; NSG, SR 325)\n\nGrimmer et al. (2022), chapter 11\nJurafsky and Martin (n.d.), chapter 21 – online\nSilge and Robinson (2017) – online, chapters 2 & 3"
  },
  {
    "objectID": "syllabus/syllabus_toolboxCSS_winter2526.html#week-9-text-as-data-ii",
    "href": "syllabus/syllabus_toolboxCSS_winter2526.html#week-9-text-as-data-ii",
    "title": "06-002-107-3: Forschungsseminar B – Experimentelle Soziologie und Computational Social Science",
    "section": "Week 9: Text as Data II",
    "text": "Week 9: Text as Data II\n\nSupervised Machine Learning in Theory (Tue, 09 December 2025; 15:15 – 16:45; NSG, SR 325)\n\nSupervised ML\n\nBarberá et al. (2021)\nGrimmer et al. (2022), chapters 17–20\nStoltz and Taylor (2024), chapters 9 & 12\n\n\n\n\nSupervised Machine Learning in Practice (Thu, 11 December 2025; 15:15 – 16:45; NSG, SR 325)\n\nHvitfeldt and Silge (2022) – online, chapters 6 & 7\nSilge and Hvitfeldt (2019) – online"
  },
  {
    "objectID": "syllabus/syllabus_toolboxCSS_winter2526.html#week-10-text-as-data-iii",
    "href": "syllabus/syllabus_toolboxCSS_winter2526.html#week-10-text-as-data-iii",
    "title": "06-002-107-3: Forschungsseminar B – Experimentelle Soziologie und Computational Social Science",
    "section": "Week 10: Text as Data III",
    "text": "Week 10: Text as Data III\n\nUnsupervised ML in Theory and Practice (Tue, 16 December 2025; 15:15 – 16:45; NSG, SR 325)\n\nBlei (2012)\nDiMaggio, Nag, and Blei (2013)\nGrimmer et al. (2022), chapters 10, 12–3\nStoltz and Taylor (2024), chapters 10 & 11\nSilge and Robinson (2017) – online, chapter 6\n\n\n\nRemote Counseling pre-Christmas Break (Thu, 18 December 2025; 15:15 – 16:45; NSG, SR 325)\n1-on-1 project counseling available on Zoom.\n—- CHRISTMAS BREAK —-"
  },
  {
    "objectID": "syllabus/syllabus_toolboxCSS_winter2526.html#week-11-text-as-data-iv",
    "href": "syllabus/syllabus_toolboxCSS_winter2526.html#week-11-text-as-data-iv",
    "title": "06-002-107-3: Forschungsseminar B – Experimentelle Soziologie und Computational Social Science",
    "section": "Week 11: Text as Data IV",
    "text": "Week 11: Text as Data IV\n\nMeasuring Similarity and the Distributional Hypothesis (Tue, 06 January 2026; 15:15 – 16:45; NSG, SR 325)\n\nJurafsky and Martin (n.d.), chapter 6 – online\nStoltz and Taylor (2021)\n\n\n\nWord Embeddings (Thu, 08 January 2026; 15:15 – 16:45; NSG, SR 325)\n\nHvitfeldt and Silge (2022) – online, chapter 5\nStoltz and Taylor (2024), chapter 11\ntext2map: R Tools for Text Matrices – online"
  },
  {
    "objectID": "syllabus/syllabus_toolboxCSS_winter2526.html#week-12-text-as-data-v",
    "href": "syllabus/syllabus_toolboxCSS_winter2526.html#week-12-text-as-data-v",
    "title": "06-002-107-3: Forschungsseminar B – Experimentelle Soziologie und Computational Social Science",
    "section": "Week 12: Text as Data V",
    "text": "Week 12: Text as Data V\n\nSupervised Learning on Steroids: BERT (Tue, 13 January 2026; 15:15 – 16:45; NSG, SR 325)\n\nDo, Ollion, and Shen (2022)\nLaurer et al. (2024)\nTörnberg (2023)\nWankmüller (2022)\n\n\n\nActive Learning with BERT (Thu, 15 January 2026; 15:15 – 16:45; NSG, SR 325)\n\nset up environments\nAugmented Social Scientist tutorial – online\nBERTopic – online"
  },
  {
    "objectID": "syllabus/syllabus_toolboxCSS_winter2526.html#week-13-text-as-data-vi",
    "href": "syllabus/syllabus_toolboxCSS_winter2526.html#week-13-text-as-data-vi",
    "title": "06-002-107-3: Forschungsseminar B – Experimentelle Soziologie und Computational Social Science",
    "section": "Week 13: Text as Data VI",
    "text": "Week 13: Text as Data VI\n\nLLMs for information extraction (Tue, 20 January 2026; 15:15 – 16:45; NSG, SR 325)\n\nStuhler, Ton, and Ollion (2025)\n\n\n\nLocal LLMs – a primer (Thu, 22 January 2026; 15:15 – 16:45; NSG, SR 325)\n\nellmer documentation – online\nTutorial from IC2S2 by Etienne Ollion, Emilien Schultz, Julien Boelaert – online"
  },
  {
    "objectID": "syllabus/syllabus_toolboxCSS_winter2526.html#week-14-presentation-preparation-week",
    "href": "syllabus/syllabus_toolboxCSS_winter2526.html#week-14-presentation-preparation-week",
    "title": "06-002-107-3: Forschungsseminar B – Experimentelle Soziologie und Computational Social Science",
    "section": "Week 14: Presentation Preparation Week",
    "text": "Week 14: Presentation Preparation Week\nNo classes. Deadline for sending presentations: January 30, 6PM."
  },
  {
    "objectID": "syllabus/syllabus_toolboxCSS_winter2526.html#week-15-presentation-wrap-up-week",
    "href": "syllabus/syllabus_toolboxCSS_winter2526.html#week-15-presentation-wrap-up-week",
    "title": "06-002-107-3: Forschungsseminar B – Experimentelle Soziologie und Computational Social Science",
    "section": "Week 15: Presentation & Wrap Up Week",
    "text": "Week 15: Presentation & Wrap Up Week\n\nPresentations (Tue, 03 February 2026; 15:15 – 16:45; NSG, SR 325)\nNo readings.\n\n\nPresentations & Wrap-up (Thu, 05 February 2026; 15:15 – 16:45; NSG, SR 325)\nNo readings."
  },
  {
    "objectID": "syllabus/syllabus_toolboxCSS_winter2526.html#deadline-forschungsbericht",
    "href": "syllabus/syllabus_toolboxCSS_winter2526.html#deadline-forschungsbericht",
    "title": "06-002-107-3: Forschungsseminar B – Experimentelle Soziologie und Computational Social Science",
    "section": "Deadline Forschungsbericht",
    "text": "Deadline Forschungsbericht\nMarch 19, 2026 (tentative)."
  },
  {
    "objectID": "lectures-overview.html",
    "href": "lectures-overview.html",
    "title": "Overview – week by week",
    "section": "",
    "text": "This week answers the following questions:\n\nWhat does the term CSS mean?\nWhich principles underly a new CSS?\nWhich methods does CSS encompass?\nHow do we set up our computational workstation?"
  },
  {
    "objectID": "lectures-overview.html#week-1-kick-off",
    "href": "lectures-overview.html#week-1-kick-off",
    "title": "Overview – week by week",
    "section": "",
    "text": "This week answers the following questions:\n\nWhat does the term CSS mean?\nWhich principles underly a new CSS?\nWhich methods does CSS encompass?\nHow do we set up our computational workstation?"
  },
  {
    "objectID": "lectures-overview.html#week-2-brief-intro-to-python-regexes",
    "href": "lectures-overview.html#week-2-brief-intro-to-python-regexes",
    "title": "Overview – week by week",
    "section": "Week 2: Brief Intro to Python & Regexes",
    "text": "Week 2: Brief Intro to Python & Regexes\nThis week answers the following questions:\n\nHow can we run Python in RStudio using reticulate?\nWhat are the basics of Python programming?\nWhat are regular expressions and why are they powerful?\nHow can we use stringr to work with text patterns?"
  },
  {
    "objectID": "lectures-overview.html#week-3-data-acquisition-i",
    "href": "lectures-overview.html#week-3-data-acquisition-i",
    "title": "Overview – week by week",
    "section": "Week 3: Data Acquisition I",
    "text": "Week 3: Data Acquisition I\nThis week answers the following questions:\n\nHow is the web written and structured?\nWhat are considerations in terms of law and ethics when scraping?\nHow do we acquire digital trace data via web scraping with rvest?\nWhat are CSS selectors and how do they work?"
  },
  {
    "objectID": "lectures-overview.html#week-4-data-acquisition-ii",
    "href": "lectures-overview.html#week-4-data-acquisition-ii",
    "title": "Overview – week by week",
    "section": "Week 4: Data Acquisition II",
    "text": "Week 4: Data Acquisition II\nThis week answers the following questions:\n\nHow do we scrape dynamic web pages that use JavaScript?\nHow can we interact with forms and buttons using selenium?\nWhat are APIs and how do we use them?\nHow do we make API calls with httr2?"
  },
  {
    "objectID": "lectures-overview.html#week-5-data-acquisition-iii",
    "href": "lectures-overview.html#week-5-data-acquisition-iii",
    "title": "Overview – week by week",
    "section": "Week 5: Data Acquisition III",
    "text": "Week 5: Data Acquisition III\nThis week answers the following questions:\n\nWhat is Optical Character Recognition (OCR)?\nHow can we extract text from images and PDFs?\nWhat is speech-to-text transcription?\nHow can we leverage these techniques for social science research?"
  },
  {
    "objectID": "lectures-overview.html#week-6-data-acquisition-iv",
    "href": "lectures-overview.html#week-6-data-acquisition-iv",
    "title": "Overview – week by week",
    "section": "Week 6: Data Acquisition IV",
    "text": "Week 6: Data Acquisition IV\nThis week answers the following questions:\n\nHow do we digitize text using Tesseract?\nHow do we digitize speech using OpenAI Whisper?\nWhat are best practices for data acquisition projects?\nHow do we plan our research projects?"
  },
  {
    "objectID": "lectures-overview.html#week-7-student-project-week",
    "href": "lectures-overview.html#week-7-student-project-week",
    "title": "Overview – week by week",
    "section": "Week 7: Student Project Week",
    "text": "Week 7: Student Project Week\nThis week is dedicated to working on your research projects in class.\n\nDiscuss your project ideas with peers and the instructor\nBegin data acquisition for your research\nTroubleshoot technical challenges\nForm study groups with matching research interests"
  },
  {
    "objectID": "lectures-overview.html#week-8-text-as-data-i",
    "href": "lectures-overview.html#week-8-text-as-data-i",
    "title": "Overview – week by week",
    "section": "Week 8: Text as Data I",
    "text": "Week 8: Text as Data I\nThis week answers the following questions:\n\nWhat do we mean by “text as data”?\nWhat do we mean by “bag of words”?\nHow do we perform sentiment analysis?\nWhat are TF-IDF, Named Entity Recognition (NER), and Part-of-Speech (POS) tagging?"
  },
  {
    "objectID": "lectures-overview.html#week-9-text-as-data-ii",
    "href": "lectures-overview.html#week-9-text-as-data-ii",
    "title": "Overview – week by week",
    "section": "Week 9: Text as Data II",
    "text": "Week 9: Text as Data II\nThis week answers the following questions:\n\nWhat is supervised machine learning?\nHow can we train classifiers to categorize text?\nWhat are best practices for supervised ML in social science?\nHow do we evaluate model performance?"
  },
  {
    "objectID": "lectures-overview.html#week-10-text-as-data-iii",
    "href": "lectures-overview.html#week-10-text-as-data-iii",
    "title": "Overview – week by week",
    "section": "Week 10: Text as Data III",
    "text": "Week 10: Text as Data III\nThis week answers the following questions:\n\nWhat is unsupervised machine learning?\nHow does topic modeling work?\nWhat can probabilistic topic models tell us about text corpora?\nWhen should we use unsupervised vs. supervised approaches?"
  },
  {
    "objectID": "lectures-overview.html#week-11-text-as-data-iv",
    "href": "lectures-overview.html#week-11-text-as-data-iv",
    "title": "Overview – week by week",
    "section": "Week 11: Text as Data IV",
    "text": "Week 11: Text as Data IV\nThis week answers the following questions:\n\nHow can we go beyond the “bag of words”?\nWhat is the distributional hypothesis?\nHow can we measure semantic similarity between texts?\nWhat are word embeddings and what do they capture?"
  },
  {
    "objectID": "lectures-overview.html#week-12-text-as-data-v",
    "href": "lectures-overview.html#week-12-text-as-data-v",
    "title": "Overview – week by week",
    "section": "Week 12: Text as Data V",
    "text": "Week 12: Text as Data V\nThis week answers the following questions:\n\nWhat are transformer models like BERT?\nHow do these models revolutionize text classification?\nWhat is transfer learning and why is it so powerful?\nWhat is active learning and how can it reduce annotation burden?"
  },
  {
    "objectID": "lectures-overview.html#week-13-text-as-data-vi",
    "href": "lectures-overview.html#week-13-text-as-data-vi",
    "title": "Overview – week by week",
    "section": "Week 13: Text as Data VI",
    "text": "Week 13: Text as Data VI\nThis week answers the following questions:\n\nWhat’s the latest in Natural Language Processing with Large Language Models (LLMs)?\nHow can we use LLMs for information extraction?\nWhat are local LLMs and when should we use them?\nHow do we move from codebooks to promptbooks?"
  },
  {
    "objectID": "lectures-overview.html#week-14-presentation-preparation-week",
    "href": "lectures-overview.html#week-14-presentation-preparation-week",
    "title": "Overview – week by week",
    "section": "Week 14: Presentation Preparation Week",
    "text": "Week 14: Presentation Preparation Week\nThis week is dedicated to preparing your final presentations.\n\nFinalize your analyses and preliminary results\nPrepare presentation slides (deadline: January 30, 6PM)\nReview the peer review guidelines\nPractice your 10-minute presentation"
  },
  {
    "objectID": "lectures-overview.html#week-15-presentations-wrap-up",
    "href": "lectures-overview.html#week-15-presentations-wrap-up",
    "title": "Overview – week by week",
    "section": "Week 15: Presentations & Wrap Up",
    "text": "Week 15: Presentations & Wrap Up\nThis week features peer-reviewed presentations of your research projects.\n\nPresent your research (10 minutes)\nReceive feedback from assigned peer reviewers (5 minutes)\nDiscuss next steps for your final paper\nReflect on what we’ve learned throughout the semester"
  },
  {
    "objectID": "4_python.html",
    "href": "4_python.html",
    "title": "Chapter 4: Introduction to Python for R Users",
    "section": "",
    "text": "This tutorial introduces Python programming with a focus on comparisons to R. If you’re familiar with R, you’ll find many concepts translate directly, though the syntax differs. Python is a general-purpose programming language that’s become increasingly popular in data science, offering powerful libraries for data manipulation, visualization, and machine learning.\n\n\nPython can be run in various environments:\n\nRStudio/Positron (see this blog post: Using Python in RStudio)\nJupyter notebooks (similar to RMarkdown/Quarto)\nVSCode with Python extensions\n\nFor this tutorial, we’ll use Python code chunks in Quarto, which can execute Python code just like they execute R code.\n\n# This is a comment in Python (like # in R)\nprint(\"Hello from Python!\")\n\nHello from Python!"
  },
  {
    "objectID": "4_python.html#introduction",
    "href": "4_python.html#introduction",
    "title": "Chapter 4: Introduction to Python for R Users",
    "section": "",
    "text": "This tutorial introduces Python programming with a focus on comparisons to R. If you’re familiar with R, you’ll find many concepts translate directly, though the syntax differs. Python is a general-purpose programming language that’s become increasingly popular in data science, offering powerful libraries for data manipulation, visualization, and machine learning.\n\n\nPython can be run in various environments:\n\nRStudio/Positron (see this blog post: Using Python in RStudio)\nJupyter notebooks (similar to RMarkdown/Quarto)\nVSCode with Python extensions\n\nFor this tutorial, we’ll use Python code chunks in Quarto, which can execute Python code just like they execute R code.\n\n# This is a comment in Python (like # in R)\nprint(\"Hello from Python!\")\n\nHello from Python!"
  },
  {
    "objectID": "4_python.html#python-environments",
    "href": "4_python.html#python-environments",
    "title": "Chapter 4: Introduction to Python for R Users",
    "section": "Python Environments",
    "text": "Python Environments\n\nWhat Are Environments?\nOne of the biggest differences between Python and R is how they handle packages and dependencies. In R, when you install a package with install.packages(), it typically goes into a central library that all your R projects share. Python takes a different approach with virtual environments.\nA Python environment is an isolated directory that contains:\n\nA specific Python version\nInstalled packages and their specific versions\nDependencies for those packages\n\nImagine you have Project A that needs version 1.0 of a package, and Project B needs version 2.0 of the same package. In R, you’d typically have one version installed. In Python, you create separate environments for each project.\n\n\nCommon Environment Tools\nWe will use conda for all things environment management in this tutorial. Other options include: - venv (built-in Python tool) - virtualenv (third-party tool)\nconda is more powerful and manages both Python versions and packages. It’s popular in data science.\n\n# Create environment with specific Python version\nconda create -n toolbox_env python=3.9\n\n# Activate\nconda activate toolbox_env\n\n# Install packages\nconda install pandas numpy matplotlib selenium openpyxl\n\n# Deactivate\nconda deactivate\n\nOr do it the reticulate way in Quarto:\n\nreticulate::conda_create(\"toolbox_env\", packages = \"python=3.9\")\nreticulate::conda_install(\"toolbox_env\", packages = c(\"pandas\", \"numpy\", \"matplotlib\", \"selenium\", \"openpyxl\"))\nreticulate::use_condaenv(\"toolbox_env\", required = TRUE)\n\n\n\nWhy Environments Matter for This Tutorial\nIf you’re working through this tutorial:\n\nUsing Jupyter/Quarto: These typically run in their own environment. Your code chunks will execute in whatever environment is active.\nInstalling packages: When we eventually use packages like NumPy, selenium, or Pandas, you’ll want to install them in an environment:\n\n\nconda install pandas numpy matplotlib selenium\n\n\nChecking your environment: You can see what’s installed with:\n\n\nconda list            # for conda\n\n\n\nQuick Setup Recommendation\nIf you have not created your environment using reticulate yet, I recommend doing it manually in the console.\n\n# Create a dedicated environment\nconda create -n toolbox_env python=3.9 pandas numpy matplotlib jupyter\n\n# Activate it\nconda activate toolbox_env\n\n# When working on exercises, make sure this environment is active!\n\n\n\n\n\n\n\nCompared to R\n\n\n\nThink of it this way: In R, you might use RStudio Projects to organize your work. In Python, you use Projects plus environments to isolate not just files, but also package versions.\n\n\n\n\nChecking Your Current Environment\n\nimport sys\n\n# Where is Python running from?\nprint(f\"Python executable: {sys.executable}\")\n\n# What version?\nprint(f\"Python version: {sys.version}\")\n\nIf you’re using conda, you can also check in your terminal:\n\nconda info --envs  # List all environments"
  },
  {
    "objectID": "4_python.html#data-types",
    "href": "4_python.html#data-types",
    "title": "Chapter 4: Introduction to Python for R Users",
    "section": "Data Types",
    "text": "Data Types\nPython has several fundamental data types. Unlike R, where everything is a vector by default, Python distinguishes between individual values (scalars) and collections. You will also use an assignment operator = instead of &lt;-.\n\nNumbers\nPython has two main numeric types: integers (int) and floating-point numbers (float).\n\n# Integer\nx = 42\nprint(type(x))  # Check the type\n\n&lt;class 'int'&gt;\n\nprint(x)\n\n42\n\n# Float\ny = 3.14159\nprint(type(y))\n\n&lt;class 'float'&gt;\n\nprint(y)\n\n3.14159\n\n\n\n\n\n\n\n\nCompared to R\n\n\n\nIn R, you’d use class() instead of type(). R doesn’t strictly distinguish between integers and doubles unless you explicitly create an integer with 42L.\n\n\n\n\nStrings\nStrings represent text data. Python treats single quotes ' and double quotes \" identically (unlike R where they’re essentially the same but double quotes are conventional).\n\n# Strings in Python\ngreeting = \"Hello\"\nname = 'World'\n\n# String concatenation uses +\nmessage = greeting + \" \" + name + \"!\"\nprint(message)\n\nHello World!\n\n# Or use f-strings (formatted string literals) -- Python 3.6+\nmessage_formatted = f\"{greeting} {name}!\"\nprint(message_formatted)\n\nHello World!\n\n\n\n\n\n\n\n\nCompared to R\n\n\n\nIn R, you’d use paste() or paste0() for concatenation, or str_c() from the tidyverse. Python’s f-strings are similar to glue::glue() in R.\n\n\n\n\nBooleans\nBoolean values are True and False (note the capitalization - this matters in Python!).\n\n# Booleans in Python\nis_python_fun = True\nis_this_hard = False\n\nprint(is_python_fun)\n\nTrue\n\nprint(type(is_python_fun))\n\n&lt;class 'bool'&gt;\n\n\n\n\n\n\n\n\nCompared to R\n\n\n\nR uses TRUE and FALSE (all caps), while Python uses True and False (capitalized). Python is case-sensitive, so true would throw an error.\n\n\n\n\nNone\nPython’s equivalent of R’s NULL or NA is None.\n\n# None represents absence of value\nnothing = None\nprint(nothing)\n\nNone\n\nprint(type(nothing))\n\n&lt;class 'NoneType'&gt;"
  },
  {
    "objectID": "4_python.html#collections-lists-tuples-and-dictionaries",
    "href": "4_python.html#collections-lists-tuples-and-dictionaries",
    "title": "Chapter 4: Introduction to Python for R Users",
    "section": "Collections: Lists, Tuples, and Dictionaries",
    "text": "Collections: Lists, Tuples, and Dictionaries\nPython has several built-in collection types. These are roughly analogous to R’s vectors and lists, but with important differences.\n\nLists\nPython lists are ordered, mutable (changeable) collections. They’re similar to R’s lists, not R’s atomic vectors.\n\n# Creating a list\nnumbers = [1, 2, 3, 4, 5]\nmixed_list = [1, \"two\", 3.0, True]  # Can contain different types\n\nprint(numbers)\n\n[1, 2, 3, 4, 5]\n\nprint(mixed_list)\n\n[1, 'two', 3.0, True]\n\n\nIndexing: Python uses 0-based indexing (the first element is at position 0), unlike R’s 1-based indexing.\n\n# Accessing elements\nfruits = [\"apple\", \"banana\", \"cherry\", \"date\"]\n\nprint(fruits[0])      # First element (R would use fruits[1])\n\napple\n\nprint(fruits[-2])     # Last element (negative indexing from end)\n\ncherry\n\nprint(fruits[1:3])    # Slicing: elements 1 and 2 (end index is exclusive)\n\n['banana', 'cherry']\n\n\n\n\n\n\n\n\nCompared to R\n\n\n\nR’s c(1, 2, 3, 4, 5) creates an atomic vector. Python’s [1, 2, 3, 4, 5] is more like R’s list(1, 2, 3, 4, 5), though it can be used for numeric operations when converted to a NumPy array.\n\n\nSome common list operations:\n\n# List operations\nnumbers = [1, 2, 3]\n\n# Append (like R's c() or append())\nnumbers.append(4)\nprint(numbers)\n\n[1, 2, 3, 4]\n\n# Extend with another list\nnumbers.extend([5, 6])\nprint(numbers)\n\n[1, 2, 3, 4, 5, 6]\n\n# Length\nprint(len(numbers))  # R's length()\n\n6\n\n\n\n\nTuples\nTuples are like lists but immutable (can’t be changed after creation). They use parentheses () instead of square brackets.\n\n# Creating a tuple\ncoordinates = (10, 20)\nprint(coordinates)\n\n(10, 20)\n\nprint(type(coordinates))\n\n&lt;class 'tuple'&gt;\n\n# Accessing works the same as lists\nprint(coordinates[0])\n\n10\n\n\n# But you can't modify them\n#coordinates[0] = 15  # This would raise an error!\n\n\n\n\n\n\n\nCompared to R\n\n\n\nR doesn’t have a direct equivalent to tuples, though you could think of them as named lists that are “frozen.”\n\n\n\n\nDictionaries\nDictionaries store key-value pairs. They’re similar to R’s named lists or named vectors.\n\n# Creating a dictionary\nperson = {\n    \"name\": \"Alice\",\n    \"age\": 30,\n    \"city\": \"Leipzig\"\n}\n\nprint(person)\n\n{'name': 'Alice', 'age': 30, 'city': 'Leipzig'}\n\n# Accessing values by key\nprint(person[\"name\"])\n\nAlice\n\nprint(person[\"age\"])\n\n30\n\n# Adding new key-value pairs\nperson[\"occupation\"] = \"Data Scientist\"\nprint(person)\n\n{'name': 'Alice', 'age': 30, 'city': 'Leipzig', 'occupation': 'Data Scientist'}\n\n\n\n\n\n\n\n\nCompared to R\n\n\n\nThis is similar to:\n\nperson &lt;- list(\n  name = \"Alice\",\n  age = 30,\n  city = \"Leipzig\"\n)\nperson$name  # or person[[\"name\"]]"
  },
  {
    "objectID": "4_python.html#simple-operations",
    "href": "4_python.html#simple-operations",
    "title": "Chapter 4: Introduction to Python for R Users",
    "section": "Simple Operations",
    "text": "Simple Operations\n\nArithmetic Operations\nPython supports standard arithmetic operators, similar to R.\n\n# Basic arithmetic\na = 11\nb = 3\n\na + b       # Addition\n\n14\n\na - b       # Subtraction\n\n8\n\na * b       # Multiplication\n\n33\n\na / b       # Division (always returns float)\n\n3.6666666666666665\n\na // b      # Floor division (integer division - R uses %/%)\n\n3\n\na % b       # Modulus (remainder)\n\n2\n\na ** b      # Exponentiation (R uses a^b or a**b in newer versions)\n\n1331\n\n\n\n\n\n\n\n\nCompared to R\n\n\n\nMost operators are the same.\nKey differences:\n\n/ always returns float in Python 3 (R returns integer if both are integers)\n// for integer division (R: %/%)\n** for exponentiation (R traditionally uses ^, though ** now works)\n\n\n\n\n\nComparison Operations\n\n# Comparison operators\nx = 5\ny = 10\n\nx == y #Equal\n\nFalse\n\nx != y # Not equal\n\nTrue\n\nx &gt; y  # Greater than\n\nFalse\n\nx &lt;= y # Less than or equal to\n\nTrue\n\n\n\n\n\n\n\n\nCompared to R\n\n\n\nSame operators, but Python uses != for “not equal” (R can use != or &lt;&gt;).\n\n\n\n\nLogical Operations\nPython uses words instead of symbols for logical operations.\n\n# Logical operators\na = True\nb = False\n\na and b # R equ: a & b\n\nFalse\n\na or b # R equ: a | b\n\nTrue\n\nnot a # R equ: !a\n\nFalse\n\n\n\n\n\n\n\n\nCompared to R\n\n\n\n\nPython: and, or, not\nR: &, |, ! (for element-wise); &&, || (for scalar)"
  },
  {
    "objectID": "4_python.html#flow-control-with-if-elif-else",
    "href": "4_python.html#flow-control-with-if-elif-else",
    "title": "Chapter 4: Introduction to Python for R Users",
    "section": "Flow Control with if, elif, else",
    "text": "Flow Control with if, elif, else\nSometimes you want your code to only run in specific cases. Python uses if statements for conditional execution.\n\n# Basic if statement\nx = 3\n\nif x &lt;= 5:\n    print(\"x is smaller than or equal to 5\")\n\nx is smaller than or equal to 5\n\n\nAdd an else block for an alternative action:\n\nx = 10\n\nif x &lt;= 5:\n    print(\"x is smaller than or equal to 5\")\nelse:\n    print(\"x is greater than 5\")\n\nx is greater than 5\n\n\n\nelif - Multiple Conditions\nWhen you need to check multiple conditions sequentially, use elif (short for “else if”). Python will check each condition in order and execute the first block where the condition is True.\n\nscore = 75\n\nif score &gt;= 90:\n    print(\"Grade: A\")\nelif score &gt;= 80:\n    print(\"Grade: B\")\nelif score &gt;= 70:\n    print(\"Grade: C\")\nelif score &gt;= 60:\n    print(\"Grade: D\")\nelse:\n    print(\"Grade: F\")\n\nGrade: C\n\n\nYou can have as many elif statements as you need. Python checks them from top to bottom and stops at the first True condition. Note that the final else is optional but highly recommended as a catch-all.\n\ntemperature = 25\n\nif temperature &lt; 0:\n    print(\"Freezing!\")\nelif temperature &lt; 10:\n    print(\"Cold\")\nelif temperature &lt; 20:\n    print(\"Cool\")\nelif temperature &lt; 30:\n    print(\"Warm\")\nelse:\n    print(\"Hot!\")\n\nWarm\n\n\n\n\n\n\n\n\nCompared to R\n\n\n\nComparison to R: R uses else if (two words) instead of elif:\n\ntemperature = 25\nif (temperature &lt; 0) {\n  print(\"Freezing\")\n} else if (temperature &gt;= 10) {\n  print(\"Cold\")\n} else if (temperature &lt; 20) {\n  print(\"Cool\")\n} else if (temperature &lt; 30) {\n  print(\"Warm\")\n} else {\n  print(\"Hot!\")\n}\n\n[1] \"Cold\"\n\n\n\n\nImportant: The condition must evaluate to a single boolean value (True or False)."
  },
  {
    "objectID": "4_python.html#functions",
    "href": "4_python.html#functions",
    "title": "Chapter 4: Introduction to Python for R Users",
    "section": "Functions",
    "text": "Functions\nFunctions allow you to package code into reusable blocks. Just like in R, functions are essential for writing clean, maintainable code that follows the DRY (Don’t Repeat Yourself) principle.\n\nDefining Functions\nThe basic syntax for defining a function in Python:\n\ndef function_name(parameter1, parameter2):\n    \"\"\"This is a docstring - describes what the function does.\"\"\"\n    # Function body\n    result = parameter1 + parameter2\n    return result\n\n# Call the function\nanswer = function_name(5, 3)\nanswer\n\n8\n\n\n\n\n\n\n\n\nCompared to R\n\n\n\n\nfunction_name &lt;- function(parameter1, parameter2) {\n  result &lt;- parameter1 + parameter2\n  return(result)\n}\n\n\n\n\n\nA Simple Example\n\ndef greet(name):\n    \"\"\"Greet someone by name.\"\"\"\n    return f\"Hello, {name}!\"\n\ngreet(\"Alice\")\n\n'Hello, Alice!'\n\ngreet(\"Bob\")\n\n'Hello, Bob!'\n\n\n### Hint: Python coders tend to use \"\" around real text/natural language and '' around symbol-like expressions (e.g., column names -- see below)\n\n\n\nDefault Arguments\nYou can provide default values for parameters, just like in R.\n\ndef greet_with_title(name, title = \"Dr.\"):\n    \"\"\"Greet someone with their title.\"\"\"\n    return f\"Hello, {title} {name}!\"\n\ngreet_with_title(\"Smith\")                    # Uses default title\n\n'Hello, Dr. Smith!'\n\ngreet_with_title(\"Smith\", \"Prof.\")           # Overrides default\n\n'Hello, Prof. Smith!'\n\ngreet_with_title(\"Smith\", title = \"Mr.\")       # Named argument (more explicit)\n\n'Hello, Mr. Smith!'\n\n\n\n\n\n\n\n\nCompared to R\n\n\n\n\nrgreet_with_title &lt;- function(name, title = \"Dr.\") {\n  paste0(\"Hello, \", title, \" \", name, \"!\")\n}\n\n\n\n\n\nreturn\nPer the official style guide it is idiomatic to be consistent with return statements:\n\nBe consistent in return statements. Either all return statements in a function should return an expression, or none of them should. If any return statement returns an expression, any return statements where no value is returned should explicitly state this as return None, and an explicit return statement should be present at the end of the function (if reachable)\n\n\n\n\n\n\n\nCompared to R\n\n\n\nThe object created in the last call will automatically be returned. return(object) shall be avoided unless you need an early return.\n\n\n\n\nMultiple Return Values\nPython can return multiple values as a tuple (similar to R’s lists).\n\ndef calculate_stats(numbers):\n    \"\"\"Calculate mean and standard deviation.\"\"\"\n    n = len(numbers)\n    mean = sum(numbers) / n\n    \n    # Calculate standard deviation\n    squared_diff = [(x - mean) ** 2 for x in numbers] # this is a list comprehension, an abbreviated for loop\n    variance = sum(squared_diff) / n\n    std_dev = variance ** 0.5\n    \n    return mean, std_dev  # Returns a tuple\n\ndata = [2, 4, 4, 4, 5, 5, 7, 9]\n\nmean_value, std_value = calculate_stats(data) # make sure to define both objects, or unpack the tuple later\nmean_value\n\n5.0\n\nstd_value\n\n2.0\n\n#this is the same as:\nresults = calculate_stats(data)\nmean_value = results[0]\nstd_value = results[1]\nmean_value\n\n5.0\n\nstd_value\n\n2.0\n\n\n\n\n\n\n\n\nCompared to R\n\n\n\nComparison to R: R typically returns a list or vector:\n\nrcalculate_stats &lt;- function(numbers) {\n  list(mean = mean(numbers), sd = sd(numbers))\n}\n\n\n\n\n\nDocstrings\nPython uses triple-quoted strings (“““…”““) right after the function definition to document what the function does. This is similar to roxygen2 comments in R.\n\ndef convert_temperature(celsius):\n    \"\"\"\n    Convert temperature from Celsius to Fahrenheit.\n    \n    Parameters:\n    -----------\n    celsius : float\n        Temperature in Celsius\n        \n    Returns:\n    --------\n    float\n        Temperature in Fahrenheit\n    \"\"\"\n    fahrenheit = (celsius * 9/5) + 32\n    return fahrenheit\n\nconvert_temperature(0)\n\n32.0\n\nconvert_temperature(100)\n\n212.0\n\n\n#'You can access the docstring with `help()` in an interactive session (e.g., Jupyter):\n#help(convert_temperature)\n\n\n\nLambda Functions (Anonymous Functions)\nPython has lambda functions for short, one-line functions. These are similar to R’s anonymous functions function(x) x + 1 or the shorthand \\(x) x + 1 in purrr.\n\n# Regular function\ndef add_ten(x):\n    return x + 10\n\n# Lambda function (anonymous)\nadd_ten_lambda = lambda x: x + 10\n\nadd_ten(5)\n\n15\n\nadd_ten_lambda(5)\n\n15\n\n\nLambda functions are especially useful when you need a simple function as an argument:\n\n# Sort a list of tuples by the second element\npairs = [(1, 'one'), (3, 'three'), (2, 'two')]\nsorted_pairs = sorted(pairs, key=lambda x: x[1])\nsorted_pairs\n\n[(1, 'one'), (3, 'three'), (2, 'two')]\n\n\n\n\n\n\n\n\nCompared to R\n\n\n\nR equivalent\n\nadd_ten &lt;- function(x) x + 10\n# or in purrr\nadd_ten &lt;- \\(x) x + 10\n\n\n\n\n\nVariable Scope\nPython follows similar scoping rules to R: variables defined inside functions are local to that function.\n\nx = 10  # Global variable\n\ndef modify_variable():\n    x = 5  # Local variable - doesn't affect global x\n    return x\n\nmodify_variable()  # Returns 5\n\n5\n\nx                  # Still 10\n\n10\n\n\nTo modify a global variable inside a function, you need the global keyword (though this is generally discouraged):\n\ncounter = 0\n\ndef increment_counter():\n    global counter\n    counter += 1\n    return counter\n\nincrement_counter()\n\n1\n\nincrement_counter()\n\n2\n\ncounter\n\n2\n\n\n\n\n\n\n\n\nCompared to R\n\n\n\nComparison to R: R uses &lt;&lt;- for assigning to parent environments, which is also discouraged."
  },
  {
    "objectID": "4_python.html#loops",
    "href": "4_python.html#loops",
    "title": "Chapter 4: Introduction to Python for R Users",
    "section": "Loops",
    "text": "Loops\nLoops allow you to repeat operations. Python has for loops and while loops, similar to R.\n\nFor Loops\nfor loops in Python iterate over sequences (lists, tuples, strings, ranges, etc.).\n\n# Basic for loop\nfruits = [\"apple\", \"banana\", \"cherry\"]\n\nfor fruit in fruits:\n    print(f\"I like {fruit}\")\n\nI like apple\nI like banana\nI like cherry\n\n\n\n\n\n\n\n\nCompared to R\n\n\n\nR’s equivalent would be:\n\nfruits = c(\"apple\", \"banana\", \"cherry\")\nfor (fruit in fruits) {\n  print(paste(\"I like\", fruit))\n}\n\n[1] \"I like apple\"\n[1] \"I like banana\"\n[1] \"I like cherry\"\n\n\n\n\n\nThe range() Function\nrange() generates a sequence of numbers and is commonly used with for loops. It’s similar to R’s seq() or : operator.\n\n# range(stop) - from 0 to stop-1\nfor i in range(5):\n    print(i)\n\n0\n1\n2\n3\n4\n\n\n\n# range(start, stop) - from start to stop-1\nfor i in range(2, 7):\n    print(i)\n\n2\n3\n4\n5\n6\n\n\n\n# range(start, stop, step) - with custom step\nfor i in range(0, 10, 2):\n    print(i)\n\n0\n2\n4\n6\n8\n\n\n\n\n\n\n\n\nCompared to R\n\n\n\nR equivalents:\n\nfor (i in 0:4) { }           # range(5)\nfor (i in 2:6) { }           # range(2, 7)\nfor (i in seq(0, 8, by=2)) { } # range(0, 10, 2)\n\n\n\n\n\n\nEnumerate\nWhen you need both the index and the value, use enumerate().\n\n# enumerate provides index and value\ncolors = [\"red\", \"green\", \"blue\"]\nenumerate(colors)\n\n&lt;enumerate object at 0x122b01480&gt;\n\nfor index, color in enumerate(colors):\n    print(f\"Color {index}: {color}\")\n\nColor 0: red\nColor 1: green\nColor 2: blue\n\n# Start counting from 1 instead of 0\nfor index, color in enumerate(colors, start=1):\n    print(f\"Color {index}: {color}\")\n\nColor 1: red\nColor 2: green\nColor 3: blue\n\n\n\n\n\n\n\n\nCompared to R\n\n\n\nR’s seq_along() is similar:\n\ncolors = c(\"red\", \"green\", \"blue\")\nfor (i in seq_along(colors)) {\n  print(paste(\"Color\", i, \":\", colors[i]))\n}\n\n[1] \"Color 1 : red\"\n[1] \"Color 2 : green\"\n[1] \"Color 3 : blue\"\n\n\n\n\n\n\nNested Loops\nYou can nest loops just like in R.\n\n# Nested loops - multiplication table\nfor i in range(1, 4):\n    for j in range(1, 4):\n        print(f\"{i} x {j} = {i * j}\")\n\n1 x 1 = 1\n1 x 2 = 2\n1 x 3 = 3\n2 x 1 = 2\n2 x 2 = 4\n2 x 3 = 6\n3 x 1 = 3\n3 x 2 = 6\n3 x 3 = 9\n\n\n\n\nList Comprehensions\nOne of Python’s most powerful features is list comprehensions – a concise way to create lists. This is similar to R’s sapply() or purrr::map().\nNow that you understand for loops, list comprehensions will make more sense as they’re essentially condensed for loops. List comprehensions will yield a list.\n\n# Traditional loop approach\nsquares = [] # define list\nfor i in range(1, 6):\n    squares.append(i ** 2) # build list as you go -- more efficient than vector growing in R\nprint(squares)\n\n[1, 4, 9, 16, 25]\n\n# List comprehension - more Pythonic\nsquares = [i ** 2 for i in range(1, 6)]\nprint(squares)\n\n[1, 4, 9, 16, 25]\n\n# With condition (like dplyr::filter)\n#[expression *for* item *in* iterable *if* condition]\neven_squares = [i ** 2 for i in range(1, 11) if i % 2 == 0]\nprint(even_squares)\n\n[4, 16, 36, 64, 100]\n\n\n\n\n\n\n\n\nCompared to R\n\n\n\nR equivalent:\n\nneeds(tidyverse)\nsquares &lt;- sapply(1:5, function(x) x^2)\n# or with purrr\nsquares &lt;- map(1:5, \\(x) x^2)\n\n\n\nThe general syntax for list comprehensions is:\n[expression *for* item *in* iterable *if* condition]\nThis reads almost like English: “Create a list of expression for each item in iterable if condition is true.”\n\n\nWhile Loops\nwhile loops continue executing as long as a condition is True. They’re identical in concept to R’s while loops.\n\n# Basic while loop\ncount = 0\n\nwhile count &lt; 5:\n    print(f\"Count is: {count}\")\n    count += 1  # Increment \n\nCount is: 0\nCount is: 1\nCount is: 2\nCount is: 3\nCount is: 4\n\nprint(\"Loop finished!\")\n\nLoop finished!\n\n\n\n\n\n\n\n\nCompared to R\n\n\n\nVery similar syntax, though Python uses count += 1 instead of count &lt;- count + 1.\n\n\n\n# while loop with user input simulation\n# Let's simulate checking until we find a value\nimport random\n\ntarget = 7\nattempts = 0\nguess = 0\n\nwhile guess != target:\n    guess = random.randint(1, 10)\n    attempts += 1\n    print(f\"Attempt {attempts}: guessed {guess}\")\n\nAttempt 1: guessed 10\nAttempt 2: guessed 8\nAttempt 3: guessed 3\nAttempt 4: guessed 3\nAttempt 5: guessed 3\nAttempt 6: guessed 5\nAttempt 7: guessed 3\nAttempt 8: guessed 6\nAttempt 9: guessed 1\nAttempt 10: guessed 1\nAttempt 11: guessed 10\nAttempt 12: guessed 5\nAttempt 13: guessed 8\nAttempt 14: guessed 9\nAttempt 15: guessed 5\nAttempt 16: guessed 9\nAttempt 17: guessed 7\n\nprint(f\"Found {target} in {attempts} attempts!\")\n\nFound 7 in 17 attempts!\n\n\n\n\nbreak and continue\nControl loop execution with break and continue.\n\n# break - exit the loop immediately\nfor i in range(10):\n    if i == 5:\n        break\n    print(i)\n\n0\n1\n2\n3\n4\n\n# continue - skip rest of current iteration\nfor i in range(10):\n    if i % 2 == 0:  # Skip even numbers\n        continue\n    print(i)\n\n1\n3\n5\n7\n9\n\n\n\n\n\n\n\n\nCompared to R\n\n\n\nbreak and next work the same way (next in R is continue in Python).\n\n\n\n\nPractical Examples\nExample 1: Filter and Transform Data Let’s say we have a list of student grades and we want to filter out those who passed (grade &gt;= 70) and calculate the average grade.\n\n# Sample data\nstudents = [\n    {\"name\": \"Alice\", \"grade\": 85},\n    {\"name\": \"Bob\", \"grade\": 72},\n    {\"name\": \"Charlie\", \"grade\": 90},\n    {\"name\": \"Diana\", \"grade\": 68},\n    {\"name\": \"Eve\", \"grade\": 95}\n]\n\n# Filter students who passed (grade &gt;= 70)\npassing_students = [s for s in students if s[\"grade\"] &gt;= 70]\n\nprint(\"Passing students:\")\n\nPassing students:\n\nfor student in passing_students:\n    print(f\"{student['name']}: {student['grade']}\")\n\nAlice: 85\nBob: 72\nCharlie: 90\nEve: 95\n\n# Calculate average grade\ngrades = [s[\"grade\"] for s in students]\naverage = sum(grades) / len(grades)\nprint(f\"\\nClass average: {average:.2f}\")\n\n\nClass average: 82.00\n\n\n\n\n\n\n\n\nCompared to R\n\n\n\nThis is similar to using dplyr::filter() and summarize().\n\n\nExample 2: FizzBuzz\nA classic programming exercise - counting with special rules.\n\n# FizzBuzz: Print numbers 1-20, but:\n# - \"Fizz\" for multiples of 3\n# - \"Buzz\" for multiples of 5\n# - \"FizzBuzz\" for multiples of both\n\nfor i in range(1, 21):\n    if i % 3 == 0 and i % 5 == 0:\n        print(\"FizzBuzz\")\n    elif i % 3 == 0:\n        print(\"Fizz\")\n    elif i % 5 == 0:\n        print(\"Buzz\")\n    else:\n        print(i)\n\n1\n2\nFizz\n4\nBuzz\nFizz\n7\n8\nFizz\nBuzz\n11\nFizz\n13\n14\nFizzBuzz\n16\n17\nFizz\n19\nBuzz"
  },
  {
    "objectID": "4_python.html#key-python-conventions",
    "href": "4_python.html#key-python-conventions",
    "title": "Chapter 4: Introduction to Python for R Users",
    "section": "Key Python Conventions",
    "text": "Key Python Conventions\n\nIndentation\nPython uses indentation to define code blocks (unlike R which uses {}). This is not optional – incorrect indentation will cause errors!"
  },
  {
    "objectID": "4_python.html#finally-the-zen-of-python",
    "href": "4_python.html#finally-the-zen-of-python",
    "title": "Chapter 4: Introduction to Python for R Users",
    "section": "Finally: The Zen of Python",
    "text": "Finally: The Zen of Python\nPython has a philosophy! Type import this to see it:\n\nimport this\n\nThe Zen of Python, by Tim Peters\n\nBeautiful is better than ugly.\nExplicit is better than implicit.\nSimple is better than complex.\nComplex is better than complicated.\nFlat is better than nested.\nSparse is better than dense.\nReadability counts.\nSpecial cases aren't special enough to break the rules.\nAlthough practicality beats purity.\nErrors should never pass silently.\nUnless explicitly silenced.\nIn the face of ambiguity, refuse the temptation to guess.\nThere should be one-- and preferably only one --obvious way to do it.\nAlthough that way may not be obvious at first unless you're Dutch.\nNow is better than never.\nAlthough never is often better than *right* now.\nIf the implementation is hard to explain, it's a bad idea.\nIf the implementation is easy to explain, it may be a good idea.\nNamespaces are one honking great idea -- let's do more of those!"
  },
  {
    "objectID": "4_python.html#exercises",
    "href": "4_python.html#exercises",
    "title": "Chapter 4: Introduction to Python for R Users",
    "section": "Exercises",
    "text": "Exercises\nExercise 1: Temperature Converter Write a program that converts temperatures between Celsius and Fahrenheit. Formula: \\(F = (C \\times 9/5) + 32\\)\n\nConvert each to Fahrenheit using a for loop\nPrint the results\nStore each Celsius value and its Fahrenheit equivalent in a DataFrame.\n\n\n\nSolution. Click to expand!\n\n\ntemperatures_celsius = [0, 10, 20, 30, 40]\ntemperatures_fahrenheit = []\n\nfor temp in temperatures_celsius:\n    fahrenheit = (temp * 9/5) + 32\n    temperatures_fahrenheit.append(fahrenheit)\n\ntemperatures_fahrenheit\n\n[32.0, 50.0, 68.0, 86.0, 104.0]\n\n\n\nExercise 2: Word Counter\nGiven a sentence, count how many times each word appears.\nHint: Use sentence.split() to get a list of words, and a dictionary to store counts. The operator in yields True if an element is in another list, e.g., if word in word_counts\n\n\nSolution. Click to expand!\n\n\npython_sentence = \"the quick brown fox jumps over the lazy dog the fox\"\n\n# Split sentence into words\nwords = python_sentence.split()\n\n# Count occurrences using a dictionary\nword_counts = {}\nfor word in words:\n    if word in word_counts:\n        word_counts[word] += 1\n    else:\n        word_counts[word] = 1\n\nword_counts\n\n{'the': 3, 'quick': 1, 'brown': 1, 'fox': 2, 'jumps': 1, 'over': 1, 'lazy': 1, 'dog': 1}\n\n# Expected output: {'the': 3, 'quick': 1, 'brown': 1, ...}\n\n\nExercise 3: Prime Numbers\nWrite a function that checks if a number is prime. Then use it to find all prime numbers between 1 and 50.\n\n\nSolution. Click to expand!\n\n\ndef is_prime(n):\n    \"\"\"Check if a number is prime\"\"\"\n    if n &lt; 2:\n        return False\n    if n == 2:\n        return True\n    if n % 2 == 0:\n        return False\n    for i in range(3, n):\n        if n % i == 0:\n            return False\n    return True\n\nis_prime(50)\n\nFalse\n\n# Find all prime numbers between 1 and 50\nprimes = []\nfor num in range(1, 51):\n    if is_prime(num):\n        primes.append(num)\n\nprimes\n\n[2, 3, 5, 7, 11, 13, 17, 19, 23, 29, 31, 37, 41, 43, 47]\n\n\n\nExercise 4: List Manipulation\n\nCreate a list of numbers from 1 to 20:\nCreate a new list with only even numbers\nCreate a new list with squares of odd numbers\nCalculate the sum of numbers divisible by 3\n\n\n\nSolution. Click to expand!\n\n\n# a. Create a list of numbers from 1 to 20\nnumbers = list(range(1, 21))\n\n# b. Create a new list with only even numbers\neven_numbers = [num for num in numbers if num % 2 == 0]\neven_numbers\n\n[2, 4, 6, 8, 10, 12, 14, 16, 18, 20]\n\n# c. Create a new list with squares of odd numbers\nodd_squares = [num ** 2 for num in numbers if num % 2 != 0]\nodd_squares\n\n[1, 9, 25, 49, 81, 121, 169, 225, 289, 361]\n\n# d. Calculate the sum of numbers divisible by 3\ndivisible_by_3 = [num for num in numbers if num % 3 == 0]\nsum(divisible_by_3)\n\n63\n\n\n\nThe syntax might be different, but the concepts you know from R will translate well!"
  },
  {
    "objectID": "4_python.html#further-resources",
    "href": "4_python.html#further-resources",
    "title": "Chapter 4: Introduction to Python for R Users",
    "section": "Further Resources",
    "text": "Further Resources\n\nOfficial Python Tutorial\nLearn Python the Hard Way\nAutomate the Boring Stuff with Python\nReal Python"
  },
  {
    "objectID": "lectures-week_2.html",
    "href": "lectures-week_2.html",
    "title": "Week 1: What Is Computational Social Science (CSS)?",
    "section": "",
    "text": "This week, you will learn the answers to the following questions:"
  },
  {
    "objectID": "lectures-week_2.html#slides",
    "href": "lectures-week_2.html#slides",
    "title": "Week 1: What Is Computational Social Science (CSS)?",
    "section": "Slides",
    "text": "Slides\nThere are no slides, just code script."
  },
  {
    "objectID": "5_pandas.html#exercises",
    "href": "5_pandas.html#exercises",
    "title": "Chapter 5: pandas",
    "section": "Exercises",
    "text": "Exercises\nTake the dplyr exercises from Chapter 2 and perform them using pandas."
  }
]