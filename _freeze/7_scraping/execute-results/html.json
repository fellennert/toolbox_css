{
  "hash": "692d0abca9ce54da54d04edb1c24938c",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Chapter 7: Scraping Static Pages with `rvest`\"\npublished-title: crawling_extracting\nengine: knitr\nfreeze: auto\nbibliography: literature.bib\ncsl: ASA.csl\n---\n\n## Intro \n\n\n::: {.cell}\n::: {.cell-output-display}\n\n```{=html}\n<div class=\"vembedr\">\n<div>\n<iframe src=\"https://www.youtube.com/embed/Yg0wUkHjigs\" width=\"533\" height=\"300\" frameborder=\"0\" allowfullscreen=\"\" data-external=\"1\"></iframe>\n</div>\n</div>\n```\n\n:::\n:::\n\n\nToday's session will be dedicated to getting data from the web. This process is also called scraping since we scrape data off from the surface (and remodel it for our purposes). The following picture shows you the [web scraping cheat sheet](https://github.com/yusuzech/r-web-scraping-cheat-sheet/) that outlines the process of scraping the web. On the left side, you can see the first step in scraping the web which is requesting the information from the server. This is basically what is going under the hood when you make requests using a browser. The response is the website, usually stored in an XML document, which is then the starting point for your subsequent queries and data extraction.\n\n![Web scraping cheat sheet](https://raw.githubusercontent.com/yusuzech/r-web-scraping-cheat-sheet/master/resources/functions_and_classes.png)\n\nIn the first part of this chapter, you will learn different techniques to get your hands on data. In particular, this will encompass making simple URL requests with `read_html()`, using `session()`s to navigate around on a web page, and submitting `html_form()`s to fill in forms on a web page. The second part will be dedicated to only choosing particular contents of the page. \n\n## Getting started with `rvest`\n\n\n::: {.cell}\n::: {.cell-output-display}\n\n```{=html}\n<div class=\"vembedr\">\n<div>\n<iframe src=\"https://www.youtube.com/embed/NZsULhv0lmE\" width=\"533\" height=\"300\" frameborder=\"0\" allowfullscreen=\"\" data-external=\"1\"></iframe>\n</div>\n</div>\n```\n\n:::\n:::\n\n\n### Making requests\n\nThe most basic form of making a request is by using `read_html()` from the `xml2` package.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nneeds(httr, rvest, tidyverse)\n\npage <- read_html(\"https://en.wikipedia.org/wiki/Tidyverse\")\n\npage |> str()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nList of 2\n $ node:<externalptr> \n $ doc :<externalptr> \n - attr(*, \"class\")= chr [1:2] \"xml_document\" \"xml_node\"\n```\n\n\n:::\n\n```{.r .cell-code}\npage |> as.character() |> write_lines(\"wiki.html\")\n\n#page |> html_text()\n```\n:::\n\n\nThis is perfectly fine for making requests to static pages where you do not need to take any further action. Sometimes, however, this is not enough, and you want to accept cookies or move on the page.\n\n### `session()`s\n\nHowever, the slickest way to do this is by using a `session()`. In a session, R behaves like a normal browser, stores cookies, allows you to navigate between pages, by going `session_forward()` or `session_back()`, `session_follow_link()`s on the page itself or `session_jump_to()` a different URL, or submit `form()`s with `session_submit()`.\n\nFirst, you start the session by simply calling `session()`.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmy_session <- session(\"https://scrapethissite.com/\")\n```\n:::\n\n\nSome servers may not want robots to make requests and block you for this reason. To circumnavigate this, we can set a \"user agent\" in a session. The user agent contains data that the server receives from us when we make the request. Hence, by adapting it we can trick the server into thinking that we are humans instead of robots. Let's check the current user agent first:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmy_session$response$request$options$useragent\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"libcurl/8.14.1 r-curl/7.0.0 httr/1.4.7\"\n```\n\n\n:::\n:::\n\n\nNot very human. We can set it to a common one using the `httr` package (which powers `rvest`).\n\n\n::: {.cell}\n\n```{.r .cell-code}\nuser_a <- user_agent(\"Mozilla/5.0 (Macintosh; Intel Mac OS X 12_0_1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/95.0.4638.69 Safari/537.36\")\nsession_with_ua <- session(\"https://scrapethissite.com/\", user_a)\nsession_with_ua$response$request$options$useragent\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"Mozilla/5.0 (Macintosh; Intel Mac OS X 12_0_1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/95.0.4638.69 Safari/537.36\"\n```\n\n\n:::\n:::\n\n\nYou can check the response using `session$response$status_code` -- 200 is good.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmy_session$response$status_code\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 200\n```\n\n\n:::\n:::\n\n\nWhen you want to save a page from the session, do so using `read_html()`.\n\n\n::: {.cell}\n\n```{.r .cell-code}\npage <- read_html(session_with_ua)\n```\n:::\n\n\nIf you want to open a new URL, use `session_jump_to()`.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsession_with_ua <- session_with_ua |> \n  session_jump_to(\"https://www.scrapethissite.com/pages/\")\nsession_with_ua\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n<session> https://www.scrapethissite.com/pages/\n  Status: 200\n  Type:   text/html; charset=utf-8\n  Size:   10603\n```\n\n\n:::\n:::\n\n\nYou can also click buttons on the page using CSS selectors or XPATHs (more on them next session!):\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsession_with_ua <- session_with_ua |> \n  session_jump_to(\"https://www.scrapethissite.com/\") |> \n  session_follow_link(css = \".btn-primary\")\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nNavigating to </lessons/>.\n```\n\n\n:::\n\n```{.r .cell-code}\nsession_with_ua\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n<session> http://www.scrapethissite.com/lessons/sign-up/\n  Status: 200\n  Type:   text/html; charset=utf-8\n  Size:   24168\n```\n\n\n:::\n:::\n\n\nWanna go back -- `session_back()`; thereafter you can go `session_forward()`, too.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsession_with_ua <- session_with_ua |> \n  session_back()\n\nsession_with_ua\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n<session> https://www.scrapethissite.com/\n  Status: 200\n  Type:   text/html; charset=utf-8\n  Size:   8117\n```\n\n\n:::\n\n```{.r .cell-code}\nsession_with_ua <- session_with_ua |> \n  session_forward()\n\nsession_with_ua\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n<session> http://www.scrapethissite.com/lessons/sign-up/\n  Status: 200\n  Type:   text/html; charset=utf-8\n  Size:   24168\n```\n\n\n:::\n:::\n\n\nYou can look at what your scraper has done with `session_history()`.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsession_with_ua |> session_history()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  https://www.scrapethissite.com/\n  https://www.scrapethissite.com/pages/\n  https://www.scrapethissite.com/\n- http://www.scrapethissite.com/lessons/sign-up/\n```\n\n\n:::\n:::\n\n\n### Exercise\n\n1.  Start a session with the tidyverse Wikipedia page. Adapt your user agent to some sort of different value. Proceed to Hadley Wickham's page. Go back. Go forth. Jump to Pierre Bourdieu's Wikipedia page. Check the `session_history()` to see if it has worked.\n\n<details>\n  <summary>Solution. Click to expand!</summary>\n\n::: {.cell}\n\n```{.r .cell-code}\nneeds(tidyverse, rvest, httr)\ntidyverse_wiki <- \"https://en.wikipedia.org/wiki/Tidyverse\"\npierre_wiki <- \"https://en.wikipedia.org/wiki/Pierre_Bourdieu\"\nuser_agent <- user_agent(\"Hi, I'm Felix and I'm trying to steal your data.\") #can be changed\n```\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nwiki_session <- session(tidyverse_wiki, user_agent)\n\nwiki_session_jumped <- wiki_session |>  \n  session_jump_to(tidyverse_wiki) |> \n  session_back() |> \n  session_forward() |> \n  session_jump_to(pierre_wiki)\n\nwiki_session_jumped |> session_history()\n```\n:::\n\n\n</details>\n\n### Forms\n\n\n::: {.cell}\n::: {.cell-output-display}\n\n```{=html}\n<div class=\"vembedr\">\n<div>\n<iframe src=\"https://www.youtube.com/embed/KA4RGlL1jjE\" width=\"533\" height=\"300\" frameborder=\"0\" allowfullscreen=\"\" data-external=\"1\"></iframe>\n</div>\n</div>\n```\n\n:::\n:::\n\n\nSometimes we also want to provide certain input, e.g., to provide login credentials or to scrape a website more systematically. That information is usually provided using so-called [forms](https://www.w3schools.com/html/html_forms.asp). A `<form>` element can contain different other elements such as text fields or check boxes. Basically, we use `html_form()` to extract the form, `html_form_set()` to define what we want to submit, and `html_form_submit()` to finally submit it. [For a basic example, we search for something on Google.](https://rvest.tidyverse.org/reference/html_form.html)\n\n\n::: {.cell}\n\n```{.r .cell-code}\ngoogle <- read_html(\"http://www.google.com\")\nsearch <- html_form(google) |> pluck(1)\n\nsearch |> str()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nList of 5\n $ name   : chr \"f\"\n $ method : chr \"GET\"\n $ action : chr \"http://www.google.com/search\"\n $ enctype: chr \"form\"\n $ fields :List of 10\n  ..$ ie    :List of 4\n  .. ..$ type : chr \"hidden\"\n  .. ..$ name : chr \"ie\"\n  .. ..$ value: chr \"ISO-8859-1\"\n  .. ..$ attr :List of 3\n  .. .. ..$ name : chr \"ie\"\n  .. .. ..$ value: chr \"ISO-8859-1\"\n  .. .. ..$ type : chr \"hidden\"\n  .. ..- attr(*, \"class\")= chr \"rvest_field\"\n  ..$ hl    :List of 4\n  .. ..$ type : chr \"hidden\"\n  .. ..$ name : chr \"hl\"\n  .. ..$ value: chr \"de\"\n  .. ..$ attr :List of 3\n  .. .. ..$ value: chr \"de\"\n  .. .. ..$ name : chr \"hl\"\n  .. .. ..$ type : chr \"hidden\"\n  .. ..- attr(*, \"class\")= chr \"rvest_field\"\n  ..$ source:List of 4\n  .. ..$ type : chr \"hidden\"\n  .. ..$ name : chr \"source\"\n  .. ..$ value: chr \"hp\"\n  .. ..$ attr :List of 3\n  .. .. ..$ name : chr \"source\"\n  .. .. ..$ type : chr \"hidden\"\n  .. .. ..$ value: chr \"hp\"\n  .. ..- attr(*, \"class\")= chr \"rvest_field\"\n  ..$ biw   :List of 4\n  .. ..$ type : chr \"hidden\"\n  .. ..$ name : chr \"biw\"\n  .. ..$ value: NULL\n  .. ..$ attr :List of 2\n  .. .. ..$ name: chr \"biw\"\n  .. .. ..$ type: chr \"hidden\"\n  .. ..- attr(*, \"class\")= chr \"rvest_field\"\n  ..$ bih   :List of 4\n  .. ..$ type : chr \"hidden\"\n  .. ..$ name : chr \"bih\"\n  .. ..$ value: NULL\n  .. ..$ attr :List of 2\n  .. .. ..$ name: chr \"bih\"\n  .. .. ..$ type: chr \"hidden\"\n  .. ..- attr(*, \"class\")= chr \"rvest_field\"\n  ..$ q     :List of 4\n  .. ..$ type : chr \"text\"\n  .. ..$ name : chr \"q\"\n  .. ..$ value: chr \"\"\n  .. ..$ attr :List of 8\n  .. .. ..$ class       : chr \"lst\"\n  .. .. ..$ style       : chr \"margin:0;padding:5px 8px 0 6px;vertical-align:top;color:#1f1f1f\"\n  .. .. ..$ autocomplete: chr \"off\"\n  .. .. ..$ value       : chr \"\"\n  .. .. ..$ title       : chr \"Google Suche\"\n  .. .. ..$ maxlength   : chr \"2048\"\n  .. .. ..$ name        : chr \"q\"\n  .. .. ..$ size        : chr \"57\"\n  .. ..- attr(*, \"class\")= chr \"rvest_field\"\n  ..$ btnG  :List of 4\n  .. ..$ type : chr \"submit\"\n  .. ..$ name : chr \"btnG\"\n  .. ..$ value: chr \"Google Suche\"\n  .. ..$ attr :List of 4\n  .. .. ..$ class: chr \"lsb\"\n  .. .. ..$ value: chr \"Google Suche\"\n  .. .. ..$ name : chr \"btnG\"\n  .. .. ..$ type : chr \"submit\"\n  .. ..- attr(*, \"class\")= chr \"rvest_field\"\n  ..$ btnI  :List of 4\n  .. ..$ type : chr \"submit\"\n  .. ..$ name : chr \"btnI\"\n  .. ..$ value: chr \"Auf gut GlÃck!\"\n  .. ..$ attr :List of 5\n  .. .. ..$ class: chr \"lsb\"\n  .. .. ..$ id   : chr \"tsuid_URsDaZ7UO9TSi-gP-Oy5sAI_1\"\n  .. .. ..$ value: chr \"Auf gut GlÃck!\"\n  .. .. ..$ name : chr \"btnI\"\n  .. .. ..$ type : chr \"submit\"\n  .. ..- attr(*, \"class\")= chr \"rvest_field\"\n  ..$ iflsig:List of 4\n  .. ..$ type : chr \"hidden\"\n  .. ..$ name : chr \"iflsig\"\n  .. ..$ value: chr \"AOw8s4IAAAAAaQMpYUzfSWxHiho1cpVy77ocxUGbC6wc\"\n  .. ..$ attr :List of 3\n  .. .. ..$ value: chr \"AOw8s4IAAAAAaQMpYUzfSWxHiho1cpVy77ocxUGbC6wc\"\n  .. .. ..$ name : chr \"iflsig\"\n  .. .. ..$ type : chr \"hidden\"\n  .. ..- attr(*, \"class\")= chr \"rvest_field\"\n  ..$ gbv   :List of 4\n  .. ..$ type : chr \"hidden\"\n  .. ..$ name : chr \"gbv\"\n  .. ..$ value: chr \"1\"\n  .. ..$ attr :List of 4\n  .. .. ..$ id   : chr \"gbv\"\n  .. .. ..$ name : chr \"gbv\"\n  .. .. ..$ type : chr \"hidden\"\n  .. .. ..$ value: chr \"1\"\n  .. ..- attr(*, \"class\")= chr \"rvest_field\"\n - attr(*, \"class\")= chr \"rvest_form\"\n```\n\n\n:::\n\n```{.r .cell-code}\nsearch_something <- search |> html_form_set(q = \"something\")\nresp <- html_form_submit(search_something, submit = \"btnG\")\nread_html(resp)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n{html_document}\n<html lang=\"de\">\n[1] <head>\\n<meta http-equiv=\"Content-Type\" content=\"text/html; charset=UTF-8 ...\n[2] <body jsmodel=\"hspDDf \">\\n<script nonce=\"bBV8WMmQJ6MzLdiW4XT-DQ\">(functio ...\n```\n\n\n:::\n\n```{.r .cell-code}\nvals <- list(q = \"web scraping\", hl = \"fr\")\n\nsearch_1 <- search |> html_form_set(!!!vals)\nsearch_2 <- search |> html_form_set(q = \"web scraping\", hl = \"fr\")\n\nresp <- html_form_submit(search_1)\nread_html(resp)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n{html_document}\n<html lang=\"fr-DE\">\n[1] <head>\\n<meta http-equiv=\"Content-Type\" content=\"text/html; charset=UTF-8 ...\n[2] <body jsmodel=\"hspDDf \">\\n<script nonce=\"UO6-5piK9KNgvPKR-xkMSw\">(functio ...\n```\n\n\n:::\n:::\n\n\nIf you are working with a session, the workflow is as follows:\n\n1.  Extract the form.\n2.  Set it.\n3.  Start your session on the page with the form.\n4.  Submit the form using `session_submit()`.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ngoogle_form <- read_html(\"http://www.google.com\") |> \n  html_form() |> \n  pluck(1) #another way to do [[1]]\n\nsearch_something <- google_form |> html_form_set(q = \"something\")\n\ngoogle_session <- session(\"http://www.google.com\") |> \n  session_submit(search_something, submit = \"btnG\")\n\ngoogle_session |> \n  read_html()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n{html_document}\n<html lang=\"de\">\n[1] <head>\\n<meta http-equiv=\"Content-Type\" content=\"text/html; charset=UTF-8 ...\n[2] <body jsmodel=\"hspDDf \">\\n<script nonce=\"ye-998TIHqlWiL2YIUUmnw\">(functio ...\n```\n\n\n:::\n:::\n\n\n### Exercise\n\n2.  Start a session on \"https://www.scrapethissite.com/pages/forms/\", fill out, and submit the form to search for a Hockey team called Toronto Maple Leafs. Store the resulting output in \"base_session\". \n\nYou can check your code by looking at the output of `base_session |> read_html() |> html_table() |> pluck(1)` and checking whether there are only Maple Leaf entries.\n\n<details>\n  <summary>Solution. Click to expand!</summary>\n\n::: {.cell}\n\n```{.r .cell-code}\nurl <- \"https://www.scrapethissite.com/pages/forms/\"\n\nsearch_form <- read_html(url) |> \n  html_form() |> \n  pluck(1) #extract \n\nset_form <- search_form |> \n  html_form_set(q = \"Toronto Maple Leafs\") #set login form \n\nbase_session <- session(url) |> \n  session_submit(set_form) \n\n\n\nbase_session |> \n  read_html() |> \n  html_table() |> \n  pluck(1)\n```\n:::\n\n\n</details>\n\n### Scraping hacks\n\nSome web pages are a bit fancier than the ones we have looked at so far (i.e., they use JavaScript). `rvest` works nicely for static web pages, but for more advanced ones you need different tools such as `selenium` -- see chapter 7.\n\nA web page may sometimes give you time-outs (i.e., it doesn't respond within a given time). This can break your loop. Wrapping your code in `safely()` or `insistently()` from the `purrr` package might help. The former moves on and notes down what has gone wrong, the latter keeps sending requests until it has been successful. They both work easiest if you put your scraping code in functions and wrap those with either [`insistently()`](https://purrr.tidyverse.org/reference/insistently.html) or [`safely()`](https://purrr.tidyverse.org/reference/safely.html).\n\nSometimes a web page keeps blocking you. Consider using a proxy server.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmy_proxy <- httr::use_proxy(url = \"http://example.com\",\n                            user_name = \"myusername\",\n                            password = \"mypassword\",\n                            auth = \"one of basic, digest, digest_ie, gssnegotiate, ntlm, any\")\n\nmy_session <- session(\"https://scrapethissite.com/\", my_proxy)\n```\n:::\n\n\nFind more useful information -- including the stuff we just described -- and links on [this GitHub page](https://github.com/yusuzech/r-web-scraping-cheat-sheet/blob/master/README.md).\n\n## Extracting Data\n\nIn the prior section you learned how to make calls to web pages and get responses. Now it will be all about how you can extract content from web pages in a structured way. The (in our opinion) easiest way to achieve that is by harnessing the way the web is written.\n\n\n::: {.cell}\n::: {.cell-output-display}\n\n```{=html}\n<div class=\"vembedr\">\n<div>\n<iframe src=\"https://www.youtube.com/embed/U6aJoeR6_nA\" width=\"533\" height=\"300\" frameborder=\"0\" allowfullscreen=\"\" data-external=\"1\"></iframe>\n</div>\n</div>\n```\n\n:::\n:::\n\n\nBefore we start to extract data from the web, we will briefly touch upon how the web is written. This is since we will harness this structure to extract content in an automated manner. Basic commands will be shown thereafter.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#install.packages(\"needs\")\nneeds::needs(janitor, polite, rvest, tidyverse)\n```\n:::\n\n\n## HTML 101\n\nWeb content is usually written in HTML (**H**yper **T**ext **M**arkup **L**anguage). An HTML document is comprised of elements that are letting its content appear in a certain way.\n\n![The tree-like structure of an HTML document](https://www.w3schools.com/js/pic_htmltree.gif)\n\nThe way these elements look is defined by so-called tags.\n\n![](https://developer.mozilla.org/en-US/docs/Learn/Getting_started_with_the_web/HTML_basics/grumpy-cat-small.png)\n\nThe opening tag is the name of the element (`p` in this case) in angle brackets, and the closing tag is the same with a forward slash before the name. `p` stands for a paragraph element and would look like this (since RMarkdown can handle HTML tags, the second line will showcase how it would appear on a web page):\n\n`<p> My cat is very grumpy. <p/>`\n\n<p>\n\nMy cat is very grumpy.\n\n<p/>\n\nThe `<p>` tag makes sure that the text is standing by itself and that a line break is included thereafter:\n\n`<p>My cat is very grumpy</p>. And so is my dog.` would look like this:\n\n<p>My cat is very grumpy</p>\n\n. And so is my dog.\n\nThere do exist many types of tags indicating different kinds of elements (about 100). Every page's content must be in an `<html>` element with two children `<head>` and `<body>`. The former contains the page title and some metadata, the latter the contents you are seeing in your browser. So-called **block tags**, e.g., `<h1>` (heading 1), `<p>` (paragraph), or `<ol>` (ordered list), structure the page. **Inline tags** (`<b>` -- bold, `<a>` -- link) format text inside block tags.\n\nYou can nest elements, e.g., if you want to make certain things bold, you can wrap text in `<b>`:\n\n`<p>My cat is <b> very </b> grumpy</p>`\n\n<p>My cat is <b> very </b> grumpy</p>\n\nThen, the `<b>` element is considered the *child* of the `<p>` element.\n\nElements can also bear attributes:\n\n![](https://developer.mozilla.org/en-US/docs/Learn/Getting_started_with_the_web/HTML_basics/grumpy-cat-attribute-small.png)\n\nThose attributes will not appear in the actual content. Moreover, they are super-handy for us as scrapers. Here, `class` is the attribute name and `\"editor-note\"` the value. Another important attribute is `id`. Combined with CSS, they control the appearance of the element on the actual page. A `class` can be used by multiple HTML elements whereas an `id` is unique.\n\n## Extracting content in `rvest`\n\nTo scrape the web, the first step is to simply read in the web page. `rvest` then stores it in the XML format -- just another format to store information. For this, we use `rvest`'s `read_html()` function.\n\nTo demonstrate the usage of CSS selectors, I create my own, basic web page using the `rvest` function `minimal_html()`:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nbasic_html <- minimal_html('\n  <html>\n  <head>\n    <title>Page title</title>\n  </head>\n  <body>\n    <h1 id=\"first\">A heading</h1>\n    <p class=\"paragraph\">Some text &amp; <b>some bold text.</b></p>\n    <a> Some more <i> italicized text which is not in a paragraph. </i> </a>\n    <a class=\"paragraph\">even more text &amp; <i>some italicized text.</i></p>\n    <a id=\"link\" href=\"www.nyt.com\"> The New York Times </a>\n  </body>\n')\n\nbasic_html\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n{html_document}\n<html>\n[1] <head>\\n<meta http-equiv=\"Content-Type\" content=\"text/html; charset=UTF-8 ...\n[2] <body>\\n    <h1 id=\"first\">A heading</h1>\\n    <p class=\"paragraph\">Some  ...\n```\n\n\n:::\n\n```{.r .cell-code}\n#https://htmledit.squarefree.com\n```\n:::\n\n\nCSS is the abbreviation for cascading style sheets and is used to define the visual styling of HTML documents. CSS selectors map elements in the HTML code to the relevant styles in the CSS. Hence, they define patterns that allow us to easily select certain elements on the page. CSS selectors can be used in conjunction with the `rvest` function `html_elements()` which takes as arguments the read-in page and a CSS selector. Alternatively, you can also provide an XPath which is usually a bit more complicated and will not be covered in this tutorial.\n\n-   `p` selects all `<p>` elements.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nbasic_html |> html_elements(css = \"p\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n{xml_nodeset (1)}\n[1] <p class=\"paragraph\">Some text &amp; <b>some bold text.</b></p>\n```\n\n\n:::\n:::\n\n\n-   `.title` selects all elements that are of `class` \"title\"\n\n\n::: {.cell}\n\n```{.r .cell-code}\nbasic_html |> html_elements(css = \".title\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n{xml_nodeset (0)}\n```\n\n\n:::\n:::\n\n\nThere are no elements of `class` \"title\". But some of `class` \"paragraph\".\n\n\n::: {.cell}\n\n```{.r .cell-code}\nbasic_html |> html_elements(css = \".paragraph\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n{xml_nodeset (2)}\n[1] <p class=\"paragraph\">Some text &amp; <b>some bold text.</b></p>\n[2] <a class=\"paragraph\">even more text &amp; <i>some italicized text.</i>\\n  ...\n```\n\n\n:::\n:::\n\n\n-   `p.paragraph` analogously takes every `<p>` element which is of `class` \"paragraph\".\n\n\n::: {.cell}\n\n```{.r .cell-code}\nbasic_html |> html_elements(css = \"p.paragraph\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n{xml_nodeset (1)}\n[1] <p class=\"paragraph\">Some text &amp; <b>some bold text.</b></p>\n```\n\n\n:::\n:::\n\n\n-   `#link` scrapes elements that are of `id` \"link\"\n\n\n::: {.cell}\n\n```{.r .cell-code}\nbasic_html |> html_elements(css = \"#link\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n{xml_nodeset (1)}\n[1] <a id=\"link\" href=\"www.nyt.com\"> The New York Times </a>\n```\n\n\n:::\n:::\n\n\nYou can also connect children with their parents by using the combinator. For instance, to extract the italicized text from \"a.paragraph,\" I can do \"a.paragraph i\".\n\n\n::: {.cell}\n\n```{.r .cell-code}\nbasic_html |> html_elements(css = \"a.paragraph i\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n{xml_nodeset (1)}\n[1] <i>some italicized text.</i>\n```\n\n\n:::\n:::\n\n\nYou can also look at the children by using `html_children()`:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nbasic_html |> html_elements(css = \"a.paragraph\") |> html_children()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n{xml_nodeset (1)}\n[1] <i>some italicized text.</i>\n```\n\n\n:::\n\n```{.r .cell-code}\nread_html(\"https://rvest.tidyverse.org\") |> \n  html_elements(\"#installation , p\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n{xml_nodeset (6)}\n[1] <p>rvest helps you scrape (or harvest) data from web pages. It is designe ...\n[2] <p>If you’re scraping multiple pages, I highly recommend using rvest in c ...\n[3] <h2 id=\"installation\">Installation<a class=\"anchor\" aria-label=\"anchor\" h ...\n[4] <p>If the page contains tabular data you can convert it directly to a dat ...\n[5] <p>Developed by <a href=\"https://hadley.nz\" class=\"external-link\">Hadley  ...\n[6] <p>Site built with <a href=\"https://pkgdown.r-lib.org/\" class=\"external-l ...\n```\n\n\n:::\n:::\n\n\nUnfortunately, web pages in the wild are usually not as easily readable as the small example one I came up with. Hence, I would recommend you to use the [SelectorGadget](javascript:(function()%7Bvar%20s=document.createElement('div');s.innerHTML='Loading...';s.style.color='black';s.style.padding='20px';s.style.position='fixed';s.style.zIndex='9999';s.style.fontSize='3.0em';s.style.border='2px%20solid%20black';s.style.right='40px';s.style.top='40px';s.setAttribute('class','selector_gadget_loading');s.style.background='white';document.body.appendChild(s);s=document.createElement('script');s.setAttribute('type','text/javascript');s.setAttribute('src','https://dv0akt2986vzh.cloudfront.net/unstable/lib/selectorgadget.js');document.body.appendChild(s);%7D)();) -- just drag it into your bookmarks list.\n\nIts usage could hardly be simpler:\n\n1.  Activate it -- i.e., click on the bookmark.\n2.  Click on the content you want to scrape -- the things the CSS selector selects will appear green.\n3.  Click on the green things that you don't want -- they will turn red; click on what's not green yet but what you want -- it will turn green.\n4.  copy the CSS selector the gadget provides you with and paste it into the `html_elements()` function.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nread_html(\"https://en.wikipedia.org/wiki/Hadley_Wickham\") |> \n  html_elements(css = \"p:nth-child(4)\") |> \n  html_text()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\ncharacter(0)\n```\n\n\n:::\n:::\n\n\n## Tying it Together: Scraping HTML pages with `rvest`\n\n\n::: {.cell}\n::: {.cell-output-display}\n\n```{=html}\n<div class=\"vembedr\">\n<div>\n<iframe src=\"https://www.youtube.com/embed/1n6Iq_16UNA\" width=\"533\" height=\"300\" frameborder=\"0\" allowfullscreen=\"\" data-external=\"1\"></iframe>\n</div>\n</div>\n```\n\n:::\n:::\n\n\nSo far, I have shown you how HTML is written and how to select elements. However, what we want to achieve is extracting the data the elements contained in a proper format and storing it in some sort of tibble. Therefore, we need functions that allow us to grab the data.\n\nThe following overview taken from the [web scraping cheatsheet](https://github.com/yusuzech/r-web-scraping-cheat-sheet) shows you the basic \"flow\" of scraping web pages plus the corresponding functions. In this tutorial, I will limit myself to `rvest` functions. Those are of course perfectly compatible with things, for instance, `RSelenium`, as long as you feed the content in XML format (i.e., by using `read_html()`).\n\n![](https://raw.githubusercontent.com/yusuzech/r-web-scraping-cheat-sheet/master/resources/functions_and_classes.png)\n\nIn the prior chapter, I have introduced you to acquiring the contents of singular pages. Given that you now know how to choose the content you want, all that you are lacking for successful scraping is the tools to extract these contents in a proper format.\n\n### `html_text()` and `html_text2()`\n\nExtracting text from HTML is easy. You use `html_text()` or `html_text2()`. The former is faster but will give you not-so-nice results. The latter will give you the text like it would be returned in a web browser.\n\nThe following example is taken from [the documentation](https://rvest.tidyverse.org/reference/html_text.html)\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# To understand the difference between html_text() and html_text2()\n# take the following html:\n\nhtml <- minimal_html(\n  \"<p>This is a paragraph.\n    This is another sentence.<br>This should start on a new line<p/>\"\n)\n```\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# html_text() returns the raw underlying text, which includes white space\n# that would be ignored by a browser, and ignores the <br>\nhtml |> html_element(\"p\") |> html_text() |> writeLines()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nThis is a paragraph.\n    This is another sentence.This should start on a new line\n```\n\n\n:::\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# html_text2() simulates what a browser would display. Non-significant\n# white space is collapsed, and <br> is turned into a line break\nhtml |> html_element(\"p\") |> html_text2() |> writeLines()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nThis is a paragraph. This is another sentence.\nThis should start on a new line\n```\n\n\n:::\n:::\n\n\nA \"real example\" would then look like this:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nus_senators <- read_html(\"https://en.wikipedia.org/wiki/List_of_current_United_States_senators\")\ntext <- us_senators |>\n  html_elements(css = \"p:nth-child(6)\") |> \n  html_text2()\n```\n:::\n\n\n### Extracting tables\n\nThe general output format we strive for is a tibble. Oftentimes, data is already stored online in a table format, basically ready for us to analyze them. In the next example, I want to get a table from the Wikipedia page that contains the senators of different States in the United States I have used before. For this first, basic example, I do not use selectors for extracting the right table. You can use `rvest::html_table()`. It will give you a list containing all tables on this particular page. We can inspect it using `str()` which returns an overview of the list and the tibbles it contains.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntables <- us_senators |> \n  html_table()\n\nstr(tables)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nList of 26\n $ : tibble [4 × 3] (S3: tbl_df/tbl/data.frame)\n  ..$ Affiliation: chr [1:4] \"\" \"\" \"\" \"Total\"\n  ..$ Affiliation: chr [1:4] \"Republican Party\" \"Democratic Party\" \"Independent\" \"Total\"\n  ..$ Members    : int [1:4] 53 45 2 100\n $ : tibble [11 × 1] (S3: tbl_df/tbl/data.frame)\n  ..$ X1: chr [1:11] \"This article is part of a series on the\" \"United States Senate\" \"Great Seal of the United States Senate\" \"History of the United States Senate\" ...\n $ : tibble [2 × 5] (S3: tbl_df/tbl/data.frame)\n  ..$ Office : chr [1:2] \"President of the Senate[a]\" \"President pro tempore\"\n  ..$ Party  : chr [1:2] \"Republican\" \"Republican\"\n  ..$ Officer: chr [1:2] \"JD Vance\" \"Chuck Grassley\"\n  ..$ State  : chr [1:2] \"OH[b]\" \"IA\"\n  ..$ Since  : chr [1:2] \"January 20, 2025\" \"January 3, 2025Party dean since January 3, 2019\"\n $ : tibble [8 × 4] (S3: tbl_df/tbl/data.frame)\n  ..$ Office : chr [1:8] \"Senate Majority Leader\" \"Senate Majority Whip\" \"Chair of the Senate Republican Conference\" \"Chair of the Senate Republican Policy Committee\" ...\n  ..$ Officer: chr [1:8] \"John Thune\" \"John Barrasso\" \"Tom Cotton\" \"Shelley Moore Capito\" ...\n  ..$ State  : chr [1:8] \"SD\" \"WY\" \"AR\" \"WV\" ...\n  ..$ Since  : chr [1:8] \"January 3, 2025Party leader since January 3, 2025\" \"January 3, 2025Party whip since January 3, 2025\" \"January 3, 2025\" \"January 3, 2025\" ...\n $ : tibble [14 × 4] (S3: tbl_df/tbl/data.frame)\n  ..$ Office : chr [1:14] \"Senate Minority LeaderChair of the Senate Democratic Caucus\" \"Senate Minority Whip\" \"Chair of the Senate Democratic Steering and Policy Committee\" \"Chair of the Senate Democratic Strategic Communications Committee\" ...\n  ..$ Officer: chr [1:14] \"Chuck Schumer\" \"Dick Durbin\" \"Amy Klobuchar\" \"Cory Booker\" ...\n  ..$ State  : chr [1:14] \"NY\" \"IL\" \"MN\" \"NJ\" ...\n  ..$ Since  : chr [1:14] \"January 3, 2025Party leader since January 3, 2017\" \"January 3, 2025Party whip since January 3, 2005\" \"January 3, 2025\" \"January 3, 2025\" ...\n $ : tibble [100 × 12] (S3: tbl_df/tbl/data.frame)\n  ..$ State                     : chr [1:100] \"Alabama\" \"Alabama\" \"Alaska\" \"Alaska\" ...\n  ..$ Portrait                  : logi [1:100] NA NA NA NA NA NA ...\n  ..$ Senator                   : chr [1:100] \"Tommy Tuberville\" \"Katie Britt\" \"Lisa Murkowski\" \"Dan Sullivan\" ...\n  ..$ Party                     : logi [1:100] NA NA NA NA NA NA ...\n  ..$ Party                     : chr [1:100] \"Republican\" \"Republican\" \"Republican\" \"Republican\" ...\n  ..$ Born                      : chr [1:100] \"(1954-09-18) September 18, 1954 (age 71)\" \"(1982-02-02) February 2, 1982 (age 43)\" \"(1957-05-22) May 22, 1957 (age 68)\" \"(1964-11-13) November 13, 1964 (age 60)\" ...\n  ..$ Occupation(s)             : chr [1:100] \"Investment management firm partner\\nCollege football coach\" \"Alabama Wildlife Federation Board Member\\nBusiness Council of Alabama President and CEO \\nCampaign manager\\nLaw\"| __truncated__ \"Lawyer\" \"Assistant Secretary of State for Economic and Business Affairs\\nLawyer\\nU.S. Marine Corps officer\" ...\n  ..$ Previous electiveoffice(s): chr [1:100] \"None\" \"None\" \"Alaska House of Representatives\" \"Alaska Attorney General\" ...\n  ..$ Education                 : chr [1:100] \"Southern Arkansas University (BS)\" \"University of Alabama (BS, JD)\" \"Georgetown University (AB)Willamette University (JD)\" \"Harvard University (AB)Georgetown University (MS, JD)\" ...\n  ..$ Assumed office            : chr [1:100] \"January 3, 2021\" \"January 3, 2023\" \"December 20, 2002[c]\" \"January 3, 2015\" ...\n  ..$ Class                     : chr [1:100] \"2026Class 2\" \"2028Class 3\" \"2028Class 3\" \"2026Class 2\" ...\n  ..$ Residence[4]              : chr [1:100] \"Auburn[5]\" \"Montgomery\" \"Girdwood\" \"Anchorage\" ...\n $ : tibble [3 × 3] (S3: tbl_df/tbl/data.frame)\n  ..$ vteCurrent United States senators: chr [1:3] \"President: ▌ JD Vance (R) ‧ President pro tempore: ▌ Chuck Grassley (R)\" \"AL: ▌ Tuberville (R)⎣ ▌ Britt (R)\\nAK: ▌ Murkowski (R)⎣ ▌ Sullivan (R)\\nAZ: ▌ Kelly (D)⎣ ▌ Gallego (D)\\nAR: ▌ B\"| __truncated__ \"▌ Republican: 53\\n▌ Democratic: 45\\n▌ Independent: 2\"\n  ..$ vteCurrent United States senators: chr [1:3] \"President: ▌ JD Vance (R) ‧ President pro tempore: ▌ Chuck Grassley (R)\" \"AL: ▌ Tuberville (R)⎣ ▌ Britt (R)\\nAK: ▌ Murkowski (R)⎣ ▌ Sullivan (R)\\nAZ: ▌ Kelly (D)⎣ ▌ Gallego (D)\\nAR: ▌ B\"| __truncated__ \"▌ Republican: 53\\n▌ Democratic: 45\\n▌ Independent: 2\"\n  ..$ vteCurrent United States senators: chr [1:3] \"President: ▌ JD Vance (R) ‧ President pro tempore: ▌ Chuck Grassley (R)\" \"\" \"▌ Republican: 53\\n▌ Democratic: 45\\n▌ Independent: 2\"\n $ : tibble [4 × 6] (S3: tbl_df/tbl/data.frame)\n  ..$ vteLeadership of the United States Senate: chr [1:4] \"President: JD Vance (R)President pro tempore: Chuck Grassley (R)\" \"Majority (Republican)Minority (Democratic)\\nJohn Thune (Leader)\\nJohn Barrasso (Whip)\\nTom Cotton (Conference C\"| __truncated__ \"Majority (Republican)\" \"John Thune (Leader)\\nJohn Barrasso (Whip)\\nTom Cotton (Conference Chair)\\nShelley Moore Capito (Policy Committe\"| __truncated__\n  ..$ vteLeadership of the United States Senate: chr [1:4] \"President: JD Vance (R)President pro tempore: Chuck Grassley (R)\" \"Majority (Republican)Minority (Democratic)\\nJohn Thune (Leader)\\nJohn Barrasso (Whip)\\nTom Cotton (Conference C\"| __truncated__ \"Minority (Democratic)\" \"Chuck Schumer (Leader and Caucus Chair)\\nDick Durbin (Whip)\\nAmy Klobuchar (Steering/Policy Committee Chair)\\nC\"| __truncated__\n  ..$                                          : chr [1:4] NA \"Majority (Republican)\" NA NA\n  ..$                                          : chr [1:4] NA \"Minority (Democratic)\" NA NA\n  ..$                                          : chr [1:4] NA \"John Thune (Leader)\\nJohn Barrasso (Whip)\\nTom Cotton (Conference Chair)\\nShelley Moore Capito (Policy Committe\"| __truncated__ NA NA\n  ..$                                          : chr [1:4] NA \"Chuck Schumer (Leader and Caucus Chair)\\nDick Durbin (Whip)\\nAmy Klobuchar (Steering/Policy Committee Chair)\\nC\"| __truncated__ NA NA\n $ : tibble [2 × 2] (S3: tbl_df/tbl/data.frame)\n  ..$ X1: chr [1:2] \"Majority (Republican)\" \"John Thune (Leader)\\nJohn Barrasso (Whip)\\nTom Cotton (Conference Chair)\\nShelley Moore Capito (Policy Committe\"| __truncated__\n  ..$ X2: chr [1:2] \"Minority (Democratic)\" \"Chuck Schumer (Leader and Caucus Chair)\\nDick Durbin (Whip)\\nAmy Klobuchar (Steering/Policy Committee Chair)\\nC\"| __truncated__\n $ : tibble [3 × 6] (S3: tbl_df/tbl/data.frame)\n  ..$ vteChairs and ranking members of United States Senate committees: chr [1:3] \"Chairs (Republican)Ranking members (Democratic)\\nAging (Special): Rick Scott\\nAgriculture, Nutrition and Forest\"| __truncated__ \"Chairs (Republican)\" \"Aging (Special): Rick Scott\\nAgriculture, Nutrition and Forestry: John Boozman\\nAppropriations: Susan Collins\\n\"| __truncated__\n  ..$ vteChairs and ranking members of United States Senate committees: chr [1:3] \"Chairs (Republican)Ranking members (Democratic)\\nAging (Special): Rick Scott\\nAgriculture, Nutrition and Forest\"| __truncated__ \"Ranking members (Democratic)\" \"Aging (Special): Kirsten Gillibrand\\nAgriculture, Nutrition and Forestry: Amy Klobuchar\\nAppropriations: Patty \"| __truncated__\n  ..$                                                                 : chr [1:3] \"Chairs (Republican)\" NA NA\n  ..$                                                                 : chr [1:3] \"Ranking members (Democratic)\" NA NA\n  ..$                                                                 : chr [1:3] \"Aging (Special): Rick Scott\\nAgriculture, Nutrition and Forestry: John Boozman\\nAppropriations: Susan Collins\\n\"| __truncated__ NA NA\n  ..$                                                                 : chr [1:3] \"Aging (Special): Kirsten Gillibrand\\nAgriculture, Nutrition and Forestry: Amy Klobuchar\\nAppropriations: Patty \"| __truncated__ NA NA\n $ : tibble [2 × 2] (S3: tbl_df/tbl/data.frame)\n  ..$ X1: chr [1:2] \"Chairs (Republican)\" \"Aging (Special): Rick Scott\\nAgriculture, Nutrition and Forestry: John Boozman\\nAppropriations: Susan Collins\\n\"| __truncated__\n  ..$ X2: chr [1:2] \"Ranking members (Democratic)\" \"Aging (Special): Kirsten Gillibrand\\nAgriculture, Nutrition and Forestry: Amy Klobuchar\\nAppropriations: Patty \"| __truncated__\n $ : tibble [49 × 36] (S3: tbl_df/tbl/data.frame)\n  ..$ vteUnited States Congress: chr [1:49] \"House of Representatives\\nSenate\\nJoint session\\n(118th → 119th → 120th)\\nLists of the United States Congress\" \"Members and leadersMembershipMembers\\nBy length of service\\nBy shortness of service\\nNew members\\nNon-voting me\"| __truncated__ \"Members and leaders\" \"MembershipMembers\\nBy length of service\\nBy shortness of service\\nNew members\\nNon-voting members\\nUnseated mem\"| __truncated__ ...\n  ..$ vteUnited States Congress: chr [1:49] \"House of Representatives\\nSenate\\nJoint session\\n(118th → 119th → 120th)\\nLists of the United States Congress\" \"Members and leadersMembershipMembers\\nBy length of service\\nBy shortness of service\\nNew members\\nNon-voting me\"| __truncated__ \"Members and leaders\" \"MembershipMembers\\nBy length of service\\nBy shortness of service\\nNew members\\nNon-voting members\\nUnseated mem\"| __truncated__ ...\n  ..$                          : chr [1:49] NA \"Members and leaders\" NA \"Membership\" ...\n  ..$                          : chr [1:49] NA \"Members and leaders\" NA \"Members\\nBy length of service\\nBy shortness of service\\nNew members\\nNon-voting members\\nUnseated members\\nYoun\"| __truncated__ ...\n  ..$                          : chr [1:49] NA \"MembershipMembers\\nBy length of service\\nBy shortness of service\\nNew members\\nNon-voting members\\nUnseated mem\"| __truncated__ NA \"Members\" ...\n  ..$                          : chr [1:49] NA \"MembershipMembers\\nBy length of service\\nBy shortness of service\\nNew members\\nNon-voting members\\nUnseated mem\"| __truncated__ NA \"By length of service\\nBy shortness of service\\nNew members\\nNon-voting members\\nUnseated members\\nYoungest members\" ...\n  ..$                          : chr [1:49] NA \"Membership\" NA \"Senate\" ...\n  ..$                          : chr [1:49] NA \"Members\\nBy length of service\\nBy shortness of service\\nNew members\\nNon-voting members\\nUnseated members\\nYoun\"| __truncated__ NA \"Members\\nseniority\\nDean\\nFormer\\nExpelled or censured\\nClasses\\nBorn outside the U.S.\\nResigned\\nAppointed\\nSwitched parties\" ...\n  ..$                          : chr [1:49] NA \"Members\" NA \"House\" ...\n  ..$                          : chr [1:49] NA \"By length of service\\nBy shortness of service\\nNew members\\nNon-voting members\\nUnseated members\\nYoungest members\" NA \"Members\\nseniority\\nDean\\nFormer\\nExpelled, censured, and reprimanded\\nServed a single term\\nLost re-election i\"| __truncated__ ...\n  ..$                          : chr [1:49] NA \"Senate\" NA \"Leaders\" ...\n  ..$                          : chr [1:49] NA \"Members\\nseniority\\nDean\\nFormer\\nExpelled or censured\\nClasses\\nBorn outside the U.S.\\nResigned\\nAppointed\\nSwitched parties\" NA \"Senate\\nPresident\\nlist\\nPresident pro tempore\\nlist\\nLeaders\\nDemocratic Caucus\\nChair\\nSecretary\\nPolicy Comm\"| __truncated__ ...\n  ..$                          : chr [1:49] NA \"House\" NA \"Senate\" ...\n  ..$                          : chr [1:49] NA \"Members\\nseniority\\nDean\\nFormer\\nExpelled, censured, and reprimanded\\nServed a single term\\nLost re-election i\"| __truncated__ NA \"President\\nlist\\nPresident pro tempore\\nlist\\nLeaders\\nDemocratic Caucus\\nChair\\nSecretary\\nPolicy Committee Ch\"| __truncated__ ...\n  ..$                          : chr [1:49] NA \"Leaders\" NA \"House\" ...\n  ..$                          : chr [1:49] NA \"Senate\\nPresident\\nlist\\nPresident pro tempore\\nlist\\nLeaders\\nDemocratic Caucus\\nChair\\nSecretary\\nPolicy Comm\"| __truncated__ NA \"Speaker\\nlist\\nLeaders\\nBipartisan Legal Advisory Group\\nDemocratic Caucus\\nRepublican Conference\" ...\n  ..$                          : chr [1:49] NA \"Senate\" NA \"Districts\" ...\n  ..$                          : chr [1:49] NA \"President\\nlist\\nPresident pro tempore\\nlist\\nLeaders\\nDemocratic Caucus\\nChair\\nSecretary\\nPolicy Committee Ch\"| __truncated__ NA \"List\\nApportionment\\nGerrymandering\" ...\n  ..$                          : chr [1:49] NA \"House\" NA \"Groups\" ...\n  ..$                          : chr [1:49] NA \"Speaker\\nlist\\nLeaders\\nBipartisan Legal Advisory Group\\nDemocratic Caucus\\nRepublican Conference\" NA \"Congressional caucus\\nCaucuses of the United States CongressEthnic and racial\\nAfrican-American members\\nSenate\"| __truncated__ ...\n  ..$                          : chr [1:49] NA \"Districts\" NA \"Congressional caucus\" ...\n  ..$                          : chr [1:49] NA \"List\\nApportionment\\nGerrymandering\" NA \"Caucuses of the United States Congress\" ...\n  ..$                          : chr [1:49] NA \"Groups\" NA \"Ethnic and racial\" ...\n  ..$                          : chr [1:49] NA \"Congressional caucus\\nCaucuses of the United States CongressEthnic and racial\\nAfrican-American members\\nSenate\"| __truncated__ NA \"African-American members\\nSenate\\nHouse\\nBlack Caucus\\nArab and Middle Eastern members\\nAsian Pacific American \"| __truncated__ ...\n  ..$                          : chr [1:49] NA \"Congressional caucus\" NA \"Gender and sexual identity\" ...\n  ..$                          : chr [1:49] NA \"Caucuses of the United States Congress\" NA \"LGBTQ members\\nEquality Caucus\\nWomen\\nSenate\\nHouse\\nIssues Caucus\\ncurrent House\" ...\n  ..$                          : chr [1:49] NA \"Ethnic and racial\" NA \"Occupation\" ...\n  ..$                          : chr [1:49] NA \"African-American members\\nSenate\\nHouse\\nBlack Caucus\\nArab and Middle Eastern members\\nAsian Pacific American \"| __truncated__ NA \"Physicians\" ...\n  ..$                          : chr [1:49] NA \"Gender and sexual identity\" NA \"Religion\" ...\n  ..$                          : chr [1:49] NA \"LGBTQ members\\nEquality Caucus\\nWomen\\nSenate\\nHouse\\nIssues Caucus\\ncurrent House\" NA \"Buddhist members\\nHindu members\\nJewish members\\nMormon (LDS) members\\nMuslim members\\nQuaker members\\nSikh members\" ...\n  ..$                          : chr [1:49] NA \"Occupation\" NA \"Related\" ...\n  ..$                          : chr [1:49] NA \"Physicians\" NA \"By length of service historically\\nCurrent members by wealth\\nFrom multiple states\\nDied in office\\n1790–1899\\n\"| __truncated__ ...\n  ..$                          : chr [1:49] NA \"Religion\" NA NA ...\n  ..$                          : chr [1:49] NA \"Buddhist members\\nHindu members\\nJewish members\\nMormon (LDS) members\\nMuslim members\\nQuaker members\\nSikh members\" NA NA ...\n  ..$                          : chr [1:49] NA \"Related\" NA NA ...\n  ..$                          : chr [1:49] NA \"By length of service historically\\nCurrent members by wealth\\nFrom multiple states\\nDied in office\\n1790–1899\\n\"| __truncated__ NA NA ...\n $ : tibble [16 × 32] (S3: tbl_df/tbl/data.frame)\n  ..$ Members and leaders: chr [1:16] \"MembershipMembers\\nBy length of service\\nBy shortness of service\\nNew members\\nNon-voting members\\nUnseated mem\"| __truncated__ \"Membership\" \"Members\" \"Senate\" ...\n  ..$ Members and leaders: chr [1:16] \"MembershipMembers\\nBy length of service\\nBy shortness of service\\nNew members\\nNon-voting members\\nUnseated mem\"| __truncated__ \"Members\\nBy length of service\\nBy shortness of service\\nNew members\\nNon-voting members\\nUnseated members\\nYoun\"| __truncated__ \"By length of service\\nBy shortness of service\\nNew members\\nNon-voting members\\nUnseated members\\nYoungest members\" \"Members\\nseniority\\nDean\\nFormer\\nExpelled or censured\\nClasses\\nBorn outside the U.S.\\nResigned\\nAppointed\\nSwitched parties\" ...\n  ..$                    : chr [1:16] \"Membership\" \"Members\" NA NA ...\n  ..$                    : chr [1:16] \"Members\\nBy length of service\\nBy shortness of service\\nNew members\\nNon-voting members\\nUnseated members\\nYoun\"| __truncated__ \"By length of service\\nBy shortness of service\\nNew members\\nNon-voting members\\nUnseated members\\nYoungest members\" NA NA ...\n  ..$                    : chr [1:16] \"Members\" \"Senate\" NA NA ...\n  ..$                    : chr [1:16] \"By length of service\\nBy shortness of service\\nNew members\\nNon-voting members\\nUnseated members\\nYoungest members\" \"Members\\nseniority\\nDean\\nFormer\\nExpelled or censured\\nClasses\\nBorn outside the U.S.\\nResigned\\nAppointed\\nSwitched parties\" NA NA ...\n  ..$                    : chr [1:16] \"Senate\" \"House\" NA NA ...\n  ..$                    : chr [1:16] \"Members\\nseniority\\nDean\\nFormer\\nExpelled or censured\\nClasses\\nBorn outside the U.S.\\nResigned\\nAppointed\\nSwitched parties\" \"Members\\nseniority\\nDean\\nFormer\\nExpelled, censured, and reprimanded\\nServed a single term\\nLost re-election i\"| __truncated__ NA NA ...\n  ..$                    : chr [1:16] \"House\" NA NA NA ...\n  ..$                    : chr [1:16] \"Members\\nseniority\\nDean\\nFormer\\nExpelled, censured, and reprimanded\\nServed a single term\\nLost re-election i\"| __truncated__ NA NA NA ...\n  ..$                    : chr [1:16] \"Leaders\" NA NA NA ...\n  ..$                    : chr [1:16] \"Senate\\nPresident\\nlist\\nPresident pro tempore\\nlist\\nLeaders\\nDemocratic Caucus\\nChair\\nSecretary\\nPolicy Comm\"| __truncated__ NA NA NA ...\n  ..$                    : chr [1:16] \"Senate\" NA NA NA ...\n  ..$                    : chr [1:16] \"President\\nlist\\nPresident pro tempore\\nlist\\nLeaders\\nDemocratic Caucus\\nChair\\nSecretary\\nPolicy Committee Ch\"| __truncated__ NA NA NA ...\n  ..$                    : chr [1:16] \"House\" NA NA NA ...\n  ..$                    : chr [1:16] \"Speaker\\nlist\\nLeaders\\nBipartisan Legal Advisory Group\\nDemocratic Caucus\\nRepublican Conference\" NA NA NA ...\n  ..$                    : chr [1:16] \"Districts\" NA NA NA ...\n  ..$                    : chr [1:16] \"List\\nApportionment\\nGerrymandering\" NA NA NA ...\n  ..$                    : chr [1:16] \"Groups\" NA NA NA ...\n  ..$                    : chr [1:16] \"Congressional caucus\\nCaucuses of the United States CongressEthnic and racial\\nAfrican-American members\\nSenate\"| __truncated__ NA NA NA ...\n  ..$                    : chr [1:16] \"Congressional caucus\" NA NA NA ...\n  ..$                    : chr [1:16] \"Caucuses of the United States Congress\" NA NA NA ...\n  ..$                    : chr [1:16] \"Ethnic and racial\" NA NA NA ...\n  ..$                    : chr [1:16] \"African-American members\\nSenate\\nHouse\\nBlack Caucus\\nArab and Middle Eastern members\\nAsian Pacific American \"| __truncated__ NA NA NA ...\n  ..$                    : chr [1:16] \"Gender and sexual identity\" NA NA NA ...\n  ..$                    : chr [1:16] \"LGBTQ members\\nEquality Caucus\\nWomen\\nSenate\\nHouse\\nIssues Caucus\\ncurrent House\" NA NA NA ...\n  ..$                    : chr [1:16] \"Occupation\" NA NA NA ...\n  ..$                    : chr [1:16] \"Physicians\" NA NA NA ...\n  ..$                    : chr [1:16] \"Religion\" NA NA NA ...\n  ..$                    : chr [1:16] \"Buddhist members\\nHindu members\\nJewish members\\nMormon (LDS) members\\nMuslim members\\nQuaker members\\nSikh members\" NA NA NA ...\n  ..$                    : chr [1:16] \"Related\" NA NA NA ...\n  ..$                    : chr [1:16] \"By length of service historically\\nCurrent members by wealth\\nFrom multiple states\\nDied in office\\n1790–1899\\n\"| __truncated__ NA NA NA ...\n $ : tibble [15 × 12] (S3: tbl_df/tbl/data.frame)\n  ..$ X1 : chr [1:15] \"Membership\" \"Members\" \"Senate\" \"House\" ...\n  ..$ X2 : chr [1:15] \"Members\\nBy length of service\\nBy shortness of service\\nNew members\\nNon-voting members\\nUnseated members\\nYoun\"| __truncated__ \"By length of service\\nBy shortness of service\\nNew members\\nNon-voting members\\nUnseated members\\nYoungest members\" \"Members\\nseniority\\nDean\\nFormer\\nExpelled or censured\\nClasses\\nBorn outside the U.S.\\nResigned\\nAppointed\\nSwitched parties\" \"Members\\nseniority\\nDean\\nFormer\\nExpelled, censured, and reprimanded\\nServed a single term\\nLost re-election i\"| __truncated__ ...\n  ..$ X3 : chr [1:15] \"Members\" NA NA NA ...\n  ..$ X4 : chr [1:15] \"By length of service\\nBy shortness of service\\nNew members\\nNon-voting members\\nUnseated members\\nYoungest members\" NA NA NA ...\n  ..$ X5 : chr [1:15] \"Senate\" NA NA NA ...\n  ..$ X6 : chr [1:15] \"Members\\nseniority\\nDean\\nFormer\\nExpelled or censured\\nClasses\\nBorn outside the U.S.\\nResigned\\nAppointed\\nSwitched parties\" NA NA NA ...\n  ..$ X7 : chr [1:15] \"House\" NA NA NA ...\n  ..$ X8 : chr [1:15] \"Members\\nseniority\\nDean\\nFormer\\nExpelled, censured, and reprimanded\\nServed a single term\\nLost re-election i\"| __truncated__ NA NA NA ...\n  ..$ X9 : chr [1:15] NA NA NA NA ...\n  ..$ X10: chr [1:15] NA NA NA NA ...\n  ..$ X11: chr [1:15] NA NA NA NA ...\n  ..$ X12: chr [1:15] NA NA NA NA ...\n $ : tibble [3 × 2] (S3: tbl_df/tbl/data.frame)\n  ..$ X1: chr [1:3] \"Members\" \"Senate\" \"House\"\n  ..$ X2: chr [1:3] \"By length of service\\nBy shortness of service\\nNew members\\nNon-voting members\\nUnseated members\\nYoungest members\" \"Members\\nseniority\\nDean\\nFormer\\nExpelled or censured\\nClasses\\nBorn outside the U.S.\\nResigned\\nAppointed\\nSwitched parties\" \"Members\\nseniority\\nDean\\nFormer\\nExpelled, censured, and reprimanded\\nServed a single term\\nLost re-election i\"| __truncated__\n $ : tibble [2 × 2] (S3: tbl_df/tbl/data.frame)\n  ..$ X1: chr [1:2] \"Senate\" \"House\"\n  ..$ X2: chr [1:2] \"President\\nlist\\nPresident pro tempore\\nlist\\nLeaders\\nDemocratic Caucus\\nChair\\nSecretary\\nPolicy Committee Ch\"| __truncated__ \"Speaker\\nlist\\nLeaders\\nBipartisan Legal Advisory Group\\nDemocratic Caucus\\nRepublican Conference\"\n $ : tibble [5 × 2] (S3: tbl_df/tbl/data.frame)\n  ..$ X1: chr [1:5] \"Congressional caucus\" \"Ethnic and racial\" \"Gender and sexual identity\" \"Occupation\" ...\n  ..$ X2: chr [1:5] \"Caucuses of the United States Congress\" \"African-American members\\nSenate\\nHouse\\nBlack Caucus\\nArab and Middle Eastern members\\nAsian Pacific American \"| __truncated__ \"LGBTQ members\\nEquality Caucus\\nWomen\\nSenate\\nHouse\\nIssues Caucus\\ncurrent House\" \"Physicians\" ...\n $ : tibble [10 × 20] (S3: tbl_df/tbl/data.frame)\n  ..$ Powers, privileges, procedure, committees, history, media: chr [1:10] \"Powers\\nArticle I\\nCopyright\\nCommerce (Dormant)\\nContempt of Congress\\nDeclaration of war\\nImpeachment\\nInquir\"| __truncated__ \"Powers\" \"Privileges\" \"Procedure\" ...\n  ..$ Powers, privileges, procedure, committees, history, media: chr [1:10] \"Powers\\nArticle I\\nCopyright\\nCommerce (Dormant)\\nContempt of Congress\\nDeclaration of war\\nImpeachment\\nInquir\"| __truncated__ \"Article I\\nCopyright\\nCommerce (Dormant)\\nContempt of Congress\\nDeclaration of war\\nImpeachment\\nInquiries\\nTri\"| __truncated__ \"Salaries\\nFranking\\nImmunity\" \"Act of Congress\\nlist\\nAppropriation bill\\nBill\\nBudget process\\nCensure\\nClosed sessions\\nHouse\\nSenate\\nClotu\"| __truncated__ ...\n  ..$                                                          : chr [1:10] \"Powers\" NA NA NA ...\n  ..$                                                          : chr [1:10] \"Article I\\nCopyright\\nCommerce (Dormant)\\nContempt of Congress\\nDeclaration of war\\nImpeachment\\nInquiries\\nTri\"| __truncated__ NA NA NA ...\n  ..$                                                          : chr [1:10] \"Privileges\" NA NA NA ...\n  ..$                                                          : chr [1:10] \"Salaries\\nFranking\\nImmunity\" NA NA NA ...\n  ..$                                                          : chr [1:10] \"Procedure\" NA NA NA ...\n  ..$                                                          : chr [1:10] \"Act of Congress\\nlist\\nAppropriation bill\\nBill\\nBudget process\\nCensure\\nClosed sessions\\nHouse\\nSenate\\nClotu\"| __truncated__ NA NA NA ...\n  ..$                                                          : chr [1:10] \"Senate-specific\" NA NA NA ...\n  ..$                                                          : chr [1:10] \"Advice and consent\\nBlue slip (U.S. Senate)\\nClasses\\nExecutive communication\\nExecutive session\\nFilibuster\\nJ\"| __truncated__ NA NA NA ...\n  ..$                                                          : chr [1:10] \"Committees\" NA NA NA ...\n  ..$                                                          : chr [1:10] \"Chairman and ranking member\\nOf the Whole\\nConference\\nDischarge petition\\nHearings\\nMarkup\\nOversight\\nList (J\"| __truncated__ NA NA NA ...\n  ..$                                                          : chr [1:10] \"Items\" NA NA NA ...\n  ..$                                                          : chr [1:10] \"Gavels\\nMace of the House\\nSeal of the Senate\" NA NA NA ...\n  ..$                                                          : chr [1:10] \"History\" NA NA NA ...\n  ..$                                                          : chr [1:10] \"House history\\nmemoirs\\nspeaker elections\\nSenate history\\nelection disputes\\nmemoirs\\nContinental Congress\\nFe\"| __truncated__ NA NA NA ...\n  ..$                                                          : chr [1:10] \"House history\\nmemoirs\\nspeaker elections\\nSenate history\\nelection disputes\\nmemoirs\\nContinental Congress\\nFe\"| __truncated__ NA NA NA ...\n  ..$                                                          : chr [1:10] \"House history\\nmemoirs\\nspeaker elections\\nSenate history\\nelection disputes\\nmemoirs\\nContinental Congress\\nFe\"| __truncated__ NA NA NA ...\n  ..$                                                          : chr [1:10] \"Media\" NA NA NA ...\n  ..$                                                          : chr [1:10] \"C-SPAN\\nCongressional Quarterly\\nThe Hill\\nPolitico\\nRoll Call\" NA NA NA ...\n $ : tibble [9 × 4] (S3: tbl_df/tbl/data.frame)\n  ..$ X1: chr [1:9] \"Powers\" \"Privileges\" \"Procedure\" \"Senate-specific\" ...\n  ..$ X2: chr [1:9] \"Article I\\nCopyright\\nCommerce (Dormant)\\nContempt of Congress\\nDeclaration of war\\nImpeachment\\nInquiries\\nTri\"| __truncated__ \"Salaries\\nFranking\\nImmunity\" \"Act of Congress\\nlist\\nAppropriation bill\\nBill\\nBudget process\\nCensure\\nClosed sessions\\nHouse\\nSenate\\nClotu\"| __truncated__ \"Advice and consent\\nBlue slip (U.S. Senate)\\nClasses\\nExecutive communication\\nExecutive session\\nFilibuster\\nJ\"| __truncated__ ...\n  ..$ X3: chr [1:9] NA NA NA NA ...\n  ..$ X4: chr [1:9] NA NA NA NA ...\n $ : tibble [1 × 2] (S3: tbl_df/tbl/data.frame)\n  ..$ X1: chr \"House history\\nmemoirs\\nspeaker elections\\nSenate history\\nelection disputes\\nmemoirs\\nContinental Congress\\nFe\"| __truncated__\n  ..$ X2: chr \"House history\\nmemoirs\\nspeaker elections\\nSenate history\\nelection disputes\\nmemoirs\\nContinental Congress\\nFe\"| __truncated__\n $ : tibble [16 × 32] (S3: tbl_df/tbl/data.frame)\n  ..$ Capitol Complex (Capitol Hill): chr [1:16] \"Legislativeoffices\\nCongressional staff\\nGov. Accountability Office (GAO)\\nComptroller General\\nArchitect of th\"| __truncated__ \"Legislativeoffices\" \"Offices\" \"Senate\" ...\n  ..$ Capitol Complex (Capitol Hill): chr [1:16] \"Legislativeoffices\\nCongressional staff\\nGov. Accountability Office (GAO)\\nComptroller General\\nArchitect of th\"| __truncated__ \"Congressional staff\\nGov. Accountability Office (GAO)\\nComptroller General\\nArchitect of the Capitol\\nCap. Poli\"| __truncated__ \"Senate\\nCurator\\nHistorical\\nLibraryHouse\\nCongr. Ethics\\nEmergency Planning, Preparedness, and Operations\\nInt\"| __truncated__ \"Curator\\nHistorical\\nLibrary\" ...\n  ..$                               : chr [1:16] \"Legislativeoffices\" NA \"Senate\" NA ...\n  ..$                               : chr [1:16] \"Congressional staff\\nGov. Accountability Office (GAO)\\nComptroller General\\nArchitect of the Capitol\\nCap. Poli\"| __truncated__ NA \"Curator\\nHistorical\\nLibrary\" NA ...\n  ..$                               : chr [1:16] \"Offices\" NA \"House\" NA ...\n  ..$                               : chr [1:16] \"Senate\\nCurator\\nHistorical\\nLibraryHouse\\nCongr. Ethics\\nEmergency Planning, Preparedness, and Operations\\nInt\"| __truncated__ NA \"Congr. Ethics\\nEmergency Planning, Preparedness, and Operations\\nInterparliamentary Affairs\\nLaw Revision Couns\"| __truncated__ NA ...\n  ..$                               : chr [1:16] \"Senate\" NA NA NA ...\n  ..$                               : chr [1:16] \"Curator\\nHistorical\\nLibrary\" NA NA NA ...\n  ..$                               : chr [1:16] \"House\" NA NA NA ...\n  ..$                               : chr [1:16] \"Congr. Ethics\\nEmergency Planning, Preparedness, and Operations\\nInterparliamentary Affairs\\nLaw Revision Couns\"| __truncated__ NA NA NA ...\n  ..$                               : chr [1:16] \"Employees\" NA NA NA ...\n  ..$                               : chr [1:16] \"Senate\\nSecretary\\nChaplain\\nCurator\\nHistorian\\nLibrarian\\nPages\\nParliamentarian\\nSergeant at Arms and Doorke\"| __truncated__ NA NA NA ...\n  ..$                               : chr [1:16] \"Senate\" NA NA NA ...\n  ..$                               : chr [1:16] \"Secretary\\nChaplain\\nCurator\\nHistorian\\nLibrarian\\nPages\\nParliamentarian\\nSergeant at Arms and Doorkeeper\" NA NA NA ...\n  ..$                               : chr [1:16] \"House\" NA NA NA ...\n  ..$                               : chr [1:16] \"Chaplain\\nChief Administrative Officer\\nClerk\\nDoorkeeper\\nFloor Operations\\nFloor Services Chief\\nHistorian\\nP\"| __truncated__ NA NA NA ...\n  ..$                               : chr [1:16] \"Library ofCongress\" NA NA NA ...\n  ..$                               : chr [1:16] \"Congressional Research Service\\nreports\\nCopyright Office\\nRegister of Copyrights\\nLaw Library\\nPoet Laureate\\n\"| __truncated__ NA NA NA ...\n  ..$                               : chr [1:16] \"Gov.Publishing Office\" NA NA NA ...\n  ..$                               : chr [1:16] \"Public Printer\\nCongressional Pictorial Directory\\nCongressional Record\\nOfficial Congressional Directory\\nU.S.\"| __truncated__ NA NA NA ...\n  ..$                               : chr [1:16] \"Capitol Building\" NA NA NA ...\n  ..$                               : chr [1:16] \"List of artwork at the United States Capitol complex\\nBrumidi Corridors\\nCongressional Prayer Room\\nCrypt\\nDome\"| __truncated__ NA NA NA ...\n  ..$                               : chr [1:16] \"Officebuildings\" NA NA NA ...\n  ..$                               : chr [1:16] \"Senate\\nDirksen\\nHart\\nMountains and Clouds\\nRussellHouse\\nBuilding Commission\\noffice lottery\\nCannon\\nFord\\nL\"| __truncated__ NA NA NA ...\n  ..$                               : chr [1:16] \"Senate\" NA NA NA ...\n  ..$                               : chr [1:16] \"Dirksen\\nHart\\nMountains and Clouds\\nRussell\" NA NA NA ...\n  ..$                               : chr [1:16] \"House\" NA NA NA ...\n  ..$                               : chr [1:16] \"Building Commission\\noffice lottery\\nCannon\\nFord\\nLongworth\\nO'Neill\\nRayburn\" NA NA NA ...\n  ..$                               : chr [1:16] \"Otherfacilities\" NA NA NA ...\n  ..$                               : chr [1:16] \"Botanic Garden\\nHealth and Fitness Facility\\nHouse Recording Studio\\nSenate chamber\\nOld Senate Chamber\\nOld Su\"| __truncated__ NA NA NA ...\n  ..$                               : chr [1:16] \"Related\" NA NA NA ...\n  ..$                               : chr [1:16] \"Capitol Hill\\nUnited States Capitol cornerstone laying\" NA NA NA ...\n $ : tibble [15 × 6] (S3: tbl_df/tbl/data.frame)\n  ..$ X1: chr [1:15] \"Legislativeoffices\" \"Offices\" \"Senate\" \"House\" ...\n  ..$ X2: chr [1:15] \"Congressional staff\\nGov. Accountability Office (GAO)\\nComptroller General\\nArchitect of the Capitol\\nCap. Poli\"| __truncated__ \"Senate\\nCurator\\nHistorical\\nLibraryHouse\\nCongr. Ethics\\nEmergency Planning, Preparedness, and Operations\\nInt\"| __truncated__ \"Curator\\nHistorical\\nLibrary\" \"Congr. Ethics\\nEmergency Planning, Preparedness, and Operations\\nInterparliamentary Affairs\\nLaw Revision Couns\"| __truncated__ ...\n  ..$ X3: chr [1:15] NA \"Senate\" NA NA ...\n  ..$ X4: chr [1:15] NA \"Curator\\nHistorical\\nLibrary\" NA NA ...\n  ..$ X5: chr [1:15] NA \"House\" NA NA ...\n  ..$ X6: chr [1:15] NA \"Congr. Ethics\\nEmergency Planning, Preparedness, and Operations\\nInterparliamentary Affairs\\nLaw Revision Couns\"| __truncated__ NA NA ...\n $ : tibble [2 × 2] (S3: tbl_df/tbl/data.frame)\n  ..$ X1: chr [1:2] \"Senate\" \"House\"\n  ..$ X2: chr [1:2] \"Curator\\nHistorical\\nLibrary\" \"Congr. Ethics\\nEmergency Planning, Preparedness, and Operations\\nInterparliamentary Affairs\\nLaw Revision Couns\"| __truncated__\n $ : tibble [2 × 2] (S3: tbl_df/tbl/data.frame)\n  ..$ X1: chr [1:2] \"Senate\" \"House\"\n  ..$ X2: chr [1:2] \"Secretary\\nChaplain\\nCurator\\nHistorian\\nLibrarian\\nPages\\nParliamentarian\\nSergeant at Arms and Doorkeeper\" \"Chaplain\\nChief Administrative Officer\\nClerk\\nDoorkeeper\\nFloor Operations\\nFloor Services Chief\\nHistorian\\nP\"| __truncated__\n $ : tibble [2 × 2] (S3: tbl_df/tbl/data.frame)\n  ..$ X1: chr [1:2] \"Senate\" \"House\"\n  ..$ X2: chr [1:2] \"Dirksen\\nHart\\nMountains and Clouds\\nRussell\" \"Building Commission\\noffice lottery\\nCannon\\nFord\\nLongworth\\nO'Neill\\nRayburn\"\n $ : tibble [2 × 2] (S3: tbl_df/tbl/data.frame)\n  ..$ vteOrder of precedence in the United States*: chr [1:2] \"President Donald TrumpVice President JD Vance\\nGovernor (of the state in which the event is held)\\nHouse Speake\"| __truncated__ \"*not including acting officeholders, visiting dignitaries, auxiliary executive and military personnel and most diplomats\"\n  ..$ vteOrder of precedence in the United States*: chr [1:2] \"President Donald TrumpVice President JD Vance\\nGovernor (of the state in which the event is held)\\nHouse Speake\"| __truncated__ \"*not including acting officeholders, visiting dignitaries, auxiliary executive and military personnel and most diplomats\"\n```\n\n\n:::\n:::\n\n\nHere, the table I want is the sixth one. We can grab it by either using double square brackets -- `[[6]]` -- or `purrr`'s `pluck(6)`.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsenators <- tables |> \n  pluck(6)\n\nglimpse(senators)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nRows: 100\nColumns: 12\n$ State                        <chr> \"Alabama\", \"Alabama\", \"Alaska\", \"Alaska\",…\n$ Portrait                     <lgl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ Senator                      <chr> \"Tommy Tuberville\", \"Katie Britt\", \"Lisa …\n$ Party                        <lgl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ Party                        <chr> \"Republican\", \"Republican\", \"Republican\",…\n$ Born                         <chr> \"(1954-09-18) September 18, 1954 (age 71)…\n$ `Occupation(s)`              <chr> \"Investment management firm partner\\nColl…\n$ `Previous electiveoffice(s)` <chr> \"None\", \"None\", \"Alaska House of Represen…\n$ Education                    <chr> \"Southern Arkansas University (BS)\", \"Uni…\n$ `Assumed office`             <chr> \"January 3, 2021\", \"January 3, 2023\", \"De…\n$ Class                        <chr> \"2026Class 2\", \"2028Class 3\", \"2028Class …\n$ `Residence[4]`               <chr> \"Auburn[5]\", \"Montgomery\", \"Girdwood\", \"A…\n```\n\n\n:::\n\n```{.r .cell-code}\n## alternative approach using css\nsenators <- us_senators |> \n  html_elements(css = \"#senators\") |> \n  html_table() |> \n  pluck(1) |> \n  janitor::clean_names()\n```\n:::\n\n\nYou can see that the tibble contains \"dirty\" names and that the party column appears twice -- which will make it impossible to work with the tibble later on. Hence, I use `clean_names()` from the `janitor` package to fix that.\n\n### Extracting attributes\n\nYou can also extract attributes such as links using `html_attrs()`. An example would be to extract the headlines and their corresponding links from r-bloggers.com.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrbloggers <- read_html(\"https://www.r-bloggers.com\")\n```\n:::\n\n\nA quick check with the SelectorGadget told me that the element I am looking for is of class \".loop-title\" and the child of it is \"a\", standing for normal text. With `html_attrs()` I can extract the attributes. This gives me a list of named vectors containing the name of the attribute and the value:\n\n\n\nLinks are stored as attribute \"href\" -- hyperlink reference. `html_attr()` allows me to extract the attribute's value. Hence, building a tibble with the article's title and its corresponding hyperlink is straight-forward now:\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntibble(\n  title = r_blogger_postings |> html_text2(),\n  link = r_blogger_postings |> html_attr(name = \"href\")\n)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 20 × 2\n   title                                                                   link \n   <chr>                                                                   <chr>\n 1 Of course, someone has to write imperative code to build reproducible … http…\n 2 Elevate Your Data Skills with Jumping Rivers Training                   http…\n 3 GSS Release                                                             http…\n 4 An update to Open Trade Statistics to showcase Tabler and D3po          http…\n 5 September 2025 Top 40 New CRAN Packages                                 http…\n 6 Using D3po with Tabler                                                  http…\n 7 Tabler 0.1.0 is here!                                                   http…\n 8 Double Descent Explained                                                http…\n 9 Approximating evidence via bounded harmonic means (and HPD regions wit… http…\n10 Mapping Antarctica                                                      http…\n11 rOpenSci News Digest, October 2025                                      http…\n12 EuroBioC2025 conference recap                                           http…\n13 Change is good, so don’t change my change                               http…\n14 Be Mindful of the Time                                                  http…\n15 Orchestrating Polyglot, Reproducible Data Science with Nix and {rixpre… http…\n16 The use of SAT/ACT for college admissions                               http…\n17 Go for Launch! Packages Shipped to the R-Multiverse                     http…\n18 Rfuzzycoco released on CRAN                                             http…\n19 Compositional modeling of plant communities with Dirichlet regression   http…\n20 gssrdoc Updates                                                         http…\n```\n\n\n:::\n:::\n\n\nAnother approach for this would be using the `polite` package and its function `html_attrs_dfr()` which binds together all the different attributes column-wise and the different elements row-wise.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrbloggers |> \n  html_elements(css = \".loop-title a\") |> \n  html_attrs_dfr() |> \n  select(title = 3, \n         link = 1) |> \n  glimpse()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nRows: 20\nColumns: 2\n$ title <chr> \"Of course, someone has to write imperative code to build reprod…\n$ link  <chr> \"https://www.r-bloggers.com/2025/10/of-course-someone-has-to-wri…\n```\n\n\n:::\n:::\n\n\n### Exercise\n\n3.  Download the links and names of the [top 250 IMDb movies](https://www.imdb.com/chart/top/). Put them in a tibble with the columns `rank` -- in numeric format (you know regexes already), `title`, `url` to IMDb entry, `rating` -- in numeric format, `number_votes` -- the number of votes a movie has received, in numeric format. Also, what do you notice?\n\n<details>\n  <summary>Solution. Click to expand!</summary>\n\n::: {.cell}\n\n```{.r .cell-code}\nimdb_top250 <- read_html(\"https://www.imdb.com/chart/top/?ref_=nv_mv_250\")\n\nmovies <- tibble(\n  rank = imdb_top250 |> \n    html_elements(\".cli-title .ipc-title__text\") |> \n    html_text2() |> \n    str_extract(\"^[0-9]+(?=\\\\.)\") |> \n    parse_integer(),\n  title = imdb_top250 |> \n    html_elements(\".cli-title .ipc-title__text\") |> \n    html_text2() |> \n    str_remove(\"^[0-9]+\\\\. \"),\n  url = imdb_top250 |> \n    html_elements(\".cli-title a\") |> \n    html_attr(\"href\") |> \n    str_c(\"https://www.imdb.com\", x = _),\n  rating = imdb_top250 |> \n    html_elements(\".ratingGroup--imdb-rating\") |> \n    html_text() |> \n    str_extract(\"[0-9]\\\\.[0-9]\") |> \n    parse_double(),\n  no_votes = imdb_top250 |> \n    html_elements(\".ratingGroup--imdb-rating\") |> \n    html_text() |> \n    str_remove(\"^[0-9]\\\\.[0-9]\") |> \n    str_remove_all(\"[() ]\")\n)\n```\n:::\n\n</details>\n\n\n## Automating scraping\n\nWell, grabbing singular points of data from websites is nice. However, if you want to do things such as collecting large amounts of data or multiple pages, you will not be able to do this without some automation.\n\n\n::: {.cell}\n::: {.cell-output-display}\n\n```{=html}\n<div class=\"vembedr\">\n<div>\n<iframe src=\"https://www.youtube.com/embed/C8LHWqfIvH4\" width=\"533\" height=\"300\" frameborder=\"0\" allowfullscreen=\"\" data-external=\"1\"></iframe>\n</div>\n</div>\n```\n\n:::\n:::\n\n\nAn example here would again be the R-bloggers page. It provides you with plenty of R-related content. If you were now eager to scrape all the articles, you would first need to acquire all the different links leading to the blog postings. Hence, you would need to navigate through the site's pages first to acquire the links.\n\nIn general, there are two ways to go about this. The first is to manually create a list of URLs the scraper will visit and take the content you need, therefore not needing to identify where it needs to go next. The other one would be automatically acquiring its next destination from the page (i.e., identifying the \"go on\" button). Both strategies can also be nicely combined with some sort of `session()`.\n\n### Looping over pages\n\nFor the first approach, we need to check the URLs first. How do they change as we navigate through the pages?\n\n\n::: {.cell}\n\n```{.r .cell-code}\nurl_1 <- \"https://www.r-bloggers.com/page/2/\"\nurl_2 <- \"https://www.r-bloggers.com/page/3/\"\n\ninitial_dist <- adist(url_1, url_2, counts = TRUE) |> \n  attr(\"trafos\") |> \n  diag() |> \n  str_locate_all(\"[^M]\")\n\n  \nstr_sub(url_1, start = initial_dist[[1]][1]-5, end = initial_dist[[1]][1]+5) # makes sense for longer urls\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"page/2/\"\n```\n\n\n:::\n\n```{.r .cell-code}\nstr_sub(url_2, start = initial_dist[[1]][1]-5, end = initial_dist[[1]][1]+5)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"page/3/\"\n```\n\n\n:::\n:::\n\n\nThere is some sort of underlying pattern and we can harness that. `url_1` refers to the second page, `url_2` to the third. Hence, if we just combine the basic URL and, say, the numbers from 1 to 10, we could then visit all the pages (exercise 3a) and extract the content we want.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nurls <- str_c(\"https://www.r-bloggers.com/page/\", 1:10, \"/\") # this is the stringr equivalent of paste()\nurls\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n [1] \"https://www.r-bloggers.com/page/1/\"  \"https://www.r-bloggers.com/page/2/\" \n [3] \"https://www.r-bloggers.com/page/3/\"  \"https://www.r-bloggers.com/page/4/\" \n [5] \"https://www.r-bloggers.com/page/5/\"  \"https://www.r-bloggers.com/page/6/\" \n [7] \"https://www.r-bloggers.com/page/7/\"  \"https://www.r-bloggers.com/page/8/\" \n [9] \"https://www.r-bloggers.com/page/9/\"  \"https://www.r-bloggers.com/page/10/\"\n```\n\n\n:::\n:::\n\n\nYou can run this in a for-loop, here's a quick revision. For the loop to run efficiently, space for every object should be pre-allocated (i.e., you create a list beforehand, and its length can be determined by an educated guess).\n\n\n::: {.cell}\n\n```{.r .cell-code}\n## THIS IS PSEUDO CODE!!!\nresult_list <- vector(mode = \"list\", length = length(urls)) # pre-allocate space!!!\nstarting_link <- \"https://www.r-bloggers.com/page/1/\"\n####PSEUDO CODE!!!\nfor (i in seq_along(urls)){\n  read in urls[[i]] --> page <- read_html(url)\n  store content of page in result_list result_list[[i]] <- extract_content(page)\n}\n```\n:::\n\n\n### Letting the scraper navigate on its own\n\nExtracting the link on the fly is the same thing, but in the end, you need to replace the link argument with the one you extracted. You will do this in exercise 3. It is probably easiest to perform those things in a `while` loop, hence here is a quick revision:\n\nHence, our `while` loop in pseudo-code will look like this:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n## THIS IS PSEUDO CODE!!!\noutput_list <- vector(mode = \"list\", length = 10L)\ni <- 0\nwhile (session$response$status_code == 200 && i <= 10) {\n  session(start-url)\n  i <- i + 1\n  read in r-bloggers results list\n  get all stuff and store it in output_list[[i]]\n  move session to next page\n}\n\n### reminder: how to click a button in rvest\n\nsession(\"https://www.scrapethissite.com/\") |> \n  session_follow_link(css = \"#nav-lessons .nav-link\") # just use selectorgadget to check for css selector of button\n```\n:::\n\n\n### Exercise\n\n4.  Scrape 5 pages of the latest [UN press releases](https://press.un.org/en/content/secretary-general/press-release) in an automated fashion. Make sure to take breaks between requests by including `Sys.sleep(2)`. For each iteration, store the articles and links in a tibble containing the columns `title`,`link`, and `date` (bonus: store it in date format). (Tip: wrap the code that extracts and stores content in a tibble in a function.)\n\na.  Do so using running numbers in the urls.\nb.  Do so by using `session()` in a loop. (Note: make sure to specify `css =`)\n\n<details>\n  <summary>Solution. Click to expand!</summary>\n\n::: {.cell}\n\n```{.r .cell-code}\nextract_press_releases <- function(page){\n  tibble(\n    title = page |> \n      html_elements(\".field__item a\") |> \n      html_text2(),\n    link = page |> \n      html_elements(\".field__item a\") |> \n      html_attr(\"href\"),\n    date = page |> \n      html_elements(\".field--type-datetime\") |> \n      html_text2() |> \n      as.Date(format = \"%d %B %Y\")\n  )\n  \n}\n\n\n#a\nurls <- str_c(\"https://press.un.org/en/content/secretary-general/press-release?page=\", 0:4)\n\npages <- map(urls, \n             \\(x){\n               Sys.sleep(2) \n               read_html(x) |> \n                 extract_press_releases()\n               }\n             )\n\n#b\nun_session <- session(\"https://press.un.org/en/content/secretary-general/press-release\")\ni <- 1\npage_list <- vector(mode = \"list\", length = 5L)\nwhile (i < 6) {\n  page_list[[i]] <- read_html(un_session) |> \n    extract_press_releases()\n  un_session <- un_session |> \n    session_follow_link(css = \".me-s .page-link\")\n  i <- i + 1\n  Sys.sleep(2)\n}\n```\n:::\n\n</details>\n\n\n## Conclusion\n\nTo sum it up: when you have a good research idea that relies on Digital Trace Data that you need to collect, ask yourself the following questions:\n\n1. Is there some sort of data dump that I can download?\n2. Is there an R package for the web service?\n3.  If 1. == FALSE: Is there an API where I can get the data (if TRUE, use it) -- next chapter.\n4.  If 1. == FALSE & 2. == FALSE: Is screen scraping an option and any structure in the data that you can harness?\n\nIf you have to rely on screen scraping, also ask yourself the question how you can minimize the number of requests you make to the server. Going back and forth on web pages or navigating through them might not be the best option since it requires multiple requests. The most efficient way is usually to try to get a list of URLs of some sort which you can then just loop over.\n\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<link href=\"site_libs/vembedr-0.1.5/css/vembedr.css\" rel=\"stylesheet\" />\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}