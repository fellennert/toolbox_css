{
  "hash": "270b237c562c12bcb0e8bc198505843d",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Chapter 5: `pandas`\"\npublished-title: pandas\nengine: knitr\nfreeze: auto\nbibliography: literature.bib\ncsl: ASA.csl\n---\n\n\n\nNow that you understand Python basics, let's look at `pandas` -- Python's most popular library for data manipulation. If you're familiar with R's tidyverse (especially `dplyr` and `tidyr`), `pandas` will feel conceptually familiar, though the syntax differs.\n\n### What is Pandas?\n\n`pandas` provides two main data structures:\n\n- `Series`: Like an R vector or a single column\n- `DataFrame`: Like an R tibble/data.frame\n\n\n::: {.cell}\n\n```{.python .cell-code}\nimport pandas as pd # Standard convention: import pandas as pd -- equivalent to library(tidyverse)\nimport numpy as np  # NumPy often used alongside pandas\n\n# Check version\npd.__version__\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n'2.3.1'\n```\n\n\n:::\n:::\n\n\n### Creating DataFrames\n\nYou can create DataFrames in several ways:\n\n\n::: {.cell}\n\n```{.python .cell-code}\n# From a dictionary (like tibble() in R)\ndf_dic = pd.DataFrame({\n    'name': ['Alice', 'Bob', 'Charlie', 'Diana'],\n    'age': [25, 30, 35, 28],\n    'city': ['New York', 'London', 'Paris', 'Tokyo']\n})\n\ndf_dic\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n      name  age      city\n0    Alice   25  New York\n1      Bob   30    London\n2  Charlie   35     Paris\n3    Diana   28     Tokyo\n```\n\n\n:::\n\n```{.python .cell-code}\n# from a list of dictionaries\ndata = [\n    {'name': 'Alice', 'age': 25, 'city': 'New York'},\n    {'name': 'Bob', 'age': 30, 'city': 'Paris'},\n    {'name': 'Charlie', 'age': 35, 'city': 'London'}\n]\ndf_dic_list = pd.DataFrame(data)\ndf_dic_list\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n      name  age      city\n0    Alice   25  New York\n1      Bob   30     Paris\n2  Charlie   35    London\n```\n\n\n:::\n\n```{.python .cell-code}\n# from a list of lists (specify column names)\ndata = [\n    ['Alice', 25, 'New York'],\n    ['Bob', 30, 'Paris'],\n    ['Charlie', 35, 'London']\n]\ndf_list_of_lists = pd.DataFrame(data, columns=['name', 'age', 'city'])\n\n# from a numpy array (essentially a matrix, specify column names)\ndata = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\ndata\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\narray([[1, 2, 3],\n       [4, 5, 6],\n       [7, 8, 9]])\n```\n\n\n:::\n\n```{.python .cell-code}\ndf_array = pd.DataFrame(data, columns=['A', 'B', 'C'])\ndf_array\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n   A  B  C\n0  1  2  3\n1  4  5  6\n2  7  8  9\n```\n\n\n:::\n:::\n\n\n\n::: {.callout-tip title=\"Compared to R\"}\nrdf <- tibble(\n  name = c('Alice', 'Bob', 'Charlie', 'Diana'),\n  age = c(25, 30, 35, 28),\n  city = c('New York', 'London', 'Paris', 'Tokyo')\n)\n::: \n\n### Basic DataFrame Operations\n\n`pandas` works through methods rather than functions. Methods are attached to specific object types. A string has string methods, a list has list methods, a DataFrame has DataFrame methods.\n\nThere are several differences:\n\n- Functions are called by putting the object as an argument:\n\n::: {.cell}\n\n```{.python .cell-code}\n# Function syntax: function(object, arguments)\nmy_list = [3, 1, 4, 1, 5]\nlen(my_list)        # len is a function\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n5\n```\n\n\n:::\n\n```{.python .cell-code}\nsorted(my_list)     # sorted is a function\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1, 1, 3, 4, 5]\n```\n\n\n:::\n:::\n\n\n- Methods are functions that \"belong to\" an object and are called using dot notation:\n\n::: {.cell}\n\n```{.python .cell-code}\n# Method syntax: object.method(arguments)\nmy_string = \"hello world\"\nupper_string = my_string.upper()      # upper() is a method of strings\nmy_string.split()      # split() is a method of strings\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n['hello', 'world']\n```\n\n\n:::\n\n```{.python .cell-code}\nmy_string              # object remains unchanged\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n'hello world'\n```\n\n\n:::\n\n```{.python .cell-code}\nmy_list.append(9)      # append() is a method of lists; note that this modifies the list in place\nmy_list\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[3, 1, 4, 1, 5, 9]\n```\n\n\n:::\n:::\n\n\n\n::: {.callout-tip title=\"Compared to R\"}\nR primarily uses functions - you write head(df), nrow(df), names(df). Python often uses methods - you write df.head(), df.shape, df.columns.\n::: \n\nThis matters for pandas, since almost everything is a method and hence the syntax differs significantly.\n\n### `pandas` in action\n\nViewing Data (note that objects remain unchanged):\n\n\n::: {.cell}\n\n```{.python .cell-code}\ndf = pd.DataFrame({\n    'name': ['Alice', 'Bob', 'Charlie', 'Diana'],\n    'age': [25, 30, 35, 28],\n    'city': ['New York', 'London', 'Paris', 'Tokyo']\n})\n\n# First few rows (like head() in R)\ndf.head(2)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n    name  age      city\n0  Alice   25  New York\n1    Bob   30    London\n```\n\n\n:::\n\n```{.python .cell-code}\n# Last few rows (like tail() in R)\ndf.tail(2)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n      name  age   city\n2  Charlie   35  Paris\n3    Diana   28  Tokyo\n```\n\n\n:::\n\n```{.python .cell-code}\n# Info about the DataFrame (like glimpse() or str() in R)\ndf.info()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 4 entries, 0 to 3\nData columns (total 3 columns):\n #   Column  Non-Null Count  Dtype \n---  ------  --------------  ----- \n 0   name    4 non-null      object\n 1   age     4 non-null      int64 \n 2   city    4 non-null      object\ndtypes: int64(1), object(2)\nmemory usage: 224.0+ bytes\n```\n\n\n:::\n\n```{.python .cell-code}\n# Summary statistics (like summary() in R)\ndf.describe()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n             age\ncount   4.000000\nmean   29.500000\nstd     4.203173\nmin    25.000000\n25%    27.250000\n50%    29.000000\n75%    31.250000\nmax    35.000000\n```\n\n\n:::\n:::\n\n\nSelecting Columns:\n\n::: {.cell}\n\n```{.python .cell-code}\n# Select single column (returns a Series)\ndf['name']           # in R: df$name\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n0      Alice\n1        Bob\n2    Charlie\n3      Diana\nName: name, dtype: object\n```\n\n\n:::\n\n```{.python .cell-code}\n# Select single column (returns a DataFrame)\ndf[['name']]         # in R: df |> select(name)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n      name\n0    Alice\n1      Bob\n2  Charlie\n3    Diana\n```\n\n\n:::\n\n```{.python .cell-code}\n# Select multiple columns (returns a DataFrame)\ndf[['name', 'age']]  # in R: df |> select(name, age)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n      name  age\n0    Alice   25\n1      Bob   30\n2  Charlie   35\n3    Diana   28\n```\n\n\n:::\n\n```{.python .cell-code}\n## OR: .filter() -- the equivalent of dplyr::select()\ndf.filter(['name'])\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n      name\n0    Alice\n1      Bob\n2  Charlie\n3    Diana\n```\n\n\n:::\n\n```{.python .cell-code}\n# Columns containing a string\ndf.filter(like='a')  # Gets 'Rating', 'Rating_Count', etc.\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n      name  age\n0    Alice   25\n1      Bob   30\n2  Charlie   35\n3    Diana   28\n```\n\n\n:::\n\n```{.python .cell-code}\n# Regex pattern\ndf.filter(regex='^(name|age)$')  # Columns matching the pattern\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n      name  age\n0    Alice   25\n1      Bob   30\n2  Charlie   35\n3    Diana   28\n```\n\n\n:::\n:::\n\n\n\nFiltering Rows:\n\n::: {.cell}\n\n```{.python .cell-code}\n# Filter rows where age > 28\ndf[df['age'] > 28]\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n      name  age    city\n1      Bob   30  London\n2  Charlie   35   Paris\n```\n\n\n:::\n\n```{.python .cell-code}\n# Multiple conditions (use & for AND, | for OR)\ndf[(df['age'] > 25) & (df['city'] == 'London')]\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  name  age    city\n1  Bob   30  London\n```\n\n\n:::\n\n```{.python .cell-code}\n# Filter something depending on its presence in another list using .isin() (R equivalent: %in%)\ncities_ive_been_to = [\"Paris\", \"New York\", \"London\"]\ndf[df['city'].isin(cities_ive_been_to)]\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n      name  age      city\n0    Alice   25  New York\n1      Bob   30    London\n2  Charlie   35     Paris\n```\n\n\n:::\n\n```{.python .cell-code}\n# or using .query()\ndf.query('age > 25') #R: df |> filter(age > 25)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n      name  age    city\n1      Bob   30  London\n2  Charlie   35   Paris\n3    Diana   28   Tokyo\n```\n\n\n:::\n:::\n\n\n\nAdding New Columns:\n\n::: {.cell}\n\n```{.python .cell-code}\n# Add a new column (like mutate() in R)\ndf['age_in_months'] = df['age'] * 12    # in R: df$age_in_months <- df$age * 12\ndf\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n      name  age      city  age_in_months\n0    Alice   25  New York            300\n1      Bob   30    London            360\n2  Charlie   35     Paris            420\n3    Diana   28     Tokyo            336\n```\n\n\n:::\n\n```{.python .cell-code}\n# or using .assign()\ndf = df.assign(year_of_birth = lambda x: 2025-x['age'])\ndf\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n      name  age      city  age_in_months  year_of_birth\n0    Alice   25  New York            300           2000\n1      Bob   30    London            360           1995\n2  Charlie   35     Paris            420           1990\n3    Diana   28     Tokyo            336           1997\n```\n\n\n:::\n:::\n\n\nSorting:\n\n::: {.cell}\n\n```{.python .cell-code}\n# Sort by age (like arrange() in R)\ndf.sort_values('age')                    # in R: df |> arrange(age)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n      name  age      city  age_in_months  year_of_birth\n0    Alice   25  New York            300           2000\n3    Diana   28     Tokyo            336           1997\n1      Bob   30    London            360           1995\n2  Charlie   35     Paris            420           1990\n```\n\n\n:::\n\n```{.python .cell-code}\n# Sort descending\ndf.sort_values('age', ascending=False)   # in R: df |> arrange(desc(age))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n      name  age      city  age_in_months  year_of_birth\n2  Charlie   35     Paris            420           1990\n1      Bob   30    London            360           1995\n3    Diana   28     Tokyo            336           1997\n0    Alice   25  New York            300           2000\n```\n\n\n:::\n:::\n\n\nRead in Data:\n\n::: {.cell}\n\n```{.python .cell-code}\n# Read CSV (like read_csv() in R)\nimdb_df = pd.read_csv('data/imdb2006-2016.csv')\nimdb_df.head()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n   Rank                    Title  ... Revenue (Millions) Metascore\n0     1  Guardians of the Galaxy  ...             333.13      76.0\n1     2               Prometheus  ...             126.46      65.0\n2     3                    Split  ...             138.12      62.0\n3     4                     Sing  ...             270.32      59.0\n4     5            Suicide Squad  ...             325.02      40.0\n\n[5 rows x 12 columns]\n```\n\n\n:::\n\n```{.python .cell-code}\n# Read Excel\npublishers_df = pd.read_excel('data/publishers_with_places.xlsx')\npublishers_df.head()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n        publisher               city\n0    37 ink atria  New York City, NY\n1          abrams  New York City, NY\n2             ace  New York City, NY\n3  alfred a knopf  New York City, NY\n4       algonquin    Chapel Hill, NC\n```\n\n\n:::\n\n```{.python .cell-code}\n# Read from URL\ndf_example = pd.read_csv('https://raw.githubusercontent.com/mwaskom/seaborn-data/master/tips.csv')\ndf_example.head()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n   total_bill   tip     sex smoker  day    time  size\n0       16.99  1.01  Female     No  Sun  Dinner     2\n1       10.34  1.66    Male     No  Sun  Dinner     3\n2       21.01  3.50    Male     No  Sun  Dinner     3\n3       23.68  3.31    Male     No  Sun  Dinner     2\n4       24.59  3.61  Female     No  Sun  Dinner     4\n```\n\n\n:::\n:::\n\n\nQuick Data Exploration:\n\n::: {.cell}\n\n```{.python .cell-code}\n# Shape (rows, columns)\ndf_example.shape                                  # in R: dim(df)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n(244, 7)\n```\n\n\n:::\n\n```{.python .cell-code}\n# Column names \ndf_example.columns.tolist()                       # in R: colnames(df)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n['total_bill', 'tip', 'sex', 'smoker', 'day', 'time', 'size']\n```\n\n\n:::\n\n```{.python .cell-code}\n# Value counts\ndf_example['day'].value_counts()                  # in R: df |> count(day)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nday\nSat     87\nSun     76\nThur    62\nFri     19\nName: count, dtype: int64\n```\n\n\n:::\n\n```{.python .cell-code}\n# Group by and aggregate (yields a Series)\ndf_example.groupby('day')['total_bill'].mean()    # in R: df |> group_by(day) |> summarize(mean_bill = mean(total_bill)) |> pull(mean_bill) |> set_names(day)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nday\nFri     17.151579\nSat     20.441379\nSun     21.410000\nThur    17.682742\nName: total_bill, dtype: float64\n```\n\n\n:::\n\n```{.python .cell-code}\n# Group by and aggregate (yields a DataFrame)\ndf_example.groupby('day')['total_bill'].mean().reset_index() # in R: df |> group_by(day) |> summarize(mean_bill = mean(total_bill))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n    day  total_bill\n0   Fri   17.151579\n1   Sat   20.441379\n2   Sun   21.410000\n3  Thur   17.682742\n```\n\n\n:::\n:::\n\n\n### Method Chaining\n`pandas` supports method chaining (similar to the pipe `|>`/`%>%` in R):\n\n::: {.cell}\n\n```{.python .cell-code}\n# Chain multiple operations\nresult = (df_example\n    .query('total_bill > 20')  # Filter\n    .assign(tip_pct = lambda x: x['tip'] / x['total_bill'])  # New column\n    .sort_values('tip_pct', ascending=False)  # Sort\n    .head(5)  # Top 5\n)\n\nresult\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n     total_bill   tip     sex smoker   day    time  size   tip_pct\n183       23.17  6.50    Male    Yes   Sun  Dinner     4  0.280535\n181       23.33  5.65    Male    Yes   Sun  Dinner     2  0.242177\n185       20.69  5.00    Male     No   Sun  Dinner     5  0.241663\n88        24.71  5.85    Male     No  Thur   Lunch     2  0.236746\n214       28.17  6.50  Female    Yes   Sat  Dinner     3  0.230742\n```\n\n\n:::\n:::\n\n\n::: {.callout-tip title=\"Compared to R\"}\n\n\n::: {.cell}\n\n```{.r .cell-code}\nresult <- df_example |>\n  filter(total_bill > 20) |>\n  mutate(tip_pct = tip / total_bill) |>\n  arrange(desc(tip_pct)) |>\n  slice(5)\n```\n:::\n\n\n::: \n\n### Joining DataFrames\n\nJoining (or merging) DataFrames is a fundamental operation in data analysis. `pandas` provides several ways to combine DataFrames, similar to SQL joins or R's `dplyr` join functions.\n\n#### Basic Join Types\n\n::: {.cell}\n\n```{.python .cell-code}\n# Create sample DataFrames\ncustomers = pd.DataFrame({\n    'customer_id': [1, 2, 3, 4],\n    'name': ['Alice', 'Bob', 'Charlie', 'Diana'],\n    'city': ['New York', 'London', 'Paris', 'Tokyo']\n})\n\norders = pd.DataFrame({\n    'order_id': [101, 102, 103, 104, 105],\n    'customer_id': [1, 2, 2, 3, 5],\n    'amount': [100, 150, 200, 75, 300]\n})\n```\n:::\n\n\n#### Inner Join\nKeep only rows that match in both DataFrames.\n\n::: {.cell}\n\n```{.python .cell-code}\n# Inner join (default) - only matching rows\ninner = pd.merge(customers, orders, on='customer_id', how='inner')\ninner\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n   customer_id     name      city  order_id  amount\n0            1    Alice  New York       101     100\n1            2      Bob    London       102     150\n2            2      Bob    London       103     200\n3            3  Charlie     Paris       104      75\n```\n\n\n:::\n:::\n\n\n::: {.callout-tip title=\"Compared to R\"}\n\n::: {.cell}\n\n```{.r .cell-code}\n# R equivalent\ninner_join(customers, orders, by = \"customer_id\")\n```\n:::\n\n:::\n\n#### Left Join\nKeep all rows from the left DataFrame, fill missing values with NaN.\n\n::: {.cell}\n\n```{.python .cell-code}\n# Left join - all customers, even if no orders\nleft = pd.merge(customers, orders, on='customer_id', how='left')\nleft\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n   customer_id     name      city  order_id  amount\n0            1    Alice  New York     101.0   100.0\n1            2      Bob    London     102.0   150.0\n2            2      Bob    London     103.0   200.0\n3            3  Charlie     Paris     104.0    75.0\n4            4    Diana     Tokyo       NaN     NaN\n```\n\n\n:::\n:::\n\n\n::: {.callout-tip title=\"Compared to R\"}\n\n::: {.cell}\n\n```{.r .cell-code}\n# R equivalent\nleft_join(customers, orders, by = \"customer_id\")\n```\n:::\n\n:::\n\n#### Right Join\nKeep all rows from the right DataFrame.\n\n::: {.cell}\n\n```{.python .cell-code}\n# Right join - all orders, even if customer doesn't exist\nright = pd.merge(customers, orders, on='customer_id', how='right')\nright\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n   customer_id     name      city  order_id  amount\n0            1    Alice  New York       101     100\n1            2      Bob    London       102     150\n2            2      Bob    London       103     200\n3            3  Charlie     Paris       104      75\n4            5      NaN       NaN       105     300\n```\n\n\n:::\n:::\n\n\n::: {.callout-tip title=\"Compared to R\"}\n\n::: {.cell}\n\n```{.r .cell-code}\n# R equivalent\nright_join(customers, orders, by = \"customer_id\")\n```\n:::\n\n:::\n\n#### Outer Join\nKeep all rows from both DataFrames.\n\n::: {.cell}\n\n```{.python .cell-code}\n# Outer join - all customers and all orders\nouter = pd.merge(customers, orders, on='customer_id', how='outer')\nouter\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n   customer_id     name      city  order_id  amount\n0            1    Alice  New York     101.0   100.0\n1            2      Bob    London     102.0   150.0\n2            2      Bob    London     103.0   200.0\n3            3  Charlie     Paris     104.0    75.0\n4            4    Diana     Tokyo       NaN     NaN\n5            5      NaN       NaN     105.0   300.0\n```\n\n\n:::\n:::\n\n\n::: {.callout-tip title=\"Compared to R\"}\n\n::: {.cell}\n\n```{.r .cell-code}\n# R equivalent\nfull_join(customers, orders, by = \"customer_id\")\n```\n:::\n\n:::\n\n#### Joining on Different Column Names\n\n::: {.cell}\n\n```{.python .cell-code}\n# When join columns have different names\nproducts = pd.DataFrame({\n    'prod_id': [1, 2, 3],\n    'product': ['Laptop', 'Phone', 'Tablet']\n})\n\nsales = pd.DataFrame({\n    'product_id': [1, 1, 2, 3],\n    'quantity': [5, 3, 8, 2]\n})\n\n# Specify left_on and right_on\nmerged = pd.merge(products, sales, \n                  left_on='prod_id', \n                  right_on='product_id', \n                  how='inner')\nprint(merged)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n   prod_id product  product_id  quantity\n0        1  Laptop           1         5\n1        1  Laptop           1         3\n2        2   Phone           2         8\n3        3  Tablet           3         2\n```\n\n\n:::\n\n```{.python .cell-code}\n# Clean up: drop redundant column\nmerged = pd.merge(products, sales, \n                  left_on='prod_id', \n                  right_on='product_id', \n                  how='inner').drop('product_id', axis=1) #axis=0 would drop the row with id 'product_id' (doesn't exist)\nmerged\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n   prod_id product  quantity\n0        1  Laptop         5\n1        1  Laptop         3\n2        2   Phone         8\n3        3  Tablet         2\n```\n\n\n:::\n:::\n\n\n::: {.callout-tip title=\"Compared to R\"}\n\n::: {.cell}\n\n```{.r .cell-code}\n# R equivalent\ninner_join(products, sales, by = join_by(\"prod_id\" == \"product_id\"))\n```\n:::\n\n:::\n\n#### Joining on Multiple Columns\n\n::: {.cell}\n\n```{.python .cell-code}\n# Join on multiple columns\ndf1 = pd.DataFrame({\n    'year': [2020, 2020, 2021, 2021],\n    'quarter': [1, 2, 1, 2],\n    'revenue': [100, 120, 110, 130]\n})\n\ndf2 = pd.DataFrame({\n    'year': [2020, 2020, 2021],\n    'quarter': [1, 2, 1],\n    'costs': [80, 90, 85]\n})\n\n# Join on both year and quarter\nmerged = pd.merge(df1, df2, on=['year', 'quarter'], how='left')\nmerged\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n   year  quarter  revenue  costs\n0  2020        1      100   80.0\n1  2020        2      120   90.0\n2  2021        1      110   85.0\n3  2021        2      130    NaN\n```\n\n\n:::\n:::\n\n\n::: {.callout-tip title=\"Compared to R\"}\n\n::: {.cell}\n\n```{.r .cell-code}\n# R equivalent\nleft_join(df1, df2, by = join_by(\"year\", \"quarter\"))\n```\n:::\n\n:::\n\n#### Handling Duplicate Column Names\n\n::: {.cell}\n\n```{.python .cell-code}\n# When both DataFrames have columns with same names (besides join key)\ndf1 = pd.DataFrame({\n    'id': [1, 2, 3],\n    'value': [10, 20, 30]\n})\n\ndf2 = pd.DataFrame({\n    'id': [1, 2, 3],\n    'value': [100, 200, 300]\n})\n\n# pandas adds suffixes to distinguish columns\nmerged = pd.merge(df1, df2, on='id', suffixes=('_left', '_right'))\nmerged\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n   id  value_left  value_right\n0   1          10          100\n1   2          20          200\n2   3          30          300\n```\n\n\n:::\n:::\n\n\n::: {.callout-tip title=\"Compared to R\"}\n\n::: {.cell}\n\n```{.r .cell-code}\n# R equivalent (default suffixes are .x and .y)\ninner_join(df1, df2, by = \"id\", suffix = c(\"_left\", \"_right\"))\n```\n:::\n\n:::\n\n#### Concatenating DataFrames (Stacking)\n\nFor simply stacking DataFrames vertically or horizontally without matching keys:\n\n::: {.cell}\n\n```{.python .cell-code}\n# Vertical concatenation (like rbind/bind_rows() in R)\ndf1 = pd.DataFrame({'A': [1, 2], 'B': [3, 4]})\ndf2 = pd.DataFrame({'A': [5, 6], 'B': [7, 8]})\n\nvertical = pd.concat([df1, df2], ignore_index=True, axis=0)\nvertical\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n   A  B\n0  1  3\n1  2  4\n2  5  7\n3  6  8\n```\n\n\n:::\n\n```{.python .cell-code}\n# Horizontal concatenation (like cbind in R)\ndf3 = pd.DataFrame({'C': [9]})\nhorizontal = pd.concat([df1, df3], axis=1)\nhorizontal\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n   A  B    C\n0  1  3  9.0\n1  2  4  NaN\n```\n\n\n:::\n:::\n\n\n::: {.callout-tip title=\"Compared to R\"}\n\n::: {.cell}\n\n```{.r .cell-code}\n# R equivalents\nbind_rows(df1, df2)    # vertical\nbind_cols(df1, df3)    # horizontal\n```\n:::\n\n:::\n\n#### Chaining Joins\n\n\n\n::: {.cell}\n\n```{.python .cell-code}\n# Real-world scenario: combining customer, order, and product data\ncustomers = pd.DataFrame({\n    'customer_id': [1, 2, 3],\n    'customer_name': ['Alice', 'Bob', 'Charlie']\n})\n\norders = pd.DataFrame({\n    'order_id': [101, 102, 103],\n    'customer_id': [1, 2, 1],\n    'product_id': [1, 2, 3]\n})\n\nproducts = pd.DataFrame({\n    'product_id': [1, 2, 3],\n    'product_name': ['Laptop', 'Phone', 'Tablet'],\n    'price': [1000, 800, 500]\n})\n\n# Chain multiple joins\nresult = (orders\n    .merge(customers, on='customer_id', how='left')\n    .merge(products, on='product_id', how='left')\n    .assign(total = lambda x: x['price'])\n)\n\nresult\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n   order_id  customer_id  product_id customer_name product_name  price  total\n0       101            1           1         Alice       Laptop   1000   1000\n1       102            2           2           Bob        Phone    800    800\n2       103            1           3         Alice       Tablet    500    500\n```\n\n\n:::\n:::\n\n\n::: {.callout-tip title=\"Compared to R\"}\n\n::: {.cell}\n\n```{.r .cell-code}\n# R equivalent with pipe\nresult <- orders |>\n  left_join(customers, by = \"customer_id\") |>\n  left_join(products, by = \"product_id\") |>\n  mutate(total = price)\n```\n:::\n\n:::\n\n#### Join Summary Table\n\n| pandas | R dplyr | Description |\n|--------|---------|-------------|\n| `pd.merge(df1, df2, how='inner')` | `inner_join(df1, df2)` | Keep only matching rows |\n| `pd.merge(df1, df2, how='left')` | `left_join(df1, df2)` | Keep all rows from left |\n| `pd.merge(df1, df2, how='right')` | `right_join(df1, df2)` | Keep all rows from right |\n| `pd.merge(df1, df2, how='outer')` | `full_join(df1, df2)` | Keep all rows from both |\n| `pd.concat([df1, df2])` | `bind_rows(df1, df2)` | Stack vertically |\n| `pd.concat([df1, df2], axis=1)` | `bind_cols(df1, df2)` | Stack horizontally |\n\n### Key Differences between `pandas` and R\n\n- Indexing: `pandas` uses 0-based indexing\n- Missing values: `pandas` uses NaN (from NumPy), not NA\n- Syntax: Methods instead of functions (e.g., df.head() not head(df))\n\nThere is one important pitfall you need to pay attention to: `pandas` modifies in place unless you use `.copy()`!\n\n\n::: {.cell}\n\n```{.python .cell-code}\ndf = pd.DataFrame({'A': [1, 2, 3], 'B': [4, 5, 6]})\n\n# This creates a reference, NOT a copy\ndf2 = df\n\n# Modify df2\ndf2['A'] = [10, 20, 30]\n\n# Surprise! df is also changed\nprint(df)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n    A  B\n0  10  4\n1  20  5\n2  30  6\n```\n\n\n:::\n\n```{.python .cell-code}\n### FIX\ndf = pd.DataFrame({'A': [1, 2, 3], 'B': [4, 5, 6]})\n\n# This creates a copy, NOT a reference\ndf2 = df.copy()\n\n# Modify df2\ndf2['A'] = [10, 20, 30]\n\n# thank god! df did not change\nprint(df)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n   A  B\n0  1  4\n1  2  5\n2  3  6\n```\n\n\n:::\n\n```{.python .cell-code}\nprint(df2)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n    A  B\n0  10  4\n1  20  5\n2  30  6\n```\n\n\n:::\n:::\n\n\n## Exercises\n\nTake the `dplyr` exercises from Chapter 2 and perform them using pandas.\n\nOpen the IMDb file.\n\n\n::: {.cell}\n\n```{.python .cell-code}\nimdb = pd.read_csv(\"data/imdb2006-2016.csv\")\nimdb\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n     Rank                    Title  ... Revenue (Millions) Metascore\n0       1  Guardians of the Galaxy  ...             333.13      76.0\n1       2               Prometheus  ...             126.46      65.0\n2       3                    Split  ...             138.12      62.0\n3       4                     Sing  ...             270.32      59.0\n4       5            Suicide Squad  ...             325.02      40.0\n..    ...                      ...  ...                ...       ...\n995   996     Secret in Their Eyes  ...                NaN      45.0\n996   997          Hostel: Part II  ...              17.54      46.0\n997   998   Step Up 2: The Streets  ...              58.01      50.0\n998   999             Search Party  ...                NaN      22.0\n999  1000               Nine Lives  ...              19.64      11.0\n\n[1000 rows x 12 columns]\n```\n\n\n:::\n:::\n\n\n1.  Find the duplicated movie. How could you go across this?\n\n\n::: {.cell}\n\n```{.python .cell-code}\nduplicated_movie = (imdb['Title']\n    .value_counts()\n    .reset_index()\n    .sort_values('count', ascending=False)\n    .head(1)\n    )\nduplicated_movie\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n      Title  count\n0  The Host      2\n```\n\n\n:::\n\n```{.python .cell-code}\nprint(duplicated_movie[['Title']])\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n      Title\n0  The Host\n```\n\n\n:::\n:::\n\n\n2.  Which director has made the longest movie?\n\n\n::: {.cell}\n\n```{.python .cell-code}\nimdb.sort_values('Runtime (Minutes)', ascending=False).head(1)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n     Rank       Title  ... Revenue (Millions) Metascore\n828   829  Grindhouse  ...              25.03       NaN\n\n[1 rows x 12 columns]\n```\n\n\n:::\n:::\n\n\n3.  What's the highest ranked movie?\n\n\n::: {.cell}\n\n```{.python .cell-code}\nimdb.sort_values('Rank').head(1)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n   Rank                    Title  ... Revenue (Millions) Metascore\n0     1  Guardians of the Galaxy  ...             333.13      76.0\n\n[1 rows x 12 columns]\n```\n\n\n:::\n:::\n\n\n4.  Which movie got the most votes?\n\n\n::: {.cell}\n\n```{.python .cell-code}\nimdb.sort_values('Votes').head(1)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n     Rank           Title  Genre  ... Votes Revenue (Millions) Metascore\n478   479  Paint It Black  Drama  ...    61                NaN      71.0\n\n[1 rows x 12 columns]\n```\n\n\n:::\n:::\n\n\n5.  Which movie had the biggest revenue in 2016?\n\n\n::: {.cell}\n\n```{.python .cell-code}\nimdb.query('Year == 2016').sort_values('Revenue (Millions)', ascending=False).head(1)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n    Rank      Title  ... Revenue (Millions) Metascore\n12    13  Rogue One  ...             532.17      65.0\n\n[1 rows x 12 columns]\n```\n\n\n:::\n:::\n\n\n6.  How much revenue did the movies in the data set make each year in total?\n\n\n::: {.cell}\n\n```{.python .cell-code}\nimdb.groupby('Year')['Revenue (Millions)'].sum().reset_index()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n    Year  Revenue (Millions)\n0   2006             3624.46\n1   2007             4306.23\n2   2008             5053.22\n3   2009             5292.26\n4   2010             5989.65\n5   2011             5431.96\n6   2012             6910.29\n7   2013             7666.72\n8   2014             7997.40\n9   2015             8854.12\n10  2016            11211.65\n```\n\n\n:::\n:::\n\n\n7.  Filter movies following some conditions:\n    a.  More runtime than the average runtime (hint: you could also use `mutate()` before).\n    b.  Movies directed by J.J. Abrams.\n    c.  More votes than the median of all of the votes.\n    d.  The movies which have the most common value (the mode) in terms of rating (you can use `mode()` from the `pandas` package).\n\n\n::: {.cell}\n\n```{.python .cell-code}\n#a \nimdb.assign(avg_runtime = lambda x: x['Runtime (Minutes)'].mean()).assign(runtime = lambda x: x['Runtime (Minutes)']).query('runtime > avg_runtime')\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n     Rank                    Title  ... avg_runtime runtime\n0       1  Guardians of the Galaxy  ...     113.172     121\n1       2               Prometheus  ...     113.172     124\n2       3                    Split  ...     113.172     117\n4       5            Suicide Squad  ...     113.172     123\n6       7               La La Land  ...     113.172     128\n..    ...                      ...  ...         ...     ...\n979   980       The Skin I Live In  ...     113.172     120\n981   982                    Annie  ...     113.172     118\n982   983      Across the Universe  ...     113.172     133\n989   990                    Selma  ...     113.172     128\n991   992         Taare Zameen Par  ...     113.172     165\n\n[433 rows x 14 columns]\n```\n\n\n:::\n:::\n\n\n::: {.cell}\n\n```{.python .cell-code}\n#b\nimdb[imdb[\"Director\"] == \"J.J. Abrams\"]\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n     Rank  ... Metascore\n50     51  ...      81.0\n140   141  ...      82.0\n362   363  ...      72.0\n497   498  ...      72.0\n869   870  ...      66.0\n\n[5 rows x 12 columns]\n```\n\n\n:::\n:::\n\n\n\n::: {.cell}\n\n```{.python .cell-code}\n#a \nimdb.assign(median_votes = lambda x: x['Votes'].median()).query('Votes > median_votes')\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n     Rank                           Title  ... Metascore median_votes\n0       1         Guardians of the Galaxy  ...      76.0     110799.0\n1       2                      Prometheus  ...      65.0     110799.0\n2       3                           Split  ...      62.0     110799.0\n4       5                   Suicide Squad  ...      40.0     110799.0\n6       7                      La La Land  ...      93.0     110799.0\n..    ...                             ...  ...       ...          ...\n971   972                       Disturbia  ...       NaN     110799.0\n983   984                   Let's Be Cops  ...      30.0     110799.0\n990   991  Underworld: Rise of the Lycans  ...      44.0     110799.0\n993   994        Resident Evil: Afterlife  ...      37.0     110799.0\n994   995                       Project X  ...      48.0     110799.0\n\n[500 rows x 13 columns]\n```\n\n\n:::\n\n```{.python .cell-code}\n#or\nimdb.query('Votes > @imdb.Votes.median()')\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n     Rank                           Title  ... Revenue (Millions) Metascore\n0       1         Guardians of the Galaxy  ...             333.13      76.0\n1       2                      Prometheus  ...             126.46      65.0\n2       3                           Split  ...             138.12      62.0\n4       5                   Suicide Squad  ...             325.02      40.0\n6       7                      La La Land  ...             151.06      93.0\n..    ...                             ...  ...                ...       ...\n971   972                       Disturbia  ...              80.05       NaN\n983   984                   Let's Be Cops  ...              82.39      30.0\n990   991  Underworld: Rise of the Lycans  ...              45.80      44.0\n993   994        Resident Evil: Afterlife  ...              60.13      37.0\n994   995                       Project X  ...              54.72      48.0\n\n[500 rows x 12 columns]\n```\n\n\n:::\n:::\n\n\n::: {.cell}\n\n```{.python .cell-code}\nrating_mode = imdb['Rating'].mode()\nimdb[imdb['Rating'].isin(rating_mode)]\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n     Rank  ... Metascore\n8       9  ...      78.0\n32     33  ...      52.0\n39     40  ...       NaN\n48     49  ...      68.0\n71     72  ...      60.0\n75     76  ...      50.0\n93     94  ...      57.0\n134   135  ...      61.0\n139   140  ...      44.0\n212   213  ...      61.0\n221   222  ...      73.0\n226   227  ...      82.0\n248   249  ...      75.0\n259   260  ...      76.0\n276   277  ...      71.0\n282   283  ...       NaN\n294   295  ...      55.0\n298   299  ...      66.0\n352   353  ...      47.0\n378   379  ...      64.0\n385   386  ...      64.0\n402   403  ...       NaN\n435   436  ...       NaN\n436   437  ...      33.0\n446   447  ...      59.0\n497   498  ...      72.0\n513   514  ...      72.0\n515   516  ...      72.0\n543   544  ...       NaN\n551   552  ...      79.0\n554   555  ...      33.0\n556   557  ...      77.0\n571   572  ...      75.0\n572   573  ...      51.0\n592   593  ...      69.0\n664   665  ...      88.0\n689   690  ...      85.0\n702   703  ...      60.0\n706   707  ...       NaN\n721   722  ...      76.0\n737   738  ...      57.0\n807   808  ...      82.0\n842   843  ...      80.0\n843   844  ...      73.0\n853   854  ...      70.0\n863   864  ...      81.0\n892   893  ...      56.0\n894   895  ...      46.0\n895   896  ...      55.0\n896   897  ...       NaN\n929   930  ...       NaN\n988   989  ...      89.0\n\n[52 rows x 12 columns]\n```\n\n\n:::\n:::\n\n\n## Further Resources\n\n- A very helpful [R vs. `pandas` cheatsheet](https://github.com/meganzhou62/stat5702cc/blob/main/cheatsheet.pdf)\n- [Python for Data Analysis](https://wesmckinney.com/book/) by Wes McKinney (`pandas` creator)\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}