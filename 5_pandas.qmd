---
title: "Chapter 5: `pandas`"
published-title: pandas
engine: knitr
freeze: auto
bibliography: literature.bib
csl: ASA.csl
---

```{r}
#| include: false
reticulate::use_condaenv("toolbox_env", required = TRUE)
```

Now that you understand Python basics, let's look at `pandas` -- Python's most popular library for data manipulation. If you're familiar with R's tidyverse (especially `dplyr` and `tidyr`), `pandas` will feel conceptually familiar, though the syntax differs.

### What is Pandas?

`pandas` provides two main data structures:

- `Series`: Like an R vector or a single column
- `DataFrame`: Like an R tibble/data.frame

```{python}
import pandas as pd  # Standard convention: import pandas as pd -- equivalent to library(tidyverse)
import numpy as np   # NumPy often used alongside pandas

# Check version
pd.__version__
```

### Creating DataFrames

You can create DataFrames in several ways:

```{python}
# From a dictionary (like tibble() in R)
df_dic = pd.DataFrame({
    'name': ['Alice', 'Bob', 'Charlie', 'Diana'],
    'age': [25, 30, 35, 28],
    'city': ['New York', 'London', 'Paris', 'Tokyo']
})

df_dic

# from a list of dictionaries
data = [
    {'name': 'Alice', 'age': 25, 'city': 'New York'},
    {'name': 'Bob', 'age': 30, 'city': 'Paris'},
    {'name': 'Charlie', 'age': 35, 'city': 'London'}
]
df_dic_list = pd.DataFrame(data)

# from a list of lists (specify column names)
data = [
    ['Alice', 25, 'New York'],
    ['Bob', 30, 'Paris'],
    ['Charlie', 35, 'London']
]
df_list_of_lists = pd.DataFrame(data, columns=['name', 'age', 'city'])

# from a numpy array (essentially a matrix, specify column names)
data = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])
data
df_array = pd.DataFrame(data, columns=['A', 'B', 'C'])
```


::: {.callout-tip title="Compared to R"}
rdf <- tibble(
  name = c('Alice', 'Bob', 'Charlie', 'Diana'),
  age = c(25, 30, 35, 28),
  city = c('New York', 'London', 'Paris', 'Tokyo')
)
::: 

### Basic DataFrame Operations

`pandas` works through methods rather than functions. Methods are attached to specific object types. A string has string methods, a list has list methods, a DataFrame has DataFrame methods.

There are several differences:

- Functions are called by putting the object as an argument:
```{python}
# Function syntax: function(object, arguments)
my_list = [3, 1, 4, 1, 5]
len(my_list)        # len is a function
sorted(my_list)     # sorted is a function
```

- Methods are functions that "belong to" an object and are called using dot notation:
```{python}
# Method syntax: object.method(arguments)
my_string = "hello world"
my_string.upper()      # upper() is a method of strings
my_string.split()      # split() is a method of strings
my_string              # object remains unchanged

my_list.append(9)      # append() is a method of lists; note that this modifies the list in place
my_list
```


::: {.callout-tip title="Compared to R"}
R primarily uses functions - you write head(df), nrow(df), names(df). Python often uses methods - you write df.head(), df.shape, df.columns.
::: 

This matters for pandas, since almost everything is a method and hence the syntax differs significantly.

### `pandas` in action

Viewing Data (note that objects remain unchanged):

```{python}
df = pd.DataFrame({
    'name': ['Alice', 'Bob', 'Charlie', 'Diana'],
    'age': [25, 30, 35, 28],
    'city': ['New York', 'London', 'Paris', 'Tokyo']
})

# First few rows (like head() in R)
df.head(2)
# Last few rows (like tail() in R)
df.tail(2)
# Info about the DataFrame (like glimpse() or str() in R)
df.info()
# Summary statistics (like summary() in R)
df.describe()
```

Selecting Columns:
```{python}
# Select single column (returns a Series)
df['name']           # in R: df$name
# Select single column (returns a DataFrame)
df[['name']]         # in R: df |> select(name)
# Select multiple columns (returns a DataFrame)
df[['name', 'age']]  # in R: df |> select(name, age)
```


Filtering Rows:
```{python}
# Filter rows where age > 28
df[df['age'] > 28]
# Multiple conditions (use & for AND, | for OR)
df[(df['age'] > 25) & (df['city'] == 'London')]

# Filter something depending on its presence in another list using .isin() (R equivalent: %in%)
cities_ive_been_to = ["Paris", "New York", "London"]
df[df['city'].isin(cities_ive_been_to)]

# or using .query()
df.query('age > 25') #R: df |> filter(age > 25)
```


Adding New Columns:
```{python}
# Add a new column (like mutate() in R)
df['age_in_months'] = df['age'] * 12    # in R: df$age_in_months <- df$age * 12

df

# or using .assign()
df = df.assign(year_of_birth = lambda x: 2025-x['age'])
df
```

Sorting:
```{python}
# Sort by age (like arrange() in R)
df.sort_values('age')                    # in R: df |> arrange(age)
# Sort descending
df.sort_values('age', ascending=False)   # in R: df |> arrange(desc(age))
```

Read in Data:
```{python}
# Read CSV (like read_csv() in R)
imdb_df = pd.read_csv('data/imdb2006-2016.csv')
imdb_df.head()

# Read Excel
publishers_df = pd.read_excel('data/publishers_with_places.xlsx')
publishers_df.head()

# Read from URL
df_example = pd.read_csv('https://raw.githubusercontent.com/mwaskom/seaborn-data/master/tips.csv')
df_example.head()
```

Quick Data Exploration:
```{python}
# Shape (rows, columns)
df_example.shape                                  # in R: dim(df)
# Column names 
df_example.columns.tolist()                       # in R: colnames(df)
# Value counts
df_example['day'].value_counts()                  # in R: df |> count(day)

# Group by and aggregate (yields a Series)
df_example.groupby('day')['total_bill'].mean()    # in R: df |> group_by(day) |> summarize(mean_bill = mean(total_bill)) |> pull(mean_bill) |> set_names(day)
# Group by and aggregate (yields a DataFrame)
df_example.groupby('day')['total_bill'].mean().reset_index() # in R: df |> group_by(day) |> summarize(mean_bill = mean(total_bill))
```

### Method Chaining
`pandas` supports method chaining (similar to the pipe `|>`/`%>%` in R):
```{python}
# Chain multiple operations
result = (df_example
    .query('total_bill > 20')  # Filter
    .assign(tip_pct = lambda x: x['tip'] / x['total_bill'])  # New column
    .sort_values('tip_pct', ascending=False)  # Sort
    .head(5)  # Top 5
)

result
```

::: {.callout-tip title="Compared to R"}

```{r}
#| eval: false
result <- df_example |>
  filter(total_bill > 20) |>
  mutate(tip_pct = tip / total_bill) |>
  arrange(desc(tip_pct)) |>
  slice(5)
```

::: 

### Joining DataFrames

Joining (or merging) DataFrames is a fundamental operation in data analysis. `pandas` provides several ways to combine DataFrames, similar to SQL joins or R's `dplyr` join functions.

#### Basic Join Types
```{python}
# Create sample DataFrames
customers = pd.DataFrame({
    'customer_id': [1, 2, 3, 4],
    'name': ['Alice', 'Bob', 'Charlie', 'Diana'],
    'city': ['New York', 'London', 'Paris', 'Tokyo']
})

orders = pd.DataFrame({
    'order_id': [101, 102, 103, 104, 105],
    'customer_id': [1, 2, 2, 3, 5],
    'amount': [100, 150, 200, 75, 300]
})
```

#### Inner Join
Keep only rows that match in both DataFrames.
```{python}
# Inner join (default) - only matching rows
inner = pd.merge(customers, orders, on='customer_id', how='inner')
inner
```

::: {.callout-tip title="Compared to R"}
```{r}
#| eval: false
# R equivalent
inner_join(customers, orders, by = "customer_id")
```
:::

#### Left Join
Keep all rows from the left DataFrame, fill missing values with NaN.
```{python}
# Left join - all customers, even if no orders
left = pd.merge(customers, orders, on='customer_id', how='left')
left
```

::: {.callout-tip title="Compared to R"}
```{r}
#| eval: false
# R equivalent
left_join(customers, orders, by = "customer_id")
```
:::

#### Right Join
Keep all rows from the right DataFrame.
```{python}
# Right join - all orders, even if customer doesn't exist
right = pd.merge(customers, orders, on='customer_id', how='right')
print(right)
```

::: {.callout-tip title="Compared to R"}
```{r}
#| eval: false
# R equivalent
right_join(customers, orders, by = "customer_id")
```
:::

#### Outer Join
Keep all rows from both DataFrames.
```{python}
# Outer join - all customers and all orders
outer = pd.merge(customers, orders, on='customer_id', how='outer')
outer
```

::: {.callout-tip title="Compared to R"}
```{r}
#| eval: false
# R equivalent
full_join(customers, orders, by = "customer_id")
```
:::

#### Joining on Different Column Names
```{python}
# When join columns have different names
products = pd.DataFrame({
    'prod_id': [1, 2, 3],
    'product': ['Laptop', 'Phone', 'Tablet']
})

sales = pd.DataFrame({
    'product_id': [1, 1, 2, 3],
    'quantity': [5, 3, 8, 2]
})

# Specify left_on and right_on
merged = pd.merge(products, sales, 
                  left_on='prod_id', 
                  right_on='product_id', 
                  how='inner')
print(merged)

# Clean up: drop redundant column
merged = pd.merge(products, sales, 
                  left_on='prod_id', 
                  right_on='product_id', 
                  how='inner').drop('product_id', axis=1) #axis=0 would drop the row with id 'product_id' (doesn't exist)
merged
```

::: {.callout-tip title="Compared to R"}
```{r}
#| eval: false
# R equivalent
inner_join(products, sales, by = join_by("prod_id" == "product_id"))
```
:::

#### Joining on Multiple Columns
```{python}
# Join on multiple columns
df1 = pd.DataFrame({
    'year': [2020, 2020, 2021, 2021],
    'quarter': [1, 2, 1, 2],
    'revenue': [100, 120, 110, 130]
})

df2 = pd.DataFrame({
    'year': [2020, 2020, 2021],
    'quarter': [1, 2, 1],
    'costs': [80, 90, 85]
})

# Join on both year and quarter
merged = pd.merge(df1, df2, on=['year', 'quarter'], how='left')
merged
```

::: {.callout-tip title="Compared to R"}
```{r}
#| eval: false
# R equivalent
left_join(df1, df2, by = join_by("year", "quarter"))
```
:::

#### Handling Duplicate Column Names
```{python}
# When both DataFrames have columns with same names (besides join key)
df1 = pd.DataFrame({
    'id': [1, 2, 3],
    'value': [10, 20, 30]
})

df2 = pd.DataFrame({
    'id': [1, 2, 3],
    'value': [100, 200, 300]
})

# pandas adds suffixes to distinguish columns
merged = pd.merge(df1, df2, on='id', suffixes=('_left', '_right'))
merged
```

::: {.callout-tip title="Compared to R"}
```{r}
#| eval: false
# R equivalent (default suffixes are .x and .y)
inner_join(df1, df2, by = "id", suffix = c("_left", "_right"))
```
:::

#### Concatenating DataFrames (Stacking)

For simply stacking DataFrames vertically or horizontally without matching keys:
```{python}
# Vertical concatenation (like rbind in R)
df1 = pd.DataFrame({'A': [1, 2], 'B': [3, 4]})
df2 = pd.DataFrame({'A': [5, 6], 'B': [7, 8]})

vertical = pd.concat([df1, df2], ignore_index=True)
vertical

# Horizontal concatenation (like cbind in R)
df3 = pd.DataFrame({'C': [9]})
horizontal = pd.concat([df1, df3], axis=1)
horizontal
```

::: {.callout-tip title="Compared to R"}
```{r}
#| eval: false
# R equivalents
bind_rows(df1, df2)    # vertical
bind_cols(df1, df3)    # horizontal
```
:::

#### Chaining Joins

In pr
```{python}
# Real-world scenario: combining customer, order, and product data
customers = pd.DataFrame({
    'customer_id': [1, 2, 3],
    'customer_name': ['Alice', 'Bob', 'Charlie']
})

orders = pd.DataFrame({
    'order_id': [101, 102, 103],
    'customer_id': [1, 2, 1],
    'product_id': [1, 2, 3]
})

products = pd.DataFrame({
    'product_id': [1, 2, 3],
    'product_name': ['Laptop', 'Phone', 'Tablet'],
    'price': [1000, 800, 500]
})

# Chain multiple joins
result = (orders
    .merge(customers, on='customer_id', how='left')
    .merge(products, on='product_id', how='left')
    .assign(total = lambda x: x['price'])
)

result
```

::: {.callout-tip title="Compared to R"}
```{r}
#| eval: false
# R equivalent with pipe
result <- orders |>
  left_join(customers, by = "customer_id") |>
  left_join(products, by = "product_id") |>
  mutate(total = price)
```
:::

#### Join Summary Table

| pandas | R dplyr | Description |
|--------|---------|-------------|
| `pd.merge(df1, df2, how='inner')` | `inner_join(df1, df2)` | Keep only matching rows |
| `pd.merge(df1, df2, how='left')` | `left_join(df1, df2)` | Keep all rows from left |
| `pd.merge(df1, df2, how='right')` | `right_join(df1, df2)` | Keep all rows from right |
| `pd.merge(df1, df2, how='outer')` | `full_join(df1, df2)` | Keep all rows from both |
| `pd.concat([df1, df2])` | `bind_rows(df1, df2)` | Stack vertically |
| `pd.concat([df1, df2], axis=1)` | `bind_cols(df1, df2)` | Stack horizontally |

### Key Differences between `pandas` and R

- Indexing: `pandas` uses 0-based indexing
- Missing values: `pandas` uses NaN (from NumPy), not NA
- Syntax: Methods instead of functions (e.g., df.head() not head(df))

There is one important pitfall you need to pay attention to: `pandas` modifies in place unless you use `.copy()`!

```{python}
df = pd.DataFrame({'A': [1, 2, 3], 'B': [4, 5, 6]})

# This creates a reference, NOT a copy
df2 = df

# Modify df2
df2['A'] = [10, 20, 30]

# Surprise! df is also changed
print(df)

### FIX
df = pd.DataFrame({'A': [1, 2, 3], 'B': [4, 5, 6]})

# This creates a copy, NOT a reference
df2 = df.copy()

# Modify df2
df2['A'] = [10, 20, 30]

# thank god! df did not change
print(df)
print(df2)
```

## Exercises

Take the `dplyr` exercises from Chapter 2 and perform them using pandas.

## Further Resources

- A very helpful [R vs. `pandas` cheatsheet](https://github.com/meganzhou62/stat5702cc/blob/main/cheatsheet.pdf)
- [Python for Data Analysis](https://wesmckinney.com/book/) by Wes McKinney (`pandas` creator)